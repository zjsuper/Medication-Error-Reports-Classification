{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification & How To \"Frame Problems\" for a Neural Network\n",
    "\n",
    "by Andrew Trask\n",
    "\n",
    "- **Twitter**: @iamtrask\n",
    "- **Blog**: http://iamtrask.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What You Should Already Know\n",
    "\n",
    "- neural networks, forward and back-propagation\n",
    "- stochastic gradient descent\n",
    "- mean squared error\n",
    "- and train/test splits\n",
    "\n",
    "### Where to Get Help if You Need it\n",
    "- Re-watch previous Udacity Lectures\n",
    "- Leverage the recommended Course Reading Material - [Grokking Deep Learning](https://www.manning.com/books/grokking-deep-learning) (Check inside your classroom for a discount code)\n",
    "- Shoot me a tweet @iamtrask\n",
    "\n",
    "\n",
    "### Tutorial Outline:\n",
    "\n",
    "- Intro: The Importance of \"Framing a Problem\" (this lesson)\n",
    "\n",
    "\n",
    "- [Curate a Dataset](#lesson_1)\n",
    "- [Developing a \"Predictive Theory\"](#lesson_2)\n",
    "- [**PROJECT 1**: Quick Theory Validation](#project_1)\n",
    "\n",
    "\n",
    "- [Transforming Text to Numbers](#lesson_3)\n",
    "- [**PROJECT 2**: Creating the Input/Output Data](#project_2)\n",
    "\n",
    "\n",
    "- Putting it all together in a Neural Network (video only - nothing in notebook)\n",
    "- [**PROJECT 3**: Building our Neural Network](#project_3)\n",
    "\n",
    "\n",
    "- [Understanding Neural Noise](#lesson_4)\n",
    "- [**PROJECT 4**: Making Learning Faster by Reducing Noise](#project_4)\n",
    "\n",
    "\n",
    "- [Analyzing Inefficiencies in our Network](#lesson_5)\n",
    "- [**PROJECT 5**: Making our Network Train and Run Faster](#project_5)\n",
    "\n",
    "\n",
    "- [Further Noise Reduction](#lesson_6)\n",
    "- [**PROJECT 6**: Reducing Noise by Strategically Reducing the Vocabulary](#project_6)\n",
    "\n",
    "\n",
    "- [Analysis: What's going on in the weights?](#lesson_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "56bb3cba-260c-4ebe-9ed6-b995b4c72aa3"
    }
   },
   "source": [
    "# Lesson: Curate a Dataset<a id='lesson_1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "eba2b193-0419-431e-8db9-60f34dd3fe83"
    }
   },
   "outputs": [],
   "source": [
    "def pretty_print_review_and_label(i):\n",
    "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")\n",
    "\n",
    "g = open('reviews.txt','r',encoding='utf8') # What we know!\n",
    "reviews = list(map(lambda x:x[:-1],g.readlines()))\n",
    "g.close()\n",
    "\n",
    "g = open('labels.txt','r',encoding='utf8') # What we WANT to know!\n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The data in `reviews.txt` we're using has already been preprocessed a bit and contains only lower case characters. If we were working from raw data, where we didn't know it was all lower case, we would want to add a step here to convert it. That's so we treat different variations of the same word, like `The`, `the`, and `THE`, all the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "bb95574b-21a0-4213-ae50-34363cf4f87f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"email received by [redacted] from caregiver: so a patient called urgent care requesting a tetanus vaccination , as she was seen here and stated that her doctor , dr . [redacted] , states that she needs one . this nurse called dr . [redacted] office to inquire on the patient s statements and to receive verbal order via phone for tetanus vaccination . upon speaking with their staff member , [redacted] , she stated that the patient was supposed to receive it at the hospital under the order of dr . [redacted] . this order was not executed ( for reasons unknown to me ) , which is why the patient needed to follow up with urgent care for the shot . it was stated that dr . [redacted] understood the situation that the vaccine was not given in-house , however i m not comfortable keeping this information to myself because it involves a physician's order that has not been carried out . ultimately , verbal order was received by this nurse and the patient will be into urgent care 5-30-15 for her vaccination . if there s any other questions i need to answer , please let me know . thank you . [redacted] 6/2/15- documentation states the tetanus immunization was ordered on 5/21 at 1540 by dr . [redacted] . order was reviewed by [redacted] at 1606 . does not appear shot was given . \""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e0408810-c424-4ed4-afb9-1735e9ddbd0a"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADMINISTER/MONITOR'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Develop a Predictive Theory<a id='lesson_2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e67a709f-234f-4493-bae6-4fb192141ee0"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.txt \t : \t reviews.txt\n",
      "\n",
      "NOTADMINISTER/MONITOR\t:\tat 1715 patient stated had not received her breathing treatment . there was an o...\n",
      "ADMINISTER/MONITOR\t:\tpatient arrived from the or with multiple medications/pressors infusing at a wro...\n",
      "NOTADMINISTER/MONITOR\t:\tpt reports shortness of breath and anxious . pt states ,  my nebulizer treatment...\n",
      "NOTADMINISTER/MONITOR\t:\tswing bed pt received from [hospital] s/p tkr . sioc order set pulled and filled...\n",
      "NOTADMINISTER/MONITOR\t:\tmd who rarely operates at [redacted] ( and has not performed this surgery here i...\n",
      "NOTADMINISTER/MONITOR\t:\ton 06/23/15 , the pharmacy received an electronic prescription for warfarin 2mg ...\n"
     ]
    }
   ],
   "source": [
    "print(\"labels.txt \\t : \\t reviews.txt\\n\")\n",
    "pretty_print_review_and_label(22)\n",
    "pretty_print_review_and_label(33)\n",
    "pretty_print_review_and_label(44)\n",
    "pretty_print_review_and_label(55)\n",
    "pretty_print_review_and_label(213)\n",
    "pretty_print_review_and_label(499)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Quick Theory Validation<a id='project_1'></a>\n",
    "\n",
    "There are multiple ways to implement these projects, but in order to get your code closer to what Andrew shows in his solutions, we've provided some hints and starter code throughout this notebook.\n",
    "\n",
    "You'll find the [Counter](https://docs.python.org/2/library/collections.html#collections.Counter) class to be useful in this exercise, as well as the [numpy](https://docs.scipy.org/doc/numpy/reference/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create three `Counter` objects, one for words from postive reviews, one for words from negative reviews, and one for all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create three Counter objects to store positive, negative and total counts\n",
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Examine all the reviews. For each word in a positive review, increase the count for that word in both your positive counter and the total words counter; likewise, for each word in a negative review, increase the count for that word in both your negative counter and the total words counter.\n",
    "\n",
    "**Note:** Throughout these projects, you should use `split(' ')` to divide a piece of text (such as a review) into individual words. If you use `split()` instead, you'll get slightly different results than what the videos and solutions show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop over all the words in all the reviews and increment the counts in the appropriate counter objects\n",
    "for i in range(len(reviews)):\n",
    "    if(labels[i] == 'ADMINISTER/MONITOR'):\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            positive_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "    else:\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following two cells to list the words used in positive reviews and negative reviews, respectively, ordered from most to least commonly used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 1079),\n",
       " ('', 810),\n",
       " ('the', 781),\n",
       " ('was', 498),\n",
       " ('to', 473),\n",
       " ('and', 433),\n",
       " (',', 330),\n",
       " ('at', 257),\n",
       " ('of', 242),\n",
       " ('patient', 212),\n",
       " ('that', 204),\n",
       " ('pt', 199),\n",
       " ('on', 194),\n",
       " ('in', 179),\n",
       " ('not', 168),\n",
       " ('for', 158),\n",
       " ('given', 148),\n",
       " ('i', 148),\n",
       " ('with', 145),\n",
       " ('a', 138),\n",
       " ('nurse', 136),\n",
       " ('it', 132),\n",
       " ('had', 120),\n",
       " ('she', 94),\n",
       " ('this', 93),\n",
       " ('dose', 85),\n",
       " ('as', 84),\n",
       " ('medication', 81),\n",
       " ('by', 77),\n",
       " ('be', 76),\n",
       " ('ordered', 76),\n",
       " ('[redacted]', 75),\n",
       " ('is', 75),\n",
       " ('from', 73),\n",
       " ('when', 72),\n",
       " ('iv', 71),\n",
       " ('dr', 69),\n",
       " ('med', 68),\n",
       " ('order', 64),\n",
       " ('pump', 63),\n",
       " ('rn', 62),\n",
       " ('been', 57),\n",
       " ('were', 54),\n",
       " ('have', 53),\n",
       " ('drip', 52),\n",
       " ('no', 50),\n",
       " ('but', 47),\n",
       " ('1', 45),\n",
       " ('heparin', 45),\n",
       " ('did', 45),\n",
       " ('received', 44),\n",
       " ('notified', 44),\n",
       " (')', 43),\n",
       " ('after', 43),\n",
       " ('stated', 42),\n",
       " ('her', 42),\n",
       " ('(', 41),\n",
       " ('called', 39),\n",
       " ('or', 39),\n",
       " ('per', 38),\n",
       " ('mg', 37),\n",
       " ('orders', 37),\n",
       " ('up', 36),\n",
       " ('should', 36),\n",
       " ('bag', 35),\n",
       " ('then', 34),\n",
       " ('there', 32),\n",
       " ('only', 32),\n",
       " ('give', 32),\n",
       " ('time', 31),\n",
       " ('0', 30),\n",
       " ('one', 29),\n",
       " ('report', 29),\n",
       " ('2', 29),\n",
       " ('weight', 29),\n",
       " ('if', 28),\n",
       " ('he', 28),\n",
       " ('started', 28),\n",
       " ('gave', 28),\n",
       " ('would', 28),\n",
       " ('doctor', 27),\n",
       " ('mar', 27),\n",
       " ('error', 27),\n",
       " ('due', 27),\n",
       " ('infusion', 27),\n",
       " ('day', 26),\n",
       " ('meds', 26),\n",
       " ('protocol', 26),\n",
       " ('which', 25),\n",
       " ('charted', 25),\n",
       " ('shift', 25),\n",
       " ('morphine', 25),\n",
       " ('instead', 25),\n",
       " ('rate', 25),\n",
       " ('an', 25),\n",
       " ('so', 23),\n",
       " ('states', 23),\n",
       " ('pain', 23),\n",
       " ('fluids', 23),\n",
       " ('new', 23),\n",
       " ('3', 22),\n",
       " ('said', 22),\n",
       " ('over', 22),\n",
       " ('found', 22),\n",
       " ('night', 22),\n",
       " ('administered', 22),\n",
       " ('gtt', 22),\n",
       " ('into', 21),\n",
       " ('icu', 21),\n",
       " ('medications', 21),\n",
       " ('noted', 21),\n",
       " ('infusing', 21),\n",
       " ('pharmacy', 21),\n",
       " ('hours', 21),\n",
       " ('told', 21),\n",
       " ('went', 21),\n",
       " ('insulin', 21),\n",
       " ('out', 20),\n",
       " ('er', 20),\n",
       " ('md', 20),\n",
       " ('noticed', 20),\n",
       " ('also', 20),\n",
       " ('room', 20),\n",
       " ('who', 20),\n",
       " ('am', 19),\n",
       " ('bolus', 19),\n",
       " ('removed', 19),\n",
       " ('about', 19),\n",
       " ('receive', 18),\n",
       " ('me', 18),\n",
       " ('has', 18),\n",
       " ('will', 18),\n",
       " ('informed', 18),\n",
       " ('physician', 18),\n",
       " ('back', 18),\n",
       " ('hour', 18),\n",
       " ('blood', 18),\n",
       " ('po', 18),\n",
       " (\"patient's\", 18),\n",
       " ('my', 18),\n",
       " ('documented', 18),\n",
       " ('antibiotic', 18),\n",
       " ('pca', 18),\n",
       " ('came', 17),\n",
       " ('running', 17),\n",
       " ('patients', 17),\n",
       " ('scheduled', 17),\n",
       " (\"pt's\", 17),\n",
       " ('off', 17),\n",
       " ('5mg', 17),\n",
       " ('get', 16),\n",
       " ('morning', 16),\n",
       " ('hung', 16),\n",
       " ('missed', 16),\n",
       " ('floor', 16),\n",
       " ('while', 16),\n",
       " ('administration', 16),\n",
       " ('hanging', 16),\n",
       " ('his', 16),\n",
       " ('we', 16),\n",
       " ('until', 16),\n",
       " ('left', 16),\n",
       " ('what', 15),\n",
       " ('scanned', 15),\n",
       " ('pyxis', 15),\n",
       " ('another', 15),\n",
       " ('pharmacist', 15),\n",
       " ('prn', 15),\n",
       " ('5', 15),\n",
       " ('any', 14),\n",
       " ('tab', 14),\n",
       " ('all', 14),\n",
       " ('vial', 14),\n",
       " ('ed', 14),\n",
       " ('they', 14),\n",
       " ('care', 13),\n",
       " ('charge', 13),\n",
       " ('reported', 13),\n",
       " ('infused', 13),\n",
       " ('4', 13),\n",
       " ('units', 13),\n",
       " ('realized', 13),\n",
       " ('already', 13),\n",
       " ('bp', 13),\n",
       " ('being', 13),\n",
       " ('ivp', 13),\n",
       " ('during', 13),\n",
       " ('change', 13),\n",
       " ('upon', 12),\n",
       " ('staff', 12),\n",
       " ('because', 12),\n",
       " ('doses', 12),\n",
       " (\"didn't\", 12),\n",
       " ('2mg', 12),\n",
       " ('discontinued', 12),\n",
       " ('still', 12),\n",
       " ('never', 12),\n",
       " ('call', 12),\n",
       " ('2100', 12),\n",
       " ('every', 12),\n",
       " ('situation', 11),\n",
       " ('information', 11),\n",
       " ('later', 11),\n",
       " ('1700', 11),\n",
       " ('two', 11),\n",
       " ('next', 11),\n",
       " ('now', 11),\n",
       " ('available', 11),\n",
       " ('prior', 11),\n",
       " ('made', 11),\n",
       " ('10', 11),\n",
       " ('happened', 11),\n",
       " ('emar', 11),\n",
       " ('again', 11),\n",
       " ('wrong', 11),\n",
       " ('minutes', 11),\n",
       " ('7', 11),\n",
       " ('ns', 11),\n",
       " ('monitor', 11),\n",
       " ('before', 11),\n",
       " ('could', 11),\n",
       " ('bs', 11),\n",
       " ('vaccine', 10),\n",
       " ('verify', 10),\n",
       " ('aware', 10),\n",
       " ('put', 10),\n",
       " ('correct', 10),\n",
       " ('times', 10),\n",
       " ('previous', 10),\n",
       " ('last', 10),\n",
       " ('changed', 10),\n",
       " ('discovered', 10),\n",
       " ('start', 10),\n",
       " ('spoke', 10),\n",
       " ('increased', 10),\n",
       " ('down', 10),\n",
       " ('however', 9),\n",
       " ('1mg', 9),\n",
       " ('same', 9),\n",
       " ('asked', 9),\n",
       " ('hr', 9),\n",
       " ('saline', 9),\n",
       " ('checked', 9),\n",
       " ('half', 9),\n",
       " ('pill', 9),\n",
       " ('looked', 9),\n",
       " ('see', 9),\n",
       " ('6', 9),\n",
       " ('right', 9),\n",
       " ('chart', 9),\n",
       " ('unit', 9),\n",
       " ('50', 9),\n",
       " ('event', 9),\n",
       " ('xxxx', 9),\n",
       " ('&', 9),\n",
       " ('nursing', 9),\n",
       " ('ivpb', 9),\n",
       " ('check', 9),\n",
       " ('antixa', 9),\n",
       " ('home', 9),\n",
       " ('needed', 8),\n",
       " ('need', 8),\n",
       " ('documentation', 8),\n",
       " ('surgery', 8),\n",
       " ('x', 8),\n",
       " ('bottle', 8),\n",
       " ('read', 8),\n",
       " ('done', 8),\n",
       " ('im', 8),\n",
       " ('very', 8),\n",
       " ('ml', 8),\n",
       " ('pulled', 8),\n",
       " ('fluid', 8),\n",
       " ('brought', 8),\n",
       " ('going', 8),\n",
       " ('line', 8),\n",
       " ('around', 8),\n",
       " ('entered', 8),\n",
       " ('both', 8),\n",
       " ('once', 8),\n",
       " ('arrived', 8),\n",
       " ('levophed', 8),\n",
       " ('15', 8),\n",
       " ('set', 8),\n",
       " ('10mg', 8),\n",
       " ('thought', 8),\n",
       " ('continue', 8),\n",
       " ('do', 8),\n",
       " ('transferred', 8),\n",
       " ('use', 8),\n",
       " ('.(', 8),\n",
       " ('initial', 8),\n",
       " ('mcg', 8),\n",
       " ('office', 7),\n",
       " ('follow', 7),\n",
       " ('other', 7),\n",
       " ('does', 7),\n",
       " ('0800', 7),\n",
       " (\"wasn't\", 7),\n",
       " ('level', 7),\n",
       " ('lpn', 7),\n",
       " ('transfer', 7),\n",
       " ('ptt', 7),\n",
       " ('normal', 7),\n",
       " ('mistake', 7),\n",
       " ('witnessed', 7),\n",
       " ('4mg', 7),\n",
       " ('got', 7),\n",
       " ('well', 7),\n",
       " ('@', 7),\n",
       " ('24', 7),\n",
       " ('take', 7),\n",
       " ('further', 7),\n",
       " ('pumps', 7),\n",
       " ('are', 7),\n",
       " ('alert', 7),\n",
       " ('count', 7),\n",
       " ('verified', 7),\n",
       " ('lovenox', 7),\n",
       " ('adverse', 7),\n",
       " ('since', 7),\n",
       " ('drug', 7),\n",
       " ('1/2', 7),\n",
       " ('lasix', 7),\n",
       " ('total', 7),\n",
       " ('solumedrol', 7),\n",
       " ('levaquin', 7),\n",
       " ('admitted', 7),\n",
       " ('just', 7),\n",
       " ('protonix', 7),\n",
       " ('continuous', 7),\n",
       " ('site', 7),\n",
       " ('listed', 7),\n",
       " ('tubing', 7),\n",
       " ('procedure', 7),\n",
       " ('having', 7),\n",
       " ('hospital', 6),\n",
       " ('why', 6),\n",
       " ('how', 6),\n",
       " ('dosing', 6),\n",
       " ('75', 6),\n",
       " ('ebox', 6),\n",
       " ('writer', 6),\n",
       " ('second', 6),\n",
       " ('pass', 6),\n",
       " ('primary', 6),\n",
       " ('through', 6),\n",
       " ('taken', 6),\n",
       " ('along', 6),\n",
       " ('-', 6),\n",
       " ('today', 6),\n",
       " ('approx', 6),\n",
       " ('programmed', 6),\n",
       " ('following', 6),\n",
       " ('potassium', 6),\n",
       " ('dosage', 6),\n",
       " ('oriented', 6),\n",
       " ('tabs', 6),\n",
       " ('low', 6),\n",
       " ('current', 6),\n",
       " ('#1', 6),\n",
       " ('discharged', 6),\n",
       " ('bedside', 6),\n",
       " ('first', 6),\n",
       " ('cut', 6),\n",
       " ('ativan', 6),\n",
       " ('allergy', 6),\n",
       " ('vitals', 6),\n",
       " ('tech', 6),\n",
       " ('different', 6),\n",
       " ('route', 6),\n",
       " ('three', 6),\n",
       " ('him', 6),\n",
       " ('6500', 6),\n",
       " ('note', 6),\n",
       " ('immediately', 6),\n",
       " ('than', 6),\n",
       " ('recieved', 6),\n",
       " ('pressure', 6),\n",
       " ('stable', 6),\n",
       " ('klonopin', 6),\n",
       " ('seen', 5),\n",
       " ('needs', 5),\n",
       " ('unknown', 5),\n",
       " ('sure', 5),\n",
       " ('2300', 5),\n",
       " ('according', 5),\n",
       " ('guardian', 5),\n",
       " ('drawn', 5),\n",
       " ('wasted', 5),\n",
       " ('actually', 5),\n",
       " ('effects', 5),\n",
       " ('emergency', 5),\n",
       " ('showed', 5),\n",
       " ('0930', 5),\n",
       " ('drawer', 5),\n",
       " ('decrease', 5),\n",
       " ('surgeon', 5),\n",
       " ('scan', 5),\n",
       " ('waste', 5),\n",
       " ('corrected', 5),\n",
       " ('decreased', 5),\n",
       " ('1800', 5),\n",
       " ('administer', 5),\n",
       " ('tramadol', 5),\n",
       " ('daily', 5),\n",
       " ('wanted', 5),\n",
       " ('20mg', 5),\n",
       " ('want', 5),\n",
       " ('monitored', 5),\n",
       " ('glucose', 5),\n",
       " ('unable', 5),\n",
       " ('incorrect', 5),\n",
       " ('rocephin', 5),\n",
       " ('30', 5),\n",
       " ('12', 5),\n",
       " ('0900', 5),\n",
       " ('80mg', 5),\n",
       " ('go', 5),\n",
       " ('more', 5),\n",
       " ('requested', 5),\n",
       " ('infuse', 5),\n",
       " ('notice', 5),\n",
       " ('patch', 5),\n",
       " ('anesthesia', 5),\n",
       " ('forgot', 5),\n",
       " ('review', 5),\n",
       " ('full', 5),\n",
       " ('2200', 5),\n",
       " ('sliding', 5),\n",
       " ('scale', 5),\n",
       " ('some', 5),\n",
       " ('explained', 5),\n",
       " ('continued', 5),\n",
       " ('rash', 5),\n",
       " ('related', 5),\n",
       " ('occurred', 5),\n",
       " ('proper', 5),\n",
       " ('stopped', 5),\n",
       " ('appears', 5),\n",
       " ('much', 5),\n",
       " ('policy', 5),\n",
       " ('incident', 5),\n",
       " ('units/kg/hr', 5),\n",
       " ('anti', 5),\n",
       " ('restart', 5),\n",
       " ('manager', 5),\n",
       " ('clinic', 5),\n",
       " ('injections', 5),\n",
       " ('antibiotics', 5),\n",
       " ('vs', 5),\n",
       " ('remained', 5),\n",
       " ('became', 5),\n",
       " ('cath', 5),\n",
       " ('syringe', 5),\n",
       " ('8', 5),\n",
       " ('them', 5),\n",
       " ('parameters', 5),\n",
       " ('fentanyl', 5),\n",
       " ('percocet', 5),\n",
       " ('urgent', 4),\n",
       " ('here', 4),\n",
       " ('s', 4),\n",
       " ('verbal', 4),\n",
       " ('via', 4),\n",
       " ('speaking', 4),\n",
       " ('their', 4),\n",
       " ('supposed', 4),\n",
       " ('you', 4),\n",
       " ('reviewed', 4),\n",
       " ('heart', 4),\n",
       " ('0700', 4),\n",
       " ('evening', 4),\n",
       " ('end', 4),\n",
       " ('make', 4),\n",
       " ('twice', 4),\n",
       " ('passed', 4),\n",
       " ('13', 4),\n",
       " ('ml/hr', 4),\n",
       " ('pt/inr', 4),\n",
       " ('9', 4),\n",
       " ('secondary', 4),\n",
       " ('receiving', 4),\n",
       " ('harm', 4),\n",
       " ('whom', 4),\n",
       " ('arm', 4),\n",
       " ('kept', 4),\n",
       " ('knew', 4),\n",
       " ('checking', 4),\n",
       " ('sugar', 4),\n",
       " ('k+', 4),\n",
       " ('pole', 4),\n",
       " ('can', 4),\n",
       " ('preop', 4),\n",
       " ('attempted', 4),\n",
       " ('1230', 4),\n",
       " ('ivig', 4),\n",
       " ('inform', 4),\n",
       " ('either', 4),\n",
       " ('few', 4),\n",
       " ('incorrectly', 4),\n",
       " ('based', 4),\n",
       " ('warfarin', 4),\n",
       " ('long', 4),\n",
       " ('system', 4),\n",
       " ('placed', 4),\n",
       " ('visit', 4),\n",
       " ('port', 4),\n",
       " ('eye', 4),\n",
       " ('dropped', 4),\n",
       " ('written', 4),\n",
       " ('taking', 4),\n",
       " ('plavix', 4),\n",
       " ('cap', 4),\n",
       " ('refused', 4),\n",
       " ('confirmed', 4),\n",
       " ('double', 4),\n",
       " ('1500', 4),\n",
       " ('6/19', 4),\n",
       " ('labeled', 4),\n",
       " ('appropriate', 4),\n",
       " ('nor', 4),\n",
       " ('old', 4),\n",
       " ('took', 4),\n",
       " ('d5w', 4),\n",
       " ('flush', 4),\n",
       " ('100mg', 4),\n",
       " ('40', 4),\n",
       " ('pts', 4),\n",
       " ('east', 4),\n",
       " ('anything', 4),\n",
       " ('come', 4),\n",
       " ('obtained', 4),\n",
       " ('cardiac', 4),\n",
       " ('dye', 4),\n",
       " ('definity', 4),\n",
       " ('giving', 4),\n",
       " ('within', 4),\n",
       " ('issues', 4),\n",
       " ('anti-xa', 4),\n",
       " ('connected', 4),\n",
       " ('reflect', 4),\n",
       " ('>1', 4),\n",
       " ('restarted', 4),\n",
       " ('5712', 4),\n",
       " ('felt', 4),\n",
       " ('regarding', 4),\n",
       " ('16', 4),\n",
       " ('ask', 4),\n",
       " ('xa', 4),\n",
       " ('each', 4),\n",
       " ('concentration', 4),\n",
       " ('clarify', 4),\n",
       " ('1900', 4),\n",
       " ('used', 4),\n",
       " ('nothing', 4),\n",
       " ('help', 4),\n",
       " ('pneumonia', 4),\n",
       " ('present', 4),\n",
       " ('wrist', 4),\n",
       " ('run', 4),\n",
       " ('1ml/hr', 4),\n",
       " ('arrival', 4),\n",
       " ('higher', 4),\n",
       " ('admin', 4),\n",
       " ('settings', 4),\n",
       " ('20', 4),\n",
       " ('oral', 4),\n",
       " ('mom', 4),\n",
       " ('liquid', 4),\n",
       " ('conjugate', 4),\n",
       " ('component', 4),\n",
       " ('aprn', 4),\n",
       " ('yyyy', 4),\n",
       " ('determined', 4),\n",
       " ('several', 4),\n",
       " ('lispro', 4),\n",
       " ('like', 4),\n",
       " ('ran', 4),\n",
       " ('tpn', 4),\n",
       " ('trying', 4),\n",
       " ('diprivan', 4),\n",
       " ('period', 4),\n",
       " ('narcan', 4),\n",
       " ('dilaudid', 4),\n",
       " ('tetanus', 3),\n",
       " ('vaccination', 3),\n",
       " ('phone', 3),\n",
       " ('member', 3),\n",
       " ('under', 3),\n",
       " ('shot', 3),\n",
       " ('myself', 3),\n",
       " ('know', 3),\n",
       " ('task', 3),\n",
       " ('meant', 3),\n",
       " ('gotten', 3),\n",
       " ('knowing', 3),\n",
       " ('bupropion', 3),\n",
       " ('sr', 3),\n",
       " ('contacted', 3),\n",
       " ('concerns', 3),\n",
       " ('0730', 3),\n",
       " ('chest', 3),\n",
       " ('thinking', 3),\n",
       " ('soon', 3),\n",
       " ('best', 3),\n",
       " ('side', 3),\n",
       " ('pitocin', 3),\n",
       " ('quickmar', 3),\n",
       " ('yet', 3),\n",
       " ('think', 3),\n",
       " ('where', 3),\n",
       " ('future', 3),\n",
       " ('controlled', 3),\n",
       " ('40mg', 3),\n",
       " ('metformin', 3),\n",
       " ('record', 3),\n",
       " ('gm', 3),\n",
       " ('7/22/15', 3),\n",
       " ('questioned', 3),\n",
       " ('delay', 3),\n",
       " ('dopamine', 3),\n",
       " ('zofran', 3),\n",
       " ('0630', 3),\n",
       " ('ancef', 3),\n",
       " ('suppose', 3),\n",
       " ('early', 3),\n",
       " ('held', 3),\n",
       " ('cta', 3),\n",
       " ('attention', 3),\n",
       " ('multiple', 3),\n",
       " ('recieving', 3),\n",
       " ('kg', 3),\n",
       " ('k', 3),\n",
       " ('assumed', 3),\n",
       " ('discrepancy', 3),\n",
       " ('followed', 3),\n",
       " ('1600', 3),\n",
       " ('days', 3),\n",
       " ('concern', 3),\n",
       " ('risk', 3),\n",
       " ('1330', 3),\n",
       " ('adjusted', 3),\n",
       " ('access', 3),\n",
       " ('close', 3),\n",
       " ('cause', 3),\n",
       " ('drops', 3),\n",
       " ('arrive', 3),\n",
       " ('admission', 3),\n",
       " ('without', 3),\n",
       " ('initially', 3),\n",
       " ('500mg', 3),\n",
       " ('ambien', 3),\n",
       " ('busy', 3),\n",
       " ('.5mg', 3),\n",
       " ('accidentally', 3),\n",
       " ('hs', 3),\n",
       " ('talked', 3),\n",
       " ('lorazepam', 3),\n",
       " ('15mg', 3),\n",
       " ('q', 3),\n",
       " ('administering', 3),\n",
       " ('zosyn', 3),\n",
       " ('timed', 3),\n",
       " ('misread', 3),\n",
       " ('empty', 3),\n",
       " ('1300', 3),\n",
       " ('kvo', 3),\n",
       " ('zyrtec', 3),\n",
       " ('prbc', 3),\n",
       " ('baseline', 3),\n",
       " ('stating', 3),\n",
       " ('meq', 3),\n",
       " ('kcl', 3),\n",
       " ('ms', 3),\n",
       " ('communication', 3),\n",
       " ('assess', 3),\n",
       " ('applied', 3),\n",
       " ('inpatient', 3),\n",
       " ('son', 3),\n",
       " ('cm', 3),\n",
       " ('getting', 3),\n",
       " ('daughter', 3),\n",
       " ('probably', 3),\n",
       " ('explain', 3),\n",
       " ('decided', 3),\n",
       " ('tl', 3),\n",
       " ('chamber', 3),\n",
       " ('injection', 3),\n",
       " ('including', 3),\n",
       " ('most', 3),\n",
       " ('separate', 3),\n",
       " ('properly', 3),\n",
       " ('able', 3),\n",
       " ('18units/kg/hr', 3),\n",
       " ('15units/kg/hr', 3),\n",
       " ('14units/kg/hr', 3),\n",
       " ('bronchoscopy', 3),\n",
       " ('sodium', 3),\n",
       " ('3%', 3),\n",
       " ('hypertonic', 3),\n",
       " ('cerner', 3),\n",
       " ('nurses', 3),\n",
       " ('issue', 3),\n",
       " ('anesthesiologist', 3),\n",
       " ('paperwork', 3),\n",
       " ('height', 3),\n",
       " ('activity', 3),\n",
       " ('hep', 3),\n",
       " ('unclear', 3),\n",
       " ('vials', 3),\n",
       " (\".'s\", 3),\n",
       " ('verifying', 3),\n",
       " ('expiration', 3),\n",
       " ('way', 3),\n",
       " ('turned', 3),\n",
       " ('catheter', 3),\n",
       " ('shows', 3),\n",
       " ('apparent', 3),\n",
       " ('intensivist', 3),\n",
       " ('discontinuation', 3),\n",
       " ('response', 3),\n",
       " ('ct', 3),\n",
       " ('05ml', 3),\n",
       " ('regular', 3),\n",
       " ('reaction', 3),\n",
       " ('mg/min', 3),\n",
       " ('afib', 3),\n",
       " ('rather', 3),\n",
       " ('notify', 3),\n",
       " ('previously', 3),\n",
       " ('list', 3),\n",
       " ('hospitalist', 3),\n",
       " ('status', 3),\n",
       " ('49', 3),\n",
       " ('versed', 3),\n",
       " ('lower', 3),\n",
       " ('window', 3),\n",
       " ('cc', 3),\n",
       " ('2nd', 3),\n",
       " ('our', 3),\n",
       " ('11mg', 3),\n",
       " ('instructed', 3),\n",
       " ('interval', 3),\n",
       " ('between', 3),\n",
       " ('setting', 3),\n",
       " ('therefore', 3),\n",
       " ('1224', 3),\n",
       " ('high', 3),\n",
       " ('week', 3),\n",
       " ('8cc/hr', 3),\n",
       " ('area', 3),\n",
       " ('student', 3),\n",
       " ('patches', 3),\n",
       " ('remove', 3),\n",
       " ('min', 3),\n",
       " ('attached', 3),\n",
       " ('100', 3),\n",
       " ('2348', 3),\n",
       " ('prescribed', 3),\n",
       " ('notifed', 3),\n",
       " ('5/325', 3),\n",
       " ('oxyir', 3),\n",
       " ('vital', 3),\n",
       " ('signs', 3),\n",
       " ('rns', 3),\n",
       " ('levothyroxine', 3),\n",
       " ('gi', 3),\n",
       " ('vistaril', 3),\n",
       " ('precedex', 3),\n",
       " ('understood', 2),\n",
       " (\"physician's\", 2),\n",
       " ('carried', 2),\n",
       " ('ultimately', 2),\n",
       " ('questions', 2),\n",
       " ('immunization', 2),\n",
       " ('appear', 2),\n",
       " ('vanco', 2),\n",
       " ('find', 2),\n",
       " ('really', 2),\n",
       " ('teh', 2),\n",
       " ('regardless', 2),\n",
       " ('id', 2),\n",
       " ('evaluate', 2),\n",
       " ('b/c', 2),\n",
       " ('doing', 2),\n",
       " ('label', 2),\n",
       " ('okay', 2),\n",
       " ('necessary', 2),\n",
       " ('ekg', 2),\n",
       " ('revealed', 2),\n",
       " ('.6', 2),\n",
       " ('26', 2),\n",
       " ('entire', 2),\n",
       " ('control', 2),\n",
       " ('.8', 2),\n",
       " ('immediatley', 2),\n",
       " ('caught', 2),\n",
       " ('hospitalized', 2),\n",
       " ('abd', 2),\n",
       " ('nauseated', 2),\n",
       " ('lr', 2),\n",
       " ('approximately', 2),\n",
       " ('causing', 2),\n",
       " ('temporary', 2),\n",
       " ('showing', 2),\n",
       " ('cart', 2),\n",
       " ('signed', 2),\n",
       " ('narc', 2),\n",
       " ('witness', 2),\n",
       " ('1000mg', 2),\n",
       " ('0653', 2),\n",
       " ('saw', 2),\n",
       " ('naproxen', 2),\n",
       " ('prilosec', 2),\n",
       " ('forgotten', 2),\n",
       " ('kaexalate', 2),\n",
       " ('7/23/15', 2),\n",
       " ('labs', 2),\n",
       " ('levels', 2),\n",
       " ('failed', 2),\n",
       " ('femoral', 2),\n",
       " ('b/p', 2),\n",
       " ('bathroom', 2),\n",
       " ('1840', 2),\n",
       " ('hooked', 2),\n",
       " ('inadvertently', 2),\n",
       " ('penicillin', 2),\n",
       " ('sdcu', 2),\n",
       " ('investigation', 2),\n",
       " ('10gm', 2),\n",
       " ('pod', 2),\n",
       " ('contrast', 2),\n",
       " ('0745', 2),\n",
       " ('g', 2),\n",
       " ('caring', 2),\n",
       " ('brough', 2),\n",
       " ('amount', 2),\n",
       " ('these', 2),\n",
       " ('significantly', 2),\n",
       " ('weighed', 2),\n",
       " ('4/23/15', 2),\n",
       " ('overnight', 2),\n",
       " ('resolved', 2),\n",
       " ('schedule', 2),\n",
       " ('correctly', 2),\n",
       " ('benefit', 2),\n",
       " ('omeprazole', 2),\n",
       " ('benadryl', 2),\n",
       " ('pa', 2),\n",
       " ('return', 2),\n",
       " ('charges', 2),\n",
       " ('meclizine', 2),\n",
       " ('dispensed', 2),\n",
       " ('31', 2),\n",
       " ('inserted', 2),\n",
       " ('g-tube', 2),\n",
       " ('bulb', 2),\n",
       " ('recognized', 2),\n",
       " ('possibly', 2),\n",
       " ('tube', 2),\n",
       " ('opened', 2),\n",
       " ('name', 2),\n",
       " ('drop', 2),\n",
       " (',000', 2),\n",
       " ('45', 2),\n",
       " ('250mg', 2),\n",
       " ('qam', 2),\n",
       " ('tablet', 2),\n",
       " ('remembered', 2),\n",
       " ('imdur', 2),\n",
       " ('60mg', 2),\n",
       " ('20meq', 2),\n",
       " ('adn', 2),\n",
       " ('ahead', 2),\n",
       " ('50mg', 2),\n",
       " ('trazodone', 2),\n",
       " ('feeling', 2),\n",
       " ('anxiety', 2),\n",
       " ('bedtime', 2),\n",
       " ('.25mg', 2),\n",
       " ('noon', 2),\n",
       " ('continuously', 2),\n",
       " ('confusion', 2),\n",
       " ('6/20', 2),\n",
       " ('bottles', 2),\n",
       " ('exactly', 2),\n",
       " ('.25', 2),\n",
       " ('someone', 2),\n",
       " ('0200', 2),\n",
       " ('condition', 2),\n",
       " ('assessment', 2),\n",
       " ('pepcid', 2),\n",
       " ('asap', 2),\n",
       " ('q12h', 2),\n",
       " ('1gm', 2),\n",
       " ('hang', 2),\n",
       " ('mixed', 2),\n",
       " ('none', 2),\n",
       " ('codeine', 2),\n",
       " ('meropenem', 2),\n",
       " ('completely', 2),\n",
       " ('lock', 2),\n",
       " ('re-timed', 2),\n",
       " ('runs', 2),\n",
       " ('completed', 2),\n",
       " ('elevated', 2),\n",
       " ('kayexlate', 2),\n",
       " ('alprazolam', 2),\n",
       " ('1000', 2),\n",
       " ('late', 2),\n",
       " ('drugs', 2),\n",
       " ('marked', 2),\n",
       " ('created', 2),\n",
       " ('7/27', 2),\n",
       " ('oxycodone/apap', 2),\n",
       " ('5/325mg', 2),\n",
       " ('year', 2),\n",
       " ('female', 2),\n",
       " ('igg', 2),\n",
       " ('rabies', 2),\n",
       " ('vacine', 2),\n",
       " ('dorsogluteal', 2),\n",
       " ('1930', 2),\n",
       " ('five', 2),\n",
       " ('x1', 2),\n",
       " ('milrinone', 2),\n",
       " ('granddaughter', 2),\n",
       " ('changes', 2),\n",
       " ('central', 2),\n",
       " ('calling', 2),\n",
       " ('pharmaceutical', 2),\n",
       " ('company', 2),\n",
       " ('2000', 2),\n",
       " ('speak', 2),\n",
       " ('restricted', 2),\n",
       " ('cvtu', 2),\n",
       " ('original', 2),\n",
       " ('cardiologist', 2),\n",
       " ('transfered', 2),\n",
       " ('hx', 2),\n",
       " ('stevens-johnson', 2),\n",
       " ('syndrome', 2),\n",
       " ('6/18', 2),\n",
       " ('reports', 2),\n",
       " ('body', 2),\n",
       " ('skin', 2),\n",
       " ('red', 2),\n",
       " ('severe', 2),\n",
       " ('6/19/15', 2),\n",
       " ('perflutren', 2),\n",
       " ('microsphere', 2),\n",
       " ('ventricular', 2),\n",
       " ('known', 2),\n",
       " ('suspected', 2),\n",
       " ('right-to-left', 2),\n",
       " ('important', 2),\n",
       " ('serious', 2),\n",
       " ('cardiopulmonary', 2),\n",
       " ('reactions', 2),\n",
       " ('[see', 2),\n",
       " ('precautions', 2),\n",
       " (')]', 2),\n",
       " ('always', 2),\n",
       " ('department', 2),\n",
       " ('draw', 2),\n",
       " ('onto', 2),\n",
       " ('fix', 2),\n",
       " (\"rn's\", 2),\n",
       " ('clarified', 2),\n",
       " ('discovery', 2),\n",
       " ('1530', 2),\n",
       " ('addition', 2),\n",
       " ('124', 2),\n",
       " ('126', 2),\n",
       " ('cvicu', 2),\n",
       " ('ok', 2),\n",
       " ('committee', 2),\n",
       " ('table', 2),\n",
       " ('infusions', 2),\n",
       " ('careful', 2),\n",
       " ('education', 2),\n",
       " ('c-section', 2),\n",
       " ('inquired', 2),\n",
       " ('mean', 2),\n",
       " ('those', 2),\n",
       " ('bilateral', 2),\n",
       " ('wrote', 2),\n",
       " ('183', 2),\n",
       " ('18', 2),\n",
       " ('recorded', 2),\n",
       " ('cc/hr', 2),\n",
       " ('hold', 2),\n",
       " ('recheck', 2),\n",
       " ('resumed', 2),\n",
       " ('indicates', 2),\n",
       " ('clarification', 2),\n",
       " ('4/17', 2),\n",
       " ('solution', 2),\n",
       " ('drew', 2),\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the counts of the most common words in positive reviews\n",
    "positive_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 2041),\n",
       " ('', 1816),\n",
       " ('the', 1548),\n",
       " ('to', 946),\n",
       " ('and', 898),\n",
       " ('was', 866),\n",
       " (',', 662),\n",
       " ('patient', 541),\n",
       " ('on', 400),\n",
       " ('of', 384),\n",
       " ('for', 376),\n",
       " ('in', 368),\n",
       " ('at', 363),\n",
       " ('that', 353),\n",
       " ('a', 327),\n",
       " ('not', 320),\n",
       " ('pt', 259),\n",
       " ('it', 214),\n",
       " ('had', 214),\n",
       " ('with', 210),\n",
       " ('medication', 208),\n",
       " ('i', 205),\n",
       " ('she', 204),\n",
       " ('this', 199),\n",
       " ('order', 181),\n",
       " ('as', 162),\n",
       " ('pharmacy', 161),\n",
       " ('given', 158),\n",
       " ('nurse', 158),\n",
       " ('dose', 154),\n",
       " ('from', 152),\n",
       " ('her', 140),\n",
       " ('rn', 140),\n",
       " ('were', 130),\n",
       " ('is', 127),\n",
       " ('by', 124),\n",
       " ('ordered', 124),\n",
       " ('dr', 120),\n",
       " ('but', 117),\n",
       " ('be', 115),\n",
       " ('[redacted]', 111),\n",
       " ('he', 107),\n",
       " ('iv', 100),\n",
       " ('called', 99),\n",
       " ('mg', 99),\n",
       " (')', 95),\n",
       " ('when', 95),\n",
       " ('did', 94),\n",
       " ('received', 94),\n",
       " ('med', 92),\n",
       " ('have', 91),\n",
       " ('been', 88),\n",
       " ('(', 86),\n",
       " ('an', 86),\n",
       " ('after', 86),\n",
       " ('no', 84),\n",
       " ('orders', 81),\n",
       " ('stated', 76),\n",
       " ('up', 74),\n",
       " ('2', 68),\n",
       " ('would', 67),\n",
       " ('then', 66),\n",
       " ('1', 66),\n",
       " ('home', 65),\n",
       " ('notified', 64),\n",
       " ('if', 62),\n",
       " ('physician', 62),\n",
       " ('entered', 60),\n",
       " ('back', 60),\n",
       " ('or', 60),\n",
       " ('pharmacist', 58),\n",
       " ('time', 56),\n",
       " ('his', 56),\n",
       " ('medications', 55),\n",
       " ('meds', 55),\n",
       " ('room', 55),\n",
       " ('call', 54),\n",
       " ('they', 54),\n",
       " ('pain', 52),\n",
       " ('we', 50),\n",
       " ('has', 49),\n",
       " ('0', 49),\n",
       " ('there', 48),\n",
       " ('morphine', 47),\n",
       " ('md', 46),\n",
       " ('doctor', 46),\n",
       " ('day', 45),\n",
       " ('started', 45),\n",
       " ('per', 44),\n",
       " ('told', 44),\n",
       " ('4', 44),\n",
       " ('give', 44),\n",
       " ('3', 44),\n",
       " ('out', 43),\n",
       " ('administered', 42),\n",
       " ('only', 41),\n",
       " ('gave', 41),\n",
       " ('o2', 41),\n",
       " (\"patient's\", 41),\n",
       " ('also', 41),\n",
       " ('one', 41),\n",
       " ('ed', 40),\n",
       " ('asked', 40),\n",
       " ('po', 39),\n",
       " ('doses', 38),\n",
       " ('put', 38),\n",
       " ('said', 38),\n",
       " ('still', 38),\n",
       " ('sent', 38),\n",
       " ('will', 37),\n",
       " ('into', 37),\n",
       " ('me', 37),\n",
       " ('so', 37),\n",
       " ('5', 37),\n",
       " ('informed', 36),\n",
       " ('which', 36),\n",
       " ('due', 36),\n",
       " ('patients', 36),\n",
       " ('bid', 36),\n",
       " ('daily', 36),\n",
       " ('any', 35),\n",
       " ('noted', 35),\n",
       " ('went', 34),\n",
       " ('states', 34),\n",
       " ('all', 34),\n",
       " ('benadryl', 34),\n",
       " ('correct', 33),\n",
       " ('get', 33),\n",
       " ('could', 32),\n",
       " ('error', 32),\n",
       " ('him', 32),\n",
       " ('er', 31),\n",
       " ('documented', 31),\n",
       " ('placed', 31),\n",
       " ('am', 30),\n",
       " ('prescription', 30),\n",
       " ('being', 30),\n",
       " ('floor', 30),\n",
       " ('pyxis', 30),\n",
       " ('list', 30),\n",
       " ('other', 30),\n",
       " ('prn', 30),\n",
       " ('removed', 30),\n",
       " ('during', 30),\n",
       " ('ct', 29),\n",
       " ('take', 29),\n",
       " ('found', 29),\n",
       " ('are', 29),\n",
       " ('another', 28),\n",
       " ('who', 28),\n",
       " ('ivp', 28),\n",
       " ('6', 28),\n",
       " ('minutes', 28),\n",
       " ('spoke', 27),\n",
       " ('allergy', 27),\n",
       " ('scan', 27),\n",
       " ('tech', 27),\n",
       " ('should', 27),\n",
       " ('bag', 27),\n",
       " ('10', 27),\n",
       " ('blood', 26),\n",
       " ('because', 26),\n",
       " ('wrong', 26),\n",
       " ('instead', 26),\n",
       " ('verified', 26),\n",
       " ('icu', 26),\n",
       " ('checked', 26),\n",
       " ('upon', 25),\n",
       " ('s', 25),\n",
       " ('contacted', 25),\n",
       " ('now', 25),\n",
       " ('label', 25),\n",
       " ('bp', 25),\n",
       " ('before', 24),\n",
       " ('them', 24),\n",
       " ('chart', 24),\n",
       " ('came', 24),\n",
       " ('changed', 24),\n",
       " ('left', 24),\n",
       " ('about', 24),\n",
       " ('surgery', 24),\n",
       " ('until', 23),\n",
       " ('different', 23),\n",
       " ('my', 23),\n",
       " ('needed', 23),\n",
       " ('infusion', 23),\n",
       " ('over', 23),\n",
       " ('prior', 22),\n",
       " ('admitted', 22),\n",
       " ('know', 22),\n",
       " ('hours', 22),\n",
       " ('written', 22),\n",
       " ('new', 22),\n",
       " ('both', 22),\n",
       " ('computer', 22),\n",
       " ('off', 22),\n",
       " ('see', 22),\n",
       " ('taking', 22),\n",
       " ('noticed', 21),\n",
       " ('made', 21),\n",
       " ('same', 21),\n",
       " ('next', 21),\n",
       " ('two', 21),\n",
       " ('taken', 21),\n",
       " ('discharge', 21),\n",
       " ('first', 20),\n",
       " ('shift', 20),\n",
       " ('morning', 20),\n",
       " ('100mg', 20),\n",
       " ('staff', 20),\n",
       " ('contrast', 20),\n",
       " ('20', 20),\n",
       " ('right', 19),\n",
       " ('discovered', 19),\n",
       " ('nursing', 19),\n",
       " ('scheduled', 19),\n",
       " ('report', 19),\n",
       " ('emar', 19),\n",
       " ('what', 19),\n",
       " ('got', 19),\n",
       " ('having', 19),\n",
       " ('test', 19),\n",
       " ('rate', 19),\n",
       " ('admission', 18),\n",
       " ('corrected', 18),\n",
       " ('discharged', 18),\n",
       " ('available', 18),\n",
       " ('reaction', 18),\n",
       " ('change', 18),\n",
       " ('brought', 18),\n",
       " ('these', 18),\n",
       " ('chest', 18),\n",
       " ('hour', 18),\n",
       " ('times', 17),\n",
       " ('check', 17),\n",
       " ('hospital', 17),\n",
       " ('more', 17),\n",
       " ('night', 17),\n",
       " ('medicine', 17),\n",
       " ('days', 17),\n",
       " ('drug', 17),\n",
       " ('25mg', 17),\n",
       " ('today', 17),\n",
       " ('without', 17),\n",
       " ('stress', 17),\n",
       " ('go', 17),\n",
       " ('percocet', 17),\n",
       " ('since', 16),\n",
       " ('used', 16),\n",
       " ('unit', 16),\n",
       " ('ml', 16),\n",
       " ('start', 16),\n",
       " ('arrived', 16),\n",
       " ('regarding', 16),\n",
       " ('immediately', 16),\n",
       " ('side', 16),\n",
       " ('returned', 16),\n",
       " ('going', 16),\n",
       " ('-', 16),\n",
       " ('@', 16),\n",
       " ('script', 16),\n",
       " ('phone', 16),\n",
       " ('oxygen', 16),\n",
       " ('however', 16),\n",
       " ('pca', 16),\n",
       " ('stopped', 16),\n",
       " ('again', 16),\n",
       " ('while', 16),\n",
       " ('itching', 16),\n",
       " ('listed', 16),\n",
       " ('receive', 15),\n",
       " ('need', 15),\n",
       " ('daughter', 15),\n",
       " ('never', 15),\n",
       " ('mother', 15),\n",
       " ('10mg', 15),\n",
       " ('bottle', 15),\n",
       " ('tablets', 15),\n",
       " ('50mg', 15),\n",
       " ('lovenox', 15),\n",
       " ('here', 15),\n",
       " ('vial', 15),\n",
       " ('mar', 15),\n",
       " ('every', 15),\n",
       " ('5mg', 15),\n",
       " ('tabs', 15),\n",
       " ('via', 15),\n",
       " ('tab', 15),\n",
       " ('able', 15),\n",
       " ('pulse', 15),\n",
       " ('increased', 15),\n",
       " ('down', 15),\n",
       " ('transferred', 15),\n",
       " ('charted', 14),\n",
       " ('office', 14),\n",
       " ('do', 14),\n",
       " ('facility', 14),\n",
       " ('vs', 14),\n",
       " ('requested', 14),\n",
       " ('ivpb', 14),\n",
       " ('through', 14),\n",
       " ('obtained', 14),\n",
       " ('aware', 14),\n",
       " ('continue', 14),\n",
       " ('patch', 14),\n",
       " ('thought', 14),\n",
       " ('name', 14),\n",
       " ('dispensed', 14),\n",
       " ('became', 14),\n",
       " ('continued', 14),\n",
       " ('saline', 14),\n",
       " ('case', 14),\n",
       " ('later', 14),\n",
       " ('air', 14),\n",
       " ('use', 14),\n",
       " ('lab', 14),\n",
       " ('pressure', 14),\n",
       " ('push', 14),\n",
       " ('narcan', 14),\n",
       " ('missed', 13),\n",
       " ('multiple', 13),\n",
       " ('administration', 13),\n",
       " ('normal', 13),\n",
       " ('further', 13),\n",
       " ('treatment', 13),\n",
       " ('post', 13),\n",
       " ('evening', 13),\n",
       " ('active', 13),\n",
       " ('breathing', 13),\n",
       " ('xxxx', 13),\n",
       " ('incorrect', 13),\n",
       " ('some', 13),\n",
       " ('reviewed', 13),\n",
       " ('already', 13),\n",
       " (\"pt's\", 13),\n",
       " ('ox', 13),\n",
       " ('where', 13),\n",
       " ('why', 13),\n",
       " ('response', 13),\n",
       " ('heparin', 13),\n",
       " ('getting', 13),\n",
       " ('scanned', 13),\n",
       " ('return', 13),\n",
       " ('well', 12),\n",
       " ('our', 12),\n",
       " ('last', 12),\n",
       " ('once', 12),\n",
       " ('reports', 12),\n",
       " ('under', 12),\n",
       " ('200mg', 12),\n",
       " ('vaccine', 12),\n",
       " ('inr', 12),\n",
       " ('concentration', 12),\n",
       " ('coumadin', 12),\n",
       " ('just', 12),\n",
       " ('took', 12),\n",
       " ('seroquel', 12),\n",
       " ('following', 12),\n",
       " ('bleeding', 12),\n",
       " ('continuous', 12),\n",
       " ('50', 12),\n",
       " ('throat', 12),\n",
       " ('ns', 12),\n",
       " ('hr', 12),\n",
       " ('information', 12),\n",
       " ('instructions', 12),\n",
       " ('how', 12),\n",
       " ('wanted', 12),\n",
       " ('7', 12),\n",
       " ('giving', 12),\n",
       " ('event', 12),\n",
       " ('nurses', 12),\n",
       " ('receiving', 11),\n",
       " ('mistake', 11),\n",
       " ('several', 11),\n",
       " ('reported', 11),\n",
       " ('clinic', 11),\n",
       " ('rec', 11),\n",
       " ('done', 11),\n",
       " ('status', 11),\n",
       " ('twice', 11),\n",
       " ('yyyy', 11),\n",
       " ('bin', 11),\n",
       " ('charge', 11),\n",
       " ('tablet', 11),\n",
       " ('sign', 11),\n",
       " ('2mg', 11),\n",
       " ('pill', 11),\n",
       " ('25', 11),\n",
       " ('epinephrine', 11),\n",
       " ('let', 11),\n",
       " ('saw', 11),\n",
       " ('monitor', 11),\n",
       " ('pepcid', 11),\n",
       " ('100', 11),\n",
       " ('does', 11),\n",
       " ('30', 11),\n",
       " ('sure', 11),\n",
       " ('questions', 11),\n",
       " ('care', 11),\n",
       " ('8', 11),\n",
       " ('pump', 11),\n",
       " ('cath', 11),\n",
       " ('unresponsive', 11),\n",
       " ('sat', 11),\n",
       " ('pick', 11),\n",
       " ('dilaudid', 11),\n",
       " ('x', 11),\n",
       " ('hydrocodone', 11),\n",
       " ('weight', 10),\n",
       " ('respiratory', 10),\n",
       " ('level', 10),\n",
       " ('vaccines', 10),\n",
       " ('caught', 10),\n",
       " ('verify', 10),\n",
       " ('communication', 10),\n",
       " ('insulin', 10),\n",
       " ('stay', 10),\n",
       " ('previous', 10),\n",
       " ('completed', 10),\n",
       " ('profile', 10),\n",
       " ('explained', 10),\n",
       " ('resident', 10),\n",
       " ('read', 10),\n",
       " ('filled', 10),\n",
       " ('recieved', 10),\n",
       " ('20mg', 10),\n",
       " ('risk', 10),\n",
       " ('signed', 10),\n",
       " ('1mg', 10),\n",
       " ('discontinued', 10),\n",
       " ('around', 10),\n",
       " ('face', 10),\n",
       " ('red', 10),\n",
       " ('chair', 10),\n",
       " ('symptoms', 10),\n",
       " (\".'\", 10),\n",
       " ('can', 10),\n",
       " ('hives', 10),\n",
       " ('approximately', 10),\n",
       " ('vanc', 10),\n",
       " ('actually', 9),\n",
       " ('too', 9),\n",
       " ('clarify', 9),\n",
       " ('administer', 9),\n",
       " ('provider', 9),\n",
       " ('tell', 9),\n",
       " ('possible', 9),\n",
       " ('hospice', 9),\n",
       " ('exam', 9),\n",
       " ('looked', 9),\n",
       " ('come', 9),\n",
       " ('tid', 9),\n",
       " ('set', 9),\n",
       " ('review', 9),\n",
       " ('cipro', 9),\n",
       " ('levaquin', 9),\n",
       " ('injection', 9),\n",
       " ('better', 9),\n",
       " ('rt', 9),\n",
       " ('op', 9),\n",
       " ('drawer', 9),\n",
       " ('high', 9),\n",
       " ('telephone', 9),\n",
       " ('record', 9),\n",
       " ('doing', 9),\n",
       " ('system', 9),\n",
       " ('15', 9),\n",
       " ('unable', 9),\n",
       " ('c/o', 9),\n",
       " ('felt', 9),\n",
       " ('husband', 9),\n",
       " ('arm', 9),\n",
       " ('cardiac', 9),\n",
       " ('responded', 9),\n",
       " ('anesthesia', 9),\n",
       " ('confirmed', 9),\n",
       " ('syringe', 9),\n",
       " ('began', 9),\n",
       " ('drops', 9),\n",
       " ('visit', 9),\n",
       " ('missing', 9),\n",
       " ('allergies', 9),\n",
       " ('alert', 9),\n",
       " ('picked', 9),\n",
       " ('hospitalist', 9),\n",
       " ('warfarin', 9),\n",
       " ('fentanyl', 9),\n",
       " ('incorrectly', 8),\n",
       " ('than', 8),\n",
       " ('child', 8),\n",
       " ('manager', 8),\n",
       " ('stat', 8),\n",
       " ('wait', 8),\n",
       " ('changes', 8),\n",
       " ('emergency', 8),\n",
       " ('saturation', 8),\n",
       " ('solumedrol', 8),\n",
       " ('send', 8),\n",
       " ('protocol', 8),\n",
       " ('750mg', 8),\n",
       " ('&', 8),\n",
       " ('feel', 8),\n",
       " ('bottles', 8),\n",
       " ('increase', 8),\n",
       " ('4mg', 8),\n",
       " ('oral', 8),\n",
       " ('showed', 8),\n",
       " ('scanning', 8),\n",
       " ('like', 8),\n",
       " ('inpatient', 8),\n",
       " ('documentation', 8),\n",
       " ('prescribed', 8),\n",
       " ('npo', 8),\n",
       " ('tried', 8),\n",
       " ('note', 8),\n",
       " ('follow', 8),\n",
       " ('hung', 8),\n",
       " ('running', 8),\n",
       " ('nc', 8),\n",
       " ('eyes', 8),\n",
       " ('process', 8),\n",
       " ('code', 8),\n",
       " ('concern', 8),\n",
       " ('hold', 8),\n",
       " ('consult', 8),\n",
       " ('antibiotic', 8),\n",
       " ('presented', 8),\n",
       " ('circulating', 8),\n",
       " ('redness', 8),\n",
       " ('radiologist', 8),\n",
       " ('zantac', 8),\n",
       " ('t', 8),\n",
       " ('employee', 8),\n",
       " ('refill', 8),\n",
       " ('gabapentin', 8),\n",
       " ('9', 8),\n",
       " ('allergic', 8),\n",
       " ('radiology', 8),\n",
       " ('nuclear', 8),\n",
       " ('remaining', 8),\n",
       " ('rapid', 8),\n",
       " ('omni', 8),\n",
       " ('rituxan', 8),\n",
       " ('q', 8),\n",
       " ('5/325', 8),\n",
       " ('hydrocodone/apap', 8),\n",
       " ('coreg', 8),\n",
       " ('amoxicillin', 8),\n",
       " (\"didn't\", 7),\n",
       " ('seen', 7),\n",
       " ('work', 7),\n",
       " ('liquid', 7),\n",
       " ('dosing', 7),\n",
       " ('within', 7),\n",
       " ('arrival', 7),\n",
       " ('therapy', 7),\n",
       " ('stable', 7),\n",
       " ('remains', 7),\n",
       " ('please', 7),\n",
       " ('good', 7),\n",
       " ('intubated', 7),\n",
       " ('40mg', 7),\n",
       " ('late', 7),\n",
       " ('0900', 7),\n",
       " ('b', 7),\n",
       " ('pulled', 7),\n",
       " ('elevated', 7),\n",
       " ('capsules', 7),\n",
       " ('ancef', 7),\n",
       " ('adverse', 7),\n",
       " ('additional', 7),\n",
       " ('paper', 7),\n",
       " ('applied', 7),\n",
       " ('verbal', 7),\n",
       " ('restarted', 7),\n",
       " ('r', 7),\n",
       " ('hand', 7),\n",
       " ('10/325mg', 7),\n",
       " ('fine', 7),\n",
       " ('clonazepam', 7),\n",
       " ('their', 7),\n",
       " ('contact', 7),\n",
       " ('soon', 7),\n",
       " ('week', 7),\n",
       " ('lorazepam', 7),\n",
       " ('waste', 7),\n",
       " ('monday', 7),\n",
       " ('assessed', 7),\n",
       " ('ok', 7),\n",
       " ('0100', 7),\n",
       " ('pull', 7),\n",
       " ('procedure', 7),\n",
       " ('caused', 7),\n",
       " ('required', 7),\n",
       " ('developed', 7),\n",
       " ('really', 7),\n",
       " ('wrote', 7),\n",
       " ('point', 7),\n",
       " ('total', 7),\n",
       " ('understanding', 7),\n",
       " ('keep', 7),\n",
       " ('skin', 7),\n",
       " ('very', 7),\n",
       " ('cardiologist', 7),\n",
       " (',000', 7),\n",
       " ('wife', 7),\n",
       " ('respirations', 7),\n",
       " ('qid', 7),\n",
       " ('delivered', 7),\n",
       " ('son', 7),\n",
       " ('d/c', 7),\n",
       " ('gtt', 7),\n",
       " ('cytoxan', 7),\n",
       " ('make', 7),\n",
       " ('manufacturer', 7),\n",
       " ('dropped', 7),\n",
       " ('old', 7),\n",
       " ('transfer', 7),\n",
       " ('dopamine', 7),\n",
       " ('labeled', 6),\n",
       " ('24', 6),\n",
       " ('injected', 6),\n",
       " ('issues', 6),\n",
       " ('errors', 6),\n",
       " ('cannot', 6),\n",
       " ('harm', 6),\n",
       " ('history', 6),\n",
       " ('drip', 6),\n",
       " ('discussed', 6),\n",
       " ('family', 6),\n",
       " ('bed', 6),\n",
       " ('lasix', 6),\n",
       " ('tylenol', 6),\n",
       " ('500mg', 6),\n",
       " ('monitoring', 6),\n",
       " ('center', 6),\n",
       " ('may', 6),\n",
       " ('2100', 6),\n",
       " ('neb', 6),\n",
       " ('closed', 6),\n",
       " ('box', 6),\n",
       " ('half', 6),\n",
       " ('look', 6),\n",
       " ('30mg', 6),\n",
       " ('ir', 6),\n",
       " ('x1', 6),\n",
       " ('current', 6),\n",
       " ('instructed', 6),\n",
       " ('q6h', 6),\n",
       " ('gm', 6),\n",
       " ('augmentin', 6),\n",
       " ('either', 6),\n",
       " ('zofran', 6),\n",
       " ('kept', 6),\n",
       " ('checking', 6),\n",
       " ('even', 6),\n",
       " ('way', 6),\n",
       " ('ordering', 6),\n",
       " ('performed', 6),\n",
       " ('turned', 6),\n",
       " ('sr', 6),\n",
       " ('100%', 6),\n",
       " ('decreased', 6),\n",
       " ('monitored', 6),\n",
       " ('feeling', 6),\n",
       " ('wanting', 6),\n",
       " ('feels', 6),\n",
       " ('card', 6),\n",
       " ('directions', 6),\n",
       " ('vials', 6),\n",
       " ('clarification', 6),\n",
       " ('cc', 6),\n",
       " ('signs', 6),\n",
       " ('less', 6),\n",
       " ('2nd', 6),\n",
       " ('bolus', 6),\n",
       " ('difficulty', 6),\n",
       " ('liters', 6),\n",
       " ('heart', 6),\n",
       " ('mom', 6),\n",
       " ('own', 6),\n",
       " ('ready', 6),\n",
       " ('rx', 6),\n",
       " ('effects', 6),\n",
       " ('outpt', 6),\n",
       " ('treated', 6),\n",
       " ('syringes', 6),\n",
       " ('fluids', 6),\n",
       " ('medical', 6),\n",
       " ('min', 6),\n",
       " ('125', 6),\n",
       " ('lpn', 6),\n",
       " ('.(', 6),\n",
       " ('realized', 6),\n",
       " ('double', 6),\n",
       " ('pacu', 6),\n",
       " ('narcotic', 6),\n",
       " ('blue', 6),\n",
       " ('ahn', 6),\n",
       " ('sets', 6),\n",
       " ('lidocaine', 6),\n",
       " ('mcg', 6),\n",
       " ('875mg', 6),\n",
       " ('emr', 5),\n",
       " ('large', 5),\n",
       " ('2200', 5),\n",
       " ('assigned', 5),\n",
       " ('realize', 5),\n",
       " ('form', 5),\n",
       " ('complaining', 5),\n",
       " ('reconciliation', 5),\n",
       " ('intended', 5),\n",
       " ('disease', 5),\n",
       " ('arrest', 5),\n",
       " ('throughout', 5),\n",
       " ('refilled', 5),\n",
       " ('acid', 5),\n",
       " ('line', 5),\n",
       " ('away', 5),\n",
       " ('pcp', 5),\n",
       " ('message', 5),\n",
       " ('friday', 5),\n",
       " ('400mg', 5),\n",
       " ('0600', 5),\n",
       " ('between', 5),\n",
       " ('full', 5),\n",
       " ('0800', 5),\n",
       " ('usually', 5),\n",
       " ('tx', 5),\n",
       " ('stock', 5),\n",
       " ('demerol', 5),\n",
       " ('appropriately', 5),\n",
       " ('mixed', 5),\n",
       " ('oxycontin', 5),\n",
       " ('oxycodone', 5),\n",
       " ('along', 5),\n",
       " ('dc', 5),\n",
       " ('extra', 5),\n",
       " ('metoprolol', 5),\n",
       " ('1110', 5),\n",
       " ('zosyn', 5),\n",
       " ('omnicell', 5),\n",
       " ('levothyroxine', 5),\n",
       " ('supply', 5),\n",
       " ('spouse', 5),\n",
       " ('starting', 5),\n",
       " ('almost', 5),\n",
       " ('cough', 5),\n",
       " ('colonoscopy', 5),\n",
       " ('bowel', 5),\n",
       " ('prep', 5),\n",
       " ('consent', 5),\n",
       " ('cerner', 5),\n",
       " ('related', 5),\n",
       " ('flushed', 5),\n",
       " ('vomitting', 5),\n",
       " ('voiced', 5),\n",
       " ('lunch', 5),\n",
       " ('much', 5),\n",
       " ('dpc', 5),\n",
       " ('circulator', 5),\n",
       " ('1:1000', 5),\n",
       " ('questioned', 5),\n",
       " ('pa', 5),\n",
       " ('close', 5),\n",
       " ('transported', 5),\n",
       " ('known', 5),\n",
       " ('concerns', 5),\n",
       " ('low', 5),\n",
       " ('recovery', 5),\n",
       " ('obtain', 5),\n",
       " ('appears', 5),\n",
       " ('run', 5),\n",
       " ('12', 5),\n",
       " ('always', 5),\n",
       " ('inform', 5),\n",
       " ('yet', 5),\n",
       " ('situation', 5),\n",
       " ('department', 5),\n",
       " ('vomiting', 5),\n",
       " ('else', 5),\n",
       " ('overnight', 5),\n",
       " ('outpatient', 5),\n",
       " ('act', 5),\n",
       " ('16', 5),\n",
       " ('attempted', 5),\n",
       " ('receptionist', 5),\n",
       " ('eye', 5),\n",
       " ('pts', 5),\n",
       " ('ear', 5),\n",
       " ('each', 5),\n",
       " ('flush', 5),\n",
       " ('shots', 5),\n",
       " ('month', 5),\n",
       " ('amount', 5),\n",
       " ('methadone', 5),\n",
       " ('area', 5),\n",
       " ('sitting', 5),\n",
       " ('im', 5),\n",
       " ('98%', 5),\n",
       " ('k', 5),\n",
       " ('bubble', 5),\n",
       " ('refills', 5),\n",
       " ('little', 5),\n",
       " ('45', 5),\n",
       " ('xxx', 5),\n",
       " ('chemotherapy', 5),\n",
       " ('sob', 5),\n",
       " ('want', 5),\n",
       " ('theophylline', 5),\n",
       " ('cr', 5),\n",
       " ('dosage', 5),\n",
       " ('asking', 5),\n",
       " ('np', 5),\n",
       " ('help', 5),\n",
       " ('station', 5),\n",
       " ('sugar', 5),\n",
       " ('refused', 5),\n",
       " ('remained', 5),\n",
       " ('hydromorphone', 5),\n",
       " ('ativan', 5),\n",
       " ('regimen', 5),\n",
       " ('pcu', 5),\n",
       " ('inhaler', 5),\n",
       " ('kg', 5),\n",
       " ('ahead', 5),\n",
       " ('sn', 5),\n",
       " ('pills', 5),\n",
       " ('appropriate', 5),\n",
       " ('patches', 5),\n",
       " ('magnesium', 5),\n",
       " (\"d/c'd\", 5),\n",
       " ('plavix', 5),\n",
       " ('entering', 4),\n",
       " ('=', 4),\n",
       " ('issue', 4),\n",
       " ('route', 4),\n",
       " ('expired', 4),\n",
       " ('xarelto', 4),\n",
       " ('observation', 4),\n",
       " ('busy', 4),\n",
       " ('access', 4),\n",
       " ('norvasc', 4),\n",
       " ('finally', 4),\n",
       " ('writer', 4),\n",
       " ('ask', 4),\n",
       " ('place', 4),\n",
       " ('depakote', 4),\n",
       " ('qhs', 4),\n",
       " ('date', 4),\n",
       " ('advised', 4),\n",
       " ('2015', 4),\n",
       " ('tubing', 4),\n",
       " ('recieve', 4),\n",
       " ('quickmar', 4),\n",
       " ('sotalol', 4),\n",
       " ('selected', 4),\n",
       " ('remote', 4),\n",
       " ('whole', 4),\n",
       " ('infusing', 4),\n",
       " ('prescriptions', 4),\n",
       " ('correctly', 4),\n",
       " ('treatments', 4),\n",
       " ('infed', 4),\n",
       " ('held', 4),\n",
       " ('outside', 4),\n",
       " ('0945', 4),\n",
       " ('count', 4),\n",
       " ('investigation', 4),\n",
       " ('takes', 4),\n",
       " ('1127', 4),\n",
       " ('second', 4),\n",
       " ('printed', 4),\n",
       " ('faxed', 4),\n",
       " ('hs', 4),\n",
       " ('drink', 4),\n",
       " ('manual', 4),\n",
       " ('override', 4),\n",
       " ('happened', 4),\n",
       " ('metformin', 4),\n",
       " ('.5mg', 4),\n",
       " ('1/2', 4),\n",
       " ('transcribed', 4),\n",
       " ('duplicates', 4),\n",
       " ('flomax', 4),\n",
       " ('cell', 4),\n",
       " ('tomorrow', 4),\n",
       " ('nor', 4),\n",
       " ('0130', 4),\n",
       " ('nauseated', 4),\n",
       " ('arms', 4),\n",
       " ('solucortef', 4),\n",
       " ('continues', 4),\n",
       " ('rest', 4),\n",
       " ('92%', 4),\n",
       " ('bathroom', 4),\n",
       " ('lock', 4),\n",
       " ('nausea', 4),\n",
       " ('stating', 4),\n",
       " ('using', 4),\n",
       " ('scrub', 4),\n",
       " ('surgeon', 4),\n",
       " ('ran', 4),\n",
       " ('lot', 4),\n",
       " ('site', 4),\n",
       " ('assistance', 4),\n",
       " ('consulted', 4),\n",
       " ('reach', 4),\n",
       " ('lack', 4),\n",
       " ('partial', 4),\n",
       " ('respond', 4),\n",
       " ('you', 4),\n",
       " ('condition', 4),\n",
       " ('500', 4),\n",
       " ('problems', 4),\n",
       " ('pharmacists', 4),\n",
       " ('units', 4),\n",
       " ('complete', 4),\n",
       " ('thus', 4),\n",
       " ('paged', 4),\n",
       " ('small', 4),\n",
       " ('water', 4),\n",
       " ('white', 4),\n",
       " ('someone', 4),\n",
       " ('drop', 4),\n",
       " ('protamine', 4),\n",
       " ('space', 4),\n",
       " ('those', 4),\n",
       " ('requesting', 4),\n",
       " ('few', 4),\n",
       " (\"wasn't\", 4),\n",
       " ('unless', 4),\n",
       " ('150mg', 4),\n",
       " ('holding', 4),\n",
       " ('mask', 4),\n",
       " ('question', 4),\n",
       " ('responsive', 4),\n",
       " ('primary', 4),\n",
       " ('1/16/15', 4),\n",
       " ('state', 4),\n",
       " ('bring', 4),\n",
       " ('answer', 4),\n",
       " ('bedtime', 4),\n",
       " ('pm', 4),\n",
       " ('many', 4),\n",
       " ('leave', 4),\n",
       " ('scanner', 4),\n",
       " ('door', 4),\n",
       " ('vitals', 4),\n",
       " ('rituxin', 4),\n",
       " ('50ml/hr', 4),\n",
       " ('complained', 4),\n",
       " ('2l', 4),\n",
       " ('nasal', 4),\n",
       " ('evaluate', 4),\n",
       " ('lamotrigine', 4),\n",
       " ('mouth', 4),\n",
       " ('thinking', 4),\n",
       " ('marked', 4),\n",
       " ('decided', 4),\n",
       " ('generic', 4),\n",
       " ('1000mg', 4),\n",
       " ('offered', 4),\n",
       " ('fluconazole', 4),\n",
       " ('recommended', 4),\n",
       " ('medrol', 4),\n",
       " ('echo', 4),\n",
       " ('denies', 4),\n",
       " ('rash', 4),\n",
       " ('five', 4),\n",
       " ('involved', 4),\n",
       " ('pre-medicated', 4),\n",
       " ('working', 4),\n",
       " ('severe', 4),\n",
       " ('theo-24', 4),\n",
       " ('swelling', 4),\n",
       " ('pack', 4),\n",
       " ('didnt', 4),\n",
       " ('1mg/hr', 4),\n",
       " ('methylprednisolone', 4),\n",
       " ('suggested', 4),\n",
       " ('hrs', 4),\n",
       " ('itchy', 4),\n",
       " ('delay', 4),\n",
       " ('discuss', 4),\n",
       " ('pre', 4),\n",
       " ('longer', 4),\n",
       " ('fluid', 4),\n",
       " ('80', 4),\n",
       " ('celexa', 4),\n",
       " ('integrilin', 4),\n",
       " ('11/30/15', 4),\n",
       " ('plan', 4),\n",
       " ('nose', 4),\n",
       " ('scripts', 4),\n",
       " ('pre-op', 4),\n",
       " ('versed', 4),\n",
       " ('pct', 4),\n",
       " ('opioid', 4),\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the counts of the most common words in negative reviews\n",
    "negative_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, common words like \"the\" appear very often in both positive and negative reviews. Instead of finding the most common words in positive or negative reviews, what you really want are the words found in positive reviews more often than in negative reviews, and vice versa. To accomplish this, you'll need to calculate the **ratios** of word usage between positive and negative reviews.\n",
    "\n",
    "**TODO:** Check all the words you've seen and calculate the ratio of postive to negative uses and store that ratio in `pos_neg_ratios`. \n",
    ">Hint: the positive-to-negative ratio for a given word can be calculated with `positive_counts[word] / float(negative_counts[word]+1)`. Notice the `+1` in the denominator that ensures we don't divide by zero for words that are only seen in positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    "\n",
    "# Calculate the ratios of positive and negative uses of the most common words\n",
    "# Consider words to be \"common\" if they've been used at least 100 times\n",
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 1):\n",
    "        pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the ratios you've calculated for a few words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'the' = 0.5041962556488057\n",
      "Pos-to-neg ratio for 'order' = 0.3516483516483517\n",
      "Pos-to-neg ratio for 'pharmacist' = 0.2542372881355932\n"
     ]
    }
   ],
   "source": [
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'order' = {}\".format(pos_neg_ratios[\"order\"]))\n",
    "print(\"Pos-to-neg ratio for 'pharmacist' = {}\".format(pos_neg_ratios[\"pharmacist\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking closely at the values you just calculated, we see the following: \n",
    "\n",
    "* Words that you would expect to see more often in positive reviews  like \"amazing\" have a ratio greater than 1. The more skewed a word is toward postive, the farther from 1 its positive-to-negative ratio  will be.\n",
    "* Words that you would expect to see more often in negative reviews  like \"terrible\"  have positive values that are less than 1. The more skewed a word is toward negative, the closer to zero its positive-to-negative ratio will be.\n",
    "* Neutral words, which don't really convey any sentiment because you would expect to see them in all sorts of reviews  like \"the\"  have values very close to 1. A perfectly neutral word one that was used in exactly the same number of positive reviews as negative reviews would be almost exactly 1. The `+1` we suggested you add to the denominator slightly biases words toward negative, but it won't matter because it will be a tiny bias and later we'll be ignoring words that are too close to neutral anyway.\n",
    "\n",
    "Ok, the ratios tell us which words are used more often in postive or negative reviews, but the specific values we've calculated are a bit difficult to work with. A very positive word like \"amazing\" has a value above 4, whereas a very negative word like \"terrible\" has a value around 0.18. Those values aren't easy to compare for a couple of reasons:\n",
    "\n",
    "* Right now, 1 is considered neutral, but the absolute value of the postive-to-negative rations of very postive words is larger than the absolute value of the ratios for the very negative words. So there is no way to directly compare two numbers and see if one word conveys the same magnitude of positive sentiment as another word conveys negative sentiment. So we should center all the values around netural so the absolute value fro neutral of the postive-to-negative ratio for a word would indicate how much sentiment (positive or negative) that word conveys.\n",
    "* When comparing absolute values it's easier to do that around zero than one. \n",
    "\n",
    "To fix these issues, we'll convert all of our ratios to new values using logarithms.\n",
    "\n",
    "**TODO:** Go through all the ratios you calculated and convert them to logarithms. (i.e. use `np.log(ratio)`)\n",
    "\n",
    "In the end, extremely positive and extremely negative words will have positive-to-negative ratios with similar magnitudes but opposite signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert ratios to logs\n",
    "for word,ratio in pos_neg_ratios.most_common():\n",
    "    if ratio > 1:\n",
    "        pos_neg_ratios[word] = np.log(ratio)\n",
    "    else:\n",
    "        pos_neg_ratios[word] = np.log(ratio+0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** In the video, Andrew uses the following formulas for the previous cell:\n",
    "> * For any postive words, convert the ratio using `np.log(ratio)`\n",
    "> * For any negative words, convert the ratio using `-np.log(1/(ratio + 0.01))`\n",
    "\n",
    "These won't give you the exact same results as the simpler code we show in this notebook, but the values will be similar. In case that second equation looks strange, here's what it's doing: First, it divides one by a very small number, which will produce a larger positive number. Then, it takes the `log` of that, which produces numbers similar to the ones for the postive words. Finally, it negates the values by adding that minus sign up front. The results are extremely positive and extremely negative words having positive-to-negative ratios with similar magnitudes but oppositite signs, just like when we use `np.log(ratio)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the new ratios you've calculated for the same words from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'the' = -0.6651502660733883\n",
      "Pos-to-neg ratio for 'order' = -1.0170829435616013\n",
      "Pos-to-neg ratio for 'pharmacist' = -1.3309077608360342\n"
     ]
    }
   ],
   "source": [
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'order' = {}\".format(pos_neg_ratios[\"order\"]))\n",
    "print(\"Pos-to-neg ratio for 'pharmacist' = {}\".format(pos_neg_ratios[\"pharmacist\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything worked, now you should see neutral words with values close to zero. In this case, \"the\" is near zero but slightly positive, so it was probably used in more positive reviews than negative reviews. But look at \"amazing\"'s ratio - it's above `1`, showing it is clearly a word with positive sentiment. And \"terrible\" has a similar score, but in the opposite direction, so it's below `-1`. It's now clear that both of these words are associated with specific, opposing sentiments.\n",
    "\n",
    "Now run the following cells to see more ratios. \n",
    "\n",
    "The first cell displays all the words, ordered by how associated they are with postive reviews. (Your notebook will most likely truncate the output so you won't actually see *all* the words in the list.)\n",
    "\n",
    "The second cell displays the 30 words most associated with negative reviews by reversing the order of the first list and then looking at the first 30 words. (If you want the second cell to display all the words, ordered by how associated they are with negative reviews, you could just write `reversed(pos_neg_ratios.most_common())`.)\n",
    "\n",
    "You should continue to see values similar to the earlier ones we checked neutral words will be close to `0`, words will get more positive as their ratios approach and go above `1`, and words will get more negative as their ratios approach and go below `-1`. That's why we decided to use the logs instead of the raw ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bs', 2.3978952727983707),\n",
       " ('antixa', 2.1972245773362196),\n",
       " ('levophed', 2.0794415416798357),\n",
       " ('drip', 2.0053335695261141),\n",
       " ('ptt', 1.9459101490553132),\n",
       " ('infused', 1.8718021769015913),\n",
       " ('ebox', 1.791759469228055),\n",
       " ('programmed', 1.791759469228055),\n",
       " ('klonopin', 1.791759469228055),\n",
       " ('pump', 1.6582280766035324),\n",
       " ('2300', 1.6094379124341003),\n",
       " ('units/kg/hr', 1.6094379124341003),\n",
       " ('anti', 1.6094379124341003),\n",
       " ('parameters', 1.6094379124341003),\n",
       " ('infusing', 1.4350845252893227),\n",
       " ('hanging', 1.3862943611198906),\n",
       " ('initial', 1.3862943611198906),\n",
       " ('urgent', 1.3862943611198906),\n",
       " ('0700', 1.3862943611198906),\n",
       " ('13', 1.3862943611198906),\n",
       " ('pt/inr', 1.3862943611198906),\n",
       " ('k+', 1.3862943611198906),\n",
       " ('1230', 1.3862943611198906),\n",
       " ('port', 1.3862943611198906),\n",
       " ('6/19', 1.3862943611198906),\n",
       " ('definity', 1.3862943611198906),\n",
       " ('anti-xa', 1.3862943611198906),\n",
       " ('connected', 1.3862943611198906),\n",
       " ('>1', 1.3862943611198906),\n",
       " ('5712', 1.3862943611198906),\n",
       " ('xa', 1.3862943611198906),\n",
       " ('pneumonia', 1.3862943611198906),\n",
       " ('1ml/hr', 1.3862943611198906),\n",
       " ('settings', 1.3862943611198906),\n",
       " ('conjugate', 1.3862943611198906),\n",
       " ('lispro', 1.3862943611198906),\n",
       " ('tpn', 1.3862943611198906),\n",
       " ('diprivan', 1.3862943611198906),\n",
       " ('1700', 1.2992829841302609),\n",
       " ('witnessed', 1.2527629684953681),\n",
       " ('pumps', 1.2527629684953681),\n",
       " ('protonix', 1.2527629684953681),\n",
       " ('fluids', 1.1895840668738364),\n",
       " ('heparin', 1.1676051601550612),\n",
       " ('approx', 1.0986122886681098),\n",
       " ('#1', 1.0986122886681098),\n",
       " ('bedside', 1.0986122886681098),\n",
       " ('6500', 1.0986122886681098),\n",
       " ('tetanus', 1.0986122886681098),\n",
       " ('vaccination', 1.0986122886681098),\n",
       " ('member', 1.0986122886681098),\n",
       " ('myself', 1.0986122886681098),\n",
       " ('knowing', 1.0986122886681098),\n",
       " ('bupropion', 1.0986122886681098),\n",
       " ('pitocin', 1.0986122886681098),\n",
       " ('7/22/15', 1.0986122886681098),\n",
       " ('1330', 1.0986122886681098),\n",
       " ('15mg', 1.0986122886681098),\n",
       " ('misread', 1.0986122886681098),\n",
       " ('kvo', 1.0986122886681098),\n",
       " ('zyrtec', 1.0986122886681098),\n",
       " ('meq', 1.0986122886681098),\n",
       " ('kcl', 1.0986122886681098),\n",
       " ('ms', 1.0986122886681098),\n",
       " ('chamber', 1.0986122886681098),\n",
       " ('separate', 1.0986122886681098),\n",
       " ('18units/kg/hr', 1.0986122886681098),\n",
       " ('15units/kg/hr', 1.0986122886681098),\n",
       " ('14units/kg/hr', 1.0986122886681098),\n",
       " ('bronchoscopy', 1.0986122886681098),\n",
       " ('3%', 1.0986122886681098),\n",
       " ('hypertonic', 1.0986122886681098),\n",
       " ('height', 1.0986122886681098),\n",
       " ('activity', 1.0986122886681098),\n",
       " ('apparent', 1.0986122886681098),\n",
       " ('intensivist', 1.0986122886681098),\n",
       " ('discontinuation', 1.0986122886681098),\n",
       " ('05ml', 1.0986122886681098),\n",
       " ('mg/min', 1.0986122886681098),\n",
       " ('49', 1.0986122886681098),\n",
       " ('11mg', 1.0986122886681098),\n",
       " ('interval', 1.0986122886681098),\n",
       " ('setting', 1.0986122886681098),\n",
       " ('1224', 1.0986122886681098),\n",
       " ('8cc/hr', 1.0986122886681098),\n",
       " ('2348', 1.0986122886681098),\n",
       " ('oxyir', 1.0986122886681098),\n",
       " ('precedex', 1.0986122886681098),\n",
       " ('protocol', 1.0608719606852626),\n",
       " ('gtt', 1.0116009116784799),\n",
       " ('bolus', 0.99852883011112725),\n",
       " ('weight', 0.96940055718810347),\n",
       " ('units', 0.95551144502743635),\n",
       " ('guardian', 0.91629073187415511),\n",
       " ('drawn', 0.91629073187415511),\n",
       " ('infuse', 0.91629073187415511),\n",
       " ('notice', 0.91629073187415511),\n",
       " ('sliding', 0.91629073187415511),\n",
       " ('occurred', 0.91629073187415511),\n",
       " ('policy', 0.91629073187415511),\n",
       " ('injections', 0.91629073187415511),\n",
       " ('happened', 0.78845736036427028),\n",
       " ('antibiotic', 0.69314718055994529),\n",
       " ('potassium', 0.69314718055994529),\n",
       " ('three', 0.69314718055994529),\n",
       " ('end', 0.69314718055994529),\n",
       " ('passed', 0.69314718055994529),\n",
       " ('pole', 0.69314718055994529),\n",
       " ('aprn', 0.69314718055994529),\n",
       " ('component', 0.69314718055994529),\n",
       " ('cap', 0.69314718055994529),\n",
       " ('reflect', 0.69314718055994529),\n",
       " ('determined', 0.69314718055994529),\n",
       " ('nothing', 0.69314718055994529),\n",
       " ('higher', 0.69314718055994529),\n",
       " ('understood', 0.69314718055994529),\n",
       " ('ultimately', 0.69314718055994529),\n",
       " ('vanco', 0.69314718055994529),\n",
       " ('teh', 0.69314718055994529),\n",
       " ('id', 0.69314718055994529),\n",
       " ('ekg', 0.69314718055994529),\n",
       " ('revealed', 0.69314718055994529),\n",
       " ('.6', 0.69314718055994529),\n",
       " ('26', 0.69314718055994529),\n",
       " ('.8', 0.69314718055994529),\n",
       " ('hospitalized', 0.69314718055994529),\n",
       " ('temporary', 0.69314718055994529),\n",
       " ('0653', 0.69314718055994529),\n",
       " ('naproxen', 0.69314718055994529),\n",
       " ('prilosec', 0.69314718055994529),\n",
       " ('forgotten', 0.69314718055994529),\n",
       " ('kaexalate', 0.69314718055994529),\n",
       " ('7/23/15', 0.69314718055994529),\n",
       " ('1840', 0.69314718055994529),\n",
       " ('penicillin', 0.69314718055994529),\n",
       " ('sdcu', 0.69314718055994529),\n",
       " ('10gm', 0.69314718055994529),\n",
       " ('pod', 0.69314718055994529),\n",
       " ('0745', 0.69314718055994529),\n",
       " ('g', 0.69314718055994529),\n",
       " ('brough', 0.69314718055994529),\n",
       " ('4/23/15', 0.69314718055994529),\n",
       " ('benefit', 0.69314718055994529),\n",
       " ('meclizine', 0.69314718055994529),\n",
       " ('31', 0.69314718055994529),\n",
       " ('inserted', 0.69314718055994529),\n",
       " ('g-tube', 0.69314718055994529),\n",
       " ('bulb', 0.69314718055994529),\n",
       " ('recognized', 0.69314718055994529),\n",
       " ('remembered', 0.69314718055994529),\n",
       " ('20meq', 0.69314718055994529),\n",
       " ('adn', 0.69314718055994529),\n",
       " ('trazodone', 0.69314718055994529),\n",
       " ('continuously', 0.69314718055994529),\n",
       " ('6/20', 0.69314718055994529),\n",
       " ('.25', 0.69314718055994529),\n",
       " ('codeine', 0.69314718055994529),\n",
       " ('meropenem', 0.69314718055994529),\n",
       " ('re-timed', 0.69314718055994529),\n",
       " ('runs', 0.69314718055994529),\n",
       " ('kayexlate', 0.69314718055994529),\n",
       " ('7/27', 0.69314718055994529),\n",
       " ('oxycodone/apap', 0.69314718055994529),\n",
       " ('igg', 0.69314718055994529),\n",
       " ('rabies', 0.69314718055994529),\n",
       " ('vacine', 0.69314718055994529),\n",
       " ('dorsogluteal', 0.69314718055994529),\n",
       " ('milrinone', 0.69314718055994529),\n",
       " ('granddaughter', 0.69314718055994529),\n",
       " ('pharmaceutical', 0.69314718055994529),\n",
       " ('company', 0.69314718055994529),\n",
       " ('restricted', 0.69314718055994529),\n",
       " ('cvtu', 0.69314718055994529),\n",
       " ('transfered', 0.69314718055994529),\n",
       " ('hx', 0.69314718055994529),\n",
       " ('stevens-johnson', 0.69314718055994529),\n",
       " ('syndrome', 0.69314718055994529),\n",
       " ('6/18', 0.69314718055994529),\n",
       " ('perflutren', 0.69314718055994529),\n",
       " ('microsphere', 0.69314718055994529),\n",
       " ('suspected', 0.69314718055994529),\n",
       " ('right-to-left', 0.69314718055994529),\n",
       " ('important', 0.69314718055994529),\n",
       " ('serious', 0.69314718055994529),\n",
       " ('cardiopulmonary', 0.69314718055994529),\n",
       " ('[see', 0.69314718055994529),\n",
       " ('precautions', 0.69314718055994529),\n",
       " (')]', 0.69314718055994529),\n",
       " ('discovery', 0.69314718055994529),\n",
       " ('1530', 0.69314718055994529),\n",
       " ('124', 0.69314718055994529),\n",
       " ('126', 0.69314718055994529),\n",
       " ('cvicu', 0.69314718055994529),\n",
       " ('committee', 0.69314718055994529),\n",
       " ('infusions', 0.69314718055994529),\n",
       " ('careful', 0.69314718055994529),\n",
       " ('c-section', 0.69314718055994529),\n",
       " ('inquired', 0.69314718055994529),\n",
       " ('mean', 0.69314718055994529),\n",
       " ('183', 0.69314718055994529),\n",
       " ('recheck', 0.69314718055994529),\n",
       " ('indicates', 0.69314718055994529),\n",
       " ('drew', 0.69314718055994529),\n",
       " ('5mg/hr', 0.69314718055994529),\n",
       " ('adrenal', 0.69314718055994529),\n",
       " ('crisis', 0.69314718055994529),\n",
       " ('negative', 0.69314718055994529),\n",
       " ('temp', 0.69314718055994529),\n",
       " ('pulm', 0.69314718055994529),\n",
       " ('2330', 0.69314718055994529),\n",
       " ('flowsheet', 0.69314718055994529),\n",
       " ('5mg/min', 0.69314718055994529),\n",
       " ('113kg', 0.69314718055994529),\n",
       " ('metoporol', 0.69314718055994529),\n",
       " ('sepsis', 0.69314718055994529),\n",
       " ('plum', 0.69314718055994529),\n",
       " ('5kg', 0.69314718055994529),\n",
       " ('105', 0.69314718055994529),\n",
       " ('8kg', 0.69314718055994529),\n",
       " ('1958', 0.69314718055994529),\n",
       " ('<0', 0.69314718055994529),\n",
       " ('identified', 0.69314718055994529),\n",
       " ('regards', 0.69314718055994529),\n",
       " ('amt', 0.69314718055994529),\n",
       " ('positive', 0.69314718055994529),\n",
       " ('clamped', 0.69314718055994529),\n",
       " ('uncharted', 0.69314718055994529),\n",
       " ('lowest', 0.69314718055994529),\n",
       " ('quadrupled', 0.69314718055994529),\n",
       " ('alarm', 0.69314718055994529),\n",
       " ('transplant', 0.69314718055994529),\n",
       " ('frequent', 0.69314718055994529),\n",
       " ('utis', 0.69314718055994529),\n",
       " ('septic', 0.69314718055994529),\n",
       " ('shock', 0.69314718055994529),\n",
       " ('slept', 0.69314718055994529),\n",
       " ('wnl', 0.69314718055994529),\n",
       " ('obs', 0.69314718055994529),\n",
       " ('pulling', 0.69314718055994529),\n",
       " ('observe', 0.69314718055994529),\n",
       " ('sterile', 0.69314718055994529),\n",
       " ('mencyw-135', 0.69314718055994529),\n",
       " ('generated', 0.69314718055994529),\n",
       " ('cow', 0.69314718055994529),\n",
       " ('accucheck', 0.69314718055994529),\n",
       " ('405', 0.69314718055994529),\n",
       " ('17:00', 0.69314718055994529),\n",
       " ('visiting', 0.69314718055994529),\n",
       " ('intreglin', 0.69314718055994529),\n",
       " ('100cc/hr', 0.69314718055994529),\n",
       " ('sigma', 0.69314718055994529),\n",
       " ('self', 0.69314718055994529),\n",
       " ('dressing', 0.69314718055994529),\n",
       " ('allergen', 0.69314718055994529),\n",
       " ('11/24/15', 0.69314718055994529),\n",
       " ('264', 0.69314718055994529),\n",
       " ('mins', 0.69314718055994529),\n",
       " ('sub', 0.69314718055994529),\n",
       " ('4/14', 0.69314718055994529),\n",
       " ('37', 0.69314718055994529),\n",
       " ('11/23/15', 0.69314718055994529),\n",
       " ('synthroid', 0.69314718055994529),\n",
       " ('12/4', 0.69314718055994529),\n",
       " ('outgoing', 0.69314718055994529),\n",
       " ('maximum', 0.69314718055994529),\n",
       " ('reprogrammed', 0.69314718055994529),\n",
       " ('8/9/15', 0.69314718055994529),\n",
       " ('mls', 0.69314718055994529),\n",
       " ('turning', 0.69314718055994529),\n",
       " ('7am', 0.69314718055994529),\n",
       " ('lactulose', 0.69314718055994529),\n",
       " (\"it's\", 0.69314718055994529),\n",
       " ('refuse', 0.69314718055994529),\n",
       " ('connector', 0.69314718055994529),\n",
       " ('5ml/hr', 0.69314718055994529),\n",
       " ('alarmed', 0.69314718055994529),\n",
       " ('alerted', 0.69314718055994529),\n",
       " ('marinol', 0.69314718055994529),\n",
       " ('preparing', 0.69314718055994529),\n",
       " ('ineffective', 0.69314718055994529),\n",
       " ('channel', 0.69314718055994529),\n",
       " ('insulin', 0.64662716492505246),\n",
       " ('running', 0.63598876671999671),\n",
       " ('realized', 0.61903920840622351),\n",
       " ('situation', 0.60613580357031549),\n",
       " ('hung', 0.5753641449035618),\n",
       " ('2100', 0.5389965007326869),\n",
       " ('mar', 0.52324814376454787),\n",
       " ('charted', 0.51082562376599072),\n",
       " ('needs', 0.51082562376599072),\n",
       " ('according', 0.51082562376599072),\n",
       " ('0930', 0.51082562376599072),\n",
       " ('decrease', 0.51082562376599072),\n",
       " ('rocephin', 0.51082562376599072),\n",
       " ('proper', 0.51082562376599072),\n",
       " ('antibiotics', 0.51082562376599072),\n",
       " ('forgot', 0.51082562376599072),\n",
       " ('fluid', 0.47000362924573563),\n",
       " (\"didn't\", 0.40546510810816438),\n",
       " ('75', 0.40546510810816438),\n",
       " ('pass', 0.40546510810816438),\n",
       " ('oriented', 0.40546510810816438),\n",
       " ('cut', 0.40546510810816438),\n",
       " ('shot', 0.40546510810816438),\n",
       " ('task', 0.40546510810816438),\n",
       " ('recieving', 0.40546510810816438),\n",
       " ('future', 0.40546510810816438),\n",
       " ('cta', 0.40546510810816438),\n",
       " ('assumed', 0.40546510810816438),\n",
       " ('1600', 0.40546510810816438),\n",
       " ('arrive', 0.40546510810816438),\n",
       " ('ambien', 0.40546510810816438),\n",
       " ('empty', 0.40546510810816438),\n",
       " ('prbc', 0.40546510810816438),\n",
       " ('baseline', 0.40546510810816438),\n",
       " ('assess', 0.40546510810816438),\n",
       " ('cm', 0.40546510810816438),\n",
       " ('tl', 0.40546510810816438),\n",
       " ('previously', 0.40546510810816438),\n",
       " ('anesthesiologist', 0.40546510810816438),\n",
       " ('properly', 0.40546510810816438),\n",
       " ('paperwork', 0.40546510810816438),\n",
       " ('hep', 0.40546510810816438),\n",
       " ('unclear', 0.40546510810816438),\n",
       " (\".'s\", 0.40546510810816438),\n",
       " ('expiration', 0.40546510810816438),\n",
       " ('shows', 0.40546510810816438),\n",
       " ('lower', 0.40546510810816438),\n",
       " ('afib', 0.40546510810816438),\n",
       " ('window', 0.40546510810816438),\n",
       " ('student', 0.40546510810816438),\n",
       " ('report', 0.37156355643248301),\n",
       " (\"wasn't\", 0.33647223662121289),\n",
       " ('tubing', 0.33647223662121289),\n",
       " ('count', 0.33647223662121289),\n",
       " ('1/2', 0.33647223662121289),\n",
       " ('site', 0.33647223662121289),\n",
       " ('im', 0.28768207245178085),\n",
       " ('line', 0.28768207245178085),\n",
       " ('secondary', 0.28768207245178085),\n",
       " ('whom', 0.28768207245178085),\n",
       " ('knew', 0.28768207245178085),\n",
       " ('long', 0.28768207245178085),\n",
       " ('1500', 0.28768207245178085),\n",
       " ('d5w', 0.28768207245178085),\n",
       " ('1900', 0.28768207245178085),\n",
       " ('east', 0.28768207245178085),\n",
       " ('anything', 0.28768207245178085),\n",
       " ('dye', 0.28768207245178085),\n",
       " ('present', 0.28768207245178085),\n",
       " ('wrist', 0.28768207245178085),\n",
       " ('admin', 0.28768207245178085),\n",
       " ('should', 0.25131442828090617),\n",
       " ('half', 0.25131442828090617),\n",
       " ('bag', 0.22314355131420976),\n",
       " ('rate', 0.22314355131420976),\n",
       " ('unknown', 0.22314355131420976),\n",
       " ('1800', 0.22314355131420976),\n",
       " ('glucose', 0.22314355131420976),\n",
       " ('80mg', 0.22314355131420976),\n",
       " ('tramadol', 0.22314355131420976),\n",
       " ('restart', 0.22314355131420976),\n",
       " ('incident', 0.22314355131420976),\n",
       " ('scale', 0.22314355131420976),\n",
       " ('night', 0.20067069546215124),\n",
       " (\"pt's\", 0.1941560144409574),\n",
       " ('writer', 0.18232155679395459),\n",
       " ('second', 0.18232155679395459),\n",
       " ('primary', 0.18232155679395459),\n",
       " ('route', 0.18232155679395459),\n",
       " ('vitals', 0.18232155679395459),\n",
       " ('shift', 0.17435338714477774),\n",
       " ('0800', 0.15415067982725836),\n",
       " ('missed', 0.13353139262452257),\n",
       " ('administration', 0.13353139262452257),\n",
       " ('.(', 0.13353139262452257),\n",
       " ('mcg', 0.13353139262452257),\n",
       " ('infusion', 0.11778303565638346),\n",
       " ('receive', 0.11778303565638346),\n",
       " ('discontinued', 0.087011376989629699),\n",
       " ('care', 0.080042707673536356),\n",
       " ('charge', 0.080042707673536356),\n",
       " ('reported', 0.080042707673536356),\n",
       " ('scanned', 0.068992871486951421),\n",
       " ('5mg', 0.06062462181643484),\n",
       " ('pca', 0.057158413839948623),\n",
       " ('new', 0.009950330853168092),\n",
       " ('2mg', 0.009950330853168092),\n",
       " ('&', 0.009950330853168092),\n",
       " ('very', 0.009950330853168092),\n",
       " ('pulled', 0.009950330853168092),\n",
       " ('24', 0.009950330853168092),\n",
       " ('lpn', 0.009950330853168092),\n",
       " ('lasix', 0.009950330853168092),\n",
       " ('along', 0.009950330853168092),\n",
       " ('dosage', 0.009950330853168092),\n",
       " ('low', 0.009950330853168092),\n",
       " ('ativan', 0.009950330853168092),\n",
       " ('wasted', 0.009950330853168092),\n",
       " ('surgeon', 0.009950330853168092),\n",
       " ('rash', 0.009950330853168092),\n",
       " ('speaking', 0.009950330853168092),\n",
       " ('supposed', 0.009950330853168092),\n",
       " ('ml/hr', 0.009950330853168092),\n",
       " ('preop', 0.009950330853168092),\n",
       " ('ivig', 0.009950330853168092),\n",
       " ('based', 0.009950330853168092),\n",
       " ('40', 0.009950330853168092),\n",
       " ('trying', 0.009950330853168092),\n",
       " ('period', 0.009950330853168092),\n",
       " ('meant', 0.009950330853168092),\n",
       " ('gotten', 0.009950330853168092),\n",
       " ('rather', 0.009950330853168092),\n",
       " ('best', 0.009950330853168092),\n",
       " ('controlled', 0.009950330853168092),\n",
       " ('0630', 0.009950330853168092),\n",
       " ('timed', 0.009950330853168092),\n",
       " ('early', 0.009950330853168092),\n",
       " ('discrepancy', 0.009950330853168092),\n",
       " ('followed', 0.009950330853168092),\n",
       " ('adjusted', 0.009950330853168092),\n",
       " ('cause', 0.009950330853168092),\n",
       " ('vistaril', 0.009950330853168092),\n",
       " ('talked', 0.009950330853168092),\n",
       " ('1300', 0.009950330853168092),\n",
       " ('probably', 0.009950330853168092),\n",
       " ('explain', 0.009950330853168092),\n",
       " ('sodium', 0.009950330853168092),\n",
       " ('therefore', 0.009950330853168092),\n",
       " ('most', 0.009950330853168092),\n",
       " ('rns', 0.009950330853168092),\n",
       " ('remove', 0.009950330853168092),\n",
       " ('attached', 0.009950330853168092),\n",
       " ('catheter', 0.009950330853168092),\n",
       " ('regular', 0.009950330853168092),\n",
       " ('okay', 0.009950330853168092),\n",
       " ('necessary', 0.009950330853168092),\n",
       " ('entire', 0.009950330853168092),\n",
       " ('6/19/15', 0.009950330853168092),\n",
       " ('immediatley', 0.009950330853168092),\n",
       " ('abd', 0.009950330853168092),\n",
       " ('lr', 0.009950330853168092),\n",
       " ('causing', 0.009950330853168092),\n",
       " ('narc', 0.009950330853168092),\n",
       " ('witness', 0.009950330853168092),\n",
       " ('levels', 0.009950330853168092),\n",
       " ('hooked', 0.009950330853168092),\n",
       " ('inadvertently', 0.009950330853168092),\n",
       " ('23', 0.009950330853168092),\n",
       " ('significantly', 0.009950330853168092),\n",
       " ('2000', 0.009950330853168092),\n",
       " ('omeprazole', 0.009950330853168092),\n",
       " ('possibly', 0.009950330853168092),\n",
       " ('imdur', 0.009950330853168092),\n",
       " ('4/17', 0.009950330853168092),\n",
       " ('.25mg', 0.009950330853168092),\n",
       " ('noon', 0.009950330853168092),\n",
       " ('hang', 0.009950330853168092),\n",
       " ('0200', 0.009950330853168092),\n",
       " ('asap', 0.009950330853168092),\n",
       " ('subq', 0.009950330853168092),\n",
       " ('alprazolam', 0.009950330853168092),\n",
       " ('1000', 0.009950330853168092),\n",
       " ('female', 0.009950330853168092),\n",
       " ('1930', 0.009950330853168092),\n",
       " ('measures', 0.009950330853168092),\n",
       " ('bleed', 0.009950330853168092),\n",
       " ('octreotide', 0.009950330853168092),\n",
       " ('ventricular', 0.009950330853168092),\n",
       " ('solution', 0.009950330853168092),\n",
       " ('body', 0.009950330853168092),\n",
       " ('reactions', 0.009950330853168092),\n",
       " ('draw', 0.009950330853168092),\n",
       " ('fix', 0.009950330853168092),\n",
       " ('addition', 0.009950330853168092),\n",
       " ('talk', 0.009950330853168092),\n",
       " ('locked', 0.009950330853168092),\n",
       " ('attempts', 0.009950330853168092),\n",
       " ('cc/hr', 0.009950330853168092),\n",
       " ('lead', 0.009950330853168092),\n",
       " ('pe', 0.009950330853168092),\n",
       " ('six', 0.009950330853168092),\n",
       " ('gone', 0.009950330853168092),\n",
       " ('agitated', 0.009950330853168092),\n",
       " ('repeat', 0.009950330853168092),\n",
       " ('diluent', 0.009950330853168092),\n",
       " ('follow-up', 0.009950330853168092),\n",
       " ('5-fu', 0.009950330853168092),\n",
       " ('d/t', 0.009950330853168092),\n",
       " ('admit', 0.009950330853168092),\n",
       " ('shoulder', 0.009950330853168092),\n",
       " ('titrate', 0.009950330853168092),\n",
       " ('hour', -0.043566986636409621),\n",
       " ('while', -0.050055670467200608),\n",
       " ('given', -0.061005983833861945),\n",
       " ('already', -0.063396316558794116),\n",
       " ('instead', -0.066218944604226199),\n",
       " ('over', -0.076161360965564029),\n",
       " ('monitor', -0.076161360965564029),\n",
       " ('hours', -0.080078940213985011),\n",
       " ('noticed', -0.084370239765990521),\n",
       " ('verify', -0.084370239765990521),\n",
       " ('previous', -0.084370239765990521),\n",
       " ('looked', -0.09431067947124129),\n",
       " ('documentation', -0.10659584626581911),\n",
       " ('tab', -0.12216763397420753),\n",
       " ('vial', -0.12216763397420753),\n",
       " ('transfer', -0.12216763397420753),\n",
       " ('adverse', -0.12216763397420753),\n",
       " ('total', -0.12216763397420753),\n",
       " ('procedure', -0.12216763397420753),\n",
       " ('current', -0.14255154398390646),\n",
       " ('nurse', -0.14462595378050636),\n",
       " ('scheduled', -0.15082288973458366),\n",
       " ('information', -0.15530519217408328),\n",
       " ('7', -0.15530519217408328),\n",
       " ('ns', -0.15530519217408328),\n",
       " ('per', -0.15730379381866677),\n",
       " ('2200', -0.17039298592868077),\n",
       " ('full', -0.17039298592868077),\n",
       " ('want', -0.17039298592868077),\n",
       " ('12', -0.17039298592868077),\n",
       " ('related', -0.17039298592868077),\n",
       " ('much', -0.17039298592868077),\n",
       " ('appears', -0.17039298592868077),\n",
       " ('remained', -0.17039298592868077),\n",
       " ('error', -0.18852256152650351),\n",
       " ('1mg', -0.18852256152650351),\n",
       " ('set', -0.21072103131565253),\n",
       " ('15', -0.21072103131565253),\n",
       " ('you', -0.21072103131565253),\n",
       " ('ask', -0.21072103131565253),\n",
       " ('few', -0.21072103131565253),\n",
       " ('nor', -0.21072103131565253),\n",
       " ('ran', -0.21072103131565253),\n",
       " ('icu', -0.23853923679218322),\n",
       " ('follow', -0.23853923679218322),\n",
       " ('4mg', -0.23853923679218322),\n",
       " ('solumedrol', -0.23853923679218322),\n",
       " ('vaccine', -0.24944803920094466),\n",
       " ('last', -0.24944803920094466),\n",
       " ('pt', -0.25439609481831421),\n",
       " ('only', -0.25889410197583829),\n",
       " ('morning', -0.25889410197583829),\n",
       " ('about', -0.26136476413440751),\n",
       " ('when', -0.2744368457017603),\n",
       " ('my', -0.2744368457017603),\n",
       " ('what', -0.2744368457017603),\n",
       " ('never', -0.2744368457017603),\n",
       " ('every', -0.2744368457017603),\n",
       " ('pill', -0.2744368457017603),\n",
       " ('dosing', -0.2744368457017603),\n",
       " ('stable', -0.2744368457017603),\n",
       " ('0730', -0.2744368457017603),\n",
       " ('including', -0.2744368457017603),\n",
       " ('think', -0.2744368457017603),\n",
       " ('suppose', -0.2744368457017603),\n",
       " ('attention', -0.2744368457017603),\n",
       " ('initially', -0.2744368457017603),\n",
       " ('accidentally', -0.2744368457017603),\n",
       " ('administering', -0.2744368457017603),\n",
       " ('gi', -0.2744368457017603),\n",
       " ('verifying', -0.2744368457017603),\n",
       " ('vital', -0.2744368457017603),\n",
       " ('notify', -0.2744368457017603),\n",
       " ('notifed', -0.2744368457017603),\n",
       " ('off', -0.28884216538931151),\n",
       " ('found', -0.29661070319608235),\n",
       " ('later', -0.29661070319608235),\n",
       " ('med', -0.29950799625569546),\n",
       " ('due', -0.30147038959163674),\n",
       " ('read', -0.30479740467104893),\n",
       " ('around', -0.30479740467104893),\n",
       " ('i', -0.31684095467199835),\n",
       " ('effects', -0.3225693314522215),\n",
       " ('decreased', -0.3225693314522215),\n",
       " ('monitored', -0.3225693314522215),\n",
       " ('give', -0.32696204662022071),\n",
       " ('at', -0.33401372278300556),\n",
       " ('iv', -0.33831551858048403),\n",
       " ('levaquin', -0.34249030894677601),\n",
       " ('alert', -0.34249030894677601),\n",
       " ('hr', -0.35338366285465966),\n",
       " ('50', -0.35338366285465966),\n",
       " ('event', -0.35338366285465966),\n",
       " ('one', -0.35599490311007687),\n",
       " ('who', -0.35716767614875056),\n",
       " ('with', -0.36067752721394608),\n",
       " ('change', -0.36498001243721717),\n",
       " ('came', -0.3710636813908319),\n",
       " ('notified', -0.37553296257312901),\n",
       " ('which', -0.37735053903303395),\n",
       " ('1', -0.38325099219405839),\n",
       " ('[redacted]', -0.38618782886714587),\n",
       " ('gave', -0.39057649561441377),\n",
       " ('blood', -0.39057649561441377),\n",
       " ('until', -0.39057649561441377),\n",
       " ('aware', -0.39057649561441377),\n",
       " ('x', -0.39057649561441377),\n",
       " ('done', -0.39057649561441377),\n",
       " ('than', -0.39057649561441377),\n",
       " ('note', -0.39057649561441377),\n",
       " ('sugar', -0.39057649561441377),\n",
       " ('attempted', -0.39057649561441377),\n",
       " ('inform', -0.39057649561441377),\n",
       " ('eye', -0.39057649561441377),\n",
       " ('plavix', -0.39057649561441377),\n",
       " ('refused', -0.39057649561441377),\n",
       " ('appropriate', -0.39057649561441377),\n",
       " ('flush', -0.39057649561441377),\n",
       " ('pts', -0.39057649561441377),\n",
       " ('run', -0.39057649561441377),\n",
       " ('16', -0.39057649561441377),\n",
       " ('each', -0.39057649561441377),\n",
       " ('help', -0.39057649561441377),\n",
       " (\"physician's\", -0.39057649561441377),\n",
       " ('carried', -0.39057649561441377),\n",
       " ('immunization', -0.39057649561441377),\n",
       " ('appear', -0.39057649561441377),\n",
       " ('regardless', -0.39057649561441377),\n",
       " ('find', -0.39057649561441377),\n",
       " ('b/c', -0.39057649561441377),\n",
       " ('control', -0.39057649561441377),\n",
       " ('tpa', -0.39057649561441377),\n",
       " ('education', -0.39057649561441377),\n",
       " ('showing', -0.39057649561441377),\n",
       " ('labs', -0.39057649561441377),\n",
       " ('failed', -0.39057649561441377),\n",
       " ('supervisor', -0.39057649561441377),\n",
       " ('assessment', -0.39057649561441377),\n",
       " ('hypoglycemia', -0.39057649561441377),\n",
       " ('1gm', -0.39057649561441377),\n",
       " ('effect', -0.39057649561441377),\n",
       " ('schedule', -0.39057649561441377),\n",
       " ('resolved', -0.39057649561441377),\n",
       " ('charges', -0.39057649561441377),\n",
       " ('0935', -0.39057649561441377),\n",
       " ('exactly', -0.39057649561441377),\n",
       " (\"rn's\", -0.39057649561441377),\n",
       " ('completely', -0.39057649561441377),\n",
       " ('drugs', -0.39057649561441377),\n",
       " ('created', -0.39057649561441377),\n",
       " ('year', -0.39057649561441377),\n",
       " ('central', -0.39057649561441377),\n",
       " ('calling', -0.39057649561441377),\n",
       " ('believed', -0.39057649561441377),\n",
       " ('300', -0.39057649561441377),\n",
       " ('clarified', -0.39057649561441377),\n",
       " ('systolic', -0.39057649561441377),\n",
       " ('together', -0.39057649561441377),\n",
       " ('steroid', -0.39057649561441377),\n",
       " ('against', -0.39057649561441377),\n",
       " ('bilateral', -0.39057649561441377),\n",
       " ('18', -0.39057649561441377),\n",
       " ('whether', -0.39057649561441377),\n",
       " ('max', -0.39057649561441377),\n",
       " ('f/u', -0.39057649561441377),\n",
       " ('strength', -0.39057649561441377),\n",
       " ('equal', -0.39057649561441377),\n",
       " ('looking', -0.39057649561441377),\n",
       " ('abilify', -0.39057649561441377),\n",
       " ('states', -0.40475107737450733),\n",
       " ('be', -0.40770900306883634),\n",
       " ('there', -0.41088794842961773),\n",
       " ('again', -0.41998173097510666),\n",
       " ('xxxx', -0.42639694414919987),\n",
       " ('been', -0.43009171164122656),\n",
       " ('left', -0.43078291609245423),\n",
       " ('or', -0.43179225253948589),\n",
       " ('level', -0.43639302898322102),\n",
       " ('of', -0.44852174042983584),\n",
       " ('er', -0.45413028008944539),\n",
       " ('increased', -0.45413028008944539),\n",
       " ('down', -0.45413028008944539),\n",
       " ('seen', -0.45413028008944539),\n",
       " ('0900', -0.45413028008944539),\n",
       " ('waste', -0.45413028008944539),\n",
       " ('by', -0.46840490788203853),\n",
       " ('once', -0.46938843390181745),\n",
       " ('it', -0.47167945125602956),\n",
       " ('am', -0.47336410804472312),\n",
       " ('removed', -0.47336410804472312),\n",
       " ('started', -0.48014180382738864),\n",
       " ('ordered', -0.48126682152444628),\n",
       " ('so', -0.48570520368246339),\n",
       " ('0', -0.49429632181478012),\n",
       " ('went', -0.49429632181478012),\n",
       " ('saline', -0.49429632181478012),\n",
       " ('ivpb', -0.49429632181478012),\n",
       " ('issue', -0.49429632181478012),\n",
       " ('thinking', -0.49429632181478012),\n",
       " ('busy', -0.49429632181478012),\n",
       " ('quickmar', -0.49429632181478012),\n",
       " ('metformin', -0.49429632181478012),\n",
       " ('delay', -0.49429632181478012),\n",
       " ('access', -0.49429632181478012),\n",
       " ('held', -0.49429632181478012),\n",
       " ('.5mg', -0.49429632181478012),\n",
       " ('hs', -0.49429632181478012),\n",
       " ('stating', -0.49429632181478012),\n",
       " ('decided', -0.49429632181478012),\n",
       " ('versed', -0.49429632181478012),\n",
       " ('no', -0.51377113399574748),\n",
       " ('start', -0.51377113399574748),\n",
       " ('is', -0.51761948318739881),\n",
       " ('noted', -0.52199892436411588),\n",
       " ('does', -0.52199892436411588),\n",
       " ('mistake', -0.52199892436411588),\n",
       " ('available', -0.52941845684260658),\n",
       " ('that', -0.533972820956642),\n",
       " ('have', -0.53428711044498867),\n",
       " ('doctor', -0.537053101602876),\n",
       " ('was', -0.53717907268260212),\n",
       " ('staff', -0.54226714960080968),\n",
       " ('labeled', -0.54226714960080968),\n",
       " ('heart', -0.54226714960080968),\n",
       " ('issues', -0.54226714960080968),\n",
       " ('harm', -0.54226714960080968),\n",
       " ('kept', -0.54226714960080968),\n",
       " ('checking', -0.54226714960080968),\n",
       " ('either', -0.54226714960080968),\n",
       " ('double', -0.54226714960080968),\n",
       " ('mom', -0.54226714960080968),\n",
       " ('dr', -0.54429979456758359),\n",
       " ('day', -0.55300723780228545),\n",
       " ('said', -0.55494721551898296),\n",
       " ('documented', -0.55774254355374231),\n",
       " ('had', -0.56538823042391328),\n",
       " ('times', -0.56994674677378798),\n",
       " ('manager', -0.56994674677378798),\n",
       " ('emergency', -0.56994674677378798),\n",
       " ('showed', -0.56994674677378798),\n",
       " ('into', -0.57513025412948648),\n",
       " ('emar', -0.57981849525294205),\n",
       " ('dose', -0.58270283529702838),\n",
       " ('stated', -0.58796849961486664),\n",
       " ('recieved', -0.58796849961486664),\n",
       " ('time', -0.59084396526464977),\n",
       " ('well', -0.60063812303533215),\n",
       " ('just', -0.60063812303533215),\n",
       " ('continuous', -0.60063812303533215),\n",
       " ('do', -0.6100322738494387),\n",
       " ('continue', -0.6100322738494387),\n",
       " ('thought', -0.6100322738494387),\n",
       " ('use', -0.6100322738494387),\n",
       " ('however', -0.61727605778784256),\n",
       " ('unit', -0.61727605778784256),\n",
       " ('.', -0.61914695172256906),\n",
       " ('not', -0.62855024991328956),\n",
       " ('morphine', -0.63330718020392829),\n",
       " ('another', -0.64009681004550301),\n",
       " ('floor', -0.64220878785222379),\n",
       " ('as', -0.64371451176866157),\n",
       " ('administered', -0.65080076716144541),\n",
       " ('then', -0.65881785969403395),\n",
       " ('the', -0.66515026607338834),\n",
       " ('bp', -0.67334455326376563),\n",
       " ('two', -0.67334455326376563),\n",
       " ('next', -0.67334455326376563),\n",
       " ('made', -0.67334455326376563),\n",
       " ('discovered', -0.67334455326376563),\n",
       " ('check', -0.67334455326376563),\n",
       " ('need', -0.67334455326376563),\n",
       " ('bottle', -0.67334455326376563),\n",
       " ('10mg', -0.67334455326376563),\n",
       " ('transferred', -0.67334455326376563),\n",
       " ('normal', -0.67334455326376563),\n",
       " ('further', -0.67334455326376563),\n",
       " ('actually', -0.67334455326376563),\n",
       " ('administer', -0.67334455326376563),\n",
       " ('drawer', -0.67334455326376563),\n",
       " ('review', -0.67334455326376563),\n",
       " ('unable', -0.67334455326376563),\n",
       " ('anesthesia', -0.67334455326376563),\n",
       " ('syringe', -0.67334455326376563),\n",
       " ('fentanyl', -0.67334455326376563),\n",
       " ('verbal', -0.67334455326376563),\n",
       " ('their', -0.67334455326376563),\n",
       " ('make', -0.67334455326376563),\n",
       " ('liquid', -0.67334455326376563),\n",
       " ('within', -0.67334455326376563),\n",
       " ('arrival', -0.67334455326376563),\n",
       " ('dropped', -0.67334455326376563),\n",
       " ('restarted', -0.67334455326376563),\n",
       " ('old', -0.67334455326376563),\n",
       " ('concerns', -0.67334455326376563),\n",
       " ('yet', -0.67334455326376563),\n",
       " ('questioned', -0.67334455326376563),\n",
       " ('between', -0.67334455326376563),\n",
       " ('kg', -0.67334455326376563),\n",
       " ('k', -0.67334455326376563),\n",
       " ('close', -0.67334455326376563),\n",
       " ('zosyn', -0.67334455326376563),\n",
       " ('levothyroxine', -0.67334455326376563),\n",
       " ('cerner', -0.67334455326376563),\n",
       " ('area', -0.67334455326376563),\n",
       " ('patches', -0.67334455326376563),\n",
       " ('weighed', -0.67334455326376563),\n",
       " ('11', -0.67334455326376563),\n",
       " ('grabbed', -0.67334455326376563),\n",
       " ('hypotension', -0.67334455326376563),\n",
       " ('stop', -0.67334455326376563),\n",
       " ('cart', -0.67334455326376563),\n",
       " ('250mg', -0.67334455326376563),\n",
       " ('femoral', -0.67334455326376563),\n",
       " ('b/p', -0.67334455326376563),\n",
       " ('qam', -0.67334455326376563),\n",
       " ('caring', -0.67334455326376563),\n",
       " ('apologized', -0.67334455326376563),\n",
       " ('none', -0.67334455326376563),\n",
       " ('tube', -0.67334455326376563),\n",
       " ('opened', -0.67334455326376563),\n",
       " ('60mg', -0.67334455326376563),\n",
       " ('recorded', -0.67334455326376563),\n",
       " ('q12h', -0.67334455326376563),\n",
       " ('anxiety', -0.67334455326376563),\n",
       " ('confusion', -0.67334455326376563),\n",
       " ('chloride', -0.67334455326376563),\n",
       " ('located', -0.67334455326376563),\n",
       " ('5/325mg', -0.67334455326376563),\n",
       " (\"don't\", -0.67334455326376563),\n",
       " ('speak', -0.67334455326376563),\n",
       " ('original', -0.67334455326376563),\n",
       " ('onto', -0.67334455326376563),\n",
       " ('currently', -0.67334455326376563),\n",
       " ('actual', -0.67334455326376563),\n",
       " ('range', -0.67334455326376563),\n",
       " ('abdominal', -0.67334455326376563),\n",
       " ('above', -0.67334455326376563),\n",
       " ('table', -0.67334455326376563),\n",
       " ('communicated', -0.67334455326376563),\n",
       " ('reached', -0.67334455326376563),\n",
       " ('resumed', -0.67334455326376563),\n",
       " ('upset', -0.67334455326376563),\n",
       " ('us', -0.67334455326376563),\n",
       " ('norco', -0.67334455326376563),\n",
       " ('inquire', -0.67334455326376563),\n",
       " ('m', -0.67334455326376563),\n",
       " ('pounds', -0.67334455326376563),\n",
       " ('kilograms', -0.67334455326376563),\n",
       " ('adult', -0.67334455326376563),\n",
       " ('calculated', -0.67334455326376563),\n",
       " ('wellbutrin', -0.67334455326376563),\n",
       " ('92', -0.67334455326376563),\n",
       " ('apn', -0.67334455326376563),\n",
       " ('hib', -0.67334455326376563),\n",
       " ('labeling', -0.67334455326376563),\n",
       " ('originally', -0.67334455326376563),\n",
       " ('thrombolytic', -0.67334455326376563),\n",
       " ('drawing', -0.67334455326376563),\n",
       " ('catch', -0.67334455326376563),\n",
       " ('sheets', -0.67334455326376563),\n",
       " ('60', -0.67334455326376563),\n",
       " ('decreasing', -0.67334455326376563),\n",
       " ('noc', -0.67334455326376563),\n",
       " ('325mg', -0.67334455326376563),\n",
       " ('cephalosporins', -0.67334455326376563),\n",
       " ('o', -0.67334455326376563),\n",
       " ('delivering', -0.67334455326376563),\n",
       " ('meningococcal', -0.67334455326376563),\n",
       " ('menveo', -0.67334455326376563),\n",
       " ('reconstituted', -0.67334455326376563),\n",
       " ('reverse', -0.67334455326376563),\n",
       " ('anticipated', -0.67334455326376563),\n",
       " ('rounding', -0.67334455326376563),\n",
       " ('show', -0.67334455326376563),\n",
       " ('couple', -0.67334455326376563),\n",
       " ('anxious', -0.67334455326376563),\n",
       " ('follows:', -0.67334455326376563),\n",
       " ('phenergan', -0.67334455326376563),\n",
       " ('closing', -0.67334455326376563),\n",
       " ('1830-1845', -0.67334455326376563),\n",
       " ('alteplase', -0.67334455326376563),\n",
       " ('[hospital]', -0.67334455326376563),\n",
       " ('s/p', -0.67334455326376563),\n",
       " ('dispensing', -0.67334455326376563),\n",
       " ('platelet', -0.67334455326376563),\n",
       " ('dvt', -0.67334455326376563),\n",
       " ('platelets', -0.67334455326376563),\n",
       " ('encephalopathy', -0.67334455326376563),\n",
       " ('simvastatin', -0.67334455326376563),\n",
       " ('caps', -0.67334455326376563),\n",
       " ('miss', -0.67334455326376563),\n",
       " ('fish', -0.67334455326376563),\n",
       " ('oil', -0.67334455326376563),\n",
       " (',rn', -0.67334455326376563),\n",
       " ('atarax', -0.67334455326376563),\n",
       " ('2/22', -0.67334455326376563),\n",
       " ('activated', -0.67334455326376563),\n",
       " ('6/14/15', -0.67334455326376563),\n",
       " ('2/15/15', -0.67334455326376563),\n",
       " ('authenticated', -0.67334455326376563),\n",
       " ('q4h', -0.67334455326376563),\n",
       " ('dated', -0.67334455326376563),\n",
       " ('5/31/15', -0.67334455326376563),\n",
       " ('diltiazem', -0.67334455326376563),\n",
       " ('1427', -0.67334455326376563),\n",
       " ('x4', -0.67334455326376563),\n",
       " ('surg', -0.67334455326376563),\n",
       " ('crna', -0.67334455326376563),\n",
       " ('alone', -0.67334455326376563),\n",
       " ('96', -0.67334455326376563),\n",
       " ('flonase', -0.67334455326376563),\n",
       " ('r/t', -0.67334455326376563),\n",
       " ('type', -0.67334455326376563),\n",
       " ('q6', -0.67334455326376563),\n",
       " ('3pm', -0.67334455326376563),\n",
       " ('recevied', -0.67334455326376563),\n",
       " ('somehow', -0.67334455326376563),\n",
       " ('conversation', -0.67334455326376563),\n",
       " ('0926', -0.67334455326376563),\n",
       " ('108', -0.67334455326376563),\n",
       " ('10/10', -0.67334455326376563),\n",
       " ('1020', -0.67334455326376563),\n",
       " ('vomit', -0.67334455326376563),\n",
       " ('81', -0.67334455326376563),\n",
       " ('awake', -0.67334455326376563),\n",
       " ('decompression', -0.67334455326376563),\n",
       " ('associated', -0.67334455326376563),\n",
       " ('slowed', -0.67334455326376563),\n",
       " ('seemed', -0.67334455326376563),\n",
       " ('helping', -0.67334455326376563),\n",
       " ('explaining', -0.67334455326376563),\n",
       " ('dosed', -0.67334455326376563),\n",
       " ('expect', -0.67334455326376563),\n",
       " ('provide', -0.67334455326376563),\n",
       " ('6/17', -0.67334455326376563),\n",
       " ('raised', -0.67334455326376563),\n",
       " ('agent', -0.67334455326376563),\n",
       " ('improve', -0.67334455326376563),\n",
       " ('hypersensitivity', -0.67334455326376563),\n",
       " ('warnings', -0.67334455326376563),\n",
       " ('contraindications', -0.67334455326376563),\n",
       " ('isolation', -0.67334455326376563),\n",
       " ('others', -0.67334455326376563),\n",
       " ('awaiting', -0.67334455326376563),\n",
       " ('emergent', -0.67334455326376563),\n",
       " ('cared', -0.67334455326376563),\n",
       " ('1101', -0.67334455326376563),\n",
       " ('final', -0.67334455326376563),\n",
       " ('cv', -0.67334455326376563),\n",
       " ('<', -0.67334455326376563),\n",
       " ('diastolic', -0.67334455326376563),\n",
       " ('911', -0.67334455326376563),\n",
       " ('1226', -0.67334455326376563),\n",
       " ('least', -0.67334455326376563),\n",
       " ('despite', -0.67334455326376563),\n",
       " ('communicate', -0.67334455326376563),\n",
       " ('meditech', -0.67334455326376563),\n",
       " ('address', -0.67334455326376563),\n",
       " ('1257', -0.67334455326376563),\n",
       " ('on-call', -0.67334455326376563),\n",
       " ('metabolic', -0.67334455326376563),\n",
       " (\"'did\", -0.67334455326376563),\n",
       " ('likely', -0.67334455326376563),\n",
       " ('contributing', -0.67334455326376563),\n",
       " ('include', -0.67334455326376563),\n",
       " ('effective', -0.67334455326376563),\n",
       " ('41/19', -0.67334455326376563),\n",
       " ('yyy', -0.67334455326376563),\n",
       " ('resume', -0.67334455326376563),\n",
       " ('2-3', -0.67334455326376563),\n",
       " ('life', -0.67334455326376563),\n",
       " ('unsuccessful', -0.67334455326376563),\n",
       " ('#', -0.67334455326376563),\n",
       " ('fellow', -0.67334455326376563),\n",
       " ('st', -0.67334455326376563),\n",
       " ('surgical', -0.67334455326376563),\n",
       " ('1915', -0.67334455326376563),\n",
       " ('updated', -0.67334455326376563),\n",
       " ('comfortably', -0.67334455326376563),\n",
       " ('admitting', -0.67334455326376563),\n",
       " ('progress', -0.67334455326376563),\n",
       " ('turn', -0.67334455326376563),\n",
       " ('14', -0.67334455326376563),\n",
       " ('board', -0.67334455326376563),\n",
       " ('comfort', -0.67334455326376563),\n",
       " ('ad', -0.67334455326376563),\n",
       " ('finishing', -0.67334455326376563),\n",
       " ('9/8/15', -0.67334455326376563),\n",
       " ('tachycardic', -0.67334455326376563),\n",
       " (\"shouldn't\", -0.67334455326376563),\n",
       " ('tele', -0.67334455326376563),\n",
       " ('sugars', -0.67334455326376563),\n",
       " ('occasions', -0.67334455326376563),\n",
       " ('spoken', -0.67334455326376563),\n",
       " ('8/6/15', -0.67334455326376563),\n",
       " ('8/8/15', -0.67334455326376563),\n",
       " ('trouble', -0.67334455326376563),\n",
       " ('lasted', -0.67334455326376563),\n",
       " ('leaving', -0.67334455326376563),\n",
       " ('asleep', -0.67334455326376563),\n",
       " ('contained', -0.67334455326376563),\n",
       " ('complications', -0.67334455326376563),\n",
       " ('transport', -0.67334455326376563),\n",
       " ('1303', -0.67334455326376563),\n",
       " ('w/', -0.67334455326376563),\n",
       " ('0547', -0.67334455326376563),\n",
       " ('ibuprofen', -0.67334455326376563),\n",
       " ('28', -0.67334455326376563),\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words most frequently seen in a review with a \"POSITIVE\" label\n",
    "pos_neg_ratios.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('400mg/5ml', -4.6051701859880909),\n",
       " ('azithromycin', -4.6051701859880909),\n",
       " ('tolerated', -4.6051701859880909),\n",
       " (\"dc'd\", -4.6051701859880909),\n",
       " ('co', -4.6051701859880909),\n",
       " ('mail', -4.6051701859880909),\n",
       " ('encounter', -4.6051701859880909),\n",
       " ('145', -4.6051701859880909),\n",
       " ('176', -4.6051701859880909),\n",
       " ('creat', -4.6051701859880909),\n",
       " ('lbs', -4.6051701859880909),\n",
       " ('delated', -4.6051701859880909),\n",
       " ('preterm', -4.6051701859880909),\n",
       " ('mg/kg', -4.6051701859880909),\n",
       " (\"inr's\", -4.6051701859880909),\n",
       " ('7/23', -4.6051701859880909),\n",
       " ('depo-medrol', -4.6051701859880909),\n",
       " ('7/28/15', -4.6051701859880909),\n",
       " ('add', -4.6051701859880909),\n",
       " ('06/05/15', -4.6051701859880909),\n",
       " ('5mcg/kg/hr', -4.6051701859880909),\n",
       " ('freezer', -4.6051701859880909),\n",
       " ('letter', -4.6051701859880909),\n",
       " ('2s', -4.6051701859880909),\n",
       " ('infection', -4.6051701859880909),\n",
       " ('hr64', -4.6051701859880909),\n",
       " ('nebivolol', -4.6051701859880909),\n",
       " ('98-99%', -4.6051701859880909),\n",
       " ('wheezing', -4.6051701859880909),\n",
       " ('lpm', -4.6051701859880909)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words most frequently seen in a review with a \"NEGATIVE\" label\n",
    "list(reversed(pos_neg_ratios.most_common()))[0:30]\n",
    "\n",
    "# Note: Above is the code Andrew uses in his solution video, \n",
    "#       so we've included it here to avoid confusion.\n",
    "#       If you explore the documentation for the Counter class, \n",
    "#       you will see you could also find the 30 least common\n",
    "#       words like this: pos_neg_ratios.most_common()[:-31:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Project 1. \n",
    "## Watch the next video to continue with Andrew's next lesson.\n",
    "\n",
    "# Transforming Text into Numbers<a id='lesson_3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sentiment_network.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-8c4d507f3324>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"This was a horrible, terrible movie.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentiment_network.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sentiment_network.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "review = \"This was a horrible, terrible movie.\"\n",
    "\n",
    "Image(filename='sentiment_network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sentiment_network_pos.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-4b1693d2c64d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The movie was excellent\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentiment_network_pos.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sentiment_network_pos.png'"
     ]
    }
   ],
   "source": [
    "review = \"The movie was excellent\"\n",
    "\n",
    "Image(filename='sentiment_network_pos.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Project 2: Creating the Input/Output Data<a id='project_2'></a>\n",
    "\n",
    "**TODO:** Create a [set](https://docs.python.org/3/tutorial/datastructures.html#sets) named `vocab` that contains every word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set(total_counts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to check your vocabulary size. If everything worked correctly, it should print **74074**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5091\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the following image. It represents the layers of the neural network you'll be building throughout this notebook. `layer_0` is the input layer, `layer_1` is a hidden layer, and `layer_2` is the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sentiment_network_2.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-57dd2d84038f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentiment_network_2.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sentiment_network_2.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='sentiment_network_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Create a numpy array called `layer_0` and initialize it to all zeros. You will find the [zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html) function particularly helpful here. Be sure you create `layer_0` as a 2-dimensional matrix with 1 row and `vocab_size` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_0 = np.zeros((1,vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell. It should display `(1, 74074)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5091)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sentiment_network.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-2431fd097e8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentiment_network.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sentiment_network.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='sentiment_network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`layer_0` contains one entry for every word in the vocabulary, as shown in the above image. We need to make sure we know the index of each word, so run the following cell to create a lookup table that stores the index of every word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'doctors': 1,\n",
       " 'ct?': 2,\n",
       " 'tetrofosmin': 3,\n",
       " 'cii': 4,\n",
       " 'transfering': 5,\n",
       " 'extended': 6,\n",
       " 'require': 7,\n",
       " 'actively': 8,\n",
       " 'interactions': 9,\n",
       " 'hour': 10,\n",
       " 'full': 11,\n",
       " 'inserted': 12,\n",
       " 'saved': 13,\n",
       " 'thrown': 14,\n",
       " 'calmer': 15,\n",
       " 'in': 16,\n",
       " '0245': 17,\n",
       " 'alarming': 18,\n",
       " 'on': 19,\n",
       " '4500mg': 20,\n",
       " 'coded': 21,\n",
       " 'sw': 22,\n",
       " 'showed': 23,\n",
       " '3/20/15': 24,\n",
       " '7/2014': 25,\n",
       " 'into': 26,\n",
       " 'suggest': 27,\n",
       " 'changed': 28,\n",
       " '0830': 29,\n",
       " '0552': 30,\n",
       " 'units/hr': 31,\n",
       " '3pm': 32,\n",
       " 'faster': 33,\n",
       " '1-drowsy': 34,\n",
       " 'card': 35,\n",
       " 'echocardiograms': 36,\n",
       " '11/25/15-new': 37,\n",
       " 'dorsogluteal': 38,\n",
       " '11/26/15': 39,\n",
       " 'events': 40,\n",
       " 'sn': 41,\n",
       " 'consult/dosing': 42,\n",
       " '1427': 43,\n",
       " 'visapaque': 44,\n",
       " 'symptoms': 45,\n",
       " 'expiration': 46,\n",
       " '03/11/2015': 47,\n",
       " '1101': 48,\n",
       " 'administer': 49,\n",
       " 'i': 50,\n",
       " 'gathered': 51,\n",
       " 'half': 52,\n",
       " '25mcg': 53,\n",
       " 'ie': 54,\n",
       " 'resource': 55,\n",
       " 'omnicell': 56,\n",
       " '264': 57,\n",
       " 'brough': 58,\n",
       " 'aroung': 59,\n",
       " '249': 60,\n",
       " 'lower': 61,\n",
       " 'talk': 62,\n",
       " 'dispensed;': 63,\n",
       " '0928': 64,\n",
       " '1gm/10ml': 65,\n",
       " '1200': 66,\n",
       " '150s': 67,\n",
       " 'bupropion': 68,\n",
       " 'hospital': 69,\n",
       " 'ml': 70,\n",
       " 'qam': 71,\n",
       " 'numb': 72,\n",
       " '3:48': 73,\n",
       " 'circulator': 74,\n",
       " 'rounds': 75,\n",
       " 'wake': 76,\n",
       " 'discussig': 77,\n",
       " 'catching': 78,\n",
       " 'company': 79,\n",
       " 'empty': 80,\n",
       " 'emergent': 81,\n",
       " 'january': 82,\n",
       " '10/9/15': 83,\n",
       " '1152': 84,\n",
       " '5/14': 85,\n",
       " 'vehicle': 86,\n",
       " '20mg': 87,\n",
       " 'reverse': 88,\n",
       " 'cut': 89,\n",
       " 'passing': 90,\n",
       " '1015': 91,\n",
       " 'dx:': 92,\n",
       " 'primary': 93,\n",
       " 'think': 94,\n",
       " 'w-135': 95,\n",
       " 'incorrect': 96,\n",
       " 'believed': 97,\n",
       " 'wife': 98,\n",
       " '800ml/hr': 99,\n",
       " 'locked': 100,\n",
       " 'x-ray': 101,\n",
       " 'c-diff': 102,\n",
       " 'importance': 103,\n",
       " 'toprol': 104,\n",
       " 'protonix': 105,\n",
       " 'eyes': 106,\n",
       " 'consultation': 107,\n",
       " 'carrying': 108,\n",
       " 'cyst': 109,\n",
       " '10gm': 110,\n",
       " 'diflucan': 111,\n",
       " 'rectal': 112,\n",
       " 'os:': 113,\n",
       " 'collect': 114,\n",
       " '26': 115,\n",
       " '3e': 116,\n",
       " '3mg': 117,\n",
       " 'associated': 118,\n",
       " 'jumped': 119,\n",
       " 'nurse-': 120,\n",
       " 'charted': 121,\n",
       " 'pacs': 122,\n",
       " 'azythromicin': 123,\n",
       " 'labor': 124,\n",
       " '%': 125,\n",
       " 'department': 126,\n",
       " 'reviewing': 127,\n",
       " 'thought': 128,\n",
       " 'ongoing': 129,\n",
       " '0700': 130,\n",
       " \"'the\": 131,\n",
       " 'bentyl': 132,\n",
       " 'seemed': 133,\n",
       " '126/89': 134,\n",
       " 'coding': 135,\n",
       " '0036': 136,\n",
       " 'pt/husband': 137,\n",
       " 'nauseous': 138,\n",
       " 'mentioning': 139,\n",
       " 'generic': 140,\n",
       " 'faint': 141,\n",
       " 'ed': 142,\n",
       " 'conerning': 143,\n",
       " 'doses(': 144,\n",
       " 'q1': 145,\n",
       " 'hr64': 146,\n",
       " '6/25/15': 147,\n",
       " '0-8': 148,\n",
       " '5mcg/kg/min': 149,\n",
       " '0/21': 150,\n",
       " 'normal': 151,\n",
       " 'ovarian': 152,\n",
       " 'xr': 153,\n",
       " '1gm': 154,\n",
       " 'secretary': 155,\n",
       " 'fentanyl': 156,\n",
       " 'hang': 157,\n",
       " 'dropping': 158,\n",
       " 'ensure': 159,\n",
       " 'nor': 160,\n",
       " '0500': 161,\n",
       " 'medicine': 162,\n",
       " 'arranged': 163,\n",
       " 'scanning-medication': 164,\n",
       " 'whether': 165,\n",
       " 'b/c': 166,\n",
       " \"'run'\": 167,\n",
       " 'diastolic': 168,\n",
       " '10ml': 169,\n",
       " 'leaking': 170,\n",
       " 'xylocain': 171,\n",
       " 'clot': 172,\n",
       " 'are': 173,\n",
       " 'running': 174,\n",
       " 'agreeable': 175,\n",
       " '54/34': 176,\n",
       " 're-timed': 177,\n",
       " '11/20': 178,\n",
       " 'tetracaine': 179,\n",
       " '8/9/15': 180,\n",
       " '2lpm': 181,\n",
       " 'modified': 182,\n",
       " 'connected': 183,\n",
       " 'complaining': 184,\n",
       " 'cuff': 185,\n",
       " 'eye': 186,\n",
       " 'undiluted': 187,\n",
       " 'erythemic/red': 188,\n",
       " 'amt': 189,\n",
       " 'mls': 190,\n",
       " 'aloxi': 191,\n",
       " '20meq': 192,\n",
       " '[pharmacist]': 193,\n",
       " 'infustion': 194,\n",
       " '.07mg': 195,\n",
       " 'vaccines': 196,\n",
       " 'having': 197,\n",
       " 'hospitalized': 198,\n",
       " '121/57': 199,\n",
       " 'unneccessary': 200,\n",
       " '2147': 201,\n",
       " 'mon-thu': 202,\n",
       " 'baby': 203,\n",
       " '0.375mg': 204,\n",
       " 'powder': 205,\n",
       " 'rather': 206,\n",
       " 'lollipops': 207,\n",
       " 'insepection': 208,\n",
       " 'infusion': 209,\n",
       " '250/50': 210,\n",
       " 'arrest': 211,\n",
       " 'omeprazole': 212,\n",
       " 'hooked': 213,\n",
       " '100mcg': 214,\n",
       " \"yyyy's\": 215,\n",
       " '1830-1845': 216,\n",
       " 'strengths': 217,\n",
       " 'rehab': 218,\n",
       " 'properly': 219,\n",
       " 'nystatin': 220,\n",
       " 'arrive': 221,\n",
       " 'cr': 222,\n",
       " 'indicating': 223,\n",
       " 'q48': 224,\n",
       " 'kayexlate': 225,\n",
       " 'renew': 226,\n",
       " '10mg/0': 227,\n",
       " 'face': 228,\n",
       " 'renally': 229,\n",
       " 'notified': 230,\n",
       " 'bupivacaine': 231,\n",
       " 'redness': 232,\n",
       " 'transesophageal': 233,\n",
       " '09:00': 234,\n",
       " 'procedure': 235,\n",
       " 'intensivist': 236,\n",
       " \"mom's\": 237,\n",
       " 'conjugate': 238,\n",
       " 'radiology': 239,\n",
       " 'spoken': 240,\n",
       " '.r': 241,\n",
       " 'morning': 242,\n",
       " 'earlier': 243,\n",
       " 'value': 244,\n",
       " '2/15/15': 245,\n",
       " '5ml': 246,\n",
       " '122': 247,\n",
       " 'old': 248,\n",
       " '0130-3/23/15': 249,\n",
       " 'pes': 250,\n",
       " 'dosae': 251,\n",
       " 'tones': 252,\n",
       " \"'pt's\": 253,\n",
       " 'oxygenation': 254,\n",
       " 'administration': 255,\n",
       " 'during': 256,\n",
       " 'inpatient': 257,\n",
       " 'display': 258,\n",
       " 'sun': 259,\n",
       " \"doesn't\": 260,\n",
       " 'doesn': 261,\n",
       " '117': 262,\n",
       " 'slowly': 263,\n",
       " '.o': 264,\n",
       " 'seems': 265,\n",
       " '5-4': 266,\n",
       " '2l/nc': 267,\n",
       " 'but': 268,\n",
       " 'formulary': 269,\n",
       " '.5mg': 270,\n",
       " 'cvtu': 271,\n",
       " 'hall': 272,\n",
       " '1300': 273,\n",
       " 'qid': 274,\n",
       " '1114': 275,\n",
       " 'w/rvr': 276,\n",
       " 'medications': 277,\n",
       " 'ivpb': 278,\n",
       " 'adjusted': 279,\n",
       " '54-119': 280,\n",
       " 'egd': 281,\n",
       " 'diabetic': 282,\n",
       " 'burning': 283,\n",
       " 'included': 284,\n",
       " '230': 285,\n",
       " 'pass': 286,\n",
       " '18units/kg/hr': 287,\n",
       " 'waiting': 288,\n",
       " 'developed': 289,\n",
       " 'patient': 290,\n",
       " 'minute': 291,\n",
       " 'heard': 292,\n",
       " 'recieving': 293,\n",
       " 'hypokalemia': 294,\n",
       " 'stimuli': 295,\n",
       " '0259': 296,\n",
       " 'ltc': 297,\n",
       " 'subq': 298,\n",
       " 'painful': 299,\n",
       " 'discrete': 300,\n",
       " 'signed': 301,\n",
       " 'above': 302,\n",
       " 'infed': 303,\n",
       " 'relieved': 304,\n",
       " 'pole': 305,\n",
       " '3/18/15': 306,\n",
       " '50s-60s': 307,\n",
       " 'requiring': 308,\n",
       " 'anti': 309,\n",
       " 'reduce': 310,\n",
       " 'seconds': 311,\n",
       " '10/14': 312,\n",
       " \"son's\": 313,\n",
       " 'desat': 314,\n",
       " 'clarified': 315,\n",
       " 'assistant': 316,\n",
       " 'december': 317,\n",
       " 'enters': 318,\n",
       " 'operatuve': 319,\n",
       " 'attack': 320,\n",
       " 'hs': 321,\n",
       " 'initiation': 322,\n",
       " 'using': 323,\n",
       " 'incomplete': 324,\n",
       " '0738': 325,\n",
       " 'scanner': 326,\n",
       " 'programed': 327,\n",
       " 'maximum': 328,\n",
       " 'hospice': 329,\n",
       " 'outgoing': 330,\n",
       " '1251': 331,\n",
       " 'nothing': 332,\n",
       " 'subsequent': 333,\n",
       " 'suicid': 334,\n",
       " 'knew': 335,\n",
       " 'together': 336,\n",
       " 'taking/clarify': 337,\n",
       " 'pharmacist': 338,\n",
       " 'discovery': 339,\n",
       " 'application': 340,\n",
       " 'apneic': 341,\n",
       " 'site': 342,\n",
       " 'apology': 343,\n",
       " 'fellow': 344,\n",
       " 'rvr': 345,\n",
       " 'noon': 346,\n",
       " '1555': 347,\n",
       " 'letter': 348,\n",
       " 'show': 349,\n",
       " 'improved': 350,\n",
       " 'conversion': 351,\n",
       " '2238': 352,\n",
       " '3/4': 353,\n",
       " 'almost': 354,\n",
       " 'precedex': 355,\n",
       " 'electronically': 356,\n",
       " 'warfarin': 357,\n",
       " '2000mg': 358,\n",
       " 'reversed': 359,\n",
       " 'cardizem': 360,\n",
       " 'difficulty': 361,\n",
       " 'mylcion': 362,\n",
       " '09:39': 363,\n",
       " 'opportunities': 364,\n",
       " 'nurse': 365,\n",
       " 'breakfast': 366,\n",
       " 'pulse/no': 367,\n",
       " '117/57': 368,\n",
       " 'steel': 369,\n",
       " 'flag': 370,\n",
       " 'different': 371,\n",
       " 'concentration': 372,\n",
       " 'q12h': 373,\n",
       " 'g': 374,\n",
       " 'neostigmine': 375,\n",
       " 'abilify': 376,\n",
       " 'oldest': 377,\n",
       " 'why': 378,\n",
       " 'dislocated': 379,\n",
       " 'p107;': 380,\n",
       " \"me'\": 381,\n",
       " 'vistaril': 382,\n",
       " 'complter': 383,\n",
       " '1216': 384,\n",
       " '1004am': 385,\n",
       " 'last': 386,\n",
       " 'population': 387,\n",
       " 'along': 388,\n",
       " ',1200': 389,\n",
       " '1421': 390,\n",
       " 'thyroidectomy': 391,\n",
       " 'limiting': 392,\n",
       " 'pm': 393,\n",
       " '11mg': 394,\n",
       " 'wasted': 395,\n",
       " 'son': 396,\n",
       " 'readmission': 397,\n",
       " '[outside': 398,\n",
       " 'woke': 399,\n",
       " 'handing': 400,\n",
       " 'expired': 401,\n",
       " 'portable': 402,\n",
       " 'bins': 403,\n",
       " '1:1000': 404,\n",
       " 'canceled': 405,\n",
       " 'packs': 406,\n",
       " 'done': 407,\n",
       " 'on-call': 408,\n",
       " '6:48': 409,\n",
       " 'skin': 410,\n",
       " 'internal': 411,\n",
       " 'eyeglass': 412,\n",
       " 'reaction': 413,\n",
       " 'white': 414,\n",
       " 'learned': 415,\n",
       " '40s': 416,\n",
       " 'formulation': 417,\n",
       " 'high': 418,\n",
       " 'definity(': 419,\n",
       " 'list': 420,\n",
       " 'connector': 421,\n",
       " 'richeh': 422,\n",
       " '218/118': 423,\n",
       " 'pe': 424,\n",
       " 'necessary': 425,\n",
       " 'sl': 426,\n",
       " 'float': 427,\n",
       " 'transcribed': 428,\n",
       " 'freezer': 429,\n",
       " 'number': 430,\n",
       " '156': 431,\n",
       " 'avoided': 432,\n",
       " '124': 433,\n",
       " 'consent': 434,\n",
       " 'both': 435,\n",
       " 'scores': 436,\n",
       " 'platelet': 437,\n",
       " 'factors': 438,\n",
       " 'draw': 439,\n",
       " '5%': 440,\n",
       " 'normally': 441,\n",
       " 'gicen': 442,\n",
       " 'my': 443,\n",
       " 'medciation': 444,\n",
       " 'closing': 445,\n",
       " 'according': 446,\n",
       " 'paper': 447,\n",
       " '8ml/hr': 448,\n",
       " 'manual': 449,\n",
       " 'completion': 450,\n",
       " 'pharmd': 451,\n",
       " 'recurrent': 452,\n",
       " 'email': 453,\n",
       " '1840': 454,\n",
       " 'didnt': 455,\n",
       " '5-fu': 456,\n",
       " 'etc': 457,\n",
       " 'pushed': 458,\n",
       " 'wrapped': 459,\n",
       " '1057': 460,\n",
       " '1223': 461,\n",
       " '1218': 462,\n",
       " '0330-': 463,\n",
       " '2052': 464,\n",
       " 'downside': 465,\n",
       " 'administrations': 466,\n",
       " 'hydralazine': 467,\n",
       " 'p92': 468,\n",
       " '350cc/hr': 469,\n",
       " 'audible': 470,\n",
       " 'cdc': 471,\n",
       " 'tetanus': 472,\n",
       " '1ml': 473,\n",
       " '@15:30': 474,\n",
       " 'merrem': 475,\n",
       " 'lactulose': 476,\n",
       " 'perform': 477,\n",
       " 'realized': 478,\n",
       " 'systolic': 479,\n",
       " 'canula': 480,\n",
       " 'supervising': 481,\n",
       " 'notifed': 482,\n",
       " 'stat': 483,\n",
       " 'dexadrine': 484,\n",
       " '1100': 485,\n",
       " 'accounts': 486,\n",
       " 'one': 487,\n",
       " 'h&p': 488,\n",
       " '5units/kg/hr': 489,\n",
       " 'patches': 490,\n",
       " 'readily': 491,\n",
       " 'report': 492,\n",
       " 'lips': 493,\n",
       " 'continuous': 494,\n",
       " 'misread': 495,\n",
       " 'code': 496,\n",
       " 'bolus': 497,\n",
       " 'minimum': 498,\n",
       " 'rate?': 499,\n",
       " 'injury': 500,\n",
       " '59yo': 501,\n",
       " 'attempt': 502,\n",
       " 'acc': 503,\n",
       " 'stimulated': 504,\n",
       " '10/325mg': 505,\n",
       " 'bright': 506,\n",
       " 'attended': 507,\n",
       " 'potent': 508,\n",
       " 'lukes': 509,\n",
       " '01/22/15': 510,\n",
       " 'north': 511,\n",
       " 'coreg': 512,\n",
       " 'drip': 513,\n",
       " 'staff': 514,\n",
       " '10/25': 515,\n",
       " '#': 516,\n",
       " 'dm': 517,\n",
       " 'kcl': 518,\n",
       " '12/20/15': 519,\n",
       " 'message': 520,\n",
       " 'uncontrasted': 521,\n",
       " 'posterior': 522,\n",
       " 'hypertension': 523,\n",
       " 'paged': 524,\n",
       " 'young': 525,\n",
       " '2g': 526,\n",
       " 'mars': 527,\n",
       " '140mg': 528,\n",
       " 'restricted': 529,\n",
       " 'short': 530,\n",
       " '180/120s': 531,\n",
       " 'showing': 532,\n",
       " 'preop': 533,\n",
       " 'about': 534,\n",
       " 'xanax': 535,\n",
       " 'early': 536,\n",
       " 'ac': 537,\n",
       " 'explained': 538,\n",
       " '105/57': 539,\n",
       " 'documentation': 540,\n",
       " '1017': 541,\n",
       " 'disolve': 542,\n",
       " 'snf': 543,\n",
       " 'hoc': 544,\n",
       " 'equal': 545,\n",
       " '2015': 546,\n",
       " '0556': 547,\n",
       " '130/67': 548,\n",
       " 'prn': 549,\n",
       " 'year': 550,\n",
       " \"don't\": 551,\n",
       " 'points': 552,\n",
       " ',000': 553,\n",
       " 'informatics': 554,\n",
       " 'air': 555,\n",
       " 'overnight': 556,\n",
       " 'azithromycin': 557,\n",
       " 'zantac': 558,\n",
       " 'pca': 559,\n",
       " 'medicaion': 560,\n",
       " 'machine': 561,\n",
       " '5/15': 562,\n",
       " 'allergy': 563,\n",
       " 'safety': 564,\n",
       " 'improper': 565,\n",
       " 'ankle': 566,\n",
       " '<': 567,\n",
       " 'q24': 568,\n",
       " 's': 569,\n",
       " '1/25/15': 570,\n",
       " 'finding': 571,\n",
       " '75mg': 572,\n",
       " 'resend': 573,\n",
       " 'extended-': 574,\n",
       " '100/42': 575,\n",
       " '72/50': 576,\n",
       " 'drops': 577,\n",
       " 'qty': 578,\n",
       " '80units/kg': 579,\n",
       " \"weren't\": 580,\n",
       " '1501': 581,\n",
       " 'visable': 582,\n",
       " 'hydration': 583,\n",
       " 'hemodynamically': 584,\n",
       " 'resume': 585,\n",
       " 'ml/hr': 586,\n",
       " '11/4/15': 587,\n",
       " 'granddaughter': 588,\n",
       " 'hr': 589,\n",
       " 'preference': 590,\n",
       " '1039': 591,\n",
       " 'background:': 592,\n",
       " 'form': 593,\n",
       " 'vaccination': 594,\n",
       " 'soon': 595,\n",
       " '176': 596,\n",
       " 'irritation': 597,\n",
       " 'entered': 598,\n",
       " '150/70': 599,\n",
       " 'id': 600,\n",
       " 'dicyclomine': 601,\n",
       " 'magnevist': 602,\n",
       " 'crisis': 603,\n",
       " 'mcg/ml': 604,\n",
       " 'emt-p': 605,\n",
       " 'nico-span': 606,\n",
       " '1000mcg/ml': 607,\n",
       " 'pt/inr': 608,\n",
       " 'substances': 609,\n",
       " 'these': 610,\n",
       " 'googled': 611,\n",
       " 'surface': 612,\n",
       " 'adjusting': 613,\n",
       " 'pre-med': 614,\n",
       " '123/59': 615,\n",
       " 'cardiacs': 616,\n",
       " 'relay': 617,\n",
       " 'prozac': 618,\n",
       " 'when': 619,\n",
       " '125mg': 620,\n",
       " 'suffered': 621,\n",
       " 'mediations': 622,\n",
       " 'drew': 623,\n",
       " 'restarted': 624,\n",
       " \"wasn't\": 625,\n",
       " 'respirations': 626,\n",
       " '5/10': 627,\n",
       " '60-80': 628,\n",
       " 'colonoscopy': 629,\n",
       " '875mg': 630,\n",
       " 'afterwards': 631,\n",
       " 'going': 632,\n",
       " '17:00': 633,\n",
       " 'sleepy': 634,\n",
       " 'aprox': 635,\n",
       " 'tylenol': 636,\n",
       " 'atrial': 637,\n",
       " 'person': 638,\n",
       " '0600': 639,\n",
       " 'as': 640,\n",
       " 'start': 641,\n",
       " 'center:': 642,\n",
       " '0803': 643,\n",
       " 'frustrated': 644,\n",
       " 'bleeding': 645,\n",
       " 'rejection': 646,\n",
       " 'opens': 647,\n",
       " 'its': 648,\n",
       " '25': 649,\n",
       " 'end': 650,\n",
       " 'fall': 651,\n",
       " '2154': 652,\n",
       " 'mixed': 653,\n",
       " 'life': 654,\n",
       " 'ones': 655,\n",
       " '108/67': 656,\n",
       " 'c/o': 657,\n",
       " 'book': 658,\n",
       " '1004': 659,\n",
       " 'preferred': 660,\n",
       " '1758': 661,\n",
       " 'up': 662,\n",
       " 'referring': 663,\n",
       " 'infusions': 664,\n",
       " 'delay': 665,\n",
       " 'o': 666,\n",
       " 'transferring': 667,\n",
       " 'takes': 668,\n",
       " 'althought': 669,\n",
       " 'safe': 670,\n",
       " 'possiblity': 671,\n",
       " 'newly': 672,\n",
       " '6/18': 673,\n",
       " 'stuffy': 674,\n",
       " '1136': 675,\n",
       " 'paste': 676,\n",
       " 'preparing': 677,\n",
       " 'though': 678,\n",
       " '.the': 679,\n",
       " 'lack': 680,\n",
       " 'understood': 681,\n",
       " '147': 682,\n",
       " '.5/8': 683,\n",
       " 'plavix': 684,\n",
       " 'excessive': 685,\n",
       " 'episode': 686,\n",
       " 'worried': 687,\n",
       " '5gm': 688,\n",
       " 'blanket': 689,\n",
       " '[another': 690,\n",
       " 'hold': 691,\n",
       " 'built': 692,\n",
       " 'scope': 693,\n",
       " 'facility': 694,\n",
       " 'envelopes': 695,\n",
       " '0000': 696,\n",
       " '11/23/15': 697,\n",
       " \"'non-coded'\": 698,\n",
       " 'pump': 699,\n",
       " '100': 700,\n",
       " \"dose'\": 701,\n",
       " 'encouraged': 702,\n",
       " 'being': 703,\n",
       " 'recovered': 704,\n",
       " 'known': 705,\n",
       " '07/24/15': 706,\n",
       " '3/25': 707,\n",
       " '325mg': 708,\n",
       " '5/29/15': 709,\n",
       " 'electrolyte': 710,\n",
       " 'clamp': 711,\n",
       " 'diaphoretic': 712,\n",
       " '1722': 713,\n",
       " 'groggy': 714,\n",
       " 'boluses': 715,\n",
       " 'indicate': 716,\n",
       " 'nurse]': 717,\n",
       " 'gastrointestinal/': 718,\n",
       " 'halucinations-': 719,\n",
       " 'supervisor;': 720,\n",
       " 'emar': 721,\n",
       " 'future': 722,\n",
       " 'revealed': 723,\n",
       " 'verge': 724,\n",
       " 'document': 725,\n",
       " 'non-coded': 726,\n",
       " 'reveiwed': 727,\n",
       " 'blisters': 728,\n",
       " 'quantities': 729,\n",
       " '.5cc': 730,\n",
       " 'feeling': 731,\n",
       " '6/20': 732,\n",
       " 'restless': 733,\n",
       " 'gave': 734,\n",
       " '6:43': 735,\n",
       " 'obtain': 736,\n",
       " 'hydrcodone': 737,\n",
       " 'hypoglycemic': 738,\n",
       " '15ml': 739,\n",
       " 'went': 740,\n",
       " 'station': 741,\n",
       " 'laid': 742,\n",
       " '4kg': 743,\n",
       " 'resolving': 744,\n",
       " 'weight': 745,\n",
       " 'quickmar': 746,\n",
       " 'miscount': 747,\n",
       " 'citrate': 748,\n",
       " 'repeat': 749,\n",
       " '8/10/15': 750,\n",
       " 'pinpoint': 751,\n",
       " 'check': 752,\n",
       " 'chair': 753,\n",
       " 'contacted': 754,\n",
       " 'laying': 755,\n",
       " '0701': 756,\n",
       " 'minimize': 757,\n",
       " 'health': 758,\n",
       " 'reported': 759,\n",
       " 'dosing': 760,\n",
       " '1530': 761,\n",
       " 'incompatible': 762,\n",
       " 'co': 763,\n",
       " 'months': 764,\n",
       " 'mag': 765,\n",
       " 'undone': 766,\n",
       " '35yo': 767,\n",
       " 'effects': 768,\n",
       " '7/30/15': 769,\n",
       " 'cabg': 770,\n",
       " 'agreed': 771,\n",
       " '3-0': 772,\n",
       " 'policy': 773,\n",
       " 'run': 774,\n",
       " 'mcg/min': 775,\n",
       " 'complete': 776,\n",
       " '885kg': 777,\n",
       " 'comorbidities': 778,\n",
       " 'they': 779,\n",
       " 'climix': 780,\n",
       " 'reactive': 781,\n",
       " 'records': 782,\n",
       " '3/31': 783,\n",
       " 'gram': 784,\n",
       " 'light': 785,\n",
       " 'he': 786,\n",
       " 'microsurgical': 787,\n",
       " '126': 788,\n",
       " '4mg/250': 789,\n",
       " 'cpr': 790,\n",
       " 'tnkase': 791,\n",
       " 'dynamap': 792,\n",
       " '1630': 793,\n",
       " 'barium': 794,\n",
       " 'order/dose': 795,\n",
       " '1958': 796,\n",
       " '21': 797,\n",
       " 'calls': 798,\n",
       " 'none': 799,\n",
       " 'tdap': 800,\n",
       " '2020': 801,\n",
       " 'hangs': 802,\n",
       " 'leader': 803,\n",
       " 'later': 804,\n",
       " '.8kg': 805,\n",
       " 'bid': 806,\n",
       " 'everything': 807,\n",
       " '1225': 808,\n",
       " 'humalog': 809,\n",
       " 'patch': 810,\n",
       " 'invensivist': 811,\n",
       " 'formula': 812,\n",
       " 'nonspecific': 813,\n",
       " 'yet': 814,\n",
       " '5-9/10': 815,\n",
       " '1mg/20': 816,\n",
       " 'dyspnea': 817,\n",
       " 'closed': 818,\n",
       " 'discontinuation': 819,\n",
       " \"'real\": 820,\n",
       " 'bicep': 821,\n",
       " 'proventil': 822,\n",
       " 'becamee': 823,\n",
       " 'awaiting': 824,\n",
       " 'accu': 825,\n",
       " 'comes': 826,\n",
       " 'matters': 827,\n",
       " 'lpm': 828,\n",
       " 'attempting': 829,\n",
       " '92': 830,\n",
       " '1520': 831,\n",
       " 'directed': 832,\n",
       " '2348': 833,\n",
       " '5/24': 834,\n",
       " 'concerns': 835,\n",
       " 'bolus/adjustment': 836,\n",
       " 'capsules': 837,\n",
       " 'instruct': 838,\n",
       " 'inability': 839,\n",
       " 'l': 840,\n",
       " 'buzzard': 841,\n",
       " 'whom': 842,\n",
       " \"'yes\": 843,\n",
       " 'extravasation': 844,\n",
       " 'ritalin': 845,\n",
       " 'operates': 846,\n",
       " 'neb': 847,\n",
       " 'bogus': 848,\n",
       " 'qhs': 849,\n",
       " '1739': 850,\n",
       " 'started': 851,\n",
       " 'rph': 852,\n",
       " 'viscous': 853,\n",
       " '43171k': 854,\n",
       " 'rx': 855,\n",
       " 'slow': 856,\n",
       " 'fentanly': 857,\n",
       " 'thing': 858,\n",
       " 'proceeded': 859,\n",
       " 'definity': 860,\n",
       " 'slowed': 861,\n",
       " 'converse': 862,\n",
       " 'calling': 863,\n",
       " 'copious': 864,\n",
       " '125iv': 865,\n",
       " 'sioc': 866,\n",
       " '?prior': 867,\n",
       " 'shock': 868,\n",
       " \"'insurance\": 869,\n",
       " 'briefcase': 870,\n",
       " 'folfiri': 871,\n",
       " 'particular': 872,\n",
       " 'k': 873,\n",
       " 'returning': 874,\n",
       " '2012': 875,\n",
       " 'subsided': 876,\n",
       " 'failed': 877,\n",
       " '77cc/hr=20': 878,\n",
       " 'clinic': 879,\n",
       " 'unlabored': 880,\n",
       " 'epinepherin': 881,\n",
       " '1ml/hr': 882,\n",
       " 'q8h': 883,\n",
       " 'bypass': 884,\n",
       " '0504': 885,\n",
       " '1658': 886,\n",
       " 'finally': 887,\n",
       " 'pre-op;': 888,\n",
       " '12/4': 889,\n",
       " 'date': 890,\n",
       " 'sheets': 891,\n",
       " 'benefit': 892,\n",
       " 'security': 893,\n",
       " 'june': 894,\n",
       " 'sub': 895,\n",
       " '11': 896,\n",
       " 'someone': 897,\n",
       " '1037': 898,\n",
       " 'tole': 899,\n",
       " 'orientee': 900,\n",
       " 'documente': 901,\n",
       " 'pre-op': 902,\n",
       " 'rolled': 903,\n",
       " 'stocked': 904,\n",
       " 'respirations/minute': 905,\n",
       " 'results': 906,\n",
       " 'overdose': 907,\n",
       " 'temporary': 908,\n",
       " 'flank': 909,\n",
       " 'bridge': 910,\n",
       " '261': 911,\n",
       " 'boxes': 912,\n",
       " 'service': 913,\n",
       " '1733': 914,\n",
       " \"'0\": 915,\n",
       " 'diagnosis': 916,\n",
       " 'responded': 917,\n",
       " '09': 918,\n",
       " 'hypersensitivity': 919,\n",
       " 'r': 920,\n",
       " '101/61': 921,\n",
       " 'breathe': 922,\n",
       " 'f/u': 923,\n",
       " '9/15': 924,\n",
       " 'midazolam': 925,\n",
       " 'standards': 926,\n",
       " '2250': 927,\n",
       " '2034': 928,\n",
       " 'tpa': 929,\n",
       " 'directions': 930,\n",
       " 'x4': 931,\n",
       " 'unresponsive': 932,\n",
       " 'correction': 933,\n",
       " 'regular': 934,\n",
       " 'ahn': 935,\n",
       " 'visually': 936,\n",
       " 'comment': 937,\n",
       " 'prevnar': 938,\n",
       " 'discovered': 939,\n",
       " 'pen': 940,\n",
       " '.6': 941,\n",
       " 'dated': 942,\n",
       " '10cc': 943,\n",
       " 'ptt': 944,\n",
       " 'involvement': 945,\n",
       " 'hanging': 946,\n",
       " 'verbalized': 947,\n",
       " 'dose/daily': 948,\n",
       " 'cataract': 949,\n",
       " 'temp': 950,\n",
       " 'rrt': 951,\n",
       " 'four': 952,\n",
       " 'leucovorin/5-fu': 953,\n",
       " 'flonase': 954,\n",
       " '-2': 955,\n",
       " 'cath;': 956,\n",
       " 'sq': 957,\n",
       " 'atherectomy': 958,\n",
       " '8/7/15': 959,\n",
       " 'wrote': 960,\n",
       " 'scu': 961,\n",
       " \"'20mcg/kg'\": 962,\n",
       " 'reaching': 963,\n",
       " 'circumstances': 964,\n",
       " 'him': 965,\n",
       " 'ox': 966,\n",
       " 'c-section': 967,\n",
       " 'respiratory': 968,\n",
       " 'anitibiotic': 969,\n",
       " 'seizure': 970,\n",
       " 'irregular': 971,\n",
       " 'cup': 972,\n",
       " 'handoff': 973,\n",
       " 'communicated': 974,\n",
       " 'luck': 975,\n",
       " 'mri': 976,\n",
       " 'scale': 977,\n",
       " 'lortab-': 978,\n",
       " 'voiced': 979,\n",
       " 'incompatibility': 980,\n",
       " 'sets': 981,\n",
       " 'nitro': 982,\n",
       " 'positive': 983,\n",
       " 'verifiy': 984,\n",
       " 'subcutaneous': 985,\n",
       " 'medcations': 986,\n",
       " 'acknowledged': 987,\n",
       " 'infiltrating': 988,\n",
       " 'assisted': 989,\n",
       " 'diphenhydramine': 990,\n",
       " 'labeled': 991,\n",
       " 'setting': 992,\n",
       " 'client': 993,\n",
       " 'trazodone': 994,\n",
       " \"'medication\": 995,\n",
       " 'airway': 996,\n",
       " 'gotten': 997,\n",
       " 'flush': 998,\n",
       " '286': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary of words in the vocabulary mapped to index positions \n",
    "# (to be used in layer_0)\n",
    "word2index = {}\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word] = i\n",
    "    \n",
    "# display the map of words to indices\n",
    "word2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**  Complete the implementation of `update_input_layer`. It should count \n",
    "          how many times each word is used in the given review, and then store\n",
    "          those counts at the appropriate indices inside `layer_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_input_layer(review):\n",
    "    \"\"\" Modify the global layer_0 to represent the vector form of review.\n",
    "    The element at a given index of layer_0 should represent\n",
    "    how many times the given word occurs in the review.\n",
    "    Args:\n",
    "        review(string) - the string of the review\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "     \n",
    "    global layer_0\n",
    "    \n",
    "    # clear out previous state, reset the layer to be all 0s\n",
    "    layer_0 *= 0\n",
    "    \n",
    "    # count how many times each word is used in the given review and store the results in layer_0 \n",
    "    for word in review.split(\" \"):\n",
    "        layer_0[0][word2index[word]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to test updating the input layer with the first review. The indices assigned may not be the same as in the solution, but hopefully you'll see some non-zero values in `layer_0`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_input_layer(reviews[0])\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Complete the implementation of `get_target_for_labels`. It should return `0` or `1`, \n",
    "          depending on whether the given label is `NEGATIVE` or `POSITIVE`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_for_label(label):\n",
    "    \"\"\"Convert a label to `0` or `1`.\n",
    "    Args:\n",
    "        label(string) - Either \"POSITIVE\" or \"NEGATIVE\".\n",
    "    Returns:\n",
    "        `0` or `1`.\n",
    "    \"\"\"\n",
    "    if(label == 'ADMINISTER/MONITOR'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following two cells. They should print out`'POSITIVE'` and `1`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADMINISTER/MONITOR'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_target_for_label(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following two cells. They should print out `'NEGATIVE'` and `0`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOTADMINISTER/MONITOR'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_target_for_label(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Project 2 solution. \n",
    "## Watch the next video to continue with Andrew's next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Building a Neural Network<a id='project_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**TODO:** We've included the framework of a class called `SentimentNetork`. Implement all of the items marked `TODO` in the code. These include doing the following:\n",
    "- Create a basic neural network much like the networks you've seen in earlier lessons and in Project 1, with an input layer, a hidden layer, and an output layer. \n",
    "- Do **not** add a non-linearity in the hidden layer. That is, do not use an activation function when calculating the hidden layer outputs.\n",
    "- Re-use the code from earlier in this notebook to create the training data (see `TODO`s in the code)\n",
    "- Implement the `pre_process_data` function to create the vocabulary for our training data generating functions\n",
    "- Ensure `train` trains over the entire corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to Get Help if You Need it\n",
    "- Re-watch previous week's Udacity Lectures\n",
    "- Chapters 3-5 - [Grokking Deep Learning](https://www.manning.com/books/grokking-deep-learning) - (Check inside your classroom for a discount code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Encapsulate our neural network in a class\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "        \"\"\"Create a SentimenNetwork with the given settings\n",
    "        Args:\n",
    "            reviews(list) - List of reviews used for training\n",
    "            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n",
    "            hidden_nodes(int) - Number of nodes to create in the hidden layer\n",
    "            learning_rate(float) - Learning rate to use while training\n",
    "        \n",
    "        \"\"\"\n",
    "        # Assign a seed to our random number generator to ensure we get\n",
    "        # reproducable results during development \n",
    "        np.random.seed(1)\n",
    "\n",
    "        # process the reviews and their associated labels so that everything\n",
    "        # is ready for training\n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        # Build the network to have the number of hidden nodes and the learning rate that\n",
    "        # were passed into this initializer. Make the same number of input nodes as\n",
    "        # there are vocabulary words and create a single output node.\n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        # populate review_vocab with all of the words in the given reviews\n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "\n",
    "        # Convert the vocabulary set to a list so we can access words via indices\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        # populate label_vocab with all of the words in the given labels.\n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of the review and label vocabularies.\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        # Create a dictionary of labels mapped to index positions\n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Store the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "\n",
    "        # These are the weights between the input layer and the hidden layer.\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        # These are the weights between the hidden layer and the output layer.\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        # The input layer, a two-dimensional matrix with shape 1 x input_nodes\n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "    \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        \n",
    "        for word in review.split(\" \"):\n",
    "            # NOTE: This if-check was not in the version of this method created in Project 2,\n",
    "            #       and it appears in Andrew's Project 3 solution without explanation. \n",
    "            #       It simply ensures the word is actually a key in word2index before\n",
    "            #       accessing it, which is important because accessing an invalid key\n",
    "            #       with raise an exception in Python. This allows us to ignore unknown\n",
    "            #       words encountered in new reviews.\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] += 1\n",
    "                \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'ADMINISTER/MONITOR'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        # make sure out we have a matching number of reviews and labels\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        # Keep track of correct predictions to display accuracy during training \n",
    "        correct_so_far = 0\n",
    "\n",
    "        # Remember when we started for printing time statistics\n",
    "        start = time.time()\n",
    "        \n",
    "        # loop through all the given reviews and run a forward and backward pass,\n",
    "        # updating weights for every item\n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            # Get the next review and its correct label\n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # Update the weights\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            # Keep track of correct predictions.\n",
    "            if(layer_2 >= 0.5 and label == 'ADMINISTER/MONITOR'):\n",
    "                correct_so_far += 1\n",
    "            elif(layer_2 < 0.5 and label == 'NOTADMINISTER/MONITOR'):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the training process. \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \"\"\"\n",
    "        Attempts to predict the labels for the given testing_reviews,\n",
    "        and uses the test_labels to calculate the accuracy of those predictions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # keep track of how many correct predictions we make\n",
    "        correct = 0\n",
    "\n",
    "        # we'll time how many predictions per second we make\n",
    "        start = time.time()\n",
    "\n",
    "        # Loop through each of the given reviews and call run to predict\n",
    "        # its label. \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the prediction process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \"\"\"\n",
    "        Returns a POSITIVE or NEGATIVE prediction for the given review.\n",
    "        \"\"\"\n",
    "        # Run a forward pass through the network, like in the \"train\" function.\n",
    "        \n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        # Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;\n",
    "        # return NEGATIVE for other values\n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"ADMINISTER/MONITOR\"\n",
    "        else:\n",
    "            return \"NOTADMINISTER/MONITOR\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to create a `SentimentNetwork` that will train on all but the last 1000 reviews (we're saving those for testing). Here we use a learning rate of `0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = SentimentNetwork(reviews[:-120],labels[:-120], learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to test the network's performance against the last 1000 reviews (the ones we held out from our training set). \n",
    "\n",
    "**We have not trained the model yet, so the results should be about 50% as it will just be guessing and there are only two possible values to choose from.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Tested:1 Testing Accuracy:0.0%\r",
      "Progress:0.83% Speed(reviews/sec):1105. #Correct:0 #Tested:2 Testing Accuracy:0.0%\r",
      "Progress:1.66% Speed(reviews/sec):1591. #Correct:0 #Tested:3 Testing Accuracy:0.0%\r",
      "Progress:2.5% Speed(reviews/sec):1811. #Correct:0 #Tested:4 Testing Accuracy:0.0%\r",
      "Progress:3.33% Speed(reviews/sec):2044. #Correct:0 #Tested:5 Testing Accuracy:0.0%\r",
      "Progress:4.16% Speed(reviews/sec):2290. #Correct:1 #Tested:6 Testing Accuracy:16.6%\r",
      "Progress:5.0% Speed(reviews/sec):2536. #Correct:1 #Tested:7 Testing Accuracy:14.2%\r",
      "Progress:5.83% Speed(reviews/sec):2597. #Correct:1 #Tested:8 Testing Accuracy:12.5%\r",
      "Progress:6.66% Speed(reviews/sec):2685. #Correct:2 #Tested:9 Testing Accuracy:22.2%\r",
      "Progress:7.5% Speed(reviews/sec):2815. #Correct:2 #Tested:10 Testing Accuracy:20.0%\r",
      "Progress:8.33% Speed(reviews/sec):2926. #Correct:2 #Tested:11 Testing Accuracy:18.1%\r",
      "Progress:9.16% Speed(reviews/sec):2992. #Correct:2 #Tested:12 Testing Accuracy:16.6%\r",
      "Progress:10.0% Speed(reviews/sec):3104. #Correct:2 #Tested:13 Testing Accuracy:15.3%\r",
      "Progress:10.8% Speed(reviews/sec):3198. #Correct:2 #Tested:14 Testing Accuracy:14.2%\r",
      "Progress:11.6% Speed(reviews/sec):3281. #Correct:3 #Tested:15 Testing Accuracy:20.0%\r",
      "Progress:12.5% Speed(reviews/sec):3364. #Correct:3 #Tested:16 Testing Accuracy:18.7%\r",
      "Progress:13.3% Speed(reviews/sec):3449. #Correct:3 #Tested:17 Testing Accuracy:17.6%\r",
      "Progress:14.1% Speed(reviews/sec):3574. #Correct:3 #Tested:18 Testing Accuracy:16.6%\r",
      "Progress:15.0% Speed(reviews/sec):3629. #Correct:4 #Tested:19 Testing Accuracy:21.0%\r",
      "Progress:15.8% Speed(reviews/sec):3676. #Correct:5 #Tested:20 Testing Accuracy:25.0%\r",
      "Progress:16.6% Speed(reviews/sec):3721. #Correct:5 #Tested:21 Testing Accuracy:23.8%\r",
      "Progress:17.5% Speed(reviews/sec):3781. #Correct:5 #Tested:22 Testing Accuracy:22.7%\r",
      "Progress:18.3% Speed(reviews/sec):3890. #Correct:5 #Tested:23 Testing Accuracy:21.7%\r",
      "Progress:19.1% Speed(reviews/sec):4001. #Correct:6 #Tested:24 Testing Accuracy:25.0%\r",
      "Progress:20.0% Speed(reviews/sec):4109. #Correct:7 #Tested:25 Testing Accuracy:28.0%\r",
      "Progress:20.8% Speed(reviews/sec):4175. #Correct:7 #Tested:26 Testing Accuracy:26.9%\r",
      "Progress:21.6% Speed(reviews/sec):4236. #Correct:7 #Tested:27 Testing Accuracy:25.9%\r",
      "Progress:22.5% Speed(reviews/sec):4324. #Correct:7 #Tested:28 Testing Accuracy:25.0%\r",
      "Progress:23.3% Speed(reviews/sec):4394. #Correct:7 #Tested:29 Testing Accuracy:24.1%\r",
      "Progress:24.1% Speed(reviews/sec):4462. #Correct:7 #Tested:30 Testing Accuracy:23.3%\r",
      "Progress:25.0% Speed(reviews/sec):4546. #Correct:7 #Tested:31 Testing Accuracy:22.5%\r",
      "Progress:25.8% Speed(reviews/sec):4626. #Correct:7 #Tested:32 Testing Accuracy:21.8%\r",
      "Progress:26.6% Speed(reviews/sec):4705. #Correct:8 #Tested:33 Testing Accuracy:24.2%\r",
      "Progress:27.5% Speed(reviews/sec):4777. #Correct:8 #Tested:34 Testing Accuracy:23.5%\r",
      "Progress:28.3% Speed(reviews/sec):4853. #Correct:9 #Tested:35 Testing Accuracy:25.7%\r",
      "Progress:29.1% Speed(reviews/sec):4928. #Correct:9 #Tested:36 Testing Accuracy:25.0%\r",
      "Progress:30.0% Speed(reviews/sec):4999. #Correct:9 #Tested:37 Testing Accuracy:24.3%\r",
      "Progress:30.8% Speed(reviews/sec):5069. #Correct:10 #Tested:38 Testing Accuracy:26.3%\r",
      "Progress:31.6% Speed(reviews/sec):5106. #Correct:10 #Tested:39 Testing Accuracy:25.6%\r",
      "Progress:32.5% Speed(reviews/sec):5132. #Correct:10 #Tested:40 Testing Accuracy:25.0%\r",
      "Progress:33.3% Speed(reviews/sec):5177. #Correct:10 #Tested:41 Testing Accuracy:24.3%\r",
      "Progress:34.1% Speed(reviews/sec):5220. #Correct:10 #Tested:42 Testing Accuracy:23.8%\r",
      "Progress:35.0% Speed(reviews/sec):5265. #Correct:11 #Tested:43 Testing Accuracy:25.5%\r",
      "Progress:35.8% Speed(reviews/sec):5306. #Correct:11 #Tested:44 Testing Accuracy:25.0%\r",
      "Progress:36.6% Speed(reviews/sec):5333. #Correct:11 #Tested:45 Testing Accuracy:24.4%\r",
      "Progress:37.5% Speed(reviews/sec):5337. #Correct:11 #Tested:46 Testing Accuracy:23.9%\r",
      "Progress:38.3% Speed(reviews/sec):5362. #Correct:11 #Tested:47 Testing Accuracy:23.4%\r",
      "Progress:39.1% Speed(reviews/sec):5395. #Correct:12 #Tested:48 Testing Accuracy:25.0%\r",
      "Progress:40.0% Speed(reviews/sec):5431. #Correct:12 #Tested:49 Testing Accuracy:24.4%\r",
      "Progress:40.8% Speed(reviews/sec):5504. #Correct:12 #Tested:50 Testing Accuracy:24.0%\r",
      "Progress:41.6% Speed(reviews/sec):5507. #Correct:12 #Tested:51 Testing Accuracy:23.5%\r",
      "Progress:42.5% Speed(reviews/sec):5579. #Correct:12 #Tested:52 Testing Accuracy:23.0%\r",
      "Progress:43.3% Speed(reviews/sec):5536. #Correct:12 #Tested:53 Testing Accuracy:22.6%\r",
      "Progress:44.1% Speed(reviews/sec):5479. #Correct:13 #Tested:54 Testing Accuracy:24.0%\r",
      "Progress:45.0% Speed(reviews/sec):5414. #Correct:13 #Tested:55 Testing Accuracy:23.6%\r",
      "Progress:45.8% Speed(reviews/sec):5380. #Correct:14 #Tested:56 Testing Accuracy:25.0%\r",
      "Progress:46.6% Speed(reviews/sec):5308. #Correct:15 #Tested:57 Testing Accuracy:26.3%\r",
      "Progress:47.5% Speed(reviews/sec):5273. #Correct:16 #Tested:58 Testing Accuracy:27.5%\r",
      "Progress:48.3% Speed(reviews/sec):5256. #Correct:17 #Tested:59 Testing Accuracy:28.8%\r",
      "Progress:49.1% Speed(reviews/sec):5232. #Correct:17 #Tested:60 Testing Accuracy:28.3%\r",
      "Progress:50.0% Speed(reviews/sec):5212. #Correct:18 #Tested:61 Testing Accuracy:29.5%\r",
      "Progress:50.8% Speed(reviews/sec):5202. #Correct:18 #Tested:62 Testing Accuracy:29.0%\r",
      "Progress:51.6% Speed(reviews/sec):5129. #Correct:19 #Tested:63 Testing Accuracy:30.1%\r",
      "Progress:52.5% Speed(reviews/sec):5088. #Correct:19 #Tested:64 Testing Accuracy:29.6%\r",
      "Progress:53.3% Speed(reviews/sec):5072. #Correct:19 #Tested:65 Testing Accuracy:29.2%\r",
      "Progress:54.1% Speed(reviews/sec):5006. #Correct:19 #Tested:66 Testing Accuracy:28.7%\r",
      "Progress:55.0% Speed(reviews/sec):4984. #Correct:20 #Tested:67 Testing Accuracy:29.8%\r",
      "Progress:55.8% Speed(reviews/sec):4966. #Correct:20 #Tested:68 Testing Accuracy:29.4%\r",
      "Progress:56.6% Speed(reviews/sec):4958. #Correct:20 #Tested:69 Testing Accuracy:28.9%\r",
      "Progress:57.5% Speed(reviews/sec):4949. #Correct:21 #Tested:70 Testing Accuracy:30.0%\r",
      "Progress:58.3% Speed(reviews/sec):4916. #Correct:22 #Tested:71 Testing Accuracy:30.9%\r",
      "Progress:59.1% Speed(reviews/sec):4901. #Correct:22 #Tested:72 Testing Accuracy:30.5%\r",
      "Progress:60.0% Speed(reviews/sec):4887. #Correct:22 #Tested:73 Testing Accuracy:30.1%\r",
      "Progress:60.8% Speed(reviews/sec):4860. #Correct:22 #Tested:74 Testing Accuracy:29.7%\r",
      "Progress:61.6% Speed(reviews/sec):4843. #Correct:22 #Tested:75 Testing Accuracy:29.3%\r",
      "Progress:62.5% Speed(reviews/sec):4853. #Correct:22 #Tested:76 Testing Accuracy:28.9%\r",
      "Progress:63.3% Speed(reviews/sec):4852. #Correct:23 #Tested:77 Testing Accuracy:29.8%\r",
      "Progress:64.1% Speed(reviews/sec):4840. #Correct:23 #Tested:78 Testing Accuracy:29.4%\r",
      "Progress:65.0% Speed(reviews/sec):4832. #Correct:23 #Tested:79 Testing Accuracy:29.1%\r",
      "Progress:65.8% Speed(reviews/sec):4815. #Correct:23 #Tested:80 Testing Accuracy:28.7%\r",
      "Progress:66.6% Speed(reviews/sec):4802. #Correct:23 #Tested:81 Testing Accuracy:28.3%\r",
      "Progress:67.5% Speed(reviews/sec):4799. #Correct:24 #Tested:82 Testing Accuracy:29.2%\r",
      "Progress:68.3% Speed(reviews/sec):4797. #Correct:25 #Tested:83 Testing Accuracy:30.1%\r",
      "Progress:69.1% Speed(reviews/sec):4798. #Correct:25 #Tested:84 Testing Accuracy:29.7%\r",
      "Progress:70.0% Speed(reviews/sec):4797. #Correct:25 #Tested:85 Testing Accuracy:29.4%\r",
      "Progress:70.8% Speed(reviews/sec):4796. #Correct:25 #Tested:86 Testing Accuracy:29.0%\r",
      "Progress:71.6% Speed(reviews/sec):4799. #Correct:25 #Tested:87 Testing Accuracy:28.7%\r",
      "Progress:72.5% Speed(reviews/sec):4801. #Correct:25 #Tested:88 Testing Accuracy:28.4%\r",
      "Progress:73.3% Speed(reviews/sec):4803. #Correct:25 #Tested:89 Testing Accuracy:28.0%\r",
      "Progress:74.1% Speed(reviews/sec):4803. #Correct:26 #Tested:90 Testing Accuracy:28.8%\r",
      "Progress:75.0% Speed(reviews/sec):4804. #Correct:26 #Tested:91 Testing Accuracy:28.5%\r",
      "Progress:75.8% Speed(reviews/sec):4804. #Correct:26 #Tested:92 Testing Accuracy:28.2%\r",
      "Progress:76.6% Speed(reviews/sec):4807. #Correct:26 #Tested:93 Testing Accuracy:27.9%\r",
      "Progress:77.5% Speed(reviews/sec):4806. #Correct:26 #Tested:94 Testing Accuracy:27.6%\r",
      "Progress:78.3% Speed(reviews/sec):4805. #Correct:27 #Tested:95 Testing Accuracy:28.4%\r",
      "Progress:79.1% Speed(reviews/sec):4805. #Correct:27 #Tested:96 Testing Accuracy:28.1%\r",
      "Progress:80.0% Speed(reviews/sec):4808. #Correct:27 #Tested:97 Testing Accuracy:27.8%\r",
      "Progress:80.8% Speed(reviews/sec):4809. #Correct:27 #Tested:98 Testing Accuracy:27.5%\r",
      "Progress:81.6% Speed(reviews/sec):4814. #Correct:27 #Tested:99 Testing Accuracy:27.2%\r",
      "Progress:82.5% Speed(reviews/sec):4816. #Correct:28 #Tested:100 Testing Accuracy:28.0%\r",
      "Progress:83.3% Speed(reviews/sec):4820. #Correct:28 #Tested:101 Testing Accuracy:27.7%\r",
      "Progress:84.1% Speed(reviews/sec):4825. #Correct:28 #Tested:102 Testing Accuracy:27.4%\r",
      "Progress:85.0% Speed(reviews/sec):4826. #Correct:28 #Tested:103 Testing Accuracy:27.1%\r",
      "Progress:85.8% Speed(reviews/sec):4829. #Correct:29 #Tested:104 Testing Accuracy:27.8%\r",
      "Progress:86.6% Speed(reviews/sec):4833. #Correct:29 #Tested:105 Testing Accuracy:27.6%\r",
      "Progress:87.5% Speed(reviews/sec):4839. #Correct:29 #Tested:106 Testing Accuracy:27.3%\r",
      "Progress:88.3% Speed(reviews/sec):4843. #Correct:30 #Tested:107 Testing Accuracy:28.0%\r",
      "Progress:89.1% Speed(reviews/sec):4848. #Correct:31 #Tested:108 Testing Accuracy:28.7%\r",
      "Progress:90.0% Speed(reviews/sec):4853. #Correct:32 #Tested:109 Testing Accuracy:29.3%\r",
      "Progress:90.8% Speed(reviews/sec):4857. #Correct:32 #Tested:110 Testing Accuracy:29.0%\r",
      "Progress:91.6% Speed(reviews/sec):4862. #Correct:32 #Tested:111 Testing Accuracy:28.8%\r",
      "Progress:92.5% Speed(reviews/sec):4868. #Correct:32 #Tested:112 Testing Accuracy:28.5%\r",
      "Progress:93.3% Speed(reviews/sec):4874. #Correct:33 #Tested:113 Testing Accuracy:29.2%\r",
      "Progress:94.1% Speed(reviews/sec):4880. #Correct:33 #Tested:114 Testing Accuracy:28.9%\r",
      "Progress:95.0% Speed(reviews/sec):4880. #Correct:33 #Tested:115 Testing Accuracy:28.6%\r",
      "Progress:95.8% Speed(reviews/sec):4882. #Correct:33 #Tested:116 Testing Accuracy:28.4%\r",
      "Progress:96.6% Speed(reviews/sec):4877. #Correct:34 #Tested:117 Testing Accuracy:29.0%\r",
      "Progress:97.5% Speed(reviews/sec):4878. #Correct:34 #Tested:118 Testing Accuracy:28.8%\r",
      "Progress:98.3% Speed(reviews/sec):4875. #Correct:34 #Tested:119 Testing Accuracy:28.5%\r",
      "Progress:99.1% Speed(reviews/sec):4871. #Correct:34 #Tested:120 Testing Accuracy:28.3%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-120:],labels[-120:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to actually train the network. During training, it will display the model's accuracy repeatedly as it trains so you can see how well it's doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "\r",
      "Progress:0.24% Speed(reviews/sec):461.9 #Correct:1 #Trained:2 Training Accuracy:50.0%\r",
      "Progress:0.49% Speed(reviews/sec):692.7 #Correct:2 #Trained:3 Training Accuracy:66.6%\r",
      "Progress:0.74% Speed(reviews/sec):828.4 #Correct:3 #Trained:4 Training Accuracy:75.0%\r",
      "Progress:0.99% Speed(reviews/sec):960.1 #Correct:4 #Trained:5 Training Accuracy:80.0%\r",
      "Progress:1.24% Speed(reviews/sec):1062. #Correct:4 #Trained:6 Training Accuracy:66.6%\r",
      "Progress:1.49% Speed(reviews/sec):1143. #Correct:4 #Trained:7 Training Accuracy:57.1%\r",
      "Progress:1.74% Speed(reviews/sec):1202. #Correct:4 #Trained:8 Training Accuracy:50.0%\r",
      "Progress:1.99% Speed(reviews/sec):1261. #Correct:5 #Trained:9 Training Accuracy:55.5%\r",
      "Progress:2.24% Speed(reviews/sec):1314. #Correct:5 #Trained:10 Training Accuracy:50.0%\r",
      "Progress:2.49% Speed(reviews/sec):1350. #Correct:6 #Trained:11 Training Accuracy:54.5%\r",
      "Progress:2.74% Speed(reviews/sec):1391. #Correct:7 #Trained:12 Training Accuracy:58.3%\r",
      "Progress:2.99% Speed(reviews/sec):1428. #Correct:8 #Trained:13 Training Accuracy:61.5%\r",
      "Progress:3.24% Speed(reviews/sec):1461. #Correct:8 #Trained:14 Training Accuracy:57.1%\r",
      "Progress:3.49% Speed(reviews/sec):1477. #Correct:8 #Trained:15 Training Accuracy:53.3%\r",
      "Progress:3.74% Speed(reviews/sec):1499. #Correct:9 #Trained:16 Training Accuracy:56.2%\r",
      "Progress:3.99% Speed(reviews/sec):1523. #Correct:10 #Trained:17 Training Accuracy:58.8%\r",
      "Progress:4.23% Speed(reviews/sec):1546. #Correct:11 #Trained:18 Training Accuracy:61.1%\r",
      "Progress:4.48% Speed(reviews/sec):1564. #Correct:11 #Trained:19 Training Accuracy:57.8%\r",
      "Progress:4.73% Speed(reviews/sec):1578. #Correct:12 #Trained:20 Training Accuracy:60.0%\r",
      "Progress:4.98% Speed(reviews/sec):1571. #Correct:12 #Trained:21 Training Accuracy:57.1%\r",
      "Progress:5.23% Speed(reviews/sec):1589. #Correct:12 #Trained:22 Training Accuracy:54.5%\r",
      "Progress:5.48% Speed(reviews/sec):1606. #Correct:12 #Trained:23 Training Accuracy:52.1%\r",
      "Progress:5.73% Speed(reviews/sec):1622. #Correct:12 #Trained:24 Training Accuracy:50.0%\r",
      "Progress:5.98% Speed(reviews/sec):1637. #Correct:12 #Trained:25 Training Accuracy:48.0%\r",
      "Progress:6.23% Speed(reviews/sec):1651. #Correct:13 #Trained:26 Training Accuracy:50.0%\r",
      "Progress:6.48% Speed(reviews/sec):1665. #Correct:13 #Trained:27 Training Accuracy:48.1%\r",
      "Progress:6.73% Speed(reviews/sec):1680. #Correct:13 #Trained:28 Training Accuracy:46.4%\r",
      "Progress:6.98% Speed(reviews/sec):1693. #Correct:13 #Trained:29 Training Accuracy:44.8%\r",
      "Progress:7.23% Speed(reviews/sec):1701. #Correct:13 #Trained:30 Training Accuracy:43.3%\r",
      "Progress:7.48% Speed(reviews/sec):1710. #Correct:14 #Trained:31 Training Accuracy:45.1%\r",
      "Progress:7.73% Speed(reviews/sec):1722. #Correct:15 #Trained:32 Training Accuracy:46.8%\r",
      "Progress:7.98% Speed(reviews/sec):1734. #Correct:15 #Trained:33 Training Accuracy:45.4%\r",
      "Progress:8.22% Speed(reviews/sec):1747. #Correct:15 #Trained:34 Training Accuracy:44.1%\r",
      "Progress:8.47% Speed(reviews/sec):1759. #Correct:16 #Trained:35 Training Accuracy:45.7%\r",
      "Progress:8.72% Speed(reviews/sec):1776. #Correct:16 #Trained:36 Training Accuracy:44.4%\r",
      "Progress:8.97% Speed(reviews/sec):1794. #Correct:16 #Trained:37 Training Accuracy:43.2%\r",
      "Progress:9.22% Speed(reviews/sec):1807. #Correct:16 #Trained:38 Training Accuracy:42.1%\r",
      "Progress:9.47% Speed(reviews/sec):1817. #Correct:17 #Trained:39 Training Accuracy:43.5%\r",
      "Progress:9.72% Speed(reviews/sec):1827. #Correct:17 #Trained:40 Training Accuracy:42.5%\r",
      "Progress:9.97% Speed(reviews/sec):1836. #Correct:17 #Trained:41 Training Accuracy:41.4%\r",
      "Progress:10.2% Speed(reviews/sec):1847. #Correct:17 #Trained:42 Training Accuracy:40.4%\r",
      "Progress:10.4% Speed(reviews/sec):1863. #Correct:17 #Trained:43 Training Accuracy:39.5%\r",
      "Progress:10.7% Speed(reviews/sec):1875. #Correct:17 #Trained:44 Training Accuracy:38.6%\r",
      "Progress:10.9% Speed(reviews/sec):1881. #Correct:18 #Trained:45 Training Accuracy:40.0%\r",
      "Progress:11.2% Speed(reviews/sec):1888. #Correct:19 #Trained:46 Training Accuracy:41.3%\r",
      "Progress:11.4% Speed(reviews/sec):1896. #Correct:20 #Trained:47 Training Accuracy:42.5%\r",
      "Progress:11.7% Speed(reviews/sec):1909. #Correct:20 #Trained:48 Training Accuracy:41.6%\r",
      "Progress:11.9% Speed(reviews/sec):1917. #Correct:21 #Trained:49 Training Accuracy:42.8%\r",
      "Progress:12.2% Speed(reviews/sec):1926. #Correct:22 #Trained:50 Training Accuracy:44.0%\r",
      "Progress:12.4% Speed(reviews/sec):1939. #Correct:22 #Trained:51 Training Accuracy:43.1%\r",
      "Progress:12.7% Speed(reviews/sec):1945. #Correct:23 #Trained:52 Training Accuracy:44.2%\r",
      "Progress:12.9% Speed(reviews/sec):1952. #Correct:24 #Trained:53 Training Accuracy:45.2%\r",
      "Progress:13.2% Speed(reviews/sec):1959. #Correct:25 #Trained:54 Training Accuracy:46.2%\r",
      "Progress:13.4% Speed(reviews/sec):1966. #Correct:26 #Trained:55 Training Accuracy:47.2%\r",
      "Progress:13.7% Speed(reviews/sec):1975. #Correct:26 #Trained:56 Training Accuracy:46.4%\r",
      "Progress:13.9% Speed(reviews/sec):1986. #Correct:26 #Trained:57 Training Accuracy:45.6%\r",
      "Progress:14.2% Speed(reviews/sec):1996. #Correct:27 #Trained:58 Training Accuracy:46.5%\r",
      "Progress:14.4% Speed(reviews/sec):2005. #Correct:28 #Trained:59 Training Accuracy:47.4%\r",
      "Progress:14.7% Speed(reviews/sec):2015. #Correct:28 #Trained:60 Training Accuracy:46.6%\r",
      "Progress:14.9% Speed(reviews/sec):2024. #Correct:29 #Trained:61 Training Accuracy:47.5%\r",
      "Progress:15.2% Speed(reviews/sec):2035. #Correct:29 #Trained:62 Training Accuracy:46.7%\r",
      "Progress:15.4% Speed(reviews/sec):2045. #Correct:30 #Trained:63 Training Accuracy:47.6%\r",
      "Progress:15.7% Speed(reviews/sec):2054. #Correct:31 #Trained:64 Training Accuracy:48.4%\r",
      "Progress:15.9% Speed(reviews/sec):2063. #Correct:31 #Trained:65 Training Accuracy:47.6%\r",
      "Progress:16.2% Speed(reviews/sec):2072. #Correct:32 #Trained:66 Training Accuracy:48.4%\r",
      "Progress:16.4% Speed(reviews/sec):2081. #Correct:32 #Trained:67 Training Accuracy:47.7%\r",
      "Progress:16.7% Speed(reviews/sec):2091. #Correct:32 #Trained:68 Training Accuracy:47.0%\r",
      "Progress:16.9% Speed(reviews/sec):2100. #Correct:33 #Trained:69 Training Accuracy:47.8%\r",
      "Progress:17.2% Speed(reviews/sec):2109. #Correct:34 #Trained:70 Training Accuracy:48.5%\r",
      "Progress:17.4% Speed(reviews/sec):2114. #Correct:34 #Trained:71 Training Accuracy:47.8%\r",
      "Progress:17.7% Speed(reviews/sec):2122. #Correct:35 #Trained:72 Training Accuracy:48.6%\r",
      "Progress:17.9% Speed(reviews/sec):2130. #Correct:35 #Trained:73 Training Accuracy:47.9%\r",
      "Progress:18.2% Speed(reviews/sec):2136. #Correct:35 #Trained:74 Training Accuracy:47.2%\r",
      "Progress:18.4% Speed(reviews/sec):2139. #Correct:36 #Trained:75 Training Accuracy:48.0%\r",
      "Progress:18.7% Speed(reviews/sec):2144. #Correct:37 #Trained:76 Training Accuracy:48.6%\r",
      "Progress:18.9% Speed(reviews/sec):2148. #Correct:38 #Trained:77 Training Accuracy:49.3%\r",
      "Progress:19.2% Speed(reviews/sec):2155. #Correct:38 #Trained:78 Training Accuracy:48.7%\r",
      "Progress:19.4% Speed(reviews/sec):2162. #Correct:38 #Trained:79 Training Accuracy:48.1%\r",
      "Progress:19.7% Speed(reviews/sec):2169. #Correct:38 #Trained:80 Training Accuracy:47.5%\r",
      "Progress:19.9% Speed(reviews/sec):2176. #Correct:39 #Trained:81 Training Accuracy:48.1%\r",
      "Progress:20.1% Speed(reviews/sec):2184. #Correct:40 #Trained:82 Training Accuracy:48.7%\r",
      "Progress:20.4% Speed(reviews/sec):2190. #Correct:40 #Trained:83 Training Accuracy:48.1%\r",
      "Progress:20.6% Speed(reviews/sec):2198. #Correct:41 #Trained:84 Training Accuracy:48.8%\r",
      "Progress:20.9% Speed(reviews/sec):2205. #Correct:41 #Trained:85 Training Accuracy:48.2%\r",
      "Progress:21.1% Speed(reviews/sec):2211. #Correct:42 #Trained:86 Training Accuracy:48.8%\r",
      "Progress:21.4% Speed(reviews/sec):2218. #Correct:42 #Trained:87 Training Accuracy:48.2%\r",
      "Progress:21.6% Speed(reviews/sec):2222. #Correct:43 #Trained:88 Training Accuracy:48.8%\r",
      "Progress:21.9% Speed(reviews/sec):2226. #Correct:43 #Trained:89 Training Accuracy:48.3%\r",
      "Progress:22.1% Speed(reviews/sec):2232. #Correct:44 #Trained:90 Training Accuracy:48.8%\r",
      "Progress:22.4% Speed(reviews/sec):2238. #Correct:45 #Trained:91 Training Accuracy:49.4%\r",
      "Progress:22.6% Speed(reviews/sec):2244. #Correct:46 #Trained:92 Training Accuracy:50.0%\r",
      "Progress:22.9% Speed(reviews/sec):2248. #Correct:46 #Trained:93 Training Accuracy:49.4%\r",
      "Progress:23.1% Speed(reviews/sec):2253. #Correct:47 #Trained:94 Training Accuracy:50.0%\r",
      "Progress:23.4% Speed(reviews/sec):2258. #Correct:47 #Trained:95 Training Accuracy:49.4%\r",
      "Progress:23.6% Speed(reviews/sec):2264. #Correct:48 #Trained:96 Training Accuracy:50.0%\r",
      "Progress:23.9% Speed(reviews/sec):2270. #Correct:48 #Trained:97 Training Accuracy:49.4%\r",
      "Progress:24.1% Speed(reviews/sec):2276. #Correct:48 #Trained:98 Training Accuracy:48.9%\r",
      "Progress:24.4% Speed(reviews/sec):2282. #Correct:48 #Trained:99 Training Accuracy:48.4%\r",
      "Progress:24.6% Speed(reviews/sec):2288. #Correct:48 #Trained:100 Training Accuracy:48.0%\r",
      "Progress:24.9% Speed(reviews/sec):2294. #Correct:49 #Trained:101 Training Accuracy:48.5%\r",
      "Progress:25.1% Speed(reviews/sec):2300. #Correct:50 #Trained:102 Training Accuracy:49.0%\r",
      "Progress:25.4% Speed(reviews/sec):2305. #Correct:50 #Trained:103 Training Accuracy:48.5%\r",
      "Progress:25.6% Speed(reviews/sec):2311. #Correct:51 #Trained:104 Training Accuracy:49.0%\r",
      "Progress:25.9% Speed(reviews/sec):2317. #Correct:52 #Trained:105 Training Accuracy:49.5%\r",
      "Progress:26.1% Speed(reviews/sec):2322. #Correct:52 #Trained:106 Training Accuracy:49.0%\r",
      "Progress:26.4% Speed(reviews/sec):2327. #Correct:53 #Trained:107 Training Accuracy:49.5%\r",
      "Progress:26.6% Speed(reviews/sec):2333. #Correct:53 #Trained:108 Training Accuracy:49.0%\r",
      "Progress:26.9% Speed(reviews/sec):2336. #Correct:53 #Trained:109 Training Accuracy:48.6%\r",
      "Progress:27.1% Speed(reviews/sec):2339. #Correct:54 #Trained:110 Training Accuracy:49.0%\r",
      "Progress:27.4% Speed(reviews/sec):2344. #Correct:54 #Trained:111 Training Accuracy:48.6%\r",
      "Progress:27.6% Speed(reviews/sec):2349. #Correct:55 #Trained:112 Training Accuracy:49.1%\r",
      "Progress:27.9% Speed(reviews/sec):2355. #Correct:56 #Trained:113 Training Accuracy:49.5%\r",
      "Progress:28.1% Speed(reviews/sec):2359. #Correct:56 #Trained:114 Training Accuracy:49.1%\r",
      "Progress:28.4% Speed(reviews/sec):2363. #Correct:57 #Trained:115 Training Accuracy:49.5%\r",
      "Progress:28.6% Speed(reviews/sec):2368. #Correct:58 #Trained:116 Training Accuracy:50.0%\r",
      "Progress:28.9% Speed(reviews/sec):2373. #Correct:59 #Trained:117 Training Accuracy:50.4%\r",
      "Progress:29.1% Speed(reviews/sec):2378. #Correct:59 #Trained:118 Training Accuracy:50.0%\r",
      "Progress:29.4% Speed(reviews/sec):2382. #Correct:59 #Trained:119 Training Accuracy:49.5%\r",
      "Progress:29.6% Speed(reviews/sec):2387. #Correct:60 #Trained:120 Training Accuracy:50.0%\r",
      "Progress:29.9% Speed(reviews/sec):2388. #Correct:61 #Trained:121 Training Accuracy:50.4%\r",
      "Progress:30.1% Speed(reviews/sec):2392. #Correct:61 #Trained:122 Training Accuracy:50.0%\r",
      "Progress:30.4% Speed(reviews/sec):2393. #Correct:62 #Trained:123 Training Accuracy:50.4%\r",
      "Progress:30.6% Speed(reviews/sec):2395. #Correct:62 #Trained:124 Training Accuracy:50.0%\r",
      "Progress:30.9% Speed(reviews/sec):2399. #Correct:63 #Trained:125 Training Accuracy:50.4%\r",
      "Progress:31.1% Speed(reviews/sec):2403. #Correct:64 #Trained:126 Training Accuracy:50.7%\r",
      "Progress:31.4% Speed(reviews/sec):2407. #Correct:64 #Trained:127 Training Accuracy:50.3%\r",
      "Progress:31.6% Speed(reviews/sec):2411. #Correct:65 #Trained:128 Training Accuracy:50.7%\r",
      "Progress:31.9% Speed(reviews/sec):2415. #Correct:65 #Trained:129 Training Accuracy:50.3%\r",
      "Progress:32.1% Speed(reviews/sec):2419. #Correct:66 #Trained:130 Training Accuracy:50.7%\r",
      "Progress:32.4% Speed(reviews/sec):2424. #Correct:67 #Trained:131 Training Accuracy:51.1%\r",
      "Progress:32.6% Speed(reviews/sec):2428. #Correct:67 #Trained:132 Training Accuracy:50.7%\r",
      "Progress:32.9% Speed(reviews/sec):2432. #Correct:67 #Trained:133 Training Accuracy:50.3%\r",
      "Progress:33.1% Speed(reviews/sec):2437. #Correct:68 #Trained:134 Training Accuracy:50.7%\r",
      "Progress:33.4% Speed(reviews/sec):2441. #Correct:69 #Trained:135 Training Accuracy:51.1%\r",
      "Progress:33.6% Speed(reviews/sec):2445. #Correct:69 #Trained:136 Training Accuracy:50.7%\r",
      "Progress:33.9% Speed(reviews/sec):2449. #Correct:69 #Trained:137 Training Accuracy:50.3%\r",
      "Progress:34.1% Speed(reviews/sec):2453. #Correct:70 #Trained:138 Training Accuracy:50.7%\r",
      "Progress:34.4% Speed(reviews/sec):2457. #Correct:71 #Trained:139 Training Accuracy:51.0%\r",
      "Progress:34.6% Speed(reviews/sec):2461. #Correct:72 #Trained:140 Training Accuracy:51.4%\r",
      "Progress:34.9% Speed(reviews/sec):2465. #Correct:72 #Trained:141 Training Accuracy:51.0%\r",
      "Progress:35.1% Speed(reviews/sec):2469. #Correct:72 #Trained:142 Training Accuracy:50.7%\r",
      "Progress:35.4% Speed(reviews/sec):2473. #Correct:73 #Trained:143 Training Accuracy:51.0%\r",
      "Progress:35.6% Speed(reviews/sec):2477. #Correct:73 #Trained:144 Training Accuracy:50.6%\r",
      "Progress:35.9% Speed(reviews/sec):2481. #Correct:74 #Trained:145 Training Accuracy:51.0%\r",
      "Progress:36.1% Speed(reviews/sec):2485. #Correct:74 #Trained:146 Training Accuracy:50.6%\r",
      "Progress:36.4% Speed(reviews/sec):2488. #Correct:74 #Trained:147 Training Accuracy:50.3%\r",
      "Progress:36.6% Speed(reviews/sec):2492. #Correct:75 #Trained:148 Training Accuracy:50.6%\r",
      "Progress:36.9% Speed(reviews/sec):2496. #Correct:75 #Trained:149 Training Accuracy:50.3%\r",
      "Progress:37.1% Speed(reviews/sec):2500. #Correct:76 #Trained:150 Training Accuracy:50.6%\r",
      "Progress:37.4% Speed(reviews/sec):2503. #Correct:76 #Trained:151 Training Accuracy:50.3%\r",
      "Progress:37.6% Speed(reviews/sec):2507. #Correct:76 #Trained:152 Training Accuracy:50.0%\r",
      "Progress:37.9% Speed(reviews/sec):2510. #Correct:77 #Trained:153 Training Accuracy:50.3%\r",
      "Progress:38.1% Speed(reviews/sec):2512. #Correct:77 #Trained:154 Training Accuracy:50.0%\r",
      "Progress:38.4% Speed(reviews/sec):2514. #Correct:78 #Trained:155 Training Accuracy:50.3%\r",
      "Progress:38.6% Speed(reviews/sec):2516. #Correct:78 #Trained:156 Training Accuracy:50.0%\r",
      "Progress:38.9% Speed(reviews/sec):2518. #Correct:79 #Trained:157 Training Accuracy:50.3%\r",
      "Progress:39.1% Speed(reviews/sec):2521. #Correct:80 #Trained:158 Training Accuracy:50.6%\r",
      "Progress:39.4% Speed(reviews/sec):2523. #Correct:81 #Trained:159 Training Accuracy:50.9%\r",
      "Progress:39.6% Speed(reviews/sec):2525. #Correct:82 #Trained:160 Training Accuracy:51.2%\r",
      "Progress:39.9% Speed(reviews/sec):2528. #Correct:83 #Trained:161 Training Accuracy:51.5%\r",
      "Progress:40.1% Speed(reviews/sec):2529. #Correct:84 #Trained:162 Training Accuracy:51.8%\r",
      "Progress:40.3% Speed(reviews/sec):2531. #Correct:84 #Trained:163 Training Accuracy:51.5%\r",
      "Progress:40.6% Speed(reviews/sec):2534. #Correct:84 #Trained:164 Training Accuracy:51.2%\r",
      "Progress:40.8% Speed(reviews/sec):2536. #Correct:84 #Trained:165 Training Accuracy:50.9%\r",
      "Progress:41.1% Speed(reviews/sec):2538. #Correct:85 #Trained:166 Training Accuracy:51.2%\r",
      "Progress:41.3% Speed(reviews/sec):2540. #Correct:86 #Trained:167 Training Accuracy:51.4%\r",
      "Progress:41.6% Speed(reviews/sec):2542. #Correct:86 #Trained:168 Training Accuracy:51.1%\r",
      "Progress:41.8% Speed(reviews/sec):2544. #Correct:86 #Trained:169 Training Accuracy:50.8%\r",
      "Progress:42.1% Speed(reviews/sec):2547. #Correct:87 #Trained:170 Training Accuracy:51.1%\r",
      "Progress:42.3% Speed(reviews/sec):2549. #Correct:88 #Trained:171 Training Accuracy:51.4%\r",
      "Progress:42.6% Speed(reviews/sec):2547. #Correct:88 #Trained:172 Training Accuracy:51.1%\r",
      "Progress:42.8% Speed(reviews/sec):2546. #Correct:88 #Trained:173 Training Accuracy:50.8%\r",
      "Progress:43.1% Speed(reviews/sec):2546. #Correct:89 #Trained:174 Training Accuracy:51.1%\r",
      "Progress:43.3% Speed(reviews/sec):2545. #Correct:90 #Trained:175 Training Accuracy:51.4%\r",
      "Progress:43.6% Speed(reviews/sec):2546. #Correct:90 #Trained:176 Training Accuracy:51.1%\r",
      "Progress:43.8% Speed(reviews/sec):2545. #Correct:91 #Trained:177 Training Accuracy:51.4%\r",
      "Progress:44.1% Speed(reviews/sec):2545. #Correct:92 #Trained:178 Training Accuracy:51.6%\r",
      "Progress:44.3% Speed(reviews/sec):2546. #Correct:93 #Trained:179 Training Accuracy:51.9%\r",
      "Progress:44.6% Speed(reviews/sec):2546. #Correct:94 #Trained:180 Training Accuracy:52.2%\r",
      "Progress:44.8% Speed(reviews/sec):2546. #Correct:95 #Trained:181 Training Accuracy:52.4%\r",
      "Progress:45.1% Speed(reviews/sec):2546. #Correct:96 #Trained:182 Training Accuracy:52.7%\r",
      "Progress:45.3% Speed(reviews/sec):2546. #Correct:97 #Trained:183 Training Accuracy:53.0%\r",
      "Progress:45.6% Speed(reviews/sec):2547. #Correct:98 #Trained:184 Training Accuracy:53.2%\r",
      "Progress:45.8% Speed(reviews/sec):2547. #Correct:98 #Trained:185 Training Accuracy:52.9%\r",
      "Progress:46.1% Speed(reviews/sec):2550. #Correct:99 #Trained:186 Training Accuracy:53.2%\r",
      "Progress:46.3% Speed(reviews/sec):2550. #Correct:99 #Trained:187 Training Accuracy:52.9%\r",
      "Progress:46.6% Speed(reviews/sec):2550. #Correct:100 #Trained:188 Training Accuracy:53.1%\r",
      "Progress:46.8% Speed(reviews/sec):2551. #Correct:100 #Trained:189 Training Accuracy:52.9%\r",
      "Progress:47.1% Speed(reviews/sec):2552. #Correct:101 #Trained:190 Training Accuracy:53.1%\r",
      "Progress:47.3% Speed(reviews/sec):2553. #Correct:102 #Trained:191 Training Accuracy:53.4%\r",
      "Progress:47.6% Speed(reviews/sec):2553. #Correct:103 #Trained:192 Training Accuracy:53.6%\r",
      "Progress:47.8% Speed(reviews/sec):2554. #Correct:103 #Trained:193 Training Accuracy:53.3%\r",
      "Progress:48.1% Speed(reviews/sec):2556. #Correct:103 #Trained:194 Training Accuracy:53.0%\r",
      "Progress:48.3% Speed(reviews/sec):2556. #Correct:103 #Trained:195 Training Accuracy:52.8%\r",
      "Progress:48.6% Speed(reviews/sec):2557. #Correct:103 #Trained:196 Training Accuracy:52.5%\r",
      "Progress:48.8% Speed(reviews/sec):2558. #Correct:104 #Trained:197 Training Accuracy:52.7%\r",
      "Progress:49.1% Speed(reviews/sec):2559. #Correct:105 #Trained:198 Training Accuracy:53.0%\r",
      "Progress:49.3% Speed(reviews/sec):2560. #Correct:106 #Trained:199 Training Accuracy:53.2%\r",
      "Progress:49.6% Speed(reviews/sec):2561. #Correct:106 #Trained:200 Training Accuracy:53.0%\r",
      "Progress:49.8% Speed(reviews/sec):2562. #Correct:107 #Trained:201 Training Accuracy:53.2%\r",
      "Progress:50.1% Speed(reviews/sec):2563. #Correct:108 #Trained:202 Training Accuracy:53.4%\r",
      "Progress:50.3% Speed(reviews/sec):2564. #Correct:109 #Trained:203 Training Accuracy:53.6%\r",
      "Progress:50.6% Speed(reviews/sec):2565. #Correct:109 #Trained:204 Training Accuracy:53.4%\r",
      "Progress:50.8% Speed(reviews/sec):2567. #Correct:110 #Trained:205 Training Accuracy:53.6%\r",
      "Progress:51.1% Speed(reviews/sec):2568. #Correct:110 #Trained:206 Training Accuracy:53.3%\r",
      "Progress:51.3% Speed(reviews/sec):2569. #Correct:111 #Trained:207 Training Accuracy:53.6%\r",
      "Progress:51.6% Speed(reviews/sec):2570. #Correct:112 #Trained:208 Training Accuracy:53.8%\r",
      "Progress:51.8% Speed(reviews/sec):2572. #Correct:113 #Trained:209 Training Accuracy:54.0%\r",
      "Progress:52.1% Speed(reviews/sec):2575. #Correct:113 #Trained:210 Training Accuracy:53.8%\r",
      "Progress:52.3% Speed(reviews/sec):2556. #Correct:113 #Trained:211 Training Accuracy:53.5%\r",
      "Progress:52.6% Speed(reviews/sec):2541. #Correct:114 #Trained:212 Training Accuracy:53.7%\r",
      "Progress:52.8% Speed(reviews/sec):2523. #Correct:114 #Trained:213 Training Accuracy:53.5%\r",
      "Progress:53.1% Speed(reviews/sec):2508. #Correct:114 #Trained:214 Training Accuracy:53.2%\r",
      "Progress:53.3% Speed(reviews/sec):2496. #Correct:114 #Trained:215 Training Accuracy:53.0%\r",
      "Progress:53.6% Speed(reviews/sec):2485. #Correct:114 #Trained:216 Training Accuracy:52.7%\r",
      "Progress:53.8% Speed(reviews/sec):2474. #Correct:114 #Trained:217 Training Accuracy:52.5%\r",
      "Progress:54.1% Speed(reviews/sec):2467. #Correct:115 #Trained:218 Training Accuracy:52.7%\r",
      "Progress:54.3% Speed(reviews/sec):2459. #Correct:116 #Trained:219 Training Accuracy:52.9%\r",
      "Progress:54.6% Speed(reviews/sec):2453. #Correct:116 #Trained:220 Training Accuracy:52.7%\r",
      "Progress:54.8% Speed(reviews/sec):2444. #Correct:117 #Trained:221 Training Accuracy:52.9%\r",
      "Progress:55.1% Speed(reviews/sec):2437. #Correct:117 #Trained:222 Training Accuracy:52.7%\r",
      "Progress:55.3% Speed(reviews/sec):2429. #Correct:118 #Trained:223 Training Accuracy:52.9%\r",
      "Progress:55.6% Speed(reviews/sec):2421. #Correct:119 #Trained:224 Training Accuracy:53.1%\r",
      "Progress:55.8% Speed(reviews/sec):2412. #Correct:120 #Trained:225 Training Accuracy:53.3%\r",
      "Progress:56.1% Speed(reviews/sec):2405. #Correct:120 #Trained:226 Training Accuracy:53.0%\r",
      "Progress:56.3% Speed(reviews/sec):2392. #Correct:121 #Trained:227 Training Accuracy:53.3%\r",
      "Progress:56.6% Speed(reviews/sec):2381. #Correct:122 #Trained:228 Training Accuracy:53.5%\r",
      "Progress:56.8% Speed(reviews/sec):2372. #Correct:123 #Trained:229 Training Accuracy:53.7%\r",
      "Progress:57.1% Speed(reviews/sec):2366. #Correct:124 #Trained:230 Training Accuracy:53.9%\r",
      "Progress:57.3% Speed(reviews/sec):2358. #Correct:125 #Trained:231 Training Accuracy:54.1%\r",
      "Progress:57.6% Speed(reviews/sec):2351. #Correct:126 #Trained:232 Training Accuracy:54.3%\r",
      "Progress:57.8% Speed(reviews/sec):2345. #Correct:127 #Trained:233 Training Accuracy:54.5%\r",
      "Progress:58.1% Speed(reviews/sec):2339. #Correct:128 #Trained:234 Training Accuracy:54.7%\r",
      "Progress:58.3% Speed(reviews/sec):2332. #Correct:128 #Trained:235 Training Accuracy:54.4%\r",
      "Progress:58.6% Speed(reviews/sec):2321. #Correct:129 #Trained:236 Training Accuracy:54.6%\r",
      "Progress:58.8% Speed(reviews/sec):2314. #Correct:130 #Trained:237 Training Accuracy:54.8%\r",
      "Progress:59.1% Speed(reviews/sec):2309. #Correct:131 #Trained:238 Training Accuracy:55.0%\r",
      "Progress:59.3% Speed(reviews/sec):2297. #Correct:131 #Trained:239 Training Accuracy:54.8%\r",
      "Progress:59.6% Speed(reviews/sec):2291. #Correct:132 #Trained:240 Training Accuracy:55.0%\r",
      "Progress:59.8% Speed(reviews/sec):2286. #Correct:133 #Trained:241 Training Accuracy:55.1%\r",
      "Progress:60.0% Speed(reviews/sec):2281. #Correct:134 #Trained:242 Training Accuracy:55.3%\r",
      "Progress:60.3% Speed(reviews/sec):2277. #Correct:135 #Trained:243 Training Accuracy:55.5%\r",
      "Progress:60.5% Speed(reviews/sec):2272. #Correct:135 #Trained:244 Training Accuracy:55.3%\r",
      "Progress:60.8% Speed(reviews/sec):2268. #Correct:135 #Trained:245 Training Accuracy:55.1%\r",
      "Progress:61.0% Speed(reviews/sec):2264. #Correct:136 #Trained:246 Training Accuracy:55.2%\r",
      "Progress:61.3% Speed(reviews/sec):2260. #Correct:136 #Trained:247 Training Accuracy:55.0%\r",
      "Progress:61.5% Speed(reviews/sec):2256. #Correct:137 #Trained:248 Training Accuracy:55.2%\r",
      "Progress:61.8% Speed(reviews/sec):2253. #Correct:137 #Trained:249 Training Accuracy:55.0%\r",
      "Progress:62.0% Speed(reviews/sec):2249. #Correct:137 #Trained:250 Training Accuracy:54.8%\r",
      "Progress:62.3% Speed(reviews/sec):2246. #Correct:138 #Trained:251 Training Accuracy:54.9%\r",
      "Progress:62.5% Speed(reviews/sec):2243. #Correct:139 #Trained:252 Training Accuracy:55.1%\r",
      "Progress:62.8% Speed(reviews/sec):2240. #Correct:140 #Trained:253 Training Accuracy:55.3%\r",
      "Progress:63.0% Speed(reviews/sec):2237. #Correct:140 #Trained:254 Training Accuracy:55.1%\r",
      "Progress:63.3% Speed(reviews/sec):2235. #Correct:141 #Trained:255 Training Accuracy:55.2%\r",
      "Progress:63.5% Speed(reviews/sec):2232. #Correct:141 #Trained:256 Training Accuracy:55.0%\r",
      "Progress:63.8% Speed(reviews/sec):2230. #Correct:142 #Trained:257 Training Accuracy:55.2%\r",
      "Progress:64.0% Speed(reviews/sec):2227. #Correct:143 #Trained:258 Training Accuracy:55.4%\r",
      "Progress:64.3% Speed(reviews/sec):2225. #Correct:144 #Trained:259 Training Accuracy:55.5%\r",
      "Progress:64.5% Speed(reviews/sec):2223. #Correct:144 #Trained:260 Training Accuracy:55.3%\r",
      "Progress:64.8% Speed(reviews/sec):2221. #Correct:144 #Trained:261 Training Accuracy:55.1%\r",
      "Progress:65.0% Speed(reviews/sec):2219. #Correct:145 #Trained:262 Training Accuracy:55.3%\r",
      "Progress:65.3% Speed(reviews/sec):2217. #Correct:145 #Trained:263 Training Accuracy:55.1%\r",
      "Progress:65.5% Speed(reviews/sec):2213. #Correct:146 #Trained:264 Training Accuracy:55.3%\r",
      "Progress:65.8% Speed(reviews/sec):2211. #Correct:147 #Trained:265 Training Accuracy:55.4%\r",
      "Progress:66.0% Speed(reviews/sec):2208. #Correct:148 #Trained:266 Training Accuracy:55.6%\r",
      "Progress:66.3% Speed(reviews/sec):2205. #Correct:148 #Trained:267 Training Accuracy:55.4%\r",
      "Progress:66.5% Speed(reviews/sec):2203. #Correct:148 #Trained:268 Training Accuracy:55.2%\r",
      "Progress:66.8% Speed(reviews/sec):2200. #Correct:148 #Trained:269 Training Accuracy:55.0%\r",
      "Progress:67.0% Speed(reviews/sec):2198. #Correct:148 #Trained:270 Training Accuracy:54.8%\r",
      "Progress:67.3% Speed(reviews/sec):2196. #Correct:149 #Trained:271 Training Accuracy:54.9%\r",
      "Progress:67.5% Speed(reviews/sec):2193. #Correct:149 #Trained:272 Training Accuracy:54.7%\r",
      "Progress:67.8% Speed(reviews/sec):2191. #Correct:150 #Trained:273 Training Accuracy:54.9%\r",
      "Progress:68.0% Speed(reviews/sec):2189. #Correct:150 #Trained:274 Training Accuracy:54.7%\r",
      "Progress:68.3% Speed(reviews/sec):2187. #Correct:151 #Trained:275 Training Accuracy:54.9%\r",
      "Progress:68.5% Speed(reviews/sec):2186. #Correct:151 #Trained:276 Training Accuracy:54.7%\r",
      "Progress:68.8% Speed(reviews/sec):2184. #Correct:151 #Trained:277 Training Accuracy:54.5%\r",
      "Progress:69.0% Speed(reviews/sec):2183. #Correct:152 #Trained:278 Training Accuracy:54.6%\r",
      "Progress:69.3% Speed(reviews/sec):2181. #Correct:152 #Trained:279 Training Accuracy:54.4%\r",
      "Progress:69.5% Speed(reviews/sec):2180. #Correct:152 #Trained:280 Training Accuracy:54.2%\r",
      "Progress:69.8% Speed(reviews/sec):2178. #Correct:152 #Trained:281 Training Accuracy:54.0%\r",
      "Progress:70.0% Speed(reviews/sec):2176. #Correct:153 #Trained:282 Training Accuracy:54.2%\r",
      "Progress:70.3% Speed(reviews/sec):2174. #Correct:153 #Trained:283 Training Accuracy:54.0%\r",
      "Progress:70.5% Speed(reviews/sec):2172. #Correct:154 #Trained:284 Training Accuracy:54.2%\r",
      "Progress:70.8% Speed(reviews/sec):2171. #Correct:154 #Trained:285 Training Accuracy:54.0%\r",
      "Progress:71.0% Speed(reviews/sec):2171. #Correct:155 #Trained:286 Training Accuracy:54.1%\r",
      "Progress:71.3% Speed(reviews/sec):2171. #Correct:156 #Trained:287 Training Accuracy:54.3%\r",
      "Progress:71.5% Speed(reviews/sec):2171. #Correct:156 #Trained:288 Training Accuracy:54.1%\r",
      "Progress:71.8% Speed(reviews/sec):2171. #Correct:156 #Trained:289 Training Accuracy:53.9%\r",
      "Progress:72.0% Speed(reviews/sec):2169. #Correct:157 #Trained:290 Training Accuracy:54.1%\r",
      "Progress:72.3% Speed(reviews/sec):2168. #Correct:157 #Trained:291 Training Accuracy:53.9%\r",
      "Progress:72.5% Speed(reviews/sec):2167. #Correct:157 #Trained:292 Training Accuracy:53.7%\r",
      "Progress:72.8% Speed(reviews/sec):2167. #Correct:158 #Trained:293 Training Accuracy:53.9%\r",
      "Progress:73.0% Speed(reviews/sec):2167. #Correct:158 #Trained:294 Training Accuracy:53.7%\r",
      "Progress:73.3% Speed(reviews/sec):2167. #Correct:159 #Trained:295 Training Accuracy:53.8%\r",
      "Progress:73.5% Speed(reviews/sec):2168. #Correct:159 #Trained:296 Training Accuracy:53.7%\r",
      "Progress:73.8% Speed(reviews/sec):2169. #Correct:160 #Trained:297 Training Accuracy:53.8%\r",
      "Progress:74.0% Speed(reviews/sec):2170. #Correct:161 #Trained:298 Training Accuracy:54.0%\r",
      "Progress:74.3% Speed(reviews/sec):2170. #Correct:161 #Trained:299 Training Accuracy:53.8%\r",
      "Progress:74.5% Speed(reviews/sec):2172. #Correct:162 #Trained:300 Training Accuracy:54.0%\r",
      "Progress:74.8% Speed(reviews/sec):2173. #Correct:162 #Trained:301 Training Accuracy:53.8%\r",
      "Progress:75.0% Speed(reviews/sec):2174. #Correct:163 #Trained:302 Training Accuracy:53.9%\r",
      "Progress:75.3% Speed(reviews/sec):2175. #Correct:164 #Trained:303 Training Accuracy:54.1%\r",
      "Progress:75.5% Speed(reviews/sec):2174. #Correct:165 #Trained:304 Training Accuracy:54.2%\r",
      "Progress:75.8% Speed(reviews/sec):2175. #Correct:165 #Trained:305 Training Accuracy:54.0%\r",
      "Progress:76.0% Speed(reviews/sec):2175. #Correct:166 #Trained:306 Training Accuracy:54.2%\r",
      "Progress:76.3% Speed(reviews/sec):2175. #Correct:166 #Trained:307 Training Accuracy:54.0%\r",
      "Progress:76.5% Speed(reviews/sec):2175. #Correct:167 #Trained:308 Training Accuracy:54.2%\r",
      "Progress:76.8% Speed(reviews/sec):2177. #Correct:168 #Trained:309 Training Accuracy:54.3%\r",
      "Progress:77.0% Speed(reviews/sec):2176. #Correct:169 #Trained:310 Training Accuracy:54.5%\r",
      "Progress:77.3% Speed(reviews/sec):2177. #Correct:170 #Trained:311 Training Accuracy:54.6%\r",
      "Progress:77.5% Speed(reviews/sec):2177. #Correct:171 #Trained:312 Training Accuracy:54.8%\r",
      "Progress:77.8% Speed(reviews/sec):2179. #Correct:171 #Trained:313 Training Accuracy:54.6%\r",
      "Progress:78.0% Speed(reviews/sec):2180. #Correct:172 #Trained:314 Training Accuracy:54.7%\r",
      "Progress:78.3% Speed(reviews/sec):2180. #Correct:173 #Trained:315 Training Accuracy:54.9%\r",
      "Progress:78.5% Speed(reviews/sec):2181. #Correct:174 #Trained:316 Training Accuracy:55.0%\r",
      "Progress:78.8% Speed(reviews/sec):2182. #Correct:174 #Trained:317 Training Accuracy:54.8%\r",
      "Progress:79.0% Speed(reviews/sec):2183. #Correct:175 #Trained:318 Training Accuracy:55.0%\r",
      "Progress:79.3% Speed(reviews/sec):2184. #Correct:175 #Trained:319 Training Accuracy:54.8%\r",
      "Progress:79.5% Speed(reviews/sec):2181. #Correct:175 #Trained:320 Training Accuracy:54.6%\r",
      "Progress:79.8% Speed(reviews/sec):2179. #Correct:176 #Trained:321 Training Accuracy:54.8%\r",
      "Progress:80.0% Speed(reviews/sec):2179. #Correct:177 #Trained:322 Training Accuracy:54.9%\r",
      "Progress:80.2% Speed(reviews/sec):2179. #Correct:178 #Trained:323 Training Accuracy:55.1%\r",
      "Progress:80.5% Speed(reviews/sec):2180. #Correct:178 #Trained:324 Training Accuracy:54.9%\r",
      "Progress:80.7% Speed(reviews/sec):2180. #Correct:179 #Trained:325 Training Accuracy:55.0%\r",
      "Progress:81.0% Speed(reviews/sec):2180. #Correct:179 #Trained:326 Training Accuracy:54.9%\r",
      "Progress:81.2% Speed(reviews/sec):2181. #Correct:180 #Trained:327 Training Accuracy:55.0%\r",
      "Progress:81.5% Speed(reviews/sec):2181. #Correct:181 #Trained:328 Training Accuracy:55.1%\r",
      "Progress:81.7% Speed(reviews/sec):2182. #Correct:181 #Trained:329 Training Accuracy:55.0%\r",
      "Progress:82.0% Speed(reviews/sec):2182. #Correct:182 #Trained:330 Training Accuracy:55.1%\r",
      "Progress:82.2% Speed(reviews/sec):2182. #Correct:183 #Trained:331 Training Accuracy:55.2%\r",
      "Progress:82.5% Speed(reviews/sec):2182. #Correct:184 #Trained:332 Training Accuracy:55.4%\r",
      "Progress:82.7% Speed(reviews/sec):2182. #Correct:184 #Trained:333 Training Accuracy:55.2%\r",
      "Progress:83.0% Speed(reviews/sec):2182. #Correct:184 #Trained:334 Training Accuracy:55.0%\r",
      "Progress:83.2% Speed(reviews/sec):2183. #Correct:185 #Trained:335 Training Accuracy:55.2%\r",
      "Progress:83.5% Speed(reviews/sec):2184. #Correct:185 #Trained:336 Training Accuracy:55.0%\r",
      "Progress:83.7% Speed(reviews/sec):2186. #Correct:186 #Trained:337 Training Accuracy:55.1%\r",
      "Progress:84.0% Speed(reviews/sec):2187. #Correct:187 #Trained:338 Training Accuracy:55.3%\r",
      "Progress:84.2% Speed(reviews/sec):2186. #Correct:188 #Trained:339 Training Accuracy:55.4%\r",
      "Progress:84.5% Speed(reviews/sec):2185. #Correct:188 #Trained:340 Training Accuracy:55.2%\r",
      "Progress:84.7% Speed(reviews/sec):2186. #Correct:189 #Trained:341 Training Accuracy:55.4%\r",
      "Progress:85.0% Speed(reviews/sec):2186. #Correct:189 #Trained:342 Training Accuracy:55.2%\r",
      "Progress:85.2% Speed(reviews/sec):2188. #Correct:190 #Trained:343 Training Accuracy:55.3%\r",
      "Progress:85.5% Speed(reviews/sec):2189. #Correct:191 #Trained:344 Training Accuracy:55.5%\r",
      "Progress:85.7% Speed(reviews/sec):2191. #Correct:191 #Trained:345 Training Accuracy:55.3%\r",
      "Progress:86.0% Speed(reviews/sec):2192. #Correct:191 #Trained:346 Training Accuracy:55.2%\r",
      "Progress:86.2% Speed(reviews/sec):2193. #Correct:192 #Trained:347 Training Accuracy:55.3%\r",
      "Progress:86.5% Speed(reviews/sec):2194. #Correct:192 #Trained:348 Training Accuracy:55.1%\r",
      "Progress:86.7% Speed(reviews/sec):2196. #Correct:193 #Trained:349 Training Accuracy:55.3%\r",
      "Progress:87.0% Speed(reviews/sec):2197. #Correct:194 #Trained:350 Training Accuracy:55.4%\r",
      "Progress:87.2% Speed(reviews/sec):2198. #Correct:194 #Trained:351 Training Accuracy:55.2%\r",
      "Progress:87.5% Speed(reviews/sec):2200. #Correct:195 #Trained:352 Training Accuracy:55.3%\r",
      "Progress:87.7% Speed(reviews/sec):2201. #Correct:196 #Trained:353 Training Accuracy:55.5%\r",
      "Progress:88.0% Speed(reviews/sec):2203. #Correct:197 #Trained:354 Training Accuracy:55.6%\r",
      "Progress:88.2% Speed(reviews/sec):2204. #Correct:197 #Trained:355 Training Accuracy:55.4%\r",
      "Progress:88.5% Speed(reviews/sec):2206. #Correct:197 #Trained:356 Training Accuracy:55.3%\r",
      "Progress:88.7% Speed(reviews/sec):2207. #Correct:198 #Trained:357 Training Accuracy:55.4%\r",
      "Progress:89.0% Speed(reviews/sec):2203. #Correct:198 #Trained:358 Training Accuracy:55.3%\r",
      "Progress:89.2% Speed(reviews/sec):2199. #Correct:199 #Trained:359 Training Accuracy:55.4%\r",
      "Progress:89.5% Speed(reviews/sec):2195. #Correct:200 #Trained:360 Training Accuracy:55.5%\r",
      "Progress:89.7% Speed(reviews/sec):2194. #Correct:200 #Trained:361 Training Accuracy:55.4%\r",
      "Progress:90.0% Speed(reviews/sec):2192. #Correct:201 #Trained:362 Training Accuracy:55.5%\r",
      "Progress:90.2% Speed(reviews/sec):2190. #Correct:202 #Trained:363 Training Accuracy:55.6%\r",
      "Progress:90.5% Speed(reviews/sec):2188. #Correct:203 #Trained:364 Training Accuracy:55.7%\r",
      "Progress:90.7% Speed(reviews/sec):2187. #Correct:204 #Trained:365 Training Accuracy:55.8%\r",
      "Progress:91.0% Speed(reviews/sec):2187. #Correct:205 #Trained:366 Training Accuracy:56.0%\r",
      "Progress:91.2% Speed(reviews/sec):2186. #Correct:206 #Trained:367 Training Accuracy:56.1%\r",
      "Progress:91.5% Speed(reviews/sec):2184. #Correct:206 #Trained:368 Training Accuracy:55.9%\r",
      "Progress:91.7% Speed(reviews/sec):2182. #Correct:207 #Trained:369 Training Accuracy:56.0%\r",
      "Progress:92.0% Speed(reviews/sec):2181. #Correct:208 #Trained:370 Training Accuracy:56.2%\r",
      "Progress:92.2% Speed(reviews/sec):2180. #Correct:209 #Trained:371 Training Accuracy:56.3%\r",
      "Progress:92.5% Speed(reviews/sec):2179. #Correct:210 #Trained:372 Training Accuracy:56.4%\r",
      "Progress:92.7% Speed(reviews/sec):2178. #Correct:211 #Trained:373 Training Accuracy:56.5%\r",
      "Progress:93.0% Speed(reviews/sec):2177. #Correct:211 #Trained:374 Training Accuracy:56.4%\r",
      "Progress:93.2% Speed(reviews/sec):2177. #Correct:212 #Trained:375 Training Accuracy:56.5%\r",
      "Progress:93.5% Speed(reviews/sec):2176. #Correct:212 #Trained:376 Training Accuracy:56.3%\r",
      "Progress:93.7% Speed(reviews/sec):2176. #Correct:213 #Trained:377 Training Accuracy:56.4%\r",
      "Progress:94.0% Speed(reviews/sec):2176. #Correct:214 #Trained:378 Training Accuracy:56.6%\r",
      "Progress:94.2% Speed(reviews/sec):2175. #Correct:214 #Trained:379 Training Accuracy:56.4%\r",
      "Progress:94.5% Speed(reviews/sec):2175. #Correct:215 #Trained:380 Training Accuracy:56.5%\r",
      "Progress:94.7% Speed(reviews/sec):2175. #Correct:215 #Trained:381 Training Accuracy:56.4%\r",
      "Progress:95.0% Speed(reviews/sec):2175. #Correct:215 #Trained:382 Training Accuracy:56.2%\r",
      "Progress:95.2% Speed(reviews/sec):2175. #Correct:215 #Trained:383 Training Accuracy:56.1%\r",
      "Progress:95.5% Speed(reviews/sec):2175. #Correct:216 #Trained:384 Training Accuracy:56.2%\r",
      "Progress:95.7% Speed(reviews/sec):2175. #Correct:216 #Trained:385 Training Accuracy:56.1%\r",
      "Progress:96.0% Speed(reviews/sec):2176. #Correct:217 #Trained:386 Training Accuracy:56.2%\r",
      "Progress:96.2% Speed(reviews/sec):2176. #Correct:218 #Trained:387 Training Accuracy:56.3%\r",
      "Progress:96.5% Speed(reviews/sec):2177. #Correct:219 #Trained:388 Training Accuracy:56.4%\r",
      "Progress:96.7% Speed(reviews/sec):2178. #Correct:219 #Trained:389 Training Accuracy:56.2%\r",
      "Progress:97.0% Speed(reviews/sec):2179. #Correct:220 #Trained:390 Training Accuracy:56.4%\r",
      "Progress:97.2% Speed(reviews/sec):2180. #Correct:221 #Trained:391 Training Accuracy:56.5%\r",
      "Progress:97.5% Speed(reviews/sec):2180. #Correct:222 #Trained:392 Training Accuracy:56.6%\r",
      "Progress:97.7% Speed(reviews/sec):2181. #Correct:223 #Trained:393 Training Accuracy:56.7%\r",
      "Progress:98.0% Speed(reviews/sec):2182. #Correct:224 #Trained:394 Training Accuracy:56.8%\r",
      "Progress:98.2% Speed(reviews/sec):2183. #Correct:225 #Trained:395 Training Accuracy:56.9%\r",
      "Progress:98.5% Speed(reviews/sec):2184. #Correct:226 #Trained:396 Training Accuracy:57.0%\r",
      "Progress:98.7% Speed(reviews/sec):2185. #Correct:227 #Trained:397 Training Accuracy:57.1%\r",
      "Progress:99.0% Speed(reviews/sec):2186. #Correct:228 #Trained:398 Training Accuracy:57.2%\r",
      "Progress:99.2% Speed(reviews/sec):2186. #Correct:228 #Trained:399 Training Accuracy:57.1%\r",
      "Progress:99.5% Speed(reviews/sec):2187. #Correct:228 #Trained:400 Training Accuracy:57.0%\r",
      "Progress:99.7% Speed(reviews/sec):2188. #Correct:229 #Trained:401 Training Accuracy:57.1%"
     ]
    }
   ],
   "source": [
    "mlp.train(reviews[:-120],labels[:-120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That most likely didn't train very well. Part of the reason may be because the learning rate is too high. Run the following cell to recreate the network with a smaller learning rate, `0.01`, and then train the new network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "\r",
      "Progress:0.24% Speed(reviews/sec):542.3 #Correct:1 #Trained:2 Training Accuracy:50.0%\r",
      "Progress:0.49% Speed(reviews/sec):834.3 #Correct:2 #Trained:3 Training Accuracy:66.6%\r",
      "Progress:0.74% Speed(reviews/sec):1032. #Correct:3 #Trained:4 Training Accuracy:75.0%\r",
      "Progress:0.99% Speed(reviews/sec):1160. #Correct:4 #Trained:5 Training Accuracy:80.0%\r",
      "Progress:1.24% Speed(reviews/sec):1256. #Correct:4 #Trained:6 Training Accuracy:66.6%\r",
      "Progress:1.49% Speed(reviews/sec):1344. #Correct:4 #Trained:7 Training Accuracy:57.1%\r",
      "Progress:1.74% Speed(reviews/sec):1409. #Correct:4 #Trained:8 Training Accuracy:50.0%\r",
      "Progress:1.99% Speed(reviews/sec):1454. #Correct:5 #Trained:9 Training Accuracy:55.5%\r",
      "Progress:2.24% Speed(reviews/sec):1494. #Correct:5 #Trained:10 Training Accuracy:50.0%\r",
      "Progress:2.49% Speed(reviews/sec):1541. #Correct:5 #Trained:11 Training Accuracy:45.4%\r",
      "Progress:2.74% Speed(reviews/sec):1593. #Correct:5 #Trained:12 Training Accuracy:41.6%\r",
      "Progress:2.99% Speed(reviews/sec):1630. #Correct:5 #Trained:13 Training Accuracy:38.4%\r",
      "Progress:3.24% Speed(reviews/sec):1659. #Correct:6 #Trained:14 Training Accuracy:42.8%\r",
      "Progress:3.49% Speed(reviews/sec):1685. #Correct:7 #Trained:15 Training Accuracy:46.6%\r",
      "Progress:3.74% Speed(reviews/sec):1705. #Correct:8 #Trained:16 Training Accuracy:50.0%\r",
      "Progress:3.99% Speed(reviews/sec):1727. #Correct:9 #Trained:17 Training Accuracy:52.9%\r",
      "Progress:4.23% Speed(reviews/sec):1749. #Correct:10 #Trained:18 Training Accuracy:55.5%\r",
      "Progress:4.48% Speed(reviews/sec):1765. #Correct:10 #Trained:19 Training Accuracy:52.6%\r",
      "Progress:4.73% Speed(reviews/sec):1778. #Correct:11 #Trained:20 Training Accuracy:55.0%\r",
      "Progress:4.98% Speed(reviews/sec):1804. #Correct:11 #Trained:21 Training Accuracy:52.3%\r",
      "Progress:5.23% Speed(reviews/sec):1830. #Correct:11 #Trained:22 Training Accuracy:50.0%\r",
      "Progress:5.48% Speed(reviews/sec):1835. #Correct:12 #Trained:23 Training Accuracy:52.1%\r",
      "Progress:5.73% Speed(reviews/sec):1843. #Correct:13 #Trained:24 Training Accuracy:54.1%\r",
      "Progress:5.98% Speed(reviews/sec):1851. #Correct:13 #Trained:25 Training Accuracy:52.0%\r",
      "Progress:6.23% Speed(reviews/sec):1861. #Correct:13 #Trained:26 Training Accuracy:50.0%\r",
      "Progress:6.48% Speed(reviews/sec):1872. #Correct:14 #Trained:27 Training Accuracy:51.8%\r",
      "Progress:6.73% Speed(reviews/sec):1883. #Correct:15 #Trained:28 Training Accuracy:53.5%\r",
      "Progress:6.98% Speed(reviews/sec):1894. #Correct:15 #Trained:29 Training Accuracy:51.7%\r",
      "Progress:7.23% Speed(reviews/sec):1905. #Correct:16 #Trained:30 Training Accuracy:53.3%\r",
      "Progress:7.48% Speed(reviews/sec):1920. #Correct:17 #Trained:31 Training Accuracy:54.8%\r",
      "Progress:7.73% Speed(reviews/sec):1932. #Correct:18 #Trained:32 Training Accuracy:56.2%\r",
      "Progress:7.98% Speed(reviews/sec):1944. #Correct:18 #Trained:33 Training Accuracy:54.5%\r",
      "Progress:8.22% Speed(reviews/sec):1956. #Correct:18 #Trained:34 Training Accuracy:52.9%\r",
      "Progress:8.47% Speed(reviews/sec):1964. #Correct:18 #Trained:35 Training Accuracy:51.4%\r",
      "Progress:8.72% Speed(reviews/sec):1973. #Correct:18 #Trained:36 Training Accuracy:50.0%\r",
      "Progress:8.97% Speed(reviews/sec):1984. #Correct:18 #Trained:37 Training Accuracy:48.6%\r",
      "Progress:9.22% Speed(reviews/sec):1992. #Correct:18 #Trained:38 Training Accuracy:47.3%\r",
      "Progress:9.47% Speed(reviews/sec):2002. #Correct:19 #Trained:39 Training Accuracy:48.7%\r",
      "Progress:9.72% Speed(reviews/sec):2011. #Correct:19 #Trained:40 Training Accuracy:47.5%\r",
      "Progress:9.97% Speed(reviews/sec):2020. #Correct:19 #Trained:41 Training Accuracy:46.3%\r",
      "Progress:10.2% Speed(reviews/sec):2029. #Correct:20 #Trained:42 Training Accuracy:47.6%\r",
      "Progress:10.4% Speed(reviews/sec):2039. #Correct:20 #Trained:43 Training Accuracy:46.5%\r",
      "Progress:10.7% Speed(reviews/sec):2047. #Correct:21 #Trained:44 Training Accuracy:47.7%\r",
      "Progress:10.9% Speed(reviews/sec):2054. #Correct:22 #Trained:45 Training Accuracy:48.8%\r",
      "Progress:11.2% Speed(reviews/sec):2062. #Correct:23 #Trained:46 Training Accuracy:50.0%\r",
      "Progress:11.4% Speed(reviews/sec):2070. #Correct:24 #Trained:47 Training Accuracy:51.0%\r",
      "Progress:11.7% Speed(reviews/sec):2077. #Correct:24 #Trained:48 Training Accuracy:50.0%\r",
      "Progress:11.9% Speed(reviews/sec):2085. #Correct:24 #Trained:49 Training Accuracy:48.9%\r",
      "Progress:12.2% Speed(reviews/sec):2093. #Correct:24 #Trained:50 Training Accuracy:48.0%\r",
      "Progress:12.4% Speed(reviews/sec):2105. #Correct:24 #Trained:51 Training Accuracy:47.0%\r",
      "Progress:12.7% Speed(reviews/sec):2116. #Correct:25 #Trained:52 Training Accuracy:48.0%\r",
      "Progress:12.9% Speed(reviews/sec):2127. #Correct:26 #Trained:53 Training Accuracy:49.0%\r",
      "Progress:13.2% Speed(reviews/sec):2137. #Correct:26 #Trained:54 Training Accuracy:48.1%\r",
      "Progress:13.4% Speed(reviews/sec):2147. #Correct:27 #Trained:55 Training Accuracy:49.0%\r",
      "Progress:13.7% Speed(reviews/sec):2153. #Correct:27 #Trained:56 Training Accuracy:48.2%\r",
      "Progress:13.9% Speed(reviews/sec):2159. #Correct:27 #Trained:57 Training Accuracy:47.3%\r",
      "Progress:14.2% Speed(reviews/sec):2162. #Correct:28 #Trained:58 Training Accuracy:48.2%\r",
      "Progress:14.4% Speed(reviews/sec):2168. #Correct:29 #Trained:59 Training Accuracy:49.1%\r",
      "Progress:14.7% Speed(reviews/sec):2177. #Correct:29 #Trained:60 Training Accuracy:48.3%\r",
      "Progress:14.9% Speed(reviews/sec):2184. #Correct:30 #Trained:61 Training Accuracy:49.1%\r",
      "Progress:15.2% Speed(reviews/sec):2192. #Correct:30 #Trained:62 Training Accuracy:48.3%\r",
      "Progress:15.4% Speed(reviews/sec):2201. #Correct:31 #Trained:63 Training Accuracy:49.2%\r",
      "Progress:15.7% Speed(reviews/sec):2209. #Correct:31 #Trained:64 Training Accuracy:48.4%\r",
      "Progress:15.9% Speed(reviews/sec):2213. #Correct:31 #Trained:65 Training Accuracy:47.6%\r",
      "Progress:16.2% Speed(reviews/sec):2217. #Correct:32 #Trained:66 Training Accuracy:48.4%\r",
      "Progress:16.4% Speed(reviews/sec):2225. #Correct:32 #Trained:67 Training Accuracy:47.7%\r",
      "Progress:16.7% Speed(reviews/sec):2233. #Correct:32 #Trained:68 Training Accuracy:47.0%\r",
      "Progress:16.9% Speed(reviews/sec):2240. #Correct:33 #Trained:69 Training Accuracy:47.8%\r",
      "Progress:17.2% Speed(reviews/sec):2247. #Correct:34 #Trained:70 Training Accuracy:48.5%\r",
      "Progress:17.4% Speed(reviews/sec):2255. #Correct:34 #Trained:71 Training Accuracy:47.8%\r",
      "Progress:17.7% Speed(reviews/sec):2262. #Correct:35 #Trained:72 Training Accuracy:48.6%\r",
      "Progress:17.9% Speed(reviews/sec):2269. #Correct:36 #Trained:73 Training Accuracy:49.3%\r",
      "Progress:18.2% Speed(reviews/sec):2276. #Correct:37 #Trained:74 Training Accuracy:50.0%\r",
      "Progress:18.4% Speed(reviews/sec):2284. #Correct:38 #Trained:75 Training Accuracy:50.6%\r",
      "Progress:18.7% Speed(reviews/sec):2291. #Correct:39 #Trained:76 Training Accuracy:51.3%\r",
      "Progress:18.9% Speed(reviews/sec):2297. #Correct:40 #Trained:77 Training Accuracy:51.9%\r",
      "Progress:19.2% Speed(reviews/sec):2304. #Correct:41 #Trained:78 Training Accuracy:52.5%\r",
      "Progress:19.4% Speed(reviews/sec):2311. #Correct:41 #Trained:79 Training Accuracy:51.8%\r",
      "Progress:19.7% Speed(reviews/sec):2319. #Correct:42 #Trained:80 Training Accuracy:52.5%\r",
      "Progress:19.9% Speed(reviews/sec):2325. #Correct:43 #Trained:81 Training Accuracy:53.0%\r",
      "Progress:20.1% Speed(reviews/sec):2332. #Correct:44 #Trained:82 Training Accuracy:53.6%\r",
      "Progress:20.4% Speed(reviews/sec):2339. #Correct:45 #Trained:83 Training Accuracy:54.2%\r",
      "Progress:20.6% Speed(reviews/sec):2346. #Correct:46 #Trained:84 Training Accuracy:54.7%\r",
      "Progress:20.9% Speed(reviews/sec):2352. #Correct:46 #Trained:85 Training Accuracy:54.1%\r",
      "Progress:21.1% Speed(reviews/sec):2358. #Correct:46 #Trained:86 Training Accuracy:53.4%\r",
      "Progress:21.4% Speed(reviews/sec):2364. #Correct:46 #Trained:87 Training Accuracy:52.8%\r",
      "Progress:21.6% Speed(reviews/sec):2369. #Correct:46 #Trained:88 Training Accuracy:52.2%\r",
      "Progress:21.9% Speed(reviews/sec):2375. #Correct:47 #Trained:89 Training Accuracy:52.8%\r",
      "Progress:22.1% Speed(reviews/sec):2381. #Correct:48 #Trained:90 Training Accuracy:53.3%\r",
      "Progress:22.4% Speed(reviews/sec):2387. #Correct:49 #Trained:91 Training Accuracy:53.8%\r",
      "Progress:22.6% Speed(reviews/sec):2390. #Correct:49 #Trained:92 Training Accuracy:53.2%\r",
      "Progress:22.9% Speed(reviews/sec):2394. #Correct:49 #Trained:93 Training Accuracy:52.6%\r",
      "Progress:23.1% Speed(reviews/sec):2399. #Correct:50 #Trained:94 Training Accuracy:53.1%\r",
      "Progress:23.4% Speed(reviews/sec):2404. #Correct:50 #Trained:95 Training Accuracy:52.6%\r",
      "Progress:23.6% Speed(reviews/sec):2407. #Correct:51 #Trained:96 Training Accuracy:53.1%\r",
      "Progress:23.9% Speed(reviews/sec):2411. #Correct:52 #Trained:97 Training Accuracy:53.6%\r",
      "Progress:24.1% Speed(reviews/sec):2416. #Correct:53 #Trained:98 Training Accuracy:54.0%\r",
      "Progress:24.4% Speed(reviews/sec):2420. #Correct:54 #Trained:99 Training Accuracy:54.5%\r",
      "Progress:24.6% Speed(reviews/sec):2425. #Correct:54 #Trained:100 Training Accuracy:54.0%\r",
      "Progress:24.9% Speed(reviews/sec):2430. #Correct:55 #Trained:101 Training Accuracy:54.4%\r",
      "Progress:25.1% Speed(reviews/sec):2435. #Correct:56 #Trained:102 Training Accuracy:54.9%\r",
      "Progress:25.4% Speed(reviews/sec):2440. #Correct:56 #Trained:103 Training Accuracy:54.3%\r",
      "Progress:25.6% Speed(reviews/sec):2445. #Correct:57 #Trained:104 Training Accuracy:54.8%\r",
      "Progress:25.9% Speed(reviews/sec):2450. #Correct:58 #Trained:105 Training Accuracy:55.2%\r",
      "Progress:26.1% Speed(reviews/sec):2455. #Correct:58 #Trained:106 Training Accuracy:54.7%\r",
      "Progress:26.4% Speed(reviews/sec):2460. #Correct:59 #Trained:107 Training Accuracy:55.1%\r",
      "Progress:26.6% Speed(reviews/sec):2465. #Correct:59 #Trained:108 Training Accuracy:54.6%\r",
      "Progress:26.9% Speed(reviews/sec):2465. #Correct:59 #Trained:109 Training Accuracy:54.1%\r",
      "Progress:27.1% Speed(reviews/sec):2468. #Correct:60 #Trained:110 Training Accuracy:54.5%\r",
      "Progress:27.4% Speed(reviews/sec):2472. #Correct:60 #Trained:111 Training Accuracy:54.0%\r",
      "Progress:27.6% Speed(reviews/sec):2475. #Correct:60 #Trained:112 Training Accuracy:53.5%\r",
      "Progress:27.9% Speed(reviews/sec):2479. #Correct:60 #Trained:113 Training Accuracy:53.0%\r",
      "Progress:28.1% Speed(reviews/sec):2484. #Correct:60 #Trained:114 Training Accuracy:52.6%\r",
      "Progress:28.4% Speed(reviews/sec):2488. #Correct:61 #Trained:115 Training Accuracy:53.0%\r",
      "Progress:28.6% Speed(reviews/sec):2493. #Correct:62 #Trained:116 Training Accuracy:53.4%\r",
      "Progress:28.9% Speed(reviews/sec):2497. #Correct:63 #Trained:117 Training Accuracy:53.8%\r",
      "Progress:29.1% Speed(reviews/sec):2501. #Correct:63 #Trained:118 Training Accuracy:53.3%\r",
      "Progress:29.4% Speed(reviews/sec):2506. #Correct:63 #Trained:119 Training Accuracy:52.9%\r",
      "Progress:29.6% Speed(reviews/sec):2510. #Correct:63 #Trained:120 Training Accuracy:52.5%\r",
      "Progress:29.9% Speed(reviews/sec):2514. #Correct:63 #Trained:121 Training Accuracy:52.0%\r",
      "Progress:30.1% Speed(reviews/sec):2518. #Correct:63 #Trained:122 Training Accuracy:51.6%\r",
      "Progress:30.4% Speed(reviews/sec):2522. #Correct:64 #Trained:123 Training Accuracy:52.0%\r",
      "Progress:30.6% Speed(reviews/sec):2526. #Correct:64 #Trained:124 Training Accuracy:51.6%\r",
      "Progress:30.9% Speed(reviews/sec):2530. #Correct:65 #Trained:125 Training Accuracy:52.0%\r",
      "Progress:31.1% Speed(reviews/sec):2534. #Correct:66 #Trained:126 Training Accuracy:52.3%\r",
      "Progress:31.4% Speed(reviews/sec):2537. #Correct:66 #Trained:127 Training Accuracy:51.9%\r",
      "Progress:31.6% Speed(reviews/sec):2541. #Correct:67 #Trained:128 Training Accuracy:52.3%\r",
      "Progress:31.9% Speed(reviews/sec):2544. #Correct:67 #Trained:129 Training Accuracy:51.9%\r",
      "Progress:32.1% Speed(reviews/sec):2548. #Correct:68 #Trained:130 Training Accuracy:52.3%\r",
      "Progress:32.4% Speed(reviews/sec):2551. #Correct:69 #Trained:131 Training Accuracy:52.6%\r",
      "Progress:32.6% Speed(reviews/sec):2555. #Correct:69 #Trained:132 Training Accuracy:52.2%\r",
      "Progress:32.9% Speed(reviews/sec):2559. #Correct:70 #Trained:133 Training Accuracy:52.6%\r",
      "Progress:33.1% Speed(reviews/sec):2562. #Correct:71 #Trained:134 Training Accuracy:52.9%\r",
      "Progress:33.4% Speed(reviews/sec):2566. #Correct:72 #Trained:135 Training Accuracy:53.3%\r",
      "Progress:33.6% Speed(reviews/sec):2569. #Correct:73 #Trained:136 Training Accuracy:53.6%\r",
      "Progress:33.9% Speed(reviews/sec):2570. #Correct:74 #Trained:137 Training Accuracy:54.0%\r",
      "Progress:34.1% Speed(reviews/sec):2572. #Correct:75 #Trained:138 Training Accuracy:54.3%\r",
      "Progress:34.4% Speed(reviews/sec):2573. #Correct:75 #Trained:139 Training Accuracy:53.9%\r",
      "Progress:34.6% Speed(reviews/sec):2574. #Correct:76 #Trained:140 Training Accuracy:54.2%\r",
      "Progress:34.9% Speed(reviews/sec):2576. #Correct:77 #Trained:141 Training Accuracy:54.6%\r",
      "Progress:35.1% Speed(reviews/sec):2577. #Correct:77 #Trained:142 Training Accuracy:54.2%\r",
      "Progress:35.4% Speed(reviews/sec):2579. #Correct:78 #Trained:143 Training Accuracy:54.5%\r",
      "Progress:35.6% Speed(reviews/sec):2581. #Correct:79 #Trained:144 Training Accuracy:54.8%\r",
      "Progress:35.9% Speed(reviews/sec):2582. #Correct:79 #Trained:145 Training Accuracy:54.4%\r",
      "Progress:36.1% Speed(reviews/sec):2584. #Correct:79 #Trained:146 Training Accuracy:54.1%\r",
      "Progress:36.4% Speed(reviews/sec):2586. #Correct:79 #Trained:147 Training Accuracy:53.7%\r",
      "Progress:36.6% Speed(reviews/sec):2587. #Correct:80 #Trained:148 Training Accuracy:54.0%\r",
      "Progress:36.9% Speed(reviews/sec):2589. #Correct:80 #Trained:149 Training Accuracy:53.6%\r",
      "Progress:37.1% Speed(reviews/sec):2591. #Correct:81 #Trained:150 Training Accuracy:54.0%\r",
      "Progress:37.4% Speed(reviews/sec):2593. #Correct:81 #Trained:151 Training Accuracy:53.6%\r",
      "Progress:37.6% Speed(reviews/sec):2595. #Correct:81 #Trained:152 Training Accuracy:53.2%\r",
      "Progress:37.9% Speed(reviews/sec):2596. #Correct:82 #Trained:153 Training Accuracy:53.5%\r",
      "Progress:38.1% Speed(reviews/sec):2598. #Correct:82 #Trained:154 Training Accuracy:53.2%\r",
      "Progress:38.4% Speed(reviews/sec):2600. #Correct:83 #Trained:155 Training Accuracy:53.5%\r",
      "Progress:38.6% Speed(reviews/sec):2602. #Correct:84 #Trained:156 Training Accuracy:53.8%\r",
      "Progress:38.9% Speed(reviews/sec):2603. #Correct:85 #Trained:157 Training Accuracy:54.1%\r",
      "Progress:39.1% Speed(reviews/sec):2598. #Correct:86 #Trained:158 Training Accuracy:54.4%\r",
      "Progress:39.4% Speed(reviews/sec):2592. #Correct:87 #Trained:159 Training Accuracy:54.7%\r",
      "Progress:39.6% Speed(reviews/sec):2576. #Correct:88 #Trained:160 Training Accuracy:55.0%\r",
      "Progress:39.9% Speed(reviews/sec):2572. #Correct:89 #Trained:161 Training Accuracy:55.2%\r",
      "Progress:40.1% Speed(reviews/sec):2570. #Correct:90 #Trained:162 Training Accuracy:55.5%\r",
      "Progress:40.3% Speed(reviews/sec):2570. #Correct:90 #Trained:163 Training Accuracy:55.2%\r",
      "Progress:40.6% Speed(reviews/sec):2571. #Correct:90 #Trained:164 Training Accuracy:54.8%\r",
      "Progress:40.8% Speed(reviews/sec):2572. #Correct:90 #Trained:165 Training Accuracy:54.5%\r",
      "Progress:41.1% Speed(reviews/sec):2574. #Correct:91 #Trained:166 Training Accuracy:54.8%\r",
      "Progress:41.3% Speed(reviews/sec):2576. #Correct:92 #Trained:167 Training Accuracy:55.0%\r",
      "Progress:41.6% Speed(reviews/sec):2578. #Correct:92 #Trained:168 Training Accuracy:54.7%\r",
      "Progress:41.8% Speed(reviews/sec):2580. #Correct:93 #Trained:169 Training Accuracy:55.0%\r",
      "Progress:42.1% Speed(reviews/sec):2582. #Correct:94 #Trained:170 Training Accuracy:55.2%\r",
      "Progress:42.3% Speed(reviews/sec):2583. #Correct:95 #Trained:171 Training Accuracy:55.5%\r",
      "Progress:42.6% Speed(reviews/sec):2586. #Correct:95 #Trained:172 Training Accuracy:55.2%\r",
      "Progress:42.8% Speed(reviews/sec):2587. #Correct:95 #Trained:173 Training Accuracy:54.9%\r",
      "Progress:43.1% Speed(reviews/sec):2588. #Correct:96 #Trained:174 Training Accuracy:55.1%\r",
      "Progress:43.3% Speed(reviews/sec):2590. #Correct:97 #Trained:175 Training Accuracy:55.4%\r",
      "Progress:43.6% Speed(reviews/sec):2591. #Correct:97 #Trained:176 Training Accuracy:55.1%\r",
      "Progress:43.8% Speed(reviews/sec):2593. #Correct:98 #Trained:177 Training Accuracy:55.3%\r",
      "Progress:44.1% Speed(reviews/sec):2595. #Correct:99 #Trained:178 Training Accuracy:55.6%\r",
      "Progress:44.3% Speed(reviews/sec):2596. #Correct:100 #Trained:179 Training Accuracy:55.8%\r",
      "Progress:44.6% Speed(reviews/sec):2598. #Correct:101 #Trained:180 Training Accuracy:56.1%\r",
      "Progress:44.8% Speed(reviews/sec):2599. #Correct:102 #Trained:181 Training Accuracy:56.3%\r",
      "Progress:45.1% Speed(reviews/sec):2600. #Correct:103 #Trained:182 Training Accuracy:56.5%\r",
      "Progress:45.3% Speed(reviews/sec):2602. #Correct:104 #Trained:183 Training Accuracy:56.8%\r",
      "Progress:45.6% Speed(reviews/sec):2604. #Correct:105 #Trained:184 Training Accuracy:57.0%\r",
      "Progress:45.8% Speed(reviews/sec):2608. #Correct:106 #Trained:185 Training Accuracy:57.2%\r",
      "Progress:46.1% Speed(reviews/sec):2607. #Correct:107 #Trained:186 Training Accuracy:57.5%\r",
      "Progress:46.3% Speed(reviews/sec):2608. #Correct:107 #Trained:187 Training Accuracy:57.2%\r",
      "Progress:46.6% Speed(reviews/sec):2609. #Correct:108 #Trained:188 Training Accuracy:57.4%\r",
      "Progress:46.8% Speed(reviews/sec):2611. #Correct:108 #Trained:189 Training Accuracy:57.1%\r",
      "Progress:47.1% Speed(reviews/sec):2613. #Correct:109 #Trained:190 Training Accuracy:57.3%\r",
      "Progress:47.3% Speed(reviews/sec):2614. #Correct:110 #Trained:191 Training Accuracy:57.5%\r",
      "Progress:47.6% Speed(reviews/sec):2617. #Correct:111 #Trained:192 Training Accuracy:57.8%\r",
      "Progress:47.8% Speed(reviews/sec):2617. #Correct:112 #Trained:193 Training Accuracy:58.0%\r",
      "Progress:48.1% Speed(reviews/sec):2618. #Correct:112 #Trained:194 Training Accuracy:57.7%\r",
      "Progress:48.3% Speed(reviews/sec):2619. #Correct:113 #Trained:195 Training Accuracy:57.9%\r",
      "Progress:48.6% Speed(reviews/sec):2620. #Correct:113 #Trained:196 Training Accuracy:57.6%\r",
      "Progress:48.8% Speed(reviews/sec):2622. #Correct:114 #Trained:197 Training Accuracy:57.8%\r",
      "Progress:49.1% Speed(reviews/sec):2623. #Correct:115 #Trained:198 Training Accuracy:58.0%\r",
      "Progress:49.3% Speed(reviews/sec):2625. #Correct:116 #Trained:199 Training Accuracy:58.2%\r",
      "Progress:49.6% Speed(reviews/sec):2626. #Correct:116 #Trained:200 Training Accuracy:58.0%\r",
      "Progress:49.8% Speed(reviews/sec):2628. #Correct:117 #Trained:201 Training Accuracy:58.2%\r",
      "Progress:50.1% Speed(reviews/sec):2630. #Correct:118 #Trained:202 Training Accuracy:58.4%\r",
      "Progress:50.3% Speed(reviews/sec):2631. #Correct:119 #Trained:203 Training Accuracy:58.6%\r",
      "Progress:50.6% Speed(reviews/sec):2632. #Correct:119 #Trained:204 Training Accuracy:58.3%\r",
      "Progress:50.8% Speed(reviews/sec):2634. #Correct:120 #Trained:205 Training Accuracy:58.5%\r",
      "Progress:51.1% Speed(reviews/sec):2635. #Correct:121 #Trained:206 Training Accuracy:58.7%\r",
      "Progress:51.3% Speed(reviews/sec):2636. #Correct:122 #Trained:207 Training Accuracy:58.9%\r",
      "Progress:51.6% Speed(reviews/sec):2637. #Correct:123 #Trained:208 Training Accuracy:59.1%\r",
      "Progress:51.8% Speed(reviews/sec):2637. #Correct:123 #Trained:209 Training Accuracy:58.8%\r",
      "Progress:52.1% Speed(reviews/sec):2637. #Correct:123 #Trained:210 Training Accuracy:58.5%\r",
      "Progress:52.3% Speed(reviews/sec):2612. #Correct:123 #Trained:211 Training Accuracy:58.2%\r",
      "Progress:52.6% Speed(reviews/sec):2596. #Correct:124 #Trained:212 Training Accuracy:58.4%\r",
      "Progress:52.8% Speed(reviews/sec):2573. #Correct:124 #Trained:213 Training Accuracy:58.2%\r",
      "Progress:53.1% Speed(reviews/sec):2551. #Correct:124 #Trained:214 Training Accuracy:57.9%\r",
      "Progress:53.3% Speed(reviews/sec):2529. #Correct:124 #Trained:215 Training Accuracy:57.6%\r",
      "Progress:53.6% Speed(reviews/sec):2516. #Correct:124 #Trained:216 Training Accuracy:57.4%\r",
      "Progress:53.8% Speed(reviews/sec):2502. #Correct:124 #Trained:217 Training Accuracy:57.1%\r",
      "Progress:54.1% Speed(reviews/sec):2490. #Correct:124 #Trained:218 Training Accuracy:56.8%\r",
      "Progress:54.3% Speed(reviews/sec):2476. #Correct:124 #Trained:219 Training Accuracy:56.6%\r",
      "Progress:54.6% Speed(reviews/sec):2467. #Correct:125 #Trained:220 Training Accuracy:56.8%\r",
      "Progress:54.8% Speed(reviews/sec):2457. #Correct:125 #Trained:221 Training Accuracy:56.5%\r",
      "Progress:55.1% Speed(reviews/sec):2441. #Correct:126 #Trained:222 Training Accuracy:56.7%\r",
      "Progress:55.3% Speed(reviews/sec):2430. #Correct:126 #Trained:223 Training Accuracy:56.5%\r",
      "Progress:55.6% Speed(reviews/sec):2419. #Correct:126 #Trained:224 Training Accuracy:56.2%\r",
      "Progress:55.8% Speed(reviews/sec):2408. #Correct:126 #Trained:225 Training Accuracy:56.0%\r",
      "Progress:56.1% Speed(reviews/sec):2392. #Correct:127 #Trained:226 Training Accuracy:56.1%\r",
      "Progress:56.3% Speed(reviews/sec):2376. #Correct:127 #Trained:227 Training Accuracy:55.9%\r",
      "Progress:56.6% Speed(reviews/sec):2362. #Correct:127 #Trained:228 Training Accuracy:55.7%\r",
      "Progress:56.8% Speed(reviews/sec):2355. #Correct:127 #Trained:229 Training Accuracy:55.4%\r",
      "Progress:57.1% Speed(reviews/sec):2349. #Correct:127 #Trained:230 Training Accuracy:55.2%\r",
      "Progress:57.3% Speed(reviews/sec):2342. #Correct:127 #Trained:231 Training Accuracy:54.9%\r",
      "Progress:57.6% Speed(reviews/sec):2336. #Correct:127 #Trained:232 Training Accuracy:54.7%\r",
      "Progress:57.8% Speed(reviews/sec):2331. #Correct:127 #Trained:233 Training Accuracy:54.5%\r",
      "Progress:58.1% Speed(reviews/sec):2324. #Correct:127 #Trained:234 Training Accuracy:54.2%\r",
      "Progress:58.3% Speed(reviews/sec):2319. #Correct:128 #Trained:235 Training Accuracy:54.4%\r",
      "Progress:58.6% Speed(reviews/sec):2311. #Correct:128 #Trained:236 Training Accuracy:54.2%\r",
      "Progress:58.8% Speed(reviews/sec):2305. #Correct:128 #Trained:237 Training Accuracy:54.0%\r",
      "Progress:59.1% Speed(reviews/sec):2300. #Correct:128 #Trained:238 Training Accuracy:53.7%\r",
      "Progress:59.3% Speed(reviews/sec):2294. #Correct:129 #Trained:239 Training Accuracy:53.9%\r",
      "Progress:59.6% Speed(reviews/sec):2290. #Correct:129 #Trained:240 Training Accuracy:53.7%\r",
      "Progress:59.8% Speed(reviews/sec):2284. #Correct:129 #Trained:241 Training Accuracy:53.5%\r",
      "Progress:60.0% Speed(reviews/sec):2280. #Correct:129 #Trained:242 Training Accuracy:53.3%\r",
      "Progress:60.3% Speed(reviews/sec):2274. #Correct:129 #Trained:243 Training Accuracy:53.0%\r",
      "Progress:60.5% Speed(reviews/sec):2270. #Correct:130 #Trained:244 Training Accuracy:53.2%\r",
      "Progress:60.8% Speed(reviews/sec):2265. #Correct:131 #Trained:245 Training Accuracy:53.4%\r",
      "Progress:61.0% Speed(reviews/sec):2261. #Correct:131 #Trained:246 Training Accuracy:53.2%\r",
      "Progress:61.3% Speed(reviews/sec):2256. #Correct:131 #Trained:247 Training Accuracy:53.0%\r",
      "Progress:61.5% Speed(reviews/sec):2251. #Correct:131 #Trained:248 Training Accuracy:52.8%\r",
      "Progress:61.8% Speed(reviews/sec):2246. #Correct:132 #Trained:249 Training Accuracy:53.0%\r",
      "Progress:62.0% Speed(reviews/sec):2242. #Correct:132 #Trained:250 Training Accuracy:52.8%\r",
      "Progress:62.3% Speed(reviews/sec):2240. #Correct:132 #Trained:251 Training Accuracy:52.5%\r",
      "Progress:62.5% Speed(reviews/sec):2237. #Correct:132 #Trained:252 Training Accuracy:52.3%\r",
      "Progress:62.8% Speed(reviews/sec):2234. #Correct:133 #Trained:253 Training Accuracy:52.5%\r",
      "Progress:63.0% Speed(reviews/sec):2231. #Correct:133 #Trained:254 Training Accuracy:52.3%\r",
      "Progress:63.3% Speed(reviews/sec):2228. #Correct:134 #Trained:255 Training Accuracy:52.5%\r",
      "Progress:63.5% Speed(reviews/sec):2225. #Correct:134 #Trained:256 Training Accuracy:52.3%\r",
      "Progress:63.8% Speed(reviews/sec):2222. #Correct:135 #Trained:257 Training Accuracy:52.5%\r",
      "Progress:64.0% Speed(reviews/sec):2220. #Correct:136 #Trained:258 Training Accuracy:52.7%\r",
      "Progress:64.3% Speed(reviews/sec):2219. #Correct:137 #Trained:259 Training Accuracy:52.8%\r",
      "Progress:64.5% Speed(reviews/sec):2217. #Correct:137 #Trained:260 Training Accuracy:52.6%\r",
      "Progress:64.8% Speed(reviews/sec):2215. #Correct:138 #Trained:261 Training Accuracy:52.8%\r",
      "Progress:65.0% Speed(reviews/sec):2213. #Correct:139 #Trained:262 Training Accuracy:53.0%\r",
      "Progress:65.3% Speed(reviews/sec):2213. #Correct:139 #Trained:263 Training Accuracy:52.8%\r",
      "Progress:65.5% Speed(reviews/sec):2211. #Correct:140 #Trained:264 Training Accuracy:53.0%\r",
      "Progress:65.8% Speed(reviews/sec):2210. #Correct:141 #Trained:265 Training Accuracy:53.2%\r",
      "Progress:66.0% Speed(reviews/sec):2208. #Correct:142 #Trained:266 Training Accuracy:53.3%\r",
      "Progress:66.3% Speed(reviews/sec):2206. #Correct:142 #Trained:267 Training Accuracy:53.1%\r",
      "Progress:66.5% Speed(reviews/sec):2204. #Correct:142 #Trained:268 Training Accuracy:52.9%\r",
      "Progress:66.8% Speed(reviews/sec):2203. #Correct:143 #Trained:269 Training Accuracy:53.1%\r",
      "Progress:67.0% Speed(reviews/sec):2201. #Correct:143 #Trained:270 Training Accuracy:52.9%\r",
      "Progress:67.3% Speed(reviews/sec):2199. #Correct:143 #Trained:271 Training Accuracy:52.7%\r",
      "Progress:67.5% Speed(reviews/sec):2195. #Correct:144 #Trained:272 Training Accuracy:52.9%\r",
      "Progress:67.8% Speed(reviews/sec):2194. #Correct:145 #Trained:273 Training Accuracy:53.1%\r",
      "Progress:68.0% Speed(reviews/sec):2192. #Correct:145 #Trained:274 Training Accuracy:52.9%\r",
      "Progress:68.3% Speed(reviews/sec):2192. #Correct:146 #Trained:275 Training Accuracy:53.0%\r",
      "Progress:68.5% Speed(reviews/sec):2190. #Correct:146 #Trained:276 Training Accuracy:52.8%\r",
      "Progress:68.8% Speed(reviews/sec):2188. #Correct:147 #Trained:277 Training Accuracy:53.0%\r",
      "Progress:69.0% Speed(reviews/sec):2187. #Correct:148 #Trained:278 Training Accuracy:53.2%\r",
      "Progress:69.3% Speed(reviews/sec):2186. #Correct:148 #Trained:279 Training Accuracy:53.0%\r",
      "Progress:69.5% Speed(reviews/sec):2186. #Correct:149 #Trained:280 Training Accuracy:53.2%\r",
      "Progress:69.8% Speed(reviews/sec):2184. #Correct:150 #Trained:281 Training Accuracy:53.3%\r",
      "Progress:70.0% Speed(reviews/sec):2182. #Correct:151 #Trained:282 Training Accuracy:53.5%\r",
      "Progress:70.3% Speed(reviews/sec):2181. #Correct:152 #Trained:283 Training Accuracy:53.7%\r",
      "Progress:70.5% Speed(reviews/sec):2179. #Correct:153 #Trained:284 Training Accuracy:53.8%\r",
      "Progress:70.8% Speed(reviews/sec):2179. #Correct:153 #Trained:285 Training Accuracy:53.6%\r",
      "Progress:71.0% Speed(reviews/sec):2178. #Correct:154 #Trained:286 Training Accuracy:53.8%\r",
      "Progress:71.3% Speed(reviews/sec):2178. #Correct:155 #Trained:287 Training Accuracy:54.0%\r",
      "Progress:71.5% Speed(reviews/sec):2177. #Correct:155 #Trained:288 Training Accuracy:53.8%\r",
      "Progress:71.8% Speed(reviews/sec):2177. #Correct:155 #Trained:289 Training Accuracy:53.6%\r",
      "Progress:72.0% Speed(reviews/sec):2176. #Correct:156 #Trained:290 Training Accuracy:53.7%\r",
      "Progress:72.3% Speed(reviews/sec):2172. #Correct:156 #Trained:291 Training Accuracy:53.6%\r",
      "Progress:72.5% Speed(reviews/sec):2170. #Correct:156 #Trained:292 Training Accuracy:53.4%\r",
      "Progress:72.8% Speed(reviews/sec):2169. #Correct:156 #Trained:293 Training Accuracy:53.2%\r",
      "Progress:73.0% Speed(reviews/sec):2167. #Correct:157 #Trained:294 Training Accuracy:53.4%\r",
      "Progress:73.3% Speed(reviews/sec):2166. #Correct:158 #Trained:295 Training Accuracy:53.5%\r",
      "Progress:73.5% Speed(reviews/sec):2167. #Correct:158 #Trained:296 Training Accuracy:53.3%\r",
      "Progress:73.8% Speed(reviews/sec):2167. #Correct:159 #Trained:297 Training Accuracy:53.5%\r",
      "Progress:74.0% Speed(reviews/sec):2167. #Correct:160 #Trained:298 Training Accuracy:53.6%\r",
      "Progress:74.3% Speed(reviews/sec):2167. #Correct:160 #Trained:299 Training Accuracy:53.5%\r",
      "Progress:74.5% Speed(reviews/sec):2167. #Correct:160 #Trained:300 Training Accuracy:53.3%\r",
      "Progress:74.8% Speed(reviews/sec):2167. #Correct:161 #Trained:301 Training Accuracy:53.4%\r",
      "Progress:75.0% Speed(reviews/sec):2167. #Correct:162 #Trained:302 Training Accuracy:53.6%\r",
      "Progress:75.3% Speed(reviews/sec):2168. #Correct:163 #Trained:303 Training Accuracy:53.7%\r",
      "Progress:75.5% Speed(reviews/sec):2168. #Correct:164 #Trained:304 Training Accuracy:53.9%\r",
      "Progress:75.8% Speed(reviews/sec):2169. #Correct:164 #Trained:305 Training Accuracy:53.7%\r",
      "Progress:76.0% Speed(reviews/sec):2169. #Correct:165 #Trained:306 Training Accuracy:53.9%\r",
      "Progress:76.3% Speed(reviews/sec):2170. #Correct:165 #Trained:307 Training Accuracy:53.7%\r",
      "Progress:76.5% Speed(reviews/sec):2169. #Correct:165 #Trained:308 Training Accuracy:53.5%\r",
      "Progress:76.8% Speed(reviews/sec):2169. #Correct:166 #Trained:309 Training Accuracy:53.7%\r",
      "Progress:77.0% Speed(reviews/sec):2170. #Correct:167 #Trained:310 Training Accuracy:53.8%\r",
      "Progress:77.3% Speed(reviews/sec):2170. #Correct:168 #Trained:311 Training Accuracy:54.0%\r",
      "Progress:77.5% Speed(reviews/sec):2171. #Correct:169 #Trained:312 Training Accuracy:54.1%\r",
      "Progress:77.8% Speed(reviews/sec):2171. #Correct:169 #Trained:313 Training Accuracy:53.9%\r",
      "Progress:78.0% Speed(reviews/sec):2171. #Correct:170 #Trained:314 Training Accuracy:54.1%\r",
      "Progress:78.3% Speed(reviews/sec):2171. #Correct:171 #Trained:315 Training Accuracy:54.2%\r",
      "Progress:78.5% Speed(reviews/sec):2171. #Correct:172 #Trained:316 Training Accuracy:54.4%\r",
      "Progress:78.8% Speed(reviews/sec):2171. #Correct:172 #Trained:317 Training Accuracy:54.2%\r",
      "Progress:79.0% Speed(reviews/sec):2171. #Correct:173 #Trained:318 Training Accuracy:54.4%\r",
      "Progress:79.3% Speed(reviews/sec):2171. #Correct:173 #Trained:319 Training Accuracy:54.2%\r",
      "Progress:79.5% Speed(reviews/sec):2172. #Correct:173 #Trained:320 Training Accuracy:54.0%\r",
      "Progress:79.8% Speed(reviews/sec):2172. #Correct:174 #Trained:321 Training Accuracy:54.2%\r",
      "Progress:80.0% Speed(reviews/sec):2173. #Correct:175 #Trained:322 Training Accuracy:54.3%\r",
      "Progress:80.2% Speed(reviews/sec):2173. #Correct:176 #Trained:323 Training Accuracy:54.4%\r",
      "Progress:80.5% Speed(reviews/sec):2174. #Correct:176 #Trained:324 Training Accuracy:54.3%\r",
      "Progress:80.7% Speed(reviews/sec):2174. #Correct:177 #Trained:325 Training Accuracy:54.4%\r",
      "Progress:81.0% Speed(reviews/sec):2175. #Correct:177 #Trained:326 Training Accuracy:54.2%\r",
      "Progress:81.2% Speed(reviews/sec):2176. #Correct:178 #Trained:327 Training Accuracy:54.4%\r",
      "Progress:81.5% Speed(reviews/sec):2177. #Correct:179 #Trained:328 Training Accuracy:54.5%\r",
      "Progress:81.7% Speed(reviews/sec):2178. #Correct:179 #Trained:329 Training Accuracy:54.4%\r",
      "Progress:82.0% Speed(reviews/sec):2179. #Correct:180 #Trained:330 Training Accuracy:54.5%\r",
      "Progress:82.2% Speed(reviews/sec):2180. #Correct:181 #Trained:331 Training Accuracy:54.6%\r",
      "Progress:82.5% Speed(reviews/sec):2182. #Correct:182 #Trained:332 Training Accuracy:54.8%\r",
      "Progress:82.7% Speed(reviews/sec):2183. #Correct:182 #Trained:333 Training Accuracy:54.6%\r",
      "Progress:83.0% Speed(reviews/sec):2184. #Correct:182 #Trained:334 Training Accuracy:54.4%\r",
      "Progress:83.2% Speed(reviews/sec):2184. #Correct:183 #Trained:335 Training Accuracy:54.6%\r",
      "Progress:83.5% Speed(reviews/sec):2186. #Correct:183 #Trained:336 Training Accuracy:54.4%\r",
      "Progress:83.7% Speed(reviews/sec):2188. #Correct:184 #Trained:337 Training Accuracy:54.5%\r",
      "Progress:84.0% Speed(reviews/sec):2189. #Correct:184 #Trained:338 Training Accuracy:54.4%\r",
      "Progress:84.2% Speed(reviews/sec):2191. #Correct:185 #Trained:339 Training Accuracy:54.5%\r",
      "Progress:84.5% Speed(reviews/sec):2192. #Correct:185 #Trained:340 Training Accuracy:54.4%\r",
      "Progress:84.7% Speed(reviews/sec):2193. #Correct:186 #Trained:341 Training Accuracy:54.5%\r",
      "Progress:85.0% Speed(reviews/sec):2195. #Correct:186 #Trained:342 Training Accuracy:54.3%\r",
      "Progress:85.2% Speed(reviews/sec):2196. #Correct:187 #Trained:343 Training Accuracy:54.5%\r",
      "Progress:85.5% Speed(reviews/sec):2197. #Correct:188 #Trained:344 Training Accuracy:54.6%\r",
      "Progress:85.7% Speed(reviews/sec):2197. #Correct:188 #Trained:345 Training Accuracy:54.4%\r",
      "Progress:86.0% Speed(reviews/sec):2198. #Correct:189 #Trained:346 Training Accuracy:54.6%\r",
      "Progress:86.2% Speed(reviews/sec):2200. #Correct:190 #Trained:347 Training Accuracy:54.7%\r",
      "Progress:86.5% Speed(reviews/sec):2201. #Correct:190 #Trained:348 Training Accuracy:54.5%\r",
      "Progress:86.7% Speed(reviews/sec):2202. #Correct:191 #Trained:349 Training Accuracy:54.7%\r",
      "Progress:87.0% Speed(reviews/sec):2203. #Correct:192 #Trained:350 Training Accuracy:54.8%\r",
      "Progress:87.2% Speed(reviews/sec):2204. #Correct:192 #Trained:351 Training Accuracy:54.7%\r",
      "Progress:87.5% Speed(reviews/sec):2206. #Correct:193 #Trained:352 Training Accuracy:54.8%\r",
      "Progress:87.7% Speed(reviews/sec):2207. #Correct:194 #Trained:353 Training Accuracy:54.9%\r",
      "Progress:88.0% Speed(reviews/sec):2208. #Correct:195 #Trained:354 Training Accuracy:55.0%\r",
      "Progress:88.2% Speed(reviews/sec):2209. #Correct:196 #Trained:355 Training Accuracy:55.2%\r",
      "Progress:88.5% Speed(reviews/sec):2210. #Correct:196 #Trained:356 Training Accuracy:55.0%\r",
      "Progress:88.7% Speed(reviews/sec):2211. #Correct:197 #Trained:357 Training Accuracy:55.1%\r",
      "Progress:89.0% Speed(reviews/sec):2207. #Correct:197 #Trained:358 Training Accuracy:55.0%\r",
      "Progress:89.2% Speed(reviews/sec):2202. #Correct:197 #Trained:359 Training Accuracy:54.8%\r",
      "Progress:89.5% Speed(reviews/sec):2198. #Correct:197 #Trained:360 Training Accuracy:54.7%\r",
      "Progress:89.7% Speed(reviews/sec):2196. #Correct:197 #Trained:361 Training Accuracy:54.5%\r",
      "Progress:90.0% Speed(reviews/sec):2195. #Correct:198 #Trained:362 Training Accuracy:54.6%\r",
      "Progress:90.2% Speed(reviews/sec):2193. #Correct:199 #Trained:363 Training Accuracy:54.8%\r",
      "Progress:90.5% Speed(reviews/sec):2191. #Correct:200 #Trained:364 Training Accuracy:54.9%\r",
      "Progress:90.7% Speed(reviews/sec):2188. #Correct:201 #Trained:365 Training Accuracy:55.0%\r",
      "Progress:91.0% Speed(reviews/sec):2186. #Correct:202 #Trained:366 Training Accuracy:55.1%\r",
      "Progress:91.2% Speed(reviews/sec):2186. #Correct:203 #Trained:367 Training Accuracy:55.3%\r",
      "Progress:91.5% Speed(reviews/sec):2185. #Correct:203 #Trained:368 Training Accuracy:55.1%\r",
      "Progress:91.7% Speed(reviews/sec):2184. #Correct:204 #Trained:369 Training Accuracy:55.2%\r",
      "Progress:92.0% Speed(reviews/sec):2184. #Correct:205 #Trained:370 Training Accuracy:55.4%\r",
      "Progress:92.2% Speed(reviews/sec):2183. #Correct:206 #Trained:371 Training Accuracy:55.5%\r",
      "Progress:92.5% Speed(reviews/sec):2183. #Correct:207 #Trained:372 Training Accuracy:55.6%\r",
      "Progress:92.7% Speed(reviews/sec):2183. #Correct:208 #Trained:373 Training Accuracy:55.7%\r",
      "Progress:93.0% Speed(reviews/sec):2183. #Correct:208 #Trained:374 Training Accuracy:55.6%\r",
      "Progress:93.2% Speed(reviews/sec):2183. #Correct:208 #Trained:375 Training Accuracy:55.4%\r",
      "Progress:93.5% Speed(reviews/sec):2183. #Correct:209 #Trained:376 Training Accuracy:55.5%\r",
      "Progress:93.7% Speed(reviews/sec):2183. #Correct:209 #Trained:377 Training Accuracy:55.4%\r",
      "Progress:94.0% Speed(reviews/sec):2184. #Correct:210 #Trained:378 Training Accuracy:55.5%\r",
      "Progress:94.2% Speed(reviews/sec):2183. #Correct:211 #Trained:379 Training Accuracy:55.6%\r",
      "Progress:94.5% Speed(reviews/sec):2183. #Correct:211 #Trained:380 Training Accuracy:55.5%\r",
      "Progress:94.7% Speed(reviews/sec):2183. #Correct:211 #Trained:381 Training Accuracy:55.3%\r",
      "Progress:95.0% Speed(reviews/sec):2184. #Correct:211 #Trained:382 Training Accuracy:55.2%\r",
      "Progress:95.2% Speed(reviews/sec):2184. #Correct:212 #Trained:383 Training Accuracy:55.3%\r",
      "Progress:95.5% Speed(reviews/sec):2185. #Correct:212 #Trained:384 Training Accuracy:55.2%\r",
      "Progress:95.7% Speed(reviews/sec):2185. #Correct:212 #Trained:385 Training Accuracy:55.0%\r",
      "Progress:96.0% Speed(reviews/sec):2185. #Correct:212 #Trained:386 Training Accuracy:54.9%\r",
      "Progress:96.2% Speed(reviews/sec):2185. #Correct:213 #Trained:387 Training Accuracy:55.0%\r",
      "Progress:96.5% Speed(reviews/sec):2186. #Correct:214 #Trained:388 Training Accuracy:55.1%\r",
      "Progress:96.7% Speed(reviews/sec):2186. #Correct:214 #Trained:389 Training Accuracy:55.0%\r",
      "Progress:97.0% Speed(reviews/sec):2186. #Correct:215 #Trained:390 Training Accuracy:55.1%\r",
      "Progress:97.2% Speed(reviews/sec):2187. #Correct:215 #Trained:391 Training Accuracy:54.9%\r",
      "Progress:97.5% Speed(reviews/sec):2187. #Correct:216 #Trained:392 Training Accuracy:55.1%\r",
      "Progress:97.7% Speed(reviews/sec):2187. #Correct:217 #Trained:393 Training Accuracy:55.2%\r",
      "Progress:98.0% Speed(reviews/sec):2188. #Correct:218 #Trained:394 Training Accuracy:55.3%\r",
      "Progress:98.2% Speed(reviews/sec):2189. #Correct:219 #Trained:395 Training Accuracy:55.4%\r",
      "Progress:98.5% Speed(reviews/sec):2189. #Correct:220 #Trained:396 Training Accuracy:55.5%\r",
      "Progress:98.7% Speed(reviews/sec):2190. #Correct:221 #Trained:397 Training Accuracy:55.6%\r",
      "Progress:99.0% Speed(reviews/sec):2190. #Correct:222 #Trained:398 Training Accuracy:55.7%\r",
      "Progress:99.2% Speed(reviews/sec):2191. #Correct:222 #Trained:399 Training Accuracy:55.6%\r",
      "Progress:99.5% Speed(reviews/sec):2191. #Correct:222 #Trained:400 Training Accuracy:55.5%\r",
      "Progress:99.7% Speed(reviews/sec):2191. #Correct:223 #Trained:401 Training Accuracy:55.6%"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-120],labels[:-120], learning_rate=0.01)\n",
    "mlp.train(reviews[:-120],labels[:-120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That probably wasn't much different. Run the following cell to recreate the network one more time with an even smaller learning rate, `0.001`, and then train the new network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "\r",
      "Progress:0.24% Speed(reviews/sec):554.9 #Correct:1 #Trained:2 Training Accuracy:50.0%\r",
      "Progress:0.49% Speed(reviews/sec):749.3 #Correct:2 #Trained:3 Training Accuracy:66.6%\r",
      "Progress:0.74% Speed(reviews/sec):860.6 #Correct:3 #Trained:4 Training Accuracy:75.0%\r",
      "Progress:0.99% Speed(reviews/sec):930.4 #Correct:4 #Trained:5 Training Accuracy:80.0%\r",
      "Progress:1.24% Speed(reviews/sec):1002. #Correct:4 #Trained:6 Training Accuracy:66.6%\r",
      "Progress:1.49% Speed(reviews/sec):1076. #Correct:4 #Trained:7 Training Accuracy:57.1%\r",
      "Progress:1.74% Speed(reviews/sec):1146. #Correct:4 #Trained:8 Training Accuracy:50.0%\r",
      "Progress:1.99% Speed(reviews/sec):1205. #Correct:5 #Trained:9 Training Accuracy:55.5%\r",
      "Progress:2.24% Speed(reviews/sec):1259. #Correct:5 #Trained:10 Training Accuracy:50.0%\r",
      "Progress:2.49% Speed(reviews/sec):1308. #Correct:6 #Trained:11 Training Accuracy:54.5%\r",
      "Progress:2.74% Speed(reviews/sec):1352. #Correct:7 #Trained:12 Training Accuracy:58.3%\r",
      "Progress:2.99% Speed(reviews/sec):1391. #Correct:8 #Trained:13 Training Accuracy:61.5%\r",
      "Progress:3.24% Speed(reviews/sec):1423. #Correct:8 #Trained:14 Training Accuracy:57.1%\r",
      "Progress:3.49% Speed(reviews/sec):1453. #Correct:8 #Trained:15 Training Accuracy:53.3%\r",
      "Progress:3.74% Speed(reviews/sec):1479. #Correct:9 #Trained:16 Training Accuracy:56.2%\r",
      "Progress:3.99% Speed(reviews/sec):1507. #Correct:10 #Trained:17 Training Accuracy:58.8%\r",
      "Progress:4.23% Speed(reviews/sec):1535. #Correct:11 #Trained:18 Training Accuracy:61.1%\r",
      "Progress:4.48% Speed(reviews/sec):1551. #Correct:11 #Trained:19 Training Accuracy:57.8%\r",
      "Progress:4.73% Speed(reviews/sec):1568. #Correct:12 #Trained:20 Training Accuracy:60.0%\r",
      "Progress:4.98% Speed(reviews/sec):1597. #Correct:12 #Trained:21 Training Accuracy:57.1%\r",
      "Progress:5.23% Speed(reviews/sec):1620. #Correct:12 #Trained:22 Training Accuracy:54.5%\r",
      "Progress:5.48% Speed(reviews/sec):1648. #Correct:12 #Trained:23 Training Accuracy:52.1%\r",
      "Progress:5.73% Speed(reviews/sec):1677. #Correct:12 #Trained:24 Training Accuracy:50.0%\r",
      "Progress:5.98% Speed(reviews/sec):1699. #Correct:12 #Trained:25 Training Accuracy:48.0%\r",
      "Progress:6.23% Speed(reviews/sec):1717. #Correct:13 #Trained:26 Training Accuracy:50.0%\r",
      "Progress:6.48% Speed(reviews/sec):1734. #Correct:13 #Trained:27 Training Accuracy:48.1%\r",
      "Progress:6.73% Speed(reviews/sec):1754. #Correct:13 #Trained:28 Training Accuracy:46.4%\r",
      "Progress:6.98% Speed(reviews/sec):1773. #Correct:13 #Trained:29 Training Accuracy:44.8%\r",
      "Progress:7.23% Speed(reviews/sec):1789. #Correct:13 #Trained:30 Training Accuracy:43.3%\r",
      "Progress:7.48% Speed(reviews/sec):1803. #Correct:14 #Trained:31 Training Accuracy:45.1%\r",
      "Progress:7.73% Speed(reviews/sec):1818. #Correct:15 #Trained:32 Training Accuracy:46.8%\r",
      "Progress:7.98% Speed(reviews/sec):1832. #Correct:15 #Trained:33 Training Accuracy:45.4%\r",
      "Progress:8.22% Speed(reviews/sec):1846. #Correct:15 #Trained:34 Training Accuracy:44.1%\r",
      "Progress:8.47% Speed(reviews/sec):1859. #Correct:16 #Trained:35 Training Accuracy:45.7%\r",
      "Progress:8.72% Speed(reviews/sec):1870. #Correct:16 #Trained:36 Training Accuracy:44.4%\r",
      "Progress:8.97% Speed(reviews/sec):1883. #Correct:16 #Trained:37 Training Accuracy:43.2%\r",
      "Progress:9.22% Speed(reviews/sec):1895. #Correct:16 #Trained:38 Training Accuracy:42.1%\r",
      "Progress:9.47% Speed(reviews/sec):1908. #Correct:17 #Trained:39 Training Accuracy:43.5%\r",
      "Progress:9.72% Speed(reviews/sec):1921. #Correct:17 #Trained:40 Training Accuracy:42.5%\r",
      "Progress:9.97% Speed(reviews/sec):1934. #Correct:17 #Trained:41 Training Accuracy:41.4%\r",
      "Progress:10.2% Speed(reviews/sec):1947. #Correct:17 #Trained:42 Training Accuracy:40.4%\r",
      "Progress:10.4% Speed(reviews/sec):1957. #Correct:17 #Trained:43 Training Accuracy:39.5%\r",
      "Progress:10.7% Speed(reviews/sec):1971. #Correct:17 #Trained:44 Training Accuracy:38.6%\r",
      "Progress:10.9% Speed(reviews/sec):1985. #Correct:18 #Trained:45 Training Accuracy:40.0%\r",
      "Progress:11.2% Speed(reviews/sec):1997. #Correct:19 #Trained:46 Training Accuracy:41.3%\r",
      "Progress:11.4% Speed(reviews/sec):2006. #Correct:20 #Trained:47 Training Accuracy:42.5%\r",
      "Progress:11.7% Speed(reviews/sec):2018. #Correct:20 #Trained:48 Training Accuracy:41.6%\r",
      "Progress:11.9% Speed(reviews/sec):2029. #Correct:21 #Trained:49 Training Accuracy:42.8%\r",
      "Progress:12.2% Speed(reviews/sec):2040. #Correct:22 #Trained:50 Training Accuracy:44.0%\r",
      "Progress:12.4% Speed(reviews/sec):2052. #Correct:22 #Trained:51 Training Accuracy:43.1%\r",
      "Progress:12.7% Speed(reviews/sec):2064. #Correct:23 #Trained:52 Training Accuracy:44.2%\r",
      "Progress:12.9% Speed(reviews/sec):2069. #Correct:24 #Trained:53 Training Accuracy:45.2%\r",
      "Progress:13.2% Speed(reviews/sec):2075. #Correct:25 #Trained:54 Training Accuracy:46.2%\r",
      "Progress:13.4% Speed(reviews/sec):2079. #Correct:26 #Trained:55 Training Accuracy:47.2%\r",
      "Progress:13.7% Speed(reviews/sec):2086. #Correct:26 #Trained:56 Training Accuracy:46.4%\r",
      "Progress:13.9% Speed(reviews/sec):2095. #Correct:26 #Trained:57 Training Accuracy:45.6%\r",
      "Progress:14.2% Speed(reviews/sec):2105. #Correct:27 #Trained:58 Training Accuracy:46.5%\r",
      "Progress:14.4% Speed(reviews/sec):2113. #Correct:28 #Trained:59 Training Accuracy:47.4%\r",
      "Progress:14.7% Speed(reviews/sec):2121. #Correct:28 #Trained:60 Training Accuracy:46.6%\r",
      "Progress:14.9% Speed(reviews/sec):2130. #Correct:29 #Trained:61 Training Accuracy:47.5%\r",
      "Progress:15.2% Speed(reviews/sec):2138. #Correct:29 #Trained:62 Training Accuracy:46.7%\r",
      "Progress:15.4% Speed(reviews/sec):2148. #Correct:30 #Trained:63 Training Accuracy:47.6%\r",
      "Progress:15.7% Speed(reviews/sec):2158. #Correct:31 #Trained:64 Training Accuracy:48.4%\r",
      "Progress:15.9% Speed(reviews/sec):2167. #Correct:31 #Trained:65 Training Accuracy:47.6%\r",
      "Progress:16.2% Speed(reviews/sec):2175. #Correct:32 #Trained:66 Training Accuracy:48.4%\r",
      "Progress:16.4% Speed(reviews/sec):2185. #Correct:32 #Trained:67 Training Accuracy:47.7%\r",
      "Progress:16.7% Speed(reviews/sec):2194. #Correct:32 #Trained:68 Training Accuracy:47.0%\r",
      "Progress:16.9% Speed(reviews/sec):2203. #Correct:33 #Trained:69 Training Accuracy:47.8%\r",
      "Progress:17.2% Speed(reviews/sec):2211. #Correct:34 #Trained:70 Training Accuracy:48.5%\r",
      "Progress:17.4% Speed(reviews/sec):2219. #Correct:34 #Trained:71 Training Accuracy:47.8%\r",
      "Progress:17.7% Speed(reviews/sec):2227. #Correct:35 #Trained:72 Training Accuracy:48.6%\r",
      "Progress:17.9% Speed(reviews/sec):2235. #Correct:35 #Trained:73 Training Accuracy:47.9%\r",
      "Progress:18.2% Speed(reviews/sec):2242. #Correct:35 #Trained:74 Training Accuracy:47.2%\r",
      "Progress:18.4% Speed(reviews/sec):2250. #Correct:36 #Trained:75 Training Accuracy:48.0%\r",
      "Progress:18.7% Speed(reviews/sec):2257. #Correct:37 #Trained:76 Training Accuracy:48.6%\r",
      "Progress:18.9% Speed(reviews/sec):2264. #Correct:38 #Trained:77 Training Accuracy:49.3%\r",
      "Progress:19.2% Speed(reviews/sec):2271. #Correct:38 #Trained:78 Training Accuracy:48.7%\r",
      "Progress:19.4% Speed(reviews/sec):2278. #Correct:38 #Trained:79 Training Accuracy:48.1%\r",
      "Progress:19.7% Speed(reviews/sec):2285. #Correct:38 #Trained:80 Training Accuracy:47.5%\r",
      "Progress:19.9% Speed(reviews/sec):2292. #Correct:39 #Trained:81 Training Accuracy:48.1%\r",
      "Progress:20.1% Speed(reviews/sec):2296. #Correct:40 #Trained:82 Training Accuracy:48.7%\r",
      "Progress:20.4% Speed(reviews/sec):2298. #Correct:40 #Trained:83 Training Accuracy:48.1%\r",
      "Progress:20.6% Speed(reviews/sec):2301. #Correct:41 #Trained:84 Training Accuracy:48.8%\r",
      "Progress:20.9% Speed(reviews/sec):2304. #Correct:41 #Trained:85 Training Accuracy:48.2%\r",
      "Progress:21.1% Speed(reviews/sec):2307. #Correct:42 #Trained:86 Training Accuracy:48.8%\r",
      "Progress:21.4% Speed(reviews/sec):2314. #Correct:42 #Trained:87 Training Accuracy:48.2%\r",
      "Progress:21.6% Speed(reviews/sec):2316. #Correct:43 #Trained:88 Training Accuracy:48.8%\r",
      "Progress:21.9% Speed(reviews/sec):2316. #Correct:43 #Trained:89 Training Accuracy:48.3%\r",
      "Progress:22.1% Speed(reviews/sec):2319. #Correct:44 #Trained:90 Training Accuracy:48.8%\r",
      "Progress:22.4% Speed(reviews/sec):2322. #Correct:45 #Trained:91 Training Accuracy:49.4%\r",
      "Progress:22.6% Speed(reviews/sec):2325. #Correct:46 #Trained:92 Training Accuracy:50.0%\r",
      "Progress:22.9% Speed(reviews/sec):2329. #Correct:46 #Trained:93 Training Accuracy:49.4%\r",
      "Progress:23.1% Speed(reviews/sec):2333. #Correct:47 #Trained:94 Training Accuracy:50.0%\r",
      "Progress:23.4% Speed(reviews/sec):2337. #Correct:47 #Trained:95 Training Accuracy:49.4%\r",
      "Progress:23.6% Speed(reviews/sec):2341. #Correct:48 #Trained:96 Training Accuracy:50.0%\r",
      "Progress:23.9% Speed(reviews/sec):2345. #Correct:48 #Trained:97 Training Accuracy:49.4%\r",
      "Progress:24.1% Speed(reviews/sec):2350. #Correct:48 #Trained:98 Training Accuracy:48.9%\r",
      "Progress:24.4% Speed(reviews/sec):2354. #Correct:48 #Trained:99 Training Accuracy:48.4%\r",
      "Progress:24.6% Speed(reviews/sec):2360. #Correct:48 #Trained:100 Training Accuracy:48.0%\r",
      "Progress:24.9% Speed(reviews/sec):2366. #Correct:49 #Trained:101 Training Accuracy:48.5%\r",
      "Progress:25.1% Speed(reviews/sec):2371. #Correct:50 #Trained:102 Training Accuracy:49.0%\r",
      "Progress:25.4% Speed(reviews/sec):2376. #Correct:50 #Trained:103 Training Accuracy:48.5%\r",
      "Progress:25.6% Speed(reviews/sec):2381. #Correct:51 #Trained:104 Training Accuracy:49.0%\r",
      "Progress:25.9% Speed(reviews/sec):2387. #Correct:52 #Trained:105 Training Accuracy:49.5%\r",
      "Progress:26.1% Speed(reviews/sec):2392. #Correct:52 #Trained:106 Training Accuracy:49.0%\r",
      "Progress:26.4% Speed(reviews/sec):2397. #Correct:53 #Trained:107 Training Accuracy:49.5%\r",
      "Progress:26.6% Speed(reviews/sec):2402. #Correct:53 #Trained:108 Training Accuracy:49.0%\r",
      "Progress:26.9% Speed(reviews/sec):2407. #Correct:53 #Trained:109 Training Accuracy:48.6%\r",
      "Progress:27.1% Speed(reviews/sec):2412. #Correct:54 #Trained:110 Training Accuracy:49.0%\r",
      "Progress:27.4% Speed(reviews/sec):2417. #Correct:54 #Trained:111 Training Accuracy:48.6%\r",
      "Progress:27.6% Speed(reviews/sec):2422. #Correct:55 #Trained:112 Training Accuracy:49.1%\r",
      "Progress:27.9% Speed(reviews/sec):2426. #Correct:56 #Trained:113 Training Accuracy:49.5%\r",
      "Progress:28.1% Speed(reviews/sec):2431. #Correct:56 #Trained:114 Training Accuracy:49.1%\r",
      "Progress:28.4% Speed(reviews/sec):2436. #Correct:57 #Trained:115 Training Accuracy:49.5%\r",
      "Progress:28.6% Speed(reviews/sec):2441. #Correct:58 #Trained:116 Training Accuracy:50.0%\r",
      "Progress:28.9% Speed(reviews/sec):2445. #Correct:59 #Trained:117 Training Accuracy:50.4%\r",
      "Progress:29.1% Speed(reviews/sec):2450. #Correct:59 #Trained:118 Training Accuracy:50.0%\r",
      "Progress:29.4% Speed(reviews/sec):2455. #Correct:59 #Trained:119 Training Accuracy:49.5%\r",
      "Progress:29.6% Speed(reviews/sec):2459. #Correct:60 #Trained:120 Training Accuracy:50.0%\r",
      "Progress:29.9% Speed(reviews/sec):2464. #Correct:61 #Trained:121 Training Accuracy:50.4%\r",
      "Progress:30.1% Speed(reviews/sec):2468. #Correct:61 #Trained:122 Training Accuracy:50.0%\r",
      "Progress:30.4% Speed(reviews/sec):2472. #Correct:62 #Trained:123 Training Accuracy:50.4%\r",
      "Progress:30.6% Speed(reviews/sec):2474. #Correct:62 #Trained:124 Training Accuracy:50.0%\r",
      "Progress:30.9% Speed(reviews/sec):2479. #Correct:63 #Trained:125 Training Accuracy:50.4%\r",
      "Progress:31.1% Speed(reviews/sec):2483. #Correct:64 #Trained:126 Training Accuracy:50.7%\r",
      "Progress:31.4% Speed(reviews/sec):2486. #Correct:64 #Trained:127 Training Accuracy:50.3%\r",
      "Progress:31.6% Speed(reviews/sec):2489. #Correct:65 #Trained:128 Training Accuracy:50.7%\r",
      "Progress:31.9% Speed(reviews/sec):2493. #Correct:65 #Trained:129 Training Accuracy:50.3%\r",
      "Progress:32.1% Speed(reviews/sec):2497. #Correct:66 #Trained:130 Training Accuracy:50.7%\r",
      "Progress:32.4% Speed(reviews/sec):2501. #Correct:67 #Trained:131 Training Accuracy:51.1%\r",
      "Progress:32.6% Speed(reviews/sec):2505. #Correct:67 #Trained:132 Training Accuracy:50.7%\r",
      "Progress:32.9% Speed(reviews/sec):2509. #Correct:67 #Trained:133 Training Accuracy:50.3%\r",
      "Progress:33.1% Speed(reviews/sec):2513. #Correct:68 #Trained:134 Training Accuracy:50.7%\r",
      "Progress:33.4% Speed(reviews/sec):2517. #Correct:69 #Trained:135 Training Accuracy:51.1%\r",
      "Progress:33.6% Speed(reviews/sec):2521. #Correct:69 #Trained:136 Training Accuracy:50.7%\r",
      "Progress:33.9% Speed(reviews/sec):2524. #Correct:69 #Trained:137 Training Accuracy:50.3%\r",
      "Progress:34.1% Speed(reviews/sec):2528. #Correct:70 #Trained:138 Training Accuracy:50.7%\r",
      "Progress:34.4% Speed(reviews/sec):2529. #Correct:71 #Trained:139 Training Accuracy:51.0%\r",
      "Progress:34.6% Speed(reviews/sec):2532. #Correct:72 #Trained:140 Training Accuracy:51.4%\r",
      "Progress:34.9% Speed(reviews/sec):2535. #Correct:72 #Trained:141 Training Accuracy:51.0%\r",
      "Progress:35.1% Speed(reviews/sec):2539. #Correct:72 #Trained:142 Training Accuracy:50.7%\r",
      "Progress:35.4% Speed(reviews/sec):2542. #Correct:73 #Trained:143 Training Accuracy:51.0%\r",
      "Progress:35.6% Speed(reviews/sec):2546. #Correct:73 #Trained:144 Training Accuracy:50.6%\r",
      "Progress:35.9% Speed(reviews/sec):2549. #Correct:74 #Trained:145 Training Accuracy:51.0%\r",
      "Progress:36.1% Speed(reviews/sec):2551. #Correct:74 #Trained:146 Training Accuracy:50.6%\r",
      "Progress:36.4% Speed(reviews/sec):2552. #Correct:74 #Trained:147 Training Accuracy:50.3%\r",
      "Progress:36.6% Speed(reviews/sec):2554. #Correct:75 #Trained:148 Training Accuracy:50.6%\r",
      "Progress:36.9% Speed(reviews/sec):2555. #Correct:75 #Trained:149 Training Accuracy:50.3%\r",
      "Progress:37.1% Speed(reviews/sec):2558. #Correct:76 #Trained:150 Training Accuracy:50.6%\r",
      "Progress:37.4% Speed(reviews/sec):2559. #Correct:76 #Trained:151 Training Accuracy:50.3%\r",
      "Progress:37.6% Speed(reviews/sec):2561. #Correct:76 #Trained:152 Training Accuracy:50.0%\r",
      "Progress:37.9% Speed(reviews/sec):2563. #Correct:77 #Trained:153 Training Accuracy:50.3%\r",
      "Progress:38.1% Speed(reviews/sec):2565. #Correct:77 #Trained:154 Training Accuracy:50.0%\r",
      "Progress:38.4% Speed(reviews/sec):2567. #Correct:78 #Trained:155 Training Accuracy:50.3%\r",
      "Progress:38.6% Speed(reviews/sec):2569. #Correct:78 #Trained:156 Training Accuracy:50.0%\r",
      "Progress:38.9% Speed(reviews/sec):2571. #Correct:79 #Trained:157 Training Accuracy:50.3%\r",
      "Progress:39.1% Speed(reviews/sec):2574. #Correct:80 #Trained:158 Training Accuracy:50.6%\r",
      "Progress:39.4% Speed(reviews/sec):2576. #Correct:81 #Trained:159 Training Accuracy:50.9%\r",
      "Progress:39.6% Speed(reviews/sec):2579. #Correct:82 #Trained:160 Training Accuracy:51.2%\r",
      "Progress:39.9% Speed(reviews/sec):2580. #Correct:83 #Trained:161 Training Accuracy:51.5%\r",
      "Progress:40.1% Speed(reviews/sec):2582. #Correct:84 #Trained:162 Training Accuracy:51.8%\r",
      "Progress:40.3% Speed(reviews/sec):2584. #Correct:84 #Trained:163 Training Accuracy:51.5%\r",
      "Progress:40.6% Speed(reviews/sec):2586. #Correct:84 #Trained:164 Training Accuracy:51.2%\r",
      "Progress:40.8% Speed(reviews/sec):2588. #Correct:84 #Trained:165 Training Accuracy:50.9%\r",
      "Progress:41.1% Speed(reviews/sec):2589. #Correct:85 #Trained:166 Training Accuracy:51.2%\r",
      "Progress:41.3% Speed(reviews/sec):2591. #Correct:86 #Trained:167 Training Accuracy:51.4%\r",
      "Progress:41.6% Speed(reviews/sec):2593. #Correct:86 #Trained:168 Training Accuracy:51.1%\r",
      "Progress:41.8% Speed(reviews/sec):2595. #Correct:86 #Trained:169 Training Accuracy:50.8%\r",
      "Progress:42.1% Speed(reviews/sec):2597. #Correct:87 #Trained:170 Training Accuracy:51.1%\r",
      "Progress:42.3% Speed(reviews/sec):2599. #Correct:88 #Trained:171 Training Accuracy:51.4%\r",
      "Progress:42.6% Speed(reviews/sec):2600. #Correct:88 #Trained:172 Training Accuracy:51.1%\r",
      "Progress:42.8% Speed(reviews/sec):2600. #Correct:88 #Trained:173 Training Accuracy:50.8%\r",
      "Progress:43.1% Speed(reviews/sec):2599. #Correct:89 #Trained:174 Training Accuracy:51.1%\r",
      "Progress:43.3% Speed(reviews/sec):2600. #Correct:90 #Trained:175 Training Accuracy:51.4%\r",
      "Progress:43.6% Speed(reviews/sec):2601. #Correct:90 #Trained:176 Training Accuracy:51.1%\r",
      "Progress:43.8% Speed(reviews/sec):2602. #Correct:91 #Trained:177 Training Accuracy:51.4%\r",
      "Progress:44.1% Speed(reviews/sec):2604. #Correct:92 #Trained:178 Training Accuracy:51.6%\r",
      "Progress:44.3% Speed(reviews/sec):2605. #Correct:93 #Trained:179 Training Accuracy:51.9%\r",
      "Progress:44.6% Speed(reviews/sec):2607. #Correct:94 #Trained:180 Training Accuracy:52.2%\r",
      "Progress:44.8% Speed(reviews/sec):2609. #Correct:95 #Trained:181 Training Accuracy:52.4%\r",
      "Progress:45.1% Speed(reviews/sec):2611. #Correct:96 #Trained:182 Training Accuracy:52.7%\r",
      "Progress:45.3% Speed(reviews/sec):2612. #Correct:97 #Trained:183 Training Accuracy:53.0%\r",
      "Progress:45.6% Speed(reviews/sec):2614. #Correct:98 #Trained:184 Training Accuracy:53.2%\r",
      "Progress:45.8% Speed(reviews/sec):2616. #Correct:98 #Trained:185 Training Accuracy:52.9%\r",
      "Progress:46.1% Speed(reviews/sec):2618. #Correct:99 #Trained:186 Training Accuracy:53.2%\r",
      "Progress:46.3% Speed(reviews/sec):2619. #Correct:99 #Trained:187 Training Accuracy:52.9%\r",
      "Progress:46.6% Speed(reviews/sec):2618. #Correct:100 #Trained:188 Training Accuracy:53.1%\r",
      "Progress:46.8% Speed(reviews/sec):2619. #Correct:100 #Trained:189 Training Accuracy:52.9%\r",
      "Progress:47.1% Speed(reviews/sec):2620. #Correct:101 #Trained:190 Training Accuracy:53.1%\r",
      "Progress:47.3% Speed(reviews/sec):2622. #Correct:102 #Trained:191 Training Accuracy:53.4%\r",
      "Progress:47.6% Speed(reviews/sec):2623. #Correct:103 #Trained:192 Training Accuracy:53.6%\r",
      "Progress:47.8% Speed(reviews/sec):2625. #Correct:103 #Trained:193 Training Accuracy:53.3%\r",
      "Progress:48.1% Speed(reviews/sec):2625. #Correct:103 #Trained:194 Training Accuracy:53.0%\r",
      "Progress:48.3% Speed(reviews/sec):2625. #Correct:103 #Trained:195 Training Accuracy:52.8%\r",
      "Progress:48.6% Speed(reviews/sec):2626. #Correct:103 #Trained:196 Training Accuracy:52.5%\r",
      "Progress:48.8% Speed(reviews/sec):2626. #Correct:104 #Trained:197 Training Accuracy:52.7%\r",
      "Progress:49.1% Speed(reviews/sec):2626. #Correct:105 #Trained:198 Training Accuracy:53.0%\r",
      "Progress:49.3% Speed(reviews/sec):2627. #Correct:106 #Trained:199 Training Accuracy:53.2%\r",
      "Progress:49.6% Speed(reviews/sec):2629. #Correct:106 #Trained:200 Training Accuracy:53.0%\r",
      "Progress:49.8% Speed(reviews/sec):2630. #Correct:107 #Trained:201 Training Accuracy:53.2%\r",
      "Progress:50.1% Speed(reviews/sec):2632. #Correct:108 #Trained:202 Training Accuracy:53.4%\r",
      "Progress:50.3% Speed(reviews/sec):2633. #Correct:109 #Trained:203 Training Accuracy:53.6%\r",
      "Progress:50.6% Speed(reviews/sec):2635. #Correct:109 #Trained:204 Training Accuracy:53.4%\r",
      "Progress:50.8% Speed(reviews/sec):2636. #Correct:110 #Trained:205 Training Accuracy:53.6%\r",
      "Progress:51.1% Speed(reviews/sec):2638. #Correct:110 #Trained:206 Training Accuracy:53.3%\r",
      "Progress:51.3% Speed(reviews/sec):2640. #Correct:111 #Trained:207 Training Accuracy:53.6%\r",
      "Progress:51.6% Speed(reviews/sec):2641. #Correct:112 #Trained:208 Training Accuracy:53.8%\r",
      "Progress:51.8% Speed(reviews/sec):2643. #Correct:113 #Trained:209 Training Accuracy:54.0%\r",
      "Progress:52.1% Speed(reviews/sec):2646. #Correct:113 #Trained:210 Training Accuracy:53.8%\r",
      "Progress:52.3% Speed(reviews/sec):2629. #Correct:113 #Trained:211 Training Accuracy:53.5%\r",
      "Progress:52.6% Speed(reviews/sec):2615. #Correct:114 #Trained:212 Training Accuracy:53.7%\r",
      "Progress:52.8% Speed(reviews/sec):2598. #Correct:114 #Trained:213 Training Accuracy:53.5%\r",
      "Progress:53.1% Speed(reviews/sec):2584. #Correct:114 #Trained:214 Training Accuracy:53.2%\r",
      "Progress:53.3% Speed(reviews/sec):2570. #Correct:114 #Trained:215 Training Accuracy:53.0%\r",
      "Progress:53.6% Speed(reviews/sec):2558. #Correct:114 #Trained:216 Training Accuracy:52.7%\r",
      "Progress:53.8% Speed(reviews/sec):2545. #Correct:114 #Trained:217 Training Accuracy:52.5%\r",
      "Progress:54.1% Speed(reviews/sec):2533. #Correct:115 #Trained:218 Training Accuracy:52.7%\r",
      "Progress:54.3% Speed(reviews/sec):2521. #Correct:116 #Trained:219 Training Accuracy:52.9%\r",
      "Progress:54.6% Speed(reviews/sec):2512. #Correct:116 #Trained:220 Training Accuracy:52.7%\r",
      "Progress:54.8% Speed(reviews/sec):2502. #Correct:117 #Trained:221 Training Accuracy:52.9%\r",
      "Progress:55.1% Speed(reviews/sec):2493. #Correct:117 #Trained:222 Training Accuracy:52.7%\r",
      "Progress:55.3% Speed(reviews/sec):2483. #Correct:118 #Trained:223 Training Accuracy:52.9%\r",
      "Progress:55.6% Speed(reviews/sec):2474. #Correct:119 #Trained:224 Training Accuracy:53.1%\r",
      "Progress:55.8% Speed(reviews/sec):2465. #Correct:120 #Trained:225 Training Accuracy:53.3%\r",
      "Progress:56.1% Speed(reviews/sec):2457. #Correct:120 #Trained:226 Training Accuracy:53.0%\r",
      "Progress:56.3% Speed(reviews/sec):2450. #Correct:121 #Trained:227 Training Accuracy:53.3%\r",
      "Progress:56.6% Speed(reviews/sec):2441. #Correct:122 #Trained:228 Training Accuracy:53.5%\r",
      "Progress:56.8% Speed(reviews/sec):2424. #Correct:123 #Trained:229 Training Accuracy:53.7%\r",
      "Progress:57.1% Speed(reviews/sec):2411. #Correct:124 #Trained:230 Training Accuracy:53.9%\r",
      "Progress:57.3% Speed(reviews/sec):2404. #Correct:125 #Trained:231 Training Accuracy:54.1%\r",
      "Progress:57.6% Speed(reviews/sec):2397. #Correct:126 #Trained:232 Training Accuracy:54.3%\r",
      "Progress:57.8% Speed(reviews/sec):2391. #Correct:127 #Trained:233 Training Accuracy:54.5%\r",
      "Progress:58.1% Speed(reviews/sec):2385. #Correct:128 #Trained:234 Training Accuracy:54.7%\r",
      "Progress:58.3% Speed(reviews/sec):2379. #Correct:128 #Trained:235 Training Accuracy:54.4%\r",
      "Progress:58.6% Speed(reviews/sec):2370. #Correct:129 #Trained:236 Training Accuracy:54.6%\r",
      "Progress:58.8% Speed(reviews/sec):2364. #Correct:130 #Trained:237 Training Accuracy:54.8%\r",
      "Progress:59.1% Speed(reviews/sec):2358. #Correct:131 #Trained:238 Training Accuracy:55.0%\r",
      "Progress:59.3% Speed(reviews/sec):2351. #Correct:131 #Trained:239 Training Accuracy:54.8%\r",
      "Progress:59.6% Speed(reviews/sec):2340. #Correct:132 #Trained:240 Training Accuracy:55.0%\r",
      "Progress:59.8% Speed(reviews/sec):2334. #Correct:133 #Trained:241 Training Accuracy:55.1%\r",
      "Progress:60.0% Speed(reviews/sec):2328. #Correct:134 #Trained:242 Training Accuracy:55.3%\r",
      "Progress:60.3% Speed(reviews/sec):2323. #Correct:135 #Trained:243 Training Accuracy:55.5%\r",
      "Progress:60.5% Speed(reviews/sec):2319. #Correct:135 #Trained:244 Training Accuracy:55.3%\r",
      "Progress:60.8% Speed(reviews/sec):2313. #Correct:135 #Trained:245 Training Accuracy:55.1%\r",
      "Progress:61.0% Speed(reviews/sec):2310. #Correct:136 #Trained:246 Training Accuracy:55.2%\r",
      "Progress:61.3% Speed(reviews/sec):2306. #Correct:136 #Trained:247 Training Accuracy:55.0%\r",
      "Progress:61.5% Speed(reviews/sec):2302. #Correct:137 #Trained:248 Training Accuracy:55.2%\r",
      "Progress:61.8% Speed(reviews/sec):2298. #Correct:137 #Trained:249 Training Accuracy:55.0%\r",
      "Progress:62.0% Speed(reviews/sec):2295. #Correct:137 #Trained:250 Training Accuracy:54.8%\r",
      "Progress:62.3% Speed(reviews/sec):2291. #Correct:138 #Trained:251 Training Accuracy:54.9%\r",
      "Progress:62.5% Speed(reviews/sec):2287. #Correct:139 #Trained:252 Training Accuracy:55.1%\r",
      "Progress:62.8% Speed(reviews/sec):2283. #Correct:140 #Trained:253 Training Accuracy:55.3%\r",
      "Progress:63.0% Speed(reviews/sec):2278. #Correct:140 #Trained:254 Training Accuracy:55.1%\r",
      "Progress:63.3% Speed(reviews/sec):2275. #Correct:141 #Trained:255 Training Accuracy:55.2%\r",
      "Progress:63.5% Speed(reviews/sec):2270. #Correct:141 #Trained:256 Training Accuracy:55.0%\r",
      "Progress:63.8% Speed(reviews/sec):2266. #Correct:142 #Trained:257 Training Accuracy:55.2%\r",
      "Progress:64.0% Speed(reviews/sec):2263. #Correct:143 #Trained:258 Training Accuracy:55.4%\r",
      "Progress:64.3% Speed(reviews/sec):2262. #Correct:144 #Trained:259 Training Accuracy:55.5%\r",
      "Progress:64.5% Speed(reviews/sec):2259. #Correct:144 #Trained:260 Training Accuracy:55.3%\r",
      "Progress:64.8% Speed(reviews/sec):2256. #Correct:144 #Trained:261 Training Accuracy:55.1%\r",
      "Progress:65.0% Speed(reviews/sec):2253. #Correct:145 #Trained:262 Training Accuracy:55.3%\r",
      "Progress:65.3% Speed(reviews/sec):2251. #Correct:145 #Trained:263 Training Accuracy:55.1%\r",
      "Progress:65.5% Speed(reviews/sec):2248. #Correct:146 #Trained:264 Training Accuracy:55.3%\r",
      "Progress:65.8% Speed(reviews/sec):2245. #Correct:147 #Trained:265 Training Accuracy:55.4%\r",
      "Progress:66.0% Speed(reviews/sec):2241. #Correct:148 #Trained:266 Training Accuracy:55.6%\r",
      "Progress:66.3% Speed(reviews/sec):2238. #Correct:148 #Trained:267 Training Accuracy:55.4%\r",
      "Progress:66.5% Speed(reviews/sec):2233. #Correct:148 #Trained:268 Training Accuracy:55.2%\r",
      "Progress:66.8% Speed(reviews/sec):2231. #Correct:148 #Trained:269 Training Accuracy:55.0%\r",
      "Progress:67.0% Speed(reviews/sec):2229. #Correct:148 #Trained:270 Training Accuracy:54.8%\r",
      "Progress:67.3% Speed(reviews/sec):2226. #Correct:149 #Trained:271 Training Accuracy:54.9%\r",
      "Progress:67.5% Speed(reviews/sec):2224. #Correct:149 #Trained:272 Training Accuracy:54.7%\r",
      "Progress:67.8% Speed(reviews/sec):2222. #Correct:150 #Trained:273 Training Accuracy:54.9%\r",
      "Progress:68.0% Speed(reviews/sec):2219. #Correct:150 #Trained:274 Training Accuracy:54.7%\r",
      "Progress:68.3% Speed(reviews/sec):2216. #Correct:151 #Trained:275 Training Accuracy:54.9%\r",
      "Progress:68.5% Speed(reviews/sec):2215. #Correct:151 #Trained:276 Training Accuracy:54.7%\r",
      "Progress:68.8% Speed(reviews/sec):2214. #Correct:151 #Trained:277 Training Accuracy:54.5%\r",
      "Progress:69.0% Speed(reviews/sec):2211. #Correct:152 #Trained:278 Training Accuracy:54.6%\r",
      "Progress:69.3% Speed(reviews/sec):2209. #Correct:152 #Trained:279 Training Accuracy:54.4%\r",
      "Progress:69.5% Speed(reviews/sec):2207. #Correct:152 #Trained:280 Training Accuracy:54.2%\r",
      "Progress:69.8% Speed(reviews/sec):2205. #Correct:152 #Trained:281 Training Accuracy:54.0%\r",
      "Progress:70.0% Speed(reviews/sec):2203. #Correct:153 #Trained:282 Training Accuracy:54.2%\r",
      "Progress:70.3% Speed(reviews/sec):2201. #Correct:153 #Trained:283 Training Accuracy:54.0%\r",
      "Progress:70.5% Speed(reviews/sec):2198. #Correct:154 #Trained:284 Training Accuracy:54.2%\r",
      "Progress:70.8% Speed(reviews/sec):2196. #Correct:154 #Trained:285 Training Accuracy:54.0%\r",
      "Progress:71.0% Speed(reviews/sec):2192. #Correct:155 #Trained:286 Training Accuracy:54.1%\r",
      "Progress:71.3% Speed(reviews/sec):2189. #Correct:156 #Trained:287 Training Accuracy:54.3%\r",
      "Progress:71.5% Speed(reviews/sec):2187. #Correct:156 #Trained:288 Training Accuracy:54.1%\r",
      "Progress:71.8% Speed(reviews/sec):2186. #Correct:156 #Trained:289 Training Accuracy:53.9%\r",
      "Progress:72.0% Speed(reviews/sec):2184. #Correct:157 #Trained:290 Training Accuracy:54.1%\r",
      "Progress:72.3% Speed(reviews/sec):2180. #Correct:157 #Trained:291 Training Accuracy:53.9%\r",
      "Progress:72.5% Speed(reviews/sec):2178. #Correct:157 #Trained:292 Training Accuracy:53.7%\r",
      "Progress:72.8% Speed(reviews/sec):2176. #Correct:158 #Trained:293 Training Accuracy:53.9%\r",
      "Progress:73.0% Speed(reviews/sec):2175. #Correct:158 #Trained:294 Training Accuracy:53.7%\r",
      "Progress:73.3% Speed(reviews/sec):2174. #Correct:159 #Trained:295 Training Accuracy:53.8%\r",
      "Progress:73.5% Speed(reviews/sec):2173. #Correct:159 #Trained:296 Training Accuracy:53.7%\r",
      "Progress:73.8% Speed(reviews/sec):2168. #Correct:160 #Trained:297 Training Accuracy:53.8%\r",
      "Progress:74.0% Speed(reviews/sec):2153. #Correct:161 #Trained:298 Training Accuracy:54.0%\r",
      "Progress:74.3% Speed(reviews/sec):2148. #Correct:161 #Trained:299 Training Accuracy:53.8%\r",
      "Progress:74.5% Speed(reviews/sec):2146. #Correct:162 #Trained:300 Training Accuracy:54.0%\r",
      "Progress:74.8% Speed(reviews/sec):2142. #Correct:162 #Trained:301 Training Accuracy:53.8%\r",
      "Progress:75.0% Speed(reviews/sec):2140. #Correct:163 #Trained:302 Training Accuracy:53.9%\r",
      "Progress:75.3% Speed(reviews/sec):2136. #Correct:164 #Trained:303 Training Accuracy:54.1%\r",
      "Progress:75.5% Speed(reviews/sec):2133. #Correct:165 #Trained:304 Training Accuracy:54.2%\r",
      "Progress:75.8% Speed(reviews/sec):2129. #Correct:165 #Trained:305 Training Accuracy:54.0%\r",
      "Progress:76.0% Speed(reviews/sec):2127. #Correct:166 #Trained:306 Training Accuracy:54.2%\r",
      "Progress:76.3% Speed(reviews/sec):2127. #Correct:166 #Trained:307 Training Accuracy:54.0%\r",
      "Progress:76.5% Speed(reviews/sec):2126. #Correct:167 #Trained:308 Training Accuracy:54.2%\r",
      "Progress:76.8% Speed(reviews/sec):2127. #Correct:168 #Trained:309 Training Accuracy:54.3%\r",
      "Progress:77.0% Speed(reviews/sec):2127. #Correct:169 #Trained:310 Training Accuracy:54.5%\r",
      "Progress:77.3% Speed(reviews/sec):2126. #Correct:170 #Trained:311 Training Accuracy:54.6%\r",
      "Progress:77.5% Speed(reviews/sec):2126. #Correct:171 #Trained:312 Training Accuracy:54.8%\r",
      "Progress:77.8% Speed(reviews/sec):2126. #Correct:171 #Trained:313 Training Accuracy:54.6%\r",
      "Progress:78.0% Speed(reviews/sec):2127. #Correct:172 #Trained:314 Training Accuracy:54.7%\r",
      "Progress:78.3% Speed(reviews/sec):2127. #Correct:173 #Trained:315 Training Accuracy:54.9%\r",
      "Progress:78.5% Speed(reviews/sec):2128. #Correct:174 #Trained:316 Training Accuracy:55.0%\r",
      "Progress:78.8% Speed(reviews/sec):2128. #Correct:174 #Trained:317 Training Accuracy:54.8%\r",
      "Progress:79.0% Speed(reviews/sec):2126. #Correct:175 #Trained:318 Training Accuracy:55.0%\r",
      "Progress:79.3% Speed(reviews/sec):2126. #Correct:175 #Trained:319 Training Accuracy:54.8%\r",
      "Progress:79.5% Speed(reviews/sec):2126. #Correct:175 #Trained:320 Training Accuracy:54.6%\r",
      "Progress:79.8% Speed(reviews/sec):2126. #Correct:176 #Trained:321 Training Accuracy:54.8%\r",
      "Progress:80.0% Speed(reviews/sec):2126. #Correct:177 #Trained:322 Training Accuracy:54.9%\r",
      "Progress:80.2% Speed(reviews/sec):2126. #Correct:178 #Trained:323 Training Accuracy:55.1%\r",
      "Progress:80.5% Speed(reviews/sec):2126. #Correct:178 #Trained:324 Training Accuracy:54.9%\r",
      "Progress:80.7% Speed(reviews/sec):2126. #Correct:179 #Trained:325 Training Accuracy:55.0%\r",
      "Progress:81.0% Speed(reviews/sec):2127. #Correct:179 #Trained:326 Training Accuracy:54.9%\r",
      "Progress:81.2% Speed(reviews/sec):2128. #Correct:180 #Trained:327 Training Accuracy:55.0%\r",
      "Progress:81.5% Speed(reviews/sec):2128. #Correct:181 #Trained:328 Training Accuracy:55.1%\r",
      "Progress:81.7% Speed(reviews/sec):2122. #Correct:181 #Trained:329 Training Accuracy:55.0%\r",
      "Progress:82.0% Speed(reviews/sec):2114. #Correct:182 #Trained:330 Training Accuracy:55.1%\r",
      "Progress:82.2% Speed(reviews/sec):2113. #Correct:183 #Trained:331 Training Accuracy:55.2%\r",
      "Progress:82.5% Speed(reviews/sec):2111. #Correct:184 #Trained:332 Training Accuracy:55.4%\r",
      "Progress:82.7% Speed(reviews/sec):2110. #Correct:184 #Trained:333 Training Accuracy:55.2%\r",
      "Progress:83.0% Speed(reviews/sec):2109. #Correct:184 #Trained:334 Training Accuracy:55.0%\r",
      "Progress:83.2% Speed(reviews/sec):2108. #Correct:185 #Trained:335 Training Accuracy:55.2%\r",
      "Progress:83.5% Speed(reviews/sec):2106. #Correct:185 #Trained:336 Training Accuracy:55.0%\r",
      "Progress:83.7% Speed(reviews/sec):2105. #Correct:186 #Trained:337 Training Accuracy:55.1%\r",
      "Progress:84.0% Speed(reviews/sec):2104. #Correct:187 #Trained:338 Training Accuracy:55.3%\r",
      "Progress:84.2% Speed(reviews/sec):2104. #Correct:188 #Trained:339 Training Accuracy:55.4%\r",
      "Progress:84.5% Speed(reviews/sec):2104. #Correct:188 #Trained:340 Training Accuracy:55.2%\r",
      "Progress:84.7% Speed(reviews/sec):2105. #Correct:189 #Trained:341 Training Accuracy:55.4%\r",
      "Progress:85.0% Speed(reviews/sec):2106. #Correct:189 #Trained:342 Training Accuracy:55.2%\r",
      "Progress:85.2% Speed(reviews/sec):2108. #Correct:190 #Trained:343 Training Accuracy:55.3%\r",
      "Progress:85.5% Speed(reviews/sec):2109. #Correct:191 #Trained:344 Training Accuracy:55.5%\r",
      "Progress:85.7% Speed(reviews/sec):2111. #Correct:191 #Trained:345 Training Accuracy:55.3%\r",
      "Progress:86.0% Speed(reviews/sec):2112. #Correct:191 #Trained:346 Training Accuracy:55.2%\r",
      "Progress:86.2% Speed(reviews/sec):2113. #Correct:192 #Trained:347 Training Accuracy:55.3%\r",
      "Progress:86.5% Speed(reviews/sec):2114. #Correct:192 #Trained:348 Training Accuracy:55.1%\r",
      "Progress:86.7% Speed(reviews/sec):2115. #Correct:193 #Trained:349 Training Accuracy:55.3%\r",
      "Progress:87.0% Speed(reviews/sec):2117. #Correct:194 #Trained:350 Training Accuracy:55.4%\r",
      "Progress:87.2% Speed(reviews/sec):2118. #Correct:194 #Trained:351 Training Accuracy:55.2%\r",
      "Progress:87.5% Speed(reviews/sec):2120. #Correct:195 #Trained:352 Training Accuracy:55.3%\r",
      "Progress:87.7% Speed(reviews/sec):2121. #Correct:196 #Trained:353 Training Accuracy:55.5%\r",
      "Progress:88.0% Speed(reviews/sec):2123. #Correct:197 #Trained:354 Training Accuracy:55.6%\r",
      "Progress:88.2% Speed(reviews/sec):2124. #Correct:197 #Trained:355 Training Accuracy:55.4%\r",
      "Progress:88.5% Speed(reviews/sec):2126. #Correct:197 #Trained:356 Training Accuracy:55.3%\r",
      "Progress:88.7% Speed(reviews/sec):2128. #Correct:198 #Trained:357 Training Accuracy:55.4%\r",
      "Progress:89.0% Speed(reviews/sec):2125. #Correct:198 #Trained:358 Training Accuracy:55.3%\r",
      "Progress:89.2% Speed(reviews/sec):2122. #Correct:199 #Trained:359 Training Accuracy:55.4%\r",
      "Progress:89.5% Speed(reviews/sec):2119. #Correct:200 #Trained:360 Training Accuracy:55.5%\r",
      "Progress:89.7% Speed(reviews/sec):2117. #Correct:200 #Trained:361 Training Accuracy:55.4%\r",
      "Progress:90.0% Speed(reviews/sec):2117. #Correct:201 #Trained:362 Training Accuracy:55.5%\r",
      "Progress:90.2% Speed(reviews/sec):2116. #Correct:202 #Trained:363 Training Accuracy:55.6%\r",
      "Progress:90.5% Speed(reviews/sec):2115. #Correct:203 #Trained:364 Training Accuracy:55.7%\r",
      "Progress:90.7% Speed(reviews/sec):2113. #Correct:204 #Trained:365 Training Accuracy:55.8%\r",
      "Progress:91.0% Speed(reviews/sec):2112. #Correct:205 #Trained:366 Training Accuracy:56.0%\r",
      "Progress:91.2% Speed(reviews/sec):2111. #Correct:206 #Trained:367 Training Accuracy:56.1%\r",
      "Progress:91.5% Speed(reviews/sec):2110. #Correct:206 #Trained:368 Training Accuracy:55.9%\r",
      "Progress:91.7% Speed(reviews/sec):2109. #Correct:207 #Trained:369 Training Accuracy:56.0%\r",
      "Progress:92.0% Speed(reviews/sec):2108. #Correct:208 #Trained:370 Training Accuracy:56.2%\r",
      "Progress:92.2% Speed(reviews/sec):2105. #Correct:209 #Trained:371 Training Accuracy:56.3%\r",
      "Progress:92.5% Speed(reviews/sec):2104. #Correct:210 #Trained:372 Training Accuracy:56.4%\r",
      "Progress:92.7% Speed(reviews/sec):2103. #Correct:211 #Trained:373 Training Accuracy:56.5%\r",
      "Progress:93.0% Speed(reviews/sec):2103. #Correct:211 #Trained:374 Training Accuracy:56.4%\r",
      "Progress:93.2% Speed(reviews/sec):2102. #Correct:212 #Trained:375 Training Accuracy:56.5%\r",
      "Progress:93.5% Speed(reviews/sec):2102. #Correct:212 #Trained:376 Training Accuracy:56.3%\r",
      "Progress:93.7% Speed(reviews/sec):2102. #Correct:213 #Trained:377 Training Accuracy:56.4%\r",
      "Progress:94.0% Speed(reviews/sec):2102. #Correct:214 #Trained:378 Training Accuracy:56.6%\r",
      "Progress:94.2% Speed(reviews/sec):2102. #Correct:214 #Trained:379 Training Accuracy:56.4%\r",
      "Progress:94.5% Speed(reviews/sec):2102. #Correct:215 #Trained:380 Training Accuracy:56.5%\r",
      "Progress:94.7% Speed(reviews/sec):2102. #Correct:215 #Trained:381 Training Accuracy:56.4%\r",
      "Progress:95.0% Speed(reviews/sec):2102. #Correct:215 #Trained:382 Training Accuracy:56.2%\r",
      "Progress:95.2% Speed(reviews/sec):2102. #Correct:215 #Trained:383 Training Accuracy:56.1%\r",
      "Progress:95.5% Speed(reviews/sec):2103. #Correct:216 #Trained:384 Training Accuracy:56.2%\r",
      "Progress:95.7% Speed(reviews/sec):2103. #Correct:216 #Trained:385 Training Accuracy:56.1%\r",
      "Progress:96.0% Speed(reviews/sec):2104. #Correct:217 #Trained:386 Training Accuracy:56.2%\r",
      "Progress:96.2% Speed(reviews/sec):2105. #Correct:218 #Trained:387 Training Accuracy:56.3%\r",
      "Progress:96.5% Speed(reviews/sec):2106. #Correct:219 #Trained:388 Training Accuracy:56.4%\r",
      "Progress:96.7% Speed(reviews/sec):2107. #Correct:219 #Trained:389 Training Accuracy:56.2%\r",
      "Progress:97.0% Speed(reviews/sec):2108. #Correct:220 #Trained:390 Training Accuracy:56.4%\r",
      "Progress:97.2% Speed(reviews/sec):2109. #Correct:221 #Trained:391 Training Accuracy:56.5%\r",
      "Progress:97.5% Speed(reviews/sec):2110. #Correct:222 #Trained:392 Training Accuracy:56.6%\r",
      "Progress:97.7% Speed(reviews/sec):2111. #Correct:223 #Trained:393 Training Accuracy:56.7%\r",
      "Progress:98.0% Speed(reviews/sec):2112. #Correct:224 #Trained:394 Training Accuracy:56.8%\r",
      "Progress:98.2% Speed(reviews/sec):2113. #Correct:225 #Trained:395 Training Accuracy:56.9%\r",
      "Progress:98.5% Speed(reviews/sec):2114. #Correct:226 #Trained:396 Training Accuracy:57.0%\r",
      "Progress:98.7% Speed(reviews/sec):2115. #Correct:227 #Trained:397 Training Accuracy:57.1%\r",
      "Progress:99.0% Speed(reviews/sec):2116. #Correct:228 #Trained:398 Training Accuracy:57.2%\r",
      "Progress:99.2% Speed(reviews/sec):2117. #Correct:228 #Trained:399 Training Accuracy:57.1%\r",
      "Progress:99.5% Speed(reviews/sec):2118. #Correct:228 #Trained:400 Training Accuracy:57.0%\r",
      "Progress:99.7% Speed(reviews/sec):2119. #Correct:229 #Trained:401 Training Accuracy:57.1%"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-120],labels[:-120], learning_rate=0.001)\n",
    "mlp.train(reviews[:-120],labels[:-120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a learning rate of `0.001`, the network should finall have started to improve during training. It's still not very good, but it shows that this solution has potential. We will improve it in the next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Project 3. \n",
    "## Watch the next video to continue with Andrew's next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Neural Noise<a id='lesson_4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sentiment_network.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-2431fd097e8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentiment_network.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sentiment_network.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='sentiment_network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_input_layer(review):\n",
    "    \n",
    "    global layer_0\n",
    "    \n",
    "    # clear out previous state, reset the layer to be all 0s\n",
    "    layer_0 *= 0\n",
    "    for word in review.split(\" \"):\n",
    "        layer_0[0][word2index[word]] += 1\n",
    "\n",
    "update_input_layer(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in reviews[0].split(\" \"):\n",
    "    review_counter[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 16),\n",
       " ('the', 10),\n",
       " ('[redacted]', 9),\n",
       " (',', 9),\n",
       " ('was', 9),\n",
       " ('to', 7),\n",
       " ('that', 6),\n",
       " ('order', 6),\n",
       " ('patient', 5),\n",
       " ('dr', 5),\n",
       " ('not', 5),\n",
       " ('by', 4),\n",
       " ('this', 4),\n",
       " ('for', 4),\n",
       " ('a', 3),\n",
       " ('urgent', 3),\n",
       " ('care', 3),\n",
       " ('tetanus', 3),\n",
       " ('vaccination', 3),\n",
       " ('she', 3),\n",
       " ('and', 3),\n",
       " ('stated', 3),\n",
       " ('it', 3),\n",
       " ('at', 3),\n",
       " ('received', 2),\n",
       " ('called', 2),\n",
       " ('her', 2),\n",
       " ('states', 2),\n",
       " ('nurse', 2),\n",
       " ('on', 2),\n",
       " ('s', 2),\n",
       " ('receive', 2),\n",
       " ('verbal', 2),\n",
       " ('with', 2),\n",
       " ('me', 2),\n",
       " ('shot', 2),\n",
       " ('given', 2),\n",
       " ('i', 2),\n",
       " ('email', 1),\n",
       " ('from', 1),\n",
       " ('caregiver:', 1),\n",
       " ('so', 1),\n",
       " ('requesting', 1),\n",
       " ('as', 1),\n",
       " ('seen', 1),\n",
       " ('here', 1),\n",
       " ('doctor', 1),\n",
       " ('needs', 1),\n",
       " ('one', 1),\n",
       " ('office', 1),\n",
       " ('inquire', 1),\n",
       " ('statements', 1),\n",
       " ('via', 1),\n",
       " ('phone', 1),\n",
       " ('upon', 1),\n",
       " ('speaking', 1),\n",
       " ('their', 1),\n",
       " ('staff', 1),\n",
       " ('member', 1),\n",
       " ('supposed', 1),\n",
       " ('hospital', 1),\n",
       " ('under', 1),\n",
       " ('of', 1),\n",
       " ('executed', 1),\n",
       " ('(', 1),\n",
       " ('reasons', 1),\n",
       " ('unknown', 1),\n",
       " (')', 1),\n",
       " ('which', 1),\n",
       " ('is', 1),\n",
       " ('why', 1),\n",
       " ('needed', 1),\n",
       " ('follow', 1),\n",
       " ('up', 1),\n",
       " ('understood', 1),\n",
       " ('situation', 1),\n",
       " ('vaccine', 1),\n",
       " ('in-house', 1),\n",
       " ('however', 1),\n",
       " ('m', 1),\n",
       " ('comfortable', 1),\n",
       " ('keeping', 1),\n",
       " ('information', 1),\n",
       " ('myself', 1),\n",
       " ('because', 1),\n",
       " ('involves', 1),\n",
       " (\"physician's\", 1),\n",
       " ('has', 1),\n",
       " ('been', 1),\n",
       " ('carried', 1),\n",
       " ('out', 1),\n",
       " ('ultimately', 1),\n",
       " ('will', 1),\n",
       " ('be', 1),\n",
       " ('into', 1),\n",
       " ('5-30-15', 1),\n",
       " ('if', 1),\n",
       " ('there', 1),\n",
       " ('any', 1),\n",
       " ('other', 1),\n",
       " ('questions', 1),\n",
       " ('need', 1),\n",
       " ('answer', 1),\n",
       " ('please', 1),\n",
       " ('let', 1),\n",
       " ('know', 1),\n",
       " ('thank', 1),\n",
       " ('you', 1),\n",
       " ('6/2/15-', 1),\n",
       " ('documentation', 1),\n",
       " ('immunization', 1),\n",
       " ('ordered', 1),\n",
       " ('5/21', 1),\n",
       " ('1540', 1),\n",
       " ('reviewed', 1),\n",
       " ('1606', 1),\n",
       " ('does', 1),\n",
       " ('appear', 1),\n",
       " ('', 1)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_counter.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Reducing Noise in Our Input Data<a id='project_4'></a>\n",
    "\n",
    "**TODO:** Attempt to reduce the noise in the input data like Andrew did in the previous video. Specifically, do the following:\n",
    "* Copy the `SentimentNetwork` class you created earlier into the following cell.\n",
    "* Modify `update_input_layer` so it does not count how many times each word is used, but rather just stores whether or not a word was used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is the same as the previous project, with project-specific changes marked with `\"New for Project 4\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Encapsulate our neural network in a class\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "        \"\"\"Create a SentimenNetwork with the given settings\n",
    "        Args:\n",
    "            reviews(list) - List of reviews used for training\n",
    "            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n",
    "            hidden_nodes(int) - Number of nodes to create in the hidden layer\n",
    "            learning_rate(float) - Learning rate to use while training\n",
    "        \n",
    "        \"\"\"\n",
    "        # Assign a seed to our random number generator to ensure we get\n",
    "        # reproducable results during development \n",
    "        np.random.seed(1)\n",
    "\n",
    "        # process the reviews and their associated labels so that everything\n",
    "        # is ready for training\n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        # Build the network to have the number of hidden nodes and the learning rate that\n",
    "        # were passed into this initializer. Make the same number of input nodes as\n",
    "        # there are vocabulary words and create a single output node.\n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        # populate review_vocab with all of the words in the given reviews\n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "\n",
    "        # Convert the vocabulary set to a list so we can access words via indices\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        # populate label_vocab with all of the words in the given labels.\n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of the review and label vocabularies.\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        # Create a dictionary of labels mapped to index positions\n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Store the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "\n",
    "        # These are the weights between the input layer and the hidden layer.\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        # These are the weights between the hidden layer and the output layer.\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        # The input layer, a two-dimensional matrix with shape 1 x input_nodes\n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "    \n",
    "        \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        \n",
    "        for word in review.split(\" \"):\n",
    "            # NOTE: This if-check was not in the version of this method created in Project 2,\n",
    "            #       and it appears in Andrew's Project 3 solution without explanation. \n",
    "            #       It simply ensures the word is actually a key in word2index before\n",
    "            #       accessing it, which is important because accessing an invalid key\n",
    "            #       with raise an exception in Python. This allows us to ignore unknown\n",
    "            #       words encountered in new reviews.\n",
    "            if(word in self.word2index.keys()):\n",
    "                ## New for Project 4: changed to set to 1 instead of add 1\n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "                \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'ADMINISTER/MONITOR'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        # make sure out we have a matching number of reviews and labels\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        # Keep track of correct predictions to display accuracy during training \n",
    "        correct_so_far = 0\n",
    "\n",
    "        # Remember when we started for printing time statistics\n",
    "        start = time.time()\n",
    "        \n",
    "        # loop through all the given reviews and run a forward and backward pass,\n",
    "        # updating weights for every item\n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            # Get the next review and its correct label\n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # Update the weights\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            # Keep track of correct predictions.\n",
    "            if(layer_2 >= 0.5 and label == 'ADMINISTER/MONITOR'):\n",
    "                correct_so_far += 1\n",
    "            elif(layer_2 < 0.5 and label == 'NOTADMINISTER/MONITOR'):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the training process. \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \"\"\"\n",
    "        Attempts to predict the labels for the given testing_reviews,\n",
    "        and uses the test_labels to calculate the accuracy of those predictions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # keep track of how many correct predictions we make\n",
    "        correct = 0\n",
    "\n",
    "        # we'll time how many predictions per second we make\n",
    "        start = time.time()\n",
    "\n",
    "        # Loop through each of the given reviews and call run to predict\n",
    "        # its label. \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the prediction process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \"\"\"\n",
    "        Returns a POSITIVE or NEGATIVE prediction for the given review.\n",
    "        \"\"\"\n",
    "        # Run a forward pass through the network, like in the \"train\" function.\n",
    "        \n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        # Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;\n",
    "        # return NEGATIVE for other values\n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"ADMINISTER/MONITOR\"\n",
    "        else:\n",
    "            return \"NOTADMINISTER/MONITOR\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to recreate the network and train it. Notice we've gone back to the higher learning rate of `0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "\r",
      "Progress:0.26% Speed(reviews/sec):559.2 #Correct:1 #Trained:2 Training Accuracy:50.0%\r",
      "Progress:0.53% Speed(reviews/sec):836.8 #Correct:2 #Trained:3 Training Accuracy:66.6%\r",
      "Progress:0.80% Speed(reviews/sec):1060. #Correct:3 #Trained:4 Training Accuracy:75.0%\r",
      "Progress:1.07% Speed(reviews/sec):1238. #Correct:4 #Trained:5 Training Accuracy:80.0%\r",
      "Progress:1.34% Speed(reviews/sec):1375. #Correct:4 #Trained:6 Training Accuracy:66.6%\r",
      "Progress:1.61% Speed(reviews/sec):1466. #Correct:4 #Trained:7 Training Accuracy:57.1%\r",
      "Progress:1.88% Speed(reviews/sec):1532. #Correct:4 #Trained:8 Training Accuracy:50.0%\r",
      "Progress:2.15% Speed(reviews/sec):1587. #Correct:4 #Trained:9 Training Accuracy:44.4%\r",
      "Progress:2.42% Speed(reviews/sec):1638. #Correct:4 #Trained:10 Training Accuracy:40.0%\r",
      "Progress:2.69% Speed(reviews/sec):1683. #Correct:5 #Trained:11 Training Accuracy:45.4%\r",
      "Progress:2.96% Speed(reviews/sec):1721. #Correct:6 #Trained:12 Training Accuracy:50.0%\r",
      "Progress:3.23% Speed(reviews/sec):1764. #Correct:7 #Trained:13 Training Accuracy:53.8%\r",
      "Progress:3.50% Speed(reviews/sec):1791. #Correct:7 #Trained:14 Training Accuracy:50.0%\r",
      "Progress:3.77% Speed(reviews/sec):1818. #Correct:7 #Trained:15 Training Accuracy:46.6%\r",
      "Progress:4.04% Speed(reviews/sec):1851. #Correct:8 #Trained:16 Training Accuracy:50.0%\r",
      "Progress:4.31% Speed(reviews/sec):1878. #Correct:9 #Trained:17 Training Accuracy:52.9%\r",
      "Progress:4.58% Speed(reviews/sec):1906. #Correct:10 #Trained:18 Training Accuracy:55.5%\r",
      "Progress:4.85% Speed(reviews/sec):1931. #Correct:10 #Trained:19 Training Accuracy:52.6%\r",
      "Progress:5.12% Speed(reviews/sec):1956. #Correct:11 #Trained:20 Training Accuracy:55.0%\r",
      "Progress:5.39% Speed(reviews/sec):1977. #Correct:11 #Trained:21 Training Accuracy:52.3%\r",
      "Progress:5.66% Speed(reviews/sec):1996. #Correct:11 #Trained:22 Training Accuracy:50.0%\r",
      "Progress:5.92% Speed(reviews/sec):2002. #Correct:11 #Trained:23 Training Accuracy:47.8%\r",
      "Progress:6.19% Speed(reviews/sec):2012. #Correct:12 #Trained:24 Training Accuracy:50.0%\r",
      "Progress:6.46% Speed(reviews/sec):2021. #Correct:12 #Trained:25 Training Accuracy:48.0%\r",
      "Progress:6.73% Speed(reviews/sec):2043. #Correct:12 #Trained:26 Training Accuracy:46.1%\r",
      "Progress:7.00% Speed(reviews/sec):2063. #Correct:12 #Trained:27 Training Accuracy:44.4%\r",
      "Progress:7.27% Speed(reviews/sec):2076. #Correct:13 #Trained:28 Training Accuracy:46.4%\r",
      "Progress:7.54% Speed(reviews/sec):2093. #Correct:13 #Trained:29 Training Accuracy:44.8%\r",
      "Progress:7.81% Speed(reviews/sec):2104. #Correct:14 #Trained:30 Training Accuracy:46.6%\r",
      "Progress:8.08% Speed(reviews/sec):2114. #Correct:15 #Trained:31 Training Accuracy:48.3%\r",
      "Progress:8.35% Speed(reviews/sec):2130. #Correct:16 #Trained:32 Training Accuracy:50.0%\r",
      "Progress:8.62% Speed(reviews/sec):2140. #Correct:16 #Trained:33 Training Accuracy:48.4%\r",
      "Progress:8.89% Speed(reviews/sec):2150. #Correct:16 #Trained:34 Training Accuracy:47.0%\r",
      "Progress:9.16% Speed(reviews/sec):2150. #Correct:16 #Trained:35 Training Accuracy:45.7%\r",
      "Progress:9.43% Speed(reviews/sec):2158. #Correct:16 #Trained:36 Training Accuracy:44.4%\r",
      "Progress:9.70% Speed(reviews/sec):2168. #Correct:16 #Trained:37 Training Accuracy:43.2%\r",
      "Progress:9.97% Speed(reviews/sec):2182. #Correct:16 #Trained:38 Training Accuracy:42.1%\r",
      "Progress:10.2% Speed(reviews/sec):2189. #Correct:17 #Trained:39 Training Accuracy:43.5%\r",
      "Progress:10.5% Speed(reviews/sec):2196. #Correct:17 #Trained:40 Training Accuracy:42.5%\r",
      "Progress:10.7% Speed(reviews/sec):2203. #Correct:17 #Trained:41 Training Accuracy:41.4%\r",
      "Progress:11.0% Speed(reviews/sec):2209. #Correct:18 #Trained:42 Training Accuracy:42.8%\r",
      "Progress:11.3% Speed(reviews/sec):2217. #Correct:19 #Trained:43 Training Accuracy:44.1%\r",
      "Progress:11.5% Speed(reviews/sec):2224. #Correct:20 #Trained:44 Training Accuracy:45.4%\r",
      "Progress:11.8% Speed(reviews/sec):2227. #Correct:20 #Trained:45 Training Accuracy:44.4%\r",
      "Progress:12.1% Speed(reviews/sec):2233. #Correct:21 #Trained:46 Training Accuracy:45.6%\r",
      "Progress:12.3% Speed(reviews/sec):2240. #Correct:22 #Trained:47 Training Accuracy:46.8%\r",
      "Progress:12.6% Speed(reviews/sec):2245. #Correct:22 #Trained:48 Training Accuracy:45.8%\r",
      "Progress:12.9% Speed(reviews/sec):2252. #Correct:23 #Trained:49 Training Accuracy:46.9%\r",
      "Progress:13.2% Speed(reviews/sec):2261. #Correct:23 #Trained:50 Training Accuracy:46.0%\r",
      "Progress:13.4% Speed(reviews/sec):2270. #Correct:23 #Trained:51 Training Accuracy:45.0%\r",
      "Progress:13.7% Speed(reviews/sec):2280. #Correct:24 #Trained:52 Training Accuracy:46.1%\r",
      "Progress:14.0% Speed(reviews/sec):2290. #Correct:24 #Trained:53 Training Accuracy:45.2%\r",
      "Progress:14.2% Speed(reviews/sec):2299. #Correct:24 #Trained:54 Training Accuracy:44.4%\r",
      "Progress:14.5% Speed(reviews/sec):2308. #Correct:25 #Trained:55 Training Accuracy:45.4%\r",
      "Progress:14.8% Speed(reviews/sec):2315. #Correct:25 #Trained:56 Training Accuracy:44.6%\r",
      "Progress:15.0% Speed(reviews/sec):2323. #Correct:25 #Trained:57 Training Accuracy:43.8%\r",
      "Progress:15.3% Speed(reviews/sec):2328. #Correct:26 #Trained:58 Training Accuracy:44.8%\r",
      "Progress:15.6% Speed(reviews/sec):2336. #Correct:27 #Trained:59 Training Accuracy:45.7%\r",
      "Progress:15.9% Speed(reviews/sec):2342. #Correct:27 #Trained:60 Training Accuracy:45.0%\r",
      "Progress:16.1% Speed(reviews/sec):2349. #Correct:28 #Trained:61 Training Accuracy:45.9%\r",
      "Progress:16.4% Speed(reviews/sec):2357. #Correct:28 #Trained:62 Training Accuracy:45.1%\r",
      "Progress:16.7% Speed(reviews/sec):2365. #Correct:29 #Trained:63 Training Accuracy:46.0%\r",
      "Progress:16.9% Speed(reviews/sec):2374. #Correct:30 #Trained:64 Training Accuracy:46.8%\r",
      "Progress:17.2% Speed(reviews/sec):2383. #Correct:30 #Trained:65 Training Accuracy:46.1%\r",
      "Progress:17.5% Speed(reviews/sec):2390. #Correct:31 #Trained:66 Training Accuracy:46.9%\r",
      "Progress:17.7% Speed(reviews/sec):2400. #Correct:31 #Trained:67 Training Accuracy:46.2%\r",
      "Progress:18.0% Speed(reviews/sec):2408. #Correct:31 #Trained:68 Training Accuracy:45.5%\r",
      "Progress:18.3% Speed(reviews/sec):2415. #Correct:32 #Trained:69 Training Accuracy:46.3%\r",
      "Progress:18.5% Speed(reviews/sec):2421. #Correct:33 #Trained:70 Training Accuracy:47.1%\r",
      "Progress:18.8% Speed(reviews/sec):2428. #Correct:33 #Trained:71 Training Accuracy:46.4%\r",
      "Progress:19.1% Speed(reviews/sec):2435. #Correct:34 #Trained:72 Training Accuracy:47.2%\r",
      "Progress:19.4% Speed(reviews/sec):2442. #Correct:34 #Trained:73 Training Accuracy:46.5%\r",
      "Progress:19.6% Speed(reviews/sec):2445. #Correct:35 #Trained:74 Training Accuracy:47.2%\r",
      "Progress:19.9% Speed(reviews/sec):2450. #Correct:36 #Trained:75 Training Accuracy:48.0%\r",
      "Progress:20.2% Speed(reviews/sec):2456. #Correct:37 #Trained:76 Training Accuracy:48.6%\r",
      "Progress:20.4% Speed(reviews/sec):2462. #Correct:38 #Trained:77 Training Accuracy:49.3%\r",
      "Progress:20.7% Speed(reviews/sec):2468. #Correct:38 #Trained:78 Training Accuracy:48.7%\r",
      "Progress:21.0% Speed(reviews/sec):2476. #Correct:38 #Trained:79 Training Accuracy:48.1%\r",
      "Progress:21.2% Speed(reviews/sec):2483. #Correct:39 #Trained:80 Training Accuracy:48.7%\r",
      "Progress:21.5% Speed(reviews/sec):2490. #Correct:40 #Trained:81 Training Accuracy:49.3%\r",
      "Progress:21.8% Speed(reviews/sec):2492. #Correct:41 #Trained:82 Training Accuracy:50.0%\r",
      "Progress:22.1% Speed(reviews/sec):2497. #Correct:41 #Trained:83 Training Accuracy:49.3%\r",
      "Progress:22.3% Speed(reviews/sec):2503. #Correct:42 #Trained:84 Training Accuracy:50.0%\r",
      "Progress:22.6% Speed(reviews/sec):2510. #Correct:43 #Trained:85 Training Accuracy:50.5%\r",
      "Progress:22.9% Speed(reviews/sec):2516. #Correct:43 #Trained:86 Training Accuracy:50.0%\r",
      "Progress:23.1% Speed(reviews/sec):2523. #Correct:43 #Trained:87 Training Accuracy:49.4%\r",
      "Progress:23.4% Speed(reviews/sec):2528. #Correct:43 #Trained:88 Training Accuracy:48.8%\r",
      "Progress:23.7% Speed(reviews/sec):2535. #Correct:44 #Trained:89 Training Accuracy:49.4%\r",
      "Progress:23.9% Speed(reviews/sec):2541. #Correct:45 #Trained:90 Training Accuracy:50.0%\r",
      "Progress:24.2% Speed(reviews/sec):2547. #Correct:46 #Trained:91 Training Accuracy:50.5%\r",
      "Progress:24.5% Speed(reviews/sec):2554. #Correct:47 #Trained:92 Training Accuracy:51.0%\r",
      "Progress:24.7% Speed(reviews/sec):2552. #Correct:47 #Trained:93 Training Accuracy:50.5%\r",
      "Progress:25.0% Speed(reviews/sec):2557. #Correct:48 #Trained:94 Training Accuracy:51.0%\r",
      "Progress:25.3% Speed(reviews/sec):2562. #Correct:48 #Trained:95 Training Accuracy:50.5%\r",
      "Progress:25.6% Speed(reviews/sec):2568. #Correct:49 #Trained:96 Training Accuracy:51.0%\r",
      "Progress:25.8% Speed(reviews/sec):2571. #Correct:49 #Trained:97 Training Accuracy:50.5%\r",
      "Progress:26.1% Speed(reviews/sec):2575. #Correct:49 #Trained:98 Training Accuracy:50.0%\r",
      "Progress:26.4% Speed(reviews/sec):2580. #Correct:49 #Trained:99 Training Accuracy:49.4%\r",
      "Progress:26.6% Speed(reviews/sec):2583. #Correct:50 #Trained:100 Training Accuracy:50.0%\r",
      "Progress:26.9% Speed(reviews/sec):2586. #Correct:51 #Trained:101 Training Accuracy:50.4%\r",
      "Progress:27.2% Speed(reviews/sec):2584. #Correct:51 #Trained:102 Training Accuracy:50.0%\r",
      "Progress:27.4% Speed(reviews/sec):2585. #Correct:51 #Trained:103 Training Accuracy:49.5%\r",
      "Progress:27.7% Speed(reviews/sec):2589. #Correct:51 #Trained:104 Training Accuracy:49.0%\r",
      "Progress:28.0% Speed(reviews/sec):2593. #Correct:52 #Trained:105 Training Accuracy:49.5%\r",
      "Progress:28.3% Speed(reviews/sec):2595. #Correct:52 #Trained:106 Training Accuracy:49.0%\r",
      "Progress:28.5% Speed(reviews/sec):2597. #Correct:52 #Trained:107 Training Accuracy:48.5%\r",
      "Progress:28.8% Speed(reviews/sec):2600. #Correct:53 #Trained:108 Training Accuracy:49.0%\r",
      "Progress:29.1% Speed(reviews/sec):2606. #Correct:53 #Trained:109 Training Accuracy:48.6%\r",
      "Progress:29.3% Speed(reviews/sec):2612. #Correct:54 #Trained:110 Training Accuracy:49.0%\r",
      "Progress:29.6% Speed(reviews/sec):2615. #Correct:54 #Trained:111 Training Accuracy:48.6%\r",
      "Progress:29.9% Speed(reviews/sec):2617. #Correct:55 #Trained:112 Training Accuracy:49.1%\r",
      "Progress:30.1% Speed(reviews/sec):2619. #Correct:55 #Trained:113 Training Accuracy:48.6%\r",
      "Progress:30.4% Speed(reviews/sec):2624. #Correct:55 #Trained:114 Training Accuracy:48.2%\r",
      "Progress:30.7% Speed(reviews/sec):2627. #Correct:56 #Trained:115 Training Accuracy:48.6%\r",
      "Progress:30.9% Speed(reviews/sec):2630. #Correct:57 #Trained:116 Training Accuracy:49.1%\r",
      "Progress:31.2% Speed(reviews/sec):2633. #Correct:58 #Trained:117 Training Accuracy:49.5%\r",
      "Progress:31.5% Speed(reviews/sec):2636. #Correct:58 #Trained:118 Training Accuracy:49.1%\r",
      "Progress:31.8% Speed(reviews/sec):2639. #Correct:59 #Trained:119 Training Accuracy:49.5%\r",
      "Progress:32.0% Speed(reviews/sec):2641. #Correct:60 #Trained:120 Training Accuracy:50.0%\r",
      "Progress:32.3% Speed(reviews/sec):2644. #Correct:61 #Trained:121 Training Accuracy:50.4%\r",
      "Progress:32.6% Speed(reviews/sec):2647. #Correct:61 #Trained:122 Training Accuracy:50.0%\r",
      "Progress:32.8% Speed(reviews/sec):2649. #Correct:61 #Trained:123 Training Accuracy:49.5%\r",
      "Progress:33.1% Speed(reviews/sec):2652. #Correct:61 #Trained:124 Training Accuracy:49.1%\r",
      "Progress:33.4% Speed(reviews/sec):2654. #Correct:62 #Trained:125 Training Accuracy:49.6%\r",
      "Progress:33.6% Speed(reviews/sec):2656. #Correct:63 #Trained:126 Training Accuracy:50.0%\r",
      "Progress:33.9% Speed(reviews/sec):2658. #Correct:64 #Trained:127 Training Accuracy:50.3%\r",
      "Progress:34.2% Speed(reviews/sec):2661. #Correct:65 #Trained:128 Training Accuracy:50.7%\r",
      "Progress:34.5% Speed(reviews/sec):2665. #Correct:66 #Trained:129 Training Accuracy:51.1%\r",
      "Progress:34.7% Speed(reviews/sec):2670. #Correct:67 #Trained:130 Training Accuracy:51.5%\r",
      "Progress:35.0% Speed(reviews/sec):2675. #Correct:68 #Trained:131 Training Accuracy:51.9%\r",
      "Progress:35.3% Speed(reviews/sec):2677. #Correct:68 #Trained:132 Training Accuracy:51.5%\r",
      "Progress:35.5% Speed(reviews/sec):2678. #Correct:69 #Trained:133 Training Accuracy:51.8%\r",
      "Progress:35.8% Speed(reviews/sec):2680. #Correct:70 #Trained:134 Training Accuracy:52.2%\r",
      "Progress:36.1% Speed(reviews/sec):2683. #Correct:71 #Trained:135 Training Accuracy:52.5%\r",
      "Progress:36.3% Speed(reviews/sec):2685. #Correct:72 #Trained:136 Training Accuracy:52.9%\r",
      "Progress:36.6% Speed(reviews/sec):2689. #Correct:73 #Trained:137 Training Accuracy:53.2%\r",
      "Progress:36.9% Speed(reviews/sec):2692. #Correct:74 #Trained:138 Training Accuracy:53.6%\r",
      "Progress:37.1% Speed(reviews/sec):2694. #Correct:74 #Trained:139 Training Accuracy:53.2%\r",
      "Progress:37.4% Speed(reviews/sec):2696. #Correct:75 #Trained:140 Training Accuracy:53.5%\r",
      "Progress:37.7% Speed(reviews/sec):2698. #Correct:76 #Trained:141 Training Accuracy:53.9%\r",
      "Progress:38.0% Speed(reviews/sec):2699. #Correct:76 #Trained:142 Training Accuracy:53.5%\r",
      "Progress:38.2% Speed(reviews/sec):2702. #Correct:77 #Trained:143 Training Accuracy:53.8%\r",
      "Progress:38.5% Speed(reviews/sec):2705. #Correct:78 #Trained:144 Training Accuracy:54.1%\r",
      "Progress:38.8% Speed(reviews/sec):2708. #Correct:78 #Trained:145 Training Accuracy:53.7%\r",
      "Progress:39.0% Speed(reviews/sec):2711. #Correct:78 #Trained:146 Training Accuracy:53.4%\r",
      "Progress:39.3% Speed(reviews/sec):2714. #Correct:78 #Trained:147 Training Accuracy:53.0%\r",
      "Progress:39.6% Speed(reviews/sec):2717. #Correct:79 #Trained:148 Training Accuracy:53.3%\r",
      "Progress:39.8% Speed(reviews/sec):2721. #Correct:79 #Trained:149 Training Accuracy:53.0%\r",
      "Progress:40.1% Speed(reviews/sec):2724. #Correct:80 #Trained:150 Training Accuracy:53.3%\r",
      "Progress:40.4% Speed(reviews/sec):2728. #Correct:81 #Trained:151 Training Accuracy:53.6%\r",
      "Progress:40.7% Speed(reviews/sec):2731. #Correct:81 #Trained:152 Training Accuracy:53.2%\r",
      "Progress:40.9% Speed(reviews/sec):2734. #Correct:82 #Trained:153 Training Accuracy:53.5%\r",
      "Progress:41.2% Speed(reviews/sec):2737. #Correct:82 #Trained:154 Training Accuracy:53.2%\r",
      "Progress:41.5% Speed(reviews/sec):2740. #Correct:83 #Trained:155 Training Accuracy:53.5%\r",
      "Progress:41.7% Speed(reviews/sec):2741. #Correct:84 #Trained:156 Training Accuracy:53.8%\r",
      "Progress:42.0% Speed(reviews/sec):2742. #Correct:85 #Trained:157 Training Accuracy:54.1%\r",
      "Progress:42.3% Speed(reviews/sec):2744. #Correct:86 #Trained:158 Training Accuracy:54.4%\r",
      "Progress:42.5% Speed(reviews/sec):2747. #Correct:87 #Trained:159 Training Accuracy:54.7%\r",
      "Progress:42.8% Speed(reviews/sec):2749. #Correct:88 #Trained:160 Training Accuracy:55.0%\r",
      "Progress:43.1% Speed(reviews/sec):2752. #Correct:89 #Trained:161 Training Accuracy:55.2%\r",
      "Progress:43.3% Speed(reviews/sec):2755. #Correct:90 #Trained:162 Training Accuracy:55.5%\r",
      "Progress:43.6% Speed(reviews/sec):2757. #Correct:90 #Trained:163 Training Accuracy:55.2%\r",
      "Progress:43.9% Speed(reviews/sec):2760. #Correct:90 #Trained:164 Training Accuracy:54.8%\r",
      "Progress:44.2% Speed(reviews/sec):2763. #Correct:90 #Trained:165 Training Accuracy:54.5%\r",
      "Progress:44.4% Speed(reviews/sec):2765. #Correct:91 #Trained:166 Training Accuracy:54.8%\r",
      "Progress:44.7% Speed(reviews/sec):2768. #Correct:92 #Trained:167 Training Accuracy:55.0%\r",
      "Progress:45.0% Speed(reviews/sec):2770. #Correct:93 #Trained:168 Training Accuracy:55.3%\r",
      "Progress:45.2% Speed(reviews/sec):2773. #Correct:94 #Trained:169 Training Accuracy:55.6%\r",
      "Progress:45.5% Speed(reviews/sec):2776. #Correct:95 #Trained:170 Training Accuracy:55.8%\r",
      "Progress:45.8% Speed(reviews/sec):2778. #Correct:96 #Trained:171 Training Accuracy:56.1%\r",
      "Progress:46.0% Speed(reviews/sec):2780. #Correct:97 #Trained:172 Training Accuracy:56.3%\r",
      "Progress:46.3% Speed(reviews/sec):2783. #Correct:97 #Trained:173 Training Accuracy:56.0%\r",
      "Progress:46.6% Speed(reviews/sec):2784. #Correct:98 #Trained:174 Training Accuracy:56.3%\r",
      "Progress:46.9% Speed(reviews/sec):2786. #Correct:99 #Trained:175 Training Accuracy:56.5%\r",
      "Progress:47.1% Speed(reviews/sec):2788. #Correct:99 #Trained:176 Training Accuracy:56.2%\r",
      "Progress:47.4% Speed(reviews/sec):2791. #Correct:100 #Trained:177 Training Accuracy:56.4%\r",
      "Progress:47.7% Speed(reviews/sec):2793. #Correct:101 #Trained:178 Training Accuracy:56.7%\r",
      "Progress:47.9% Speed(reviews/sec):2796. #Correct:102 #Trained:179 Training Accuracy:56.9%\r",
      "Progress:48.2% Speed(reviews/sec):2798. #Correct:103 #Trained:180 Training Accuracy:57.2%\r",
      "Progress:48.5% Speed(reviews/sec):2800. #Correct:104 #Trained:181 Training Accuracy:57.4%\r",
      "Progress:48.7% Speed(reviews/sec):2803. #Correct:105 #Trained:182 Training Accuracy:57.6%\r",
      "Progress:49.0% Speed(reviews/sec):2803. #Correct:106 #Trained:183 Training Accuracy:57.9%\r",
      "Progress:49.3% Speed(reviews/sec):2804. #Correct:107 #Trained:184 Training Accuracy:58.1%\r",
      "Progress:49.5% Speed(reviews/sec):2806. #Correct:107 #Trained:185 Training Accuracy:57.8%\r",
      "Progress:49.8% Speed(reviews/sec):2808. #Correct:108 #Trained:186 Training Accuracy:58.0%\r",
      "Progress:50.1% Speed(reviews/sec):2806. #Correct:108 #Trained:187 Training Accuracy:57.7%\r",
      "Progress:50.4% Speed(reviews/sec):2805. #Correct:109 #Trained:188 Training Accuracy:57.9%\r",
      "Progress:50.6% Speed(reviews/sec):2805. #Correct:109 #Trained:189 Training Accuracy:57.6%\r",
      "Progress:50.9% Speed(reviews/sec):2805. #Correct:110 #Trained:190 Training Accuracy:57.8%\r",
      "Progress:51.2% Speed(reviews/sec):2805. #Correct:111 #Trained:191 Training Accuracy:58.1%\r",
      "Progress:51.4% Speed(reviews/sec):2806. #Correct:112 #Trained:192 Training Accuracy:58.3%\r",
      "Progress:51.7% Speed(reviews/sec):2806. #Correct:113 #Trained:193 Training Accuracy:58.5%\r",
      "Progress:52.0% Speed(reviews/sec):2807. #Correct:113 #Trained:194 Training Accuracy:58.2%\r",
      "Progress:52.2% Speed(reviews/sec):2807. #Correct:113 #Trained:195 Training Accuracy:57.9%\r",
      "Progress:52.5% Speed(reviews/sec):2808. #Correct:114 #Trained:196 Training Accuracy:58.1%\r",
      "Progress:52.8% Speed(reviews/sec):2808. #Correct:115 #Trained:197 Training Accuracy:58.3%\r",
      "Progress:53.0% Speed(reviews/sec):2809. #Correct:115 #Trained:198 Training Accuracy:58.0%\r",
      "Progress:53.3% Speed(reviews/sec):2809. #Correct:116 #Trained:199 Training Accuracy:58.2%\r",
      "Progress:53.6% Speed(reviews/sec):2810. #Correct:116 #Trained:200 Training Accuracy:58.0%\r",
      "Progress:53.9% Speed(reviews/sec):2811. #Correct:117 #Trained:201 Training Accuracy:58.2%\r",
      "Progress:54.1% Speed(reviews/sec):2812. #Correct:117 #Trained:202 Training Accuracy:57.9%\r",
      "Progress:54.4% Speed(reviews/sec):2813. #Correct:118 #Trained:203 Training Accuracy:58.1%\r",
      "Progress:54.7% Speed(reviews/sec):2814. #Correct:118 #Trained:204 Training Accuracy:57.8%\r",
      "Progress:54.9% Speed(reviews/sec):2815. #Correct:119 #Trained:205 Training Accuracy:58.0%\r",
      "Progress:55.2% Speed(reviews/sec):2816. #Correct:120 #Trained:206 Training Accuracy:58.2%\r",
      "Progress:55.5% Speed(reviews/sec):2817. #Correct:121 #Trained:207 Training Accuracy:58.4%\r",
      "Progress:55.7% Speed(reviews/sec):2818. #Correct:122 #Trained:208 Training Accuracy:58.6%\r",
      "Progress:56.0% Speed(reviews/sec):2819. #Correct:122 #Trained:209 Training Accuracy:58.3%\r",
      "Progress:56.3% Speed(reviews/sec):2822. #Correct:122 #Trained:210 Training Accuracy:58.0%\r",
      "Progress:56.6% Speed(reviews/sec):2805. #Correct:122 #Trained:211 Training Accuracy:57.8%\r",
      "Progress:56.8% Speed(reviews/sec):2791. #Correct:123 #Trained:212 Training Accuracy:58.0%\r",
      "Progress:57.1% Speed(reviews/sec):2778. #Correct:123 #Trained:213 Training Accuracy:57.7%\r",
      "Progress:57.4% Speed(reviews/sec):2758. #Correct:124 #Trained:214 Training Accuracy:57.9%\r",
      "Progress:57.6% Speed(reviews/sec):2737. #Correct:124 #Trained:215 Training Accuracy:57.6%\r",
      "Progress:57.9% Speed(reviews/sec):2717. #Correct:125 #Trained:216 Training Accuracy:57.8%\r",
      "Progress:58.2% Speed(reviews/sec):2698. #Correct:126 #Trained:217 Training Accuracy:58.0%\r",
      "Progress:58.4% Speed(reviews/sec):2668. #Correct:127 #Trained:218 Training Accuracy:58.2%\r",
      "Progress:58.7% Speed(reviews/sec):2649. #Correct:128 #Trained:219 Training Accuracy:58.4%\r",
      "Progress:59.0% Speed(reviews/sec):2637. #Correct:128 #Trained:220 Training Accuracy:58.1%\r",
      "Progress:59.2% Speed(reviews/sec):2627. #Correct:129 #Trained:221 Training Accuracy:58.3%\r",
      "Progress:59.5% Speed(reviews/sec):2620. #Correct:129 #Trained:222 Training Accuracy:58.1%\r",
      "Progress:59.8% Speed(reviews/sec):2611. #Correct:130 #Trained:223 Training Accuracy:58.2%\r",
      "Progress:60.1% Speed(reviews/sec):2598. #Correct:131 #Trained:224 Training Accuracy:58.4%\r",
      "Progress:60.3% Speed(reviews/sec):2585. #Correct:132 #Trained:225 Training Accuracy:58.6%\r",
      "Progress:60.6% Speed(reviews/sec):2575. #Correct:132 #Trained:226 Training Accuracy:58.4%\r",
      "Progress:60.9% Speed(reviews/sec):2568. #Correct:133 #Trained:227 Training Accuracy:58.5%\r",
      "Progress:61.1% Speed(reviews/sec):2561. #Correct:134 #Trained:228 Training Accuracy:58.7%\r",
      "Progress:61.4% Speed(reviews/sec):2555. #Correct:135 #Trained:229 Training Accuracy:58.9%\r",
      "Progress:61.7% Speed(reviews/sec):2548. #Correct:136 #Trained:230 Training Accuracy:59.1%\r",
      "Progress:61.9% Speed(reviews/sec):2541. #Correct:137 #Trained:231 Training Accuracy:59.3%\r",
      "Progress:62.2% Speed(reviews/sec):2530. #Correct:138 #Trained:232 Training Accuracy:59.4%\r",
      "Progress:62.5% Speed(reviews/sec):2522. #Correct:139 #Trained:233 Training Accuracy:59.6%\r",
      "Progress:62.8% Speed(reviews/sec):2519. #Correct:140 #Trained:234 Training Accuracy:59.8%\r",
      "Progress:63.0% Speed(reviews/sec):2515. #Correct:140 #Trained:235 Training Accuracy:59.5%\r",
      "Progress:63.3% Speed(reviews/sec):2509. #Correct:141 #Trained:236 Training Accuracy:59.7%\r",
      "Progress:63.6% Speed(reviews/sec):2502. #Correct:142 #Trained:237 Training Accuracy:59.9%\r",
      "Progress:63.8% Speed(reviews/sec):2497. #Correct:143 #Trained:238 Training Accuracy:60.0%\r",
      "Progress:64.1% Speed(reviews/sec):2490. #Correct:143 #Trained:239 Training Accuracy:59.8%\r",
      "Progress:64.4% Speed(reviews/sec):2488. #Correct:144 #Trained:240 Training Accuracy:60.0%\r",
      "Progress:64.6% Speed(reviews/sec):2484. #Correct:145 #Trained:241 Training Accuracy:60.1%\r",
      "Progress:64.9% Speed(reviews/sec):2480. #Correct:146 #Trained:242 Training Accuracy:60.3%\r",
      "Progress:65.2% Speed(reviews/sec):2476. #Correct:147 #Trained:243 Training Accuracy:60.4%\r",
      "Progress:65.4% Speed(reviews/sec):2472. #Correct:147 #Trained:244 Training Accuracy:60.2%\r",
      "Progress:65.7% Speed(reviews/sec):2468. #Correct:147 #Trained:245 Training Accuracy:60.0%\r",
      "Progress:66.0% Speed(reviews/sec):2462. #Correct:148 #Trained:246 Training Accuracy:60.1%\r",
      "Progress:66.3% Speed(reviews/sec):2456. #Correct:148 #Trained:247 Training Accuracy:59.9%\r",
      "Progress:66.5% Speed(reviews/sec):2453. #Correct:149 #Trained:248 Training Accuracy:60.0%\r",
      "Progress:66.8% Speed(reviews/sec):2446. #Correct:149 #Trained:249 Training Accuracy:59.8%\r",
      "Progress:67.1% Speed(reviews/sec):2439. #Correct:150 #Trained:250 Training Accuracy:60.0%\r",
      "Progress:67.3% Speed(reviews/sec):2433. #Correct:151 #Trained:251 Training Accuracy:60.1%\r",
      "Progress:67.6% Speed(reviews/sec):2429. #Correct:152 #Trained:252 Training Accuracy:60.3%\r",
      "Progress:67.9% Speed(reviews/sec):2425. #Correct:153 #Trained:253 Training Accuracy:60.4%\r",
      "Progress:68.1% Speed(reviews/sec):2420. #Correct:154 #Trained:254 Training Accuracy:60.6%\r",
      "Progress:68.4% Speed(reviews/sec):2420. #Correct:155 #Trained:255 Training Accuracy:60.7%\r",
      "Progress:68.7% Speed(reviews/sec):2419. #Correct:156 #Trained:256 Training Accuracy:60.9%\r",
      "Progress:69.0% Speed(reviews/sec):2416. #Correct:157 #Trained:257 Training Accuracy:61.0%\r",
      "Progress:69.2% Speed(reviews/sec):2413. #Correct:158 #Trained:258 Training Accuracy:61.2%\r",
      "Progress:69.5% Speed(reviews/sec):2409. #Correct:159 #Trained:259 Training Accuracy:61.3%\r",
      "Progress:69.8% Speed(reviews/sec):2406. #Correct:160 #Trained:260 Training Accuracy:61.5%\r",
      "Progress:70.0% Speed(reviews/sec):2403. #Correct:161 #Trained:261 Training Accuracy:61.6%\r",
      "Progress:70.3% Speed(reviews/sec):2400. #Correct:162 #Trained:262 Training Accuracy:61.8%\r",
      "Progress:70.6% Speed(reviews/sec):2398. #Correct:163 #Trained:263 Training Accuracy:61.9%\r",
      "Progress:70.8% Speed(reviews/sec):2394. #Correct:164 #Trained:264 Training Accuracy:62.1%\r",
      "Progress:71.1% Speed(reviews/sec):2394. #Correct:165 #Trained:265 Training Accuracy:62.2%\r",
      "Progress:71.4% Speed(reviews/sec):2392. #Correct:166 #Trained:266 Training Accuracy:62.4%\r",
      "Progress:71.6% Speed(reviews/sec):2388. #Correct:166 #Trained:267 Training Accuracy:62.1%\r",
      "Progress:71.9% Speed(reviews/sec):2388. #Correct:166 #Trained:268 Training Accuracy:61.9%\r",
      "Progress:72.2% Speed(reviews/sec):2386. #Correct:167 #Trained:269 Training Accuracy:62.0%\r",
      "Progress:72.5% Speed(reviews/sec):2383. #Correct:168 #Trained:270 Training Accuracy:62.2%\r",
      "Progress:72.7% Speed(reviews/sec):2380. #Correct:169 #Trained:271 Training Accuracy:62.3%\r",
      "Progress:73.0% Speed(reviews/sec):2378. #Correct:170 #Trained:272 Training Accuracy:62.5%\r",
      "Progress:73.3% Speed(reviews/sec):2375. #Correct:171 #Trained:273 Training Accuracy:62.6%\r",
      "Progress:73.5% Speed(reviews/sec):2372. #Correct:171 #Trained:274 Training Accuracy:62.4%\r",
      "Progress:73.8% Speed(reviews/sec):2370. #Correct:172 #Trained:275 Training Accuracy:62.5%\r",
      "Progress:74.1% Speed(reviews/sec):2370. #Correct:172 #Trained:276 Training Accuracy:62.3%\r",
      "Progress:74.3% Speed(reviews/sec):2368. #Correct:172 #Trained:277 Training Accuracy:62.0%\r",
      "Progress:74.6% Speed(reviews/sec):2366. #Correct:173 #Trained:278 Training Accuracy:62.2%\r",
      "Progress:74.9% Speed(reviews/sec):2365. #Correct:173 #Trained:279 Training Accuracy:62.0%\r",
      "Progress:75.2% Speed(reviews/sec):2363. #Correct:173 #Trained:280 Training Accuracy:61.7%\r",
      "Progress:75.4% Speed(reviews/sec):2364. #Correct:174 #Trained:281 Training Accuracy:61.9%\r",
      "Progress:75.7% Speed(reviews/sec):2364. #Correct:175 #Trained:282 Training Accuracy:62.0%\r",
      "Progress:76.0% Speed(reviews/sec):2364. #Correct:176 #Trained:283 Training Accuracy:62.1%\r",
      "Progress:76.2% Speed(reviews/sec):2363. #Correct:177 #Trained:284 Training Accuracy:62.3%\r",
      "Progress:76.5% Speed(reviews/sec):2361. #Correct:177 #Trained:285 Training Accuracy:62.1%\r",
      "Progress:76.8% Speed(reviews/sec):2361. #Correct:178 #Trained:286 Training Accuracy:62.2%\r",
      "Progress:77.0% Speed(reviews/sec):2360. #Correct:179 #Trained:287 Training Accuracy:62.3%\r",
      "Progress:77.3% Speed(reviews/sec):2358. #Correct:179 #Trained:288 Training Accuracy:62.1%\r",
      "Progress:77.6% Speed(reviews/sec):2357. #Correct:179 #Trained:289 Training Accuracy:61.9%\r",
      "Progress:77.8% Speed(reviews/sec):2356. #Correct:180 #Trained:290 Training Accuracy:62.0%\r",
      "Progress:78.1% Speed(reviews/sec):2355. #Correct:180 #Trained:291 Training Accuracy:61.8%\r",
      "Progress:78.4% Speed(reviews/sec):2354. #Correct:180 #Trained:292 Training Accuracy:61.6%\r",
      "Progress:78.7% Speed(reviews/sec):2354. #Correct:181 #Trained:293 Training Accuracy:61.7%\r",
      "Progress:78.9% Speed(reviews/sec):2353. #Correct:182 #Trained:294 Training Accuracy:61.9%\r",
      "Progress:79.2% Speed(reviews/sec):2353. #Correct:183 #Trained:295 Training Accuracy:62.0%\r",
      "Progress:79.5% Speed(reviews/sec):2352. #Correct:183 #Trained:296 Training Accuracy:61.8%\r",
      "Progress:79.7% Speed(reviews/sec):2352. #Correct:184 #Trained:297 Training Accuracy:61.9%\r",
      "Progress:80.0% Speed(reviews/sec):2352. #Correct:185 #Trained:298 Training Accuracy:62.0%\r",
      "Progress:80.3% Speed(reviews/sec):2353. #Correct:185 #Trained:299 Training Accuracy:61.8%\r",
      "Progress:80.5% Speed(reviews/sec):2353. #Correct:186 #Trained:300 Training Accuracy:62.0%\r",
      "Progress:80.8% Speed(reviews/sec):2353. #Correct:187 #Trained:301 Training Accuracy:62.1%\r",
      "Progress:81.1% Speed(reviews/sec):2353. #Correct:187 #Trained:302 Training Accuracy:61.9%\r",
      "Progress:81.4% Speed(reviews/sec):2353. #Correct:187 #Trained:303 Training Accuracy:61.7%\r",
      "Progress:81.6% Speed(reviews/sec):2353. #Correct:188 #Trained:304 Training Accuracy:61.8%\r",
      "Progress:81.9% Speed(reviews/sec):2354. #Correct:188 #Trained:305 Training Accuracy:61.6%\r",
      "Progress:82.2% Speed(reviews/sec):2355. #Correct:189 #Trained:306 Training Accuracy:61.7%\r",
      "Progress:82.4% Speed(reviews/sec):2355. #Correct:189 #Trained:307 Training Accuracy:61.5%\r",
      "Progress:82.7% Speed(reviews/sec):2354. #Correct:190 #Trained:308 Training Accuracy:61.6%\r",
      "Progress:83.0% Speed(reviews/sec):2354. #Correct:191 #Trained:309 Training Accuracy:61.8%\r",
      "Progress:83.2% Speed(reviews/sec):2355. #Correct:192 #Trained:310 Training Accuracy:61.9%\r",
      "Progress:83.5% Speed(reviews/sec):2355. #Correct:193 #Trained:311 Training Accuracy:62.0%\r",
      "Progress:83.8% Speed(reviews/sec):2356. #Correct:194 #Trained:312 Training Accuracy:62.1%\r",
      "Progress:84.0% Speed(reviews/sec):2357. #Correct:195 #Trained:313 Training Accuracy:62.3%\r",
      "Progress:84.3% Speed(reviews/sec):2358. #Correct:196 #Trained:314 Training Accuracy:62.4%\r",
      "Progress:84.6% Speed(reviews/sec):2359. #Correct:197 #Trained:315 Training Accuracy:62.5%\r",
      "Progress:84.9% Speed(reviews/sec):2360. #Correct:198 #Trained:316 Training Accuracy:62.6%\r",
      "Progress:85.1% Speed(reviews/sec):2360. #Correct:199 #Trained:317 Training Accuracy:62.7%\r",
      "Progress:85.4% Speed(reviews/sec):2361. #Correct:200 #Trained:318 Training Accuracy:62.8%\r",
      "Progress:85.7% Speed(reviews/sec):2361. #Correct:201 #Trained:319 Training Accuracy:63.0%\r",
      "Progress:85.9% Speed(reviews/sec):2361. #Correct:202 #Trained:320 Training Accuracy:63.1%\r",
      "Progress:86.2% Speed(reviews/sec):2359. #Correct:203 #Trained:321 Training Accuracy:63.2%\r",
      "Progress:86.5% Speed(reviews/sec):2360. #Correct:204 #Trained:322 Training Accuracy:63.3%\r",
      "Progress:86.7% Speed(reviews/sec):2360. #Correct:205 #Trained:323 Training Accuracy:63.4%\r",
      "Progress:87.0% Speed(reviews/sec):2360. #Correct:206 #Trained:324 Training Accuracy:63.5%\r",
      "Progress:87.3% Speed(reviews/sec):2361. #Correct:207 #Trained:325 Training Accuracy:63.6%\r",
      "Progress:87.6% Speed(reviews/sec):2363. #Correct:207 #Trained:326 Training Accuracy:63.4%\r",
      "Progress:87.8% Speed(reviews/sec):2364. #Correct:208 #Trained:327 Training Accuracy:63.6%\r",
      "Progress:88.1% Speed(reviews/sec):2365. #Correct:208 #Trained:328 Training Accuracy:63.4%\r",
      "Progress:88.4% Speed(reviews/sec):2366. #Correct:209 #Trained:329 Training Accuracy:63.5%\r",
      "Progress:88.6% Speed(reviews/sec):2367. #Correct:210 #Trained:330 Training Accuracy:63.6%\r",
      "Progress:88.9% Speed(reviews/sec):2367. #Correct:211 #Trained:331 Training Accuracy:63.7%\r",
      "Progress:89.2% Speed(reviews/sec):2368. #Correct:212 #Trained:332 Training Accuracy:63.8%\r",
      "Progress:89.4% Speed(reviews/sec):2369. #Correct:213 #Trained:333 Training Accuracy:63.9%\r",
      "Progress:89.7% Speed(reviews/sec):2370. #Correct:214 #Trained:334 Training Accuracy:64.0%\r",
      "Progress:90.0% Speed(reviews/sec):2372. #Correct:215 #Trained:335 Training Accuracy:64.1%\r",
      "Progress:90.2% Speed(reviews/sec):2373. #Correct:215 #Trained:336 Training Accuracy:63.9%\r",
      "Progress:90.5% Speed(reviews/sec):2374. #Correct:215 #Trained:337 Training Accuracy:63.7%\r",
      "Progress:90.8% Speed(reviews/sec):2375. #Correct:215 #Trained:338 Training Accuracy:63.6%\r",
      "Progress:91.1% Speed(reviews/sec):2376. #Correct:216 #Trained:339 Training Accuracy:63.7%\r",
      "Progress:91.3% Speed(reviews/sec):2378. #Correct:217 #Trained:340 Training Accuracy:63.8%\r",
      "Progress:91.6% Speed(reviews/sec):2378. #Correct:217 #Trained:341 Training Accuracy:63.6%\r",
      "Progress:91.9% Speed(reviews/sec):2379. #Correct:218 #Trained:342 Training Accuracy:63.7%\r",
      "Progress:92.1% Speed(reviews/sec):2379. #Correct:219 #Trained:343 Training Accuracy:63.8%\r",
      "Progress:92.4% Speed(reviews/sec):2380. #Correct:220 #Trained:344 Training Accuracy:63.9%\r",
      "Progress:92.7% Speed(reviews/sec):2381. #Correct:220 #Trained:345 Training Accuracy:63.7%\r",
      "Progress:92.9% Speed(reviews/sec):2383. #Correct:220 #Trained:346 Training Accuracy:63.5%\r",
      "Progress:93.2% Speed(reviews/sec):2384. #Correct:221 #Trained:347 Training Accuracy:63.6%\r",
      "Progress:93.5% Speed(reviews/sec):2385. #Correct:221 #Trained:348 Training Accuracy:63.5%\r",
      "Progress:93.8% Speed(reviews/sec):2387. #Correct:222 #Trained:349 Training Accuracy:63.6%\r",
      "Progress:94.0% Speed(reviews/sec):2388. #Correct:223 #Trained:350 Training Accuracy:63.7%\r",
      "Progress:94.3% Speed(reviews/sec):2389. #Correct:223 #Trained:351 Training Accuracy:63.5%\r",
      "Progress:94.6% Speed(reviews/sec):2391. #Correct:224 #Trained:352 Training Accuracy:63.6%\r",
      "Progress:94.8% Speed(reviews/sec):2392. #Correct:225 #Trained:353 Training Accuracy:63.7%\r",
      "Progress:95.1% Speed(reviews/sec):2393. #Correct:226 #Trained:354 Training Accuracy:63.8%\r",
      "Progress:95.4% Speed(reviews/sec):2395. #Correct:226 #Trained:355 Training Accuracy:63.6%\r",
      "Progress:95.6% Speed(reviews/sec):2396. #Correct:227 #Trained:356 Training Accuracy:63.7%\r",
      "Progress:95.9% Speed(reviews/sec):2398. #Correct:228 #Trained:357 Training Accuracy:63.8%\r",
      "Progress:96.2% Speed(reviews/sec):2394. #Correct:229 #Trained:358 Training Accuracy:63.9%\r",
      "Progress:96.4% Speed(reviews/sec):2390. #Correct:230 #Trained:359 Training Accuracy:64.0%\r",
      "Progress:96.7% Speed(reviews/sec):2387. #Correct:231 #Trained:360 Training Accuracy:64.1%\r",
      "Progress:97.0% Speed(reviews/sec):2386. #Correct:231 #Trained:361 Training Accuracy:63.9%\r",
      "Progress:97.3% Speed(reviews/sec):2386. #Correct:232 #Trained:362 Training Accuracy:64.0%\r",
      "Progress:97.5% Speed(reviews/sec):2385. #Correct:233 #Trained:363 Training Accuracy:64.1%\r",
      "Progress:97.8% Speed(reviews/sec):2383. #Correct:234 #Trained:364 Training Accuracy:64.2%\r",
      "Progress:98.1% Speed(reviews/sec):2382. #Correct:235 #Trained:365 Training Accuracy:64.3%\r",
      "Progress:98.3% Speed(reviews/sec):2382. #Correct:236 #Trained:366 Training Accuracy:64.4%\r",
      "Progress:98.6% Speed(reviews/sec):2382. #Correct:237 #Trained:367 Training Accuracy:64.5%\r",
      "Progress:98.9% Speed(reviews/sec):2381. #Correct:238 #Trained:368 Training Accuracy:64.6%\r",
      "Progress:99.1% Speed(reviews/sec):2381. #Correct:239 #Trained:369 Training Accuracy:64.7%\r",
      "Progress:99.4% Speed(reviews/sec):2381. #Correct:240 #Trained:370 Training Accuracy:64.8%\r",
      "Progress:99.7% Speed(reviews/sec):2381. #Correct:241 #Trained:371 Training Accuracy:64.9%"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-150],labels[:-150], learning_rate=0.01)\n",
    "mlp.train(reviews[:-150],labels[:-150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Tested:1 Testing Accuracy:100.%\r",
      "Progress:0.66% Speed(reviews/sec):1218. #Correct:2 #Tested:2 Testing Accuracy:100.%\r",
      "Progress:1.33% Speed(reviews/sec):1380. #Correct:2 #Tested:3 Testing Accuracy:66.6%\r",
      "Progress:2.0% Speed(reviews/sec):1687. #Correct:3 #Tested:4 Testing Accuracy:75.0%\r",
      "Progress:2.66% Speed(reviews/sec):1905. #Correct:3 #Tested:5 Testing Accuracy:60.0%\r",
      "Progress:3.33% Speed(reviews/sec):2132. #Correct:4 #Tested:6 Testing Accuracy:66.6%\r",
      "Progress:4.0% Speed(reviews/sec):2356. #Correct:5 #Tested:7 Testing Accuracy:71.4%\r",
      "Progress:4.66% Speed(reviews/sec):2427. #Correct:5 #Tested:8 Testing Accuracy:62.5%\r",
      "Progress:5.33% Speed(reviews/sec):2491. #Correct:6 #Tested:9 Testing Accuracy:66.6%\r",
      "Progress:6.0% Speed(reviews/sec):2593. #Correct:7 #Tested:10 Testing Accuracy:70.0%\r",
      "Progress:6.66% Speed(reviews/sec):2691. #Correct:7 #Tested:11 Testing Accuracy:63.6%\r",
      "Progress:7.33% Speed(reviews/sec):2772. #Correct:7 #Tested:12 Testing Accuracy:58.3%\r",
      "Progress:8.0% Speed(reviews/sec):2854. #Correct:8 #Tested:13 Testing Accuracy:61.5%\r",
      "Progress:8.66% Speed(reviews/sec):2922. #Correct:8 #Tested:14 Testing Accuracy:57.1%\r",
      "Progress:9.33% Speed(reviews/sec):2990. #Correct:9 #Tested:15 Testing Accuracy:60.0%\r",
      "Progress:10.0% Speed(reviews/sec):3058. #Correct:10 #Tested:16 Testing Accuracy:62.5%\r",
      "Progress:10.6% Speed(reviews/sec):3091. #Correct:11 #Tested:17 Testing Accuracy:64.7%\r",
      "Progress:11.3% Speed(reviews/sec):3094. #Correct:11 #Tested:18 Testing Accuracy:61.1%\r",
      "Progress:12.0% Speed(reviews/sec):3136. #Correct:12 #Tested:19 Testing Accuracy:63.1%\r",
      "Progress:12.6% Speed(reviews/sec):3150. #Correct:13 #Tested:20 Testing Accuracy:65.0%\r",
      "Progress:13.3% Speed(reviews/sec):3182. #Correct:14 #Tested:21 Testing Accuracy:66.6%\r",
      "Progress:14.0% Speed(reviews/sec):3213. #Correct:15 #Tested:22 Testing Accuracy:68.1%\r",
      "Progress:14.6% Speed(reviews/sec):3228. #Correct:16 #Tested:23 Testing Accuracy:69.5%\r",
      "Progress:15.3% Speed(reviews/sec):3314. #Correct:17 #Tested:24 Testing Accuracy:70.8%\r",
      "Progress:16.0% Speed(reviews/sec):3343. #Correct:18 #Tested:25 Testing Accuracy:72.0%\r",
      "Progress:16.6% Speed(reviews/sec):3384. #Correct:19 #Tested:26 Testing Accuracy:73.0%\r",
      "Progress:17.3% Speed(reviews/sec):3430. #Correct:20 #Tested:27 Testing Accuracy:74.0%\r",
      "Progress:18.0% Speed(reviews/sec):3474. #Correct:20 #Tested:28 Testing Accuracy:71.4%\r",
      "Progress:18.6% Speed(reviews/sec):3519. #Correct:21 #Tested:29 Testing Accuracy:72.4%\r",
      "Progress:19.3% Speed(reviews/sec):3595. #Correct:22 #Tested:30 Testing Accuracy:73.3%\r",
      "Progress:20.0% Speed(reviews/sec):3617. #Correct:22 #Tested:31 Testing Accuracy:70.9%\r",
      "Progress:20.6% Speed(reviews/sec):3662. #Correct:23 #Tested:32 Testing Accuracy:71.8%\r",
      "Progress:21.3% Speed(reviews/sec):3726. #Correct:24 #Tested:33 Testing Accuracy:72.7%\r",
      "Progress:22.0% Speed(reviews/sec):3774. #Correct:25 #Tested:34 Testing Accuracy:73.5%\r",
      "Progress:22.6% Speed(reviews/sec):3846. #Correct:26 #Tested:35 Testing Accuracy:74.2%\r",
      "Progress:23.3% Speed(reviews/sec):3885. #Correct:27 #Tested:36 Testing Accuracy:75.0%\r",
      "Progress:24.0% Speed(reviews/sec):3895. #Correct:28 #Tested:37 Testing Accuracy:75.6%\r",
      "Progress:24.6% Speed(reviews/sec):3928. #Correct:29 #Tested:38 Testing Accuracy:76.3%\r",
      "Progress:25.3% Speed(reviews/sec):3984. #Correct:29 #Tested:39 Testing Accuracy:74.3%\r",
      "Progress:26.0% Speed(reviews/sec):4028. #Correct:30 #Tested:40 Testing Accuracy:75.0%\r",
      "Progress:26.6% Speed(reviews/sec):4080. #Correct:31 #Tested:41 Testing Accuracy:75.6%\r",
      "Progress:27.3% Speed(reviews/sec):4134. #Correct:32 #Tested:42 Testing Accuracy:76.1%\r",
      "Progress:28.0% Speed(reviews/sec):4184. #Correct:33 #Tested:43 Testing Accuracy:76.7%\r",
      "Progress:28.6% Speed(reviews/sec):4236. #Correct:34 #Tested:44 Testing Accuracy:77.2%\r",
      "Progress:29.3% Speed(reviews/sec):4288. #Correct:34 #Tested:45 Testing Accuracy:75.5%\r",
      "Progress:30.0% Speed(reviews/sec):4340. #Correct:35 #Tested:46 Testing Accuracy:76.0%\r",
      "Progress:30.6% Speed(reviews/sec):4391. #Correct:36 #Tested:47 Testing Accuracy:76.5%\r",
      "Progress:31.3% Speed(reviews/sec):4440. #Correct:37 #Tested:48 Testing Accuracy:77.0%\r",
      "Progress:32.0% Speed(reviews/sec):4488. #Correct:37 #Tested:49 Testing Accuracy:75.5%\r",
      "Progress:32.6% Speed(reviews/sec):4520. #Correct:38 #Tested:50 Testing Accuracy:76.0%\r",
      "Progress:33.3% Speed(reviews/sec):4517. #Correct:39 #Tested:51 Testing Accuracy:76.4%\r",
      "Progress:34.0% Speed(reviews/sec):4532. #Correct:40 #Tested:52 Testing Accuracy:76.9%\r",
      "Progress:34.6% Speed(reviews/sec):4564. #Correct:41 #Tested:53 Testing Accuracy:77.3%\r",
      "Progress:35.3% Speed(reviews/sec):4603. #Correct:42 #Tested:54 Testing Accuracy:77.7%\r",
      "Progress:36.0% Speed(reviews/sec):4644. #Correct:43 #Tested:55 Testing Accuracy:78.1%\r",
      "Progress:36.6% Speed(reviews/sec):4688. #Correct:44 #Tested:56 Testing Accuracy:78.5%\r",
      "Progress:37.3% Speed(reviews/sec):4734. #Correct:45 #Tested:57 Testing Accuracy:78.9%\r",
      "Progress:38.0% Speed(reviews/sec):4774. #Correct:45 #Tested:58 Testing Accuracy:77.5%\r",
      "Progress:38.6% Speed(reviews/sec):4820. #Correct:46 #Tested:59 Testing Accuracy:77.9%\r",
      "Progress:39.3% Speed(reviews/sec):4865. #Correct:47 #Tested:60 Testing Accuracy:78.3%\r",
      "Progress:40.0% Speed(reviews/sec):4911. #Correct:48 #Tested:61 Testing Accuracy:78.6%\r",
      "Progress:40.6% Speed(reviews/sec):4956. #Correct:48 #Tested:62 Testing Accuracy:77.4%\r",
      "Progress:41.3% Speed(reviews/sec):4997. #Correct:49 #Tested:63 Testing Accuracy:77.7%\r",
      "Progress:42.0% Speed(reviews/sec):5039. #Correct:49 #Tested:64 Testing Accuracy:76.5%\r",
      "Progress:42.6% Speed(reviews/sec):5082. #Correct:49 #Tested:65 Testing Accuracy:75.3%\r",
      "Progress:43.3% Speed(reviews/sec):5125. #Correct:50 #Tested:66 Testing Accuracy:75.7%\r",
      "Progress:44.0% Speed(reviews/sec):5168. #Correct:50 #Tested:67 Testing Accuracy:74.6%\r",
      "Progress:44.6% Speed(reviews/sec):5209. #Correct:51 #Tested:68 Testing Accuracy:75.0%\r",
      "Progress:45.3% Speed(reviews/sec):5250. #Correct:52 #Tested:69 Testing Accuracy:75.3%\r",
      "Progress:46.0% Speed(reviews/sec):5292. #Correct:53 #Tested:70 Testing Accuracy:75.7%\r",
      "Progress:46.6% Speed(reviews/sec):5332. #Correct:54 #Tested:71 Testing Accuracy:76.0%\r",
      "Progress:47.3% Speed(reviews/sec):5373. #Correct:55 #Tested:72 Testing Accuracy:76.3%\r",
      "Progress:48.0% Speed(reviews/sec):5413. #Correct:55 #Tested:73 Testing Accuracy:75.3%\r",
      "Progress:48.6% Speed(reviews/sec):5451. #Correct:56 #Tested:74 Testing Accuracy:75.6%\r",
      "Progress:49.3% Speed(reviews/sec):5489. #Correct:57 #Tested:75 Testing Accuracy:76.0%\r",
      "Progress:50.0% Speed(reviews/sec):5527. #Correct:58 #Tested:76 Testing Accuracy:76.3%\r",
      "Progress:50.6% Speed(reviews/sec):5565. #Correct:59 #Tested:77 Testing Accuracy:76.6%\r",
      "Progress:51.3% Speed(reviews/sec):5602. #Correct:60 #Tested:78 Testing Accuracy:76.9%\r",
      "Progress:52.0% Speed(reviews/sec):5640. #Correct:61 #Tested:79 Testing Accuracy:77.2%\r",
      "Progress:52.6% Speed(reviews/sec):5680. #Correct:61 #Tested:80 Testing Accuracy:76.2%\r",
      "Progress:53.3% Speed(reviews/sec):5719. #Correct:61 #Tested:81 Testing Accuracy:75.3%\r",
      "Progress:54.0% Speed(reviews/sec):5758. #Correct:61 #Tested:82 Testing Accuracy:74.3%\r",
      "Progress:54.6% Speed(reviews/sec):5742. #Correct:62 #Tested:83 Testing Accuracy:74.6%\r",
      "Progress:55.3% Speed(reviews/sec):5739. #Correct:62 #Tested:84 Testing Accuracy:73.8%\r",
      "Progress:56.0% Speed(reviews/sec):5735. #Correct:63 #Tested:85 Testing Accuracy:74.1%\r",
      "Progress:56.6% Speed(reviews/sec):5730. #Correct:63 #Tested:86 Testing Accuracy:73.2%\r",
      "Progress:57.3% Speed(reviews/sec):5728. #Correct:63 #Tested:87 Testing Accuracy:72.4%\r",
      "Progress:58.0% Speed(reviews/sec):5720. #Correct:64 #Tested:88 Testing Accuracy:72.7%\r",
      "Progress:58.6% Speed(reviews/sec):5718. #Correct:65 #Tested:89 Testing Accuracy:73.0%\r",
      "Progress:59.3% Speed(reviews/sec):5715. #Correct:66 #Tested:90 Testing Accuracy:73.3%\r",
      "Progress:60.0% Speed(reviews/sec):5710. #Correct:67 #Tested:91 Testing Accuracy:73.6%\r",
      "Progress:60.6% Speed(reviews/sec):5711. #Correct:68 #Tested:92 Testing Accuracy:73.9%\r",
      "Progress:61.3% Speed(reviews/sec):5710. #Correct:68 #Tested:93 Testing Accuracy:73.1%\r",
      "Progress:62.0% Speed(reviews/sec):5707. #Correct:69 #Tested:94 Testing Accuracy:73.4%\r",
      "Progress:62.6% Speed(reviews/sec):5704. #Correct:70 #Tested:95 Testing Accuracy:73.6%\r",
      "Progress:63.3% Speed(reviews/sec):5698. #Correct:71 #Tested:96 Testing Accuracy:73.9%\r",
      "Progress:64.0% Speed(reviews/sec):5695. #Correct:71 #Tested:97 Testing Accuracy:73.1%\r",
      "Progress:64.6% Speed(reviews/sec):5689. #Correct:72 #Tested:98 Testing Accuracy:73.4%\r",
      "Progress:65.3% Speed(reviews/sec):5691. #Correct:73 #Tested:99 Testing Accuracy:73.7%\r",
      "Progress:66.0% Speed(reviews/sec):5674. #Correct:73 #Tested:100 Testing Accuracy:73.0%\r",
      "Progress:66.6% Speed(reviews/sec):5670. #Correct:74 #Tested:101 Testing Accuracy:73.2%\r",
      "Progress:67.3% Speed(reviews/sec):5670. #Correct:75 #Tested:102 Testing Accuracy:73.5%\r",
      "Progress:68.0% Speed(reviews/sec):5636. #Correct:76 #Tested:103 Testing Accuracy:73.7%\r",
      "Progress:68.6% Speed(reviews/sec):5630. #Correct:77 #Tested:104 Testing Accuracy:74.0%\r",
      "Progress:69.3% Speed(reviews/sec):5619. #Correct:78 #Tested:105 Testing Accuracy:74.2%\r",
      "Progress:70.0% Speed(reviews/sec):5631. #Correct:79 #Tested:106 Testing Accuracy:74.5%\r",
      "Progress:70.6% Speed(reviews/sec):5638. #Correct:79 #Tested:107 Testing Accuracy:73.8%\r",
      "Progress:71.3% Speed(reviews/sec):5611. #Correct:80 #Tested:108 Testing Accuracy:74.0%\r",
      "Progress:72.0% Speed(reviews/sec):5581. #Correct:81 #Tested:109 Testing Accuracy:74.3%\r",
      "Progress:72.6% Speed(reviews/sec):5569. #Correct:82 #Tested:110 Testing Accuracy:74.5%\r",
      "Progress:73.3% Speed(reviews/sec):5565. #Correct:83 #Tested:111 Testing Accuracy:74.7%\r",
      "Progress:74.0% Speed(reviews/sec):5565. #Correct:83 #Tested:112 Testing Accuracy:74.1%\r",
      "Progress:74.6% Speed(reviews/sec):5563. #Correct:83 #Tested:113 Testing Accuracy:73.4%\r",
      "Progress:75.3% Speed(reviews/sec):5564. #Correct:84 #Tested:114 Testing Accuracy:73.6%\r",
      "Progress:76.0% Speed(reviews/sec):5564. #Correct:85 #Tested:115 Testing Accuracy:73.9%\r",
      "Progress:76.6% Speed(reviews/sec):5567. #Correct:86 #Tested:116 Testing Accuracy:74.1%\r",
      "Progress:77.3% Speed(reviews/sec):5569. #Correct:87 #Tested:117 Testing Accuracy:74.3%\r",
      "Progress:78.0% Speed(reviews/sec):5571. #Correct:88 #Tested:118 Testing Accuracy:74.5%\r",
      "Progress:78.6% Speed(reviews/sec):5573. #Correct:89 #Tested:119 Testing Accuracy:74.7%\r",
      "Progress:79.3% Speed(reviews/sec):5575. #Correct:89 #Tested:120 Testing Accuracy:74.1%\r",
      "Progress:80.0% Speed(reviews/sec):5575. #Correct:90 #Tested:121 Testing Accuracy:74.3%\r",
      "Progress:80.6% Speed(reviews/sec):5578. #Correct:91 #Tested:122 Testing Accuracy:74.5%\r",
      "Progress:81.3% Speed(reviews/sec):5580. #Correct:92 #Tested:123 Testing Accuracy:74.7%\r",
      "Progress:82.0% Speed(reviews/sec):5583. #Correct:93 #Tested:124 Testing Accuracy:75.0%\r",
      "Progress:82.6% Speed(reviews/sec):5584. #Correct:94 #Tested:125 Testing Accuracy:75.2%\r",
      "Progress:83.3% Speed(reviews/sec):5586. #Correct:94 #Tested:126 Testing Accuracy:74.6%\r",
      "Progress:84.0% Speed(reviews/sec):5588. #Correct:95 #Tested:127 Testing Accuracy:74.8%\r",
      "Progress:84.6% Speed(reviews/sec):5589. #Correct:96 #Tested:128 Testing Accuracy:75.0%\r",
      "Progress:85.3% Speed(reviews/sec):5591. #Correct:97 #Tested:129 Testing Accuracy:75.1%\r",
      "Progress:86.0% Speed(reviews/sec):5593. #Correct:97 #Tested:130 Testing Accuracy:74.6%\r",
      "Progress:86.6% Speed(reviews/sec):5596. #Correct:98 #Tested:131 Testing Accuracy:74.8%\r",
      "Progress:87.3% Speed(reviews/sec):5601. #Correct:99 #Tested:132 Testing Accuracy:75.0%\r",
      "Progress:88.0% Speed(reviews/sec):5602. #Correct:100 #Tested:133 Testing Accuracy:75.1%\r",
      "Progress:88.6% Speed(reviews/sec):5605. #Correct:100 #Tested:134 Testing Accuracy:74.6%\r",
      "Progress:89.3% Speed(reviews/sec):5610. #Correct:101 #Tested:135 Testing Accuracy:74.8%\r",
      "Progress:90.0% Speed(reviews/sec):5614. #Correct:102 #Tested:136 Testing Accuracy:75.0%\r",
      "Progress:90.6% Speed(reviews/sec):5620. #Correct:102 #Tested:137 Testing Accuracy:74.4%\r",
      "Progress:91.3% Speed(reviews/sec):5623. #Correct:102 #Tested:138 Testing Accuracy:73.9%\r",
      "Progress:92.0% Speed(reviews/sec):5629. #Correct:102 #Tested:139 Testing Accuracy:73.3%\r",
      "Progress:92.6% Speed(reviews/sec):5633. #Correct:103 #Tested:140 Testing Accuracy:73.5%\r",
      "Progress:93.3% Speed(reviews/sec):5639. #Correct:104 #Tested:141 Testing Accuracy:73.7%\r",
      "Progress:94.0% Speed(reviews/sec):5631. #Correct:105 #Tested:142 Testing Accuracy:73.9%\r",
      "Progress:94.6% Speed(reviews/sec):5627. #Correct:105 #Tested:143 Testing Accuracy:73.4%\r",
      "Progress:95.3% Speed(reviews/sec):5629. #Correct:106 #Tested:144 Testing Accuracy:73.6%\r",
      "Progress:96.0% Speed(reviews/sec):5633. #Correct:107 #Tested:145 Testing Accuracy:73.7%\r",
      "Progress:96.6% Speed(reviews/sec):5638. #Correct:108 #Tested:146 Testing Accuracy:73.9%\r",
      "Progress:97.3% Speed(reviews/sec):5644. #Correct:108 #Tested:147 Testing Accuracy:73.4%\r",
      "Progress:98.0% Speed(reviews/sec):5652. #Correct:109 #Tested:148 Testing Accuracy:73.6%\r",
      "Progress:98.6% Speed(reviews/sec):5658. #Correct:110 #Tested:149 Testing Accuracy:73.8%\r",
      "Progress:99.3% Speed(reviews/sec):5662. #Correct:111 #Tested:150 Testing Accuracy:74.0%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-150:],labels[-150:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Project 4 solution. \n",
    "## Watch the next video to continue with Andrew's next lesson.\n",
    "# Analyzing Inefficiencies in our Network<a id='lesson_5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sentiment_network_sparse.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-ad99e3c27299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentiment_network_sparse.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sentiment_network_sparse.png'"
     ]
    }
   ],
   "source": [
    "Image(filename='sentiment_network_sparse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_0 = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_0[4] = 1\n",
    "layer_0[9] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_0_1 = np.random.randn(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10503756,  0.44222989,  0.24392938, -0.55961832,  0.21389503])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0.dot(weights_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = [4,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_1 = np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in indices:\n",
    "    layer_1 += (1 * weights_0_1[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10503756,  0.44222989,  0.24392938, -0.55961832,  0.21389503])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAEpCAYAAAB1IONWAAAABGdBTUEAALGPC/xhBQAAACBjSFJN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\nRK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='sentiment_network_sparse_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_1 = np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in indices:\n",
    "    layer_1 += (weights_0_1[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10503756,  0.44222989,  0.24392938, -0.55961832,  0.21389503])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: Making our Network More Efficient<a id='project_5'></a>\n",
    "**TODO:** Make the `SentimentNetwork` class more efficient by eliminating unnecessary multiplications and additions that occur during forward and backward propagation. To do that, you can do the following:\n",
    "* Copy the `SentimentNetwork` class from the previous project into the following cell.\n",
    "* Remove the `update_input_layer` function - you will not need it in this version.\n",
    "* Modify `init_network`:\n",
    ">* You no longer need a separate input layer, so remove any mention of `self.layer_0`\n",
    ">* You will be dealing with the old hidden layer more directly, so create `self.layer_1`, a two-dimensional matrix with shape 1 x hidden_nodes, with all values initialized to zero\n",
    "* Modify `train`:\n",
    ">* Change the name of the input parameter `training_reviews` to `training_reviews_raw`. This will help with the next step.\n",
    ">* At the beginning of the function, you'll want to preprocess your reviews to convert them to a list of indices (from `word2index`) that are actually used in the review. This is equivalent to what you saw in the video when Andrew set specific indices to 1. Your code should create a local `list` variable named `training_reviews` that should contain a `list` for each review in `training_reviews_raw`. Those lists should contain the indices for words found in the review.\n",
    ">* Remove call to `update_input_layer`\n",
    ">* Use `self`'s  `layer_1` instead of a local `layer_1` object.\n",
    ">* In the forward pass, replace the code that updates `layer_1` with new logic that only adds the weights for the indices used in the review.\n",
    ">* When updating `weights_0_1`, only update the individual weights that were used in the forward pass.\n",
    "* Modify `run`:\n",
    ">* Remove call to `update_input_layer` \n",
    ">* Use `self`'s  `layer_1` instead of a local `layer_1` object.\n",
    ">* Much like you did in `train`, you will need to pre-process the `review` so you can work with word indices, then update `layer_1` by adding weights for the indices used in the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is the same as the previous project, with project-specific changes marked with `\"New for Project 5\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Encapsulate our neural network in a class\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "        \"\"\"Create a SentimenNetwork with the given settings\n",
    "        Args:\n",
    "            reviews(list) - List of reviews used for training\n",
    "            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n",
    "            hidden_nodes(int) - Number of nodes to create in the hidden layer\n",
    "            learning_rate(float) - Learning rate to use while training\n",
    "        \n",
    "        \"\"\"\n",
    "        # Assign a seed to our random number generator to ensure we get\n",
    "        # reproducable results during development \n",
    "        np.random.seed(1)\n",
    "\n",
    "        # process the reviews and their associated labels so that everything\n",
    "        # is ready for training\n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        # Build the network to have the number of hidden nodes and the learning rate that\n",
    "        # were passed into this initializer. Make the same number of input nodes as\n",
    "        # there are vocabulary words and create a single output node.\n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        # populate review_vocab with all of the words in the given reviews\n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "\n",
    "        # Convert the vocabulary set to a list so we can access words via indices\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        # populate label_vocab with all of the words in the given labels.\n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of the review and label vocabularies.\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        # Create a dictionary of labels mapped to index positions\n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "\n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Store the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "\n",
    "        # These are the weights between the input layer and the hidden layer.\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "\n",
    "        # These are the weights between the hidden layer and the output layer.\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        ## New for Project 5: Removed self.layer_0; added self.layer_1\n",
    "        # The input layer, a two-dimensional matrix with shape 1 x hidden_nodes\n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "    \n",
    "    ## New for Project 5: Removed update_input_layer function\n",
    "    \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'ADMINISTER/MONITOR'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    ## New for Project 5: changed name of first parameter form 'training_reviews' \n",
    "    #                     to 'training_reviews_raw'\n",
    "    def train(self, training_reviews_raw, training_labels):\n",
    "\n",
    "        ## New for Project 5: pre-process training reviews so we can deal \n",
    "        #                     directly with the indices of non-zero inputs\n",
    "        training_reviews = list()\n",
    "        for review in training_reviews_raw:\n",
    "            indices = set()\n",
    "            for word in review.split(\" \"):\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_reviews.append(list(indices))\n",
    "\n",
    "        # make sure out we have a matching number of reviews and labels\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        # Keep track of correct predictions to display accuracy during training \n",
    "        correct_so_far = 0\n",
    "\n",
    "        # Remember when we started for printing time statistics\n",
    "        start = time.time()\n",
    "        \n",
    "        # loop through all the given reviews and run a forward and backward pass,\n",
    "        # updating weights for every item\n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            # Get the next review and its correct label\n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            ## New for Project 5: Removed call to 'update_input_layer' function\n",
    "            #                     because 'layer_0' is no longer used\n",
    "\n",
    "            # Hidden layer\n",
    "            ## New for Project 5: Add in only the weights for non-zero items\n",
    "            self.layer_1 *= 0\n",
    "            for index in review:\n",
    "                self.layer_1 += self.weights_0_1[index]\n",
    "\n",
    "            # Output layer\n",
    "            ## New for Project 5: changed to use 'self.layer_1' instead of 'local layer_1'\n",
    "            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))            \n",
    "            \n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # Update the weights\n",
    "            ## New for Project 5: changed to use 'self.layer_1' instead of local 'layer_1'\n",
    "            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            \n",
    "            ## New for Project 5: Only update the weights that were used in the forward pass\n",
    "            for index in review:\n",
    "                self.weights_0_1[index] -= layer_1_delta[0] * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            # Keep track of correct predictions.\n",
    "            if(layer_2 >= 0.5 and label == 'ADMINISTER/MONITOR'):\n",
    "                correct_so_far += 1\n",
    "            elif(layer_2 < 0.5 and label == 'NOTADMINISTER/MONITOR'):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the training process. \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \"\"\"\n",
    "        Attempts to predict the labels for the given testing_reviews,\n",
    "        and uses the test_labels to calculate the accuracy of those predictions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # keep track of how many correct predictions we make\n",
    "        correct = 0\n",
    "\n",
    "        # we'll time how many predictions per second we make\n",
    "        start = time.time()\n",
    "\n",
    "        # Loop through each of the given reviews and call run to predict\n",
    "        # its label. \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the prediction process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \"\"\"\n",
    "        Returns a POSITIVE or NEGATIVE prediction for the given review.\n",
    "        \"\"\"\n",
    "        # Run a forward pass through the network, like in the \"train\" function.\n",
    "        \n",
    "        ## New for Project 5: Removed call to update_input_layer function\n",
    "        #                     because layer_0 is no longer used\n",
    "\n",
    "        # Hidden layer\n",
    "        ## New for Project 5: Identify the indices used in the review and then add\n",
    "        #                     just those weights to layer_1 \n",
    "        self.layer_1 *= 0\n",
    "        unique_indices = set()\n",
    "        for word in review.lower().split(\" \"):\n",
    "            if word in self.word2index.keys():\n",
    "                unique_indices.add(self.word2index[word])\n",
    "        for index in unique_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "        \n",
    "        # Output layer\n",
    "        ## New for Project 5: changed to use self.layer_1 instead of local layer_1\n",
    "        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        # Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;\n",
    "        # return NEGATIVE for other values\n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"ADMINISTER/MONITOR\"\n",
    "        else:\n",
    "            return \"NOTADMINISTER/MONITOR\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to recreate the network and train it once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "\r",
      "Progress:0.26% Speed(reviews/sec):988.0 #Correct:1 #Trained:2 Training Accuracy:50.0%\r",
      "Progress:0.52% Speed(reviews/sec):1373. #Correct:2 #Trained:3 Training Accuracy:66.6%\r",
      "Progress:0.78% Speed(reviews/sec):1604. #Correct:3 #Trained:4 Training Accuracy:75.0%\r",
      "Progress:1.04% Speed(reviews/sec):1697. #Correct:4 #Trained:5 Training Accuracy:80.0%\r",
      "Progress:1.31% Speed(reviews/sec):1847. #Correct:4 #Trained:6 Training Accuracy:66.6%\r",
      "Progress:1.57% Speed(reviews/sec):1979. #Correct:4 #Trained:7 Training Accuracy:57.1%\r",
      "Progress:1.83% Speed(reviews/sec):2036. #Correct:4 #Trained:8 Training Accuracy:50.0%\r",
      "Progress:2.09% Speed(reviews/sec):1990. #Correct:4 #Trained:9 Training Accuracy:44.4%\r",
      "Progress:2.36% Speed(reviews/sec):2065. #Correct:4 #Trained:10 Training Accuracy:40.0%\r",
      "Progress:2.62% Speed(reviews/sec):2168. #Correct:5 #Trained:11 Training Accuracy:45.4%\r",
      "Progress:2.88% Speed(reviews/sec):2267. #Correct:6 #Trained:12 Training Accuracy:50.0%\r",
      "Progress:3.14% Speed(reviews/sec):2340. #Correct:7 #Trained:13 Training Accuracy:53.8%\r",
      "Progress:3.41% Speed(reviews/sec):2394. #Correct:7 #Trained:14 Training Accuracy:50.0%\r",
      "Progress:3.67% Speed(reviews/sec):2447. #Correct:7 #Trained:15 Training Accuracy:46.6%\r",
      "Progress:3.93% Speed(reviews/sec):2497. #Correct:8 #Trained:16 Training Accuracy:50.0%\r",
      "Progress:4.19% Speed(reviews/sec):2562. #Correct:9 #Trained:17 Training Accuracy:52.9%\r",
      "Progress:4.46% Speed(reviews/sec):2616. #Correct:10 #Trained:18 Training Accuracy:55.5%\r",
      "Progress:4.72% Speed(reviews/sec):2582. #Correct:10 #Trained:19 Training Accuracy:52.6%\r",
      "Progress:4.98% Speed(reviews/sec):2631. #Correct:11 #Trained:20 Training Accuracy:55.0%\r",
      "Progress:5.24% Speed(reviews/sec):2677. #Correct:11 #Trained:21 Training Accuracy:52.3%\r",
      "Progress:5.51% Speed(reviews/sec):2679. #Correct:11 #Trained:22 Training Accuracy:50.0%\r",
      "Progress:5.77% Speed(reviews/sec):2711. #Correct:11 #Trained:23 Training Accuracy:47.8%\r",
      "Progress:6.03% Speed(reviews/sec):2740. #Correct:12 #Trained:24 Training Accuracy:50.0%\r",
      "Progress:6.29% Speed(reviews/sec):2772. #Correct:12 #Trained:25 Training Accuracy:48.0%\r",
      "Progress:6.56% Speed(reviews/sec):2814. #Correct:12 #Trained:26 Training Accuracy:46.1%\r",
      "Progress:6.82% Speed(reviews/sec):2840. #Correct:12 #Trained:27 Training Accuracy:44.4%\r",
      "Progress:7.08% Speed(reviews/sec):2871. #Correct:13 #Trained:28 Training Accuracy:46.4%\r",
      "Progress:7.34% Speed(reviews/sec):2899. #Correct:13 #Trained:29 Training Accuracy:44.8%\r",
      "Progress:7.61% Speed(reviews/sec):2933. #Correct:14 #Trained:30 Training Accuracy:46.6%\r",
      "Progress:7.87% Speed(reviews/sec):2973. #Correct:15 #Trained:31 Training Accuracy:48.3%\r",
      "Progress:8.13% Speed(reviews/sec):2990. #Correct:16 #Trained:32 Training Accuracy:50.0%\r",
      "Progress:8.39% Speed(reviews/sec):3014. #Correct:16 #Trained:33 Training Accuracy:48.4%\r",
      "Progress:8.66% Speed(reviews/sec):3042. #Correct:16 #Trained:34 Training Accuracy:47.0%\r",
      "Progress:8.92% Speed(reviews/sec):3066. #Correct:16 #Trained:35 Training Accuracy:45.7%\r",
      "Progress:9.18% Speed(reviews/sec):3097. #Correct:16 #Trained:36 Training Accuracy:44.4%\r",
      "Progress:9.44% Speed(reviews/sec):3115. #Correct:16 #Trained:37 Training Accuracy:43.2%\r",
      "Progress:9.71% Speed(reviews/sec):3132. #Correct:16 #Trained:38 Training Accuracy:42.1%\r",
      "Progress:9.97% Speed(reviews/sec):3156. #Correct:17 #Trained:39 Training Accuracy:43.5%\r",
      "Progress:10.2% Speed(reviews/sec):3186. #Correct:17 #Trained:40 Training Accuracy:42.5%\r",
      "Progress:10.4% Speed(reviews/sec):3211. #Correct:17 #Trained:41 Training Accuracy:41.4%\r",
      "Progress:10.7% Speed(reviews/sec):3234. #Correct:18 #Trained:42 Training Accuracy:42.8%\r",
      "Progress:11.0% Speed(reviews/sec):3247. #Correct:19 #Trained:43 Training Accuracy:44.1%\r",
      "Progress:11.2% Speed(reviews/sec):3267. #Correct:20 #Trained:44 Training Accuracy:45.4%\r",
      "Progress:11.5% Speed(reviews/sec):3277. #Correct:20 #Trained:45 Training Accuracy:44.4%\r",
      "Progress:11.8% Speed(reviews/sec):3263. #Correct:21 #Trained:46 Training Accuracy:45.6%\r",
      "Progress:12.0% Speed(reviews/sec):3283. #Correct:22 #Trained:47 Training Accuracy:46.8%\r",
      "Progress:12.3% Speed(reviews/sec):3307. #Correct:22 #Trained:48 Training Accuracy:45.8%\r",
      "Progress:12.5% Speed(reviews/sec):3325. #Correct:23 #Trained:49 Training Accuracy:46.9%\r",
      "Progress:12.8% Speed(reviews/sec):3350. #Correct:23 #Trained:50 Training Accuracy:46.0%\r",
      "Progress:13.1% Speed(reviews/sec):3370. #Correct:23 #Trained:51 Training Accuracy:45.0%\r",
      "Progress:13.3% Speed(reviews/sec):3367. #Correct:24 #Trained:52 Training Accuracy:46.1%\r",
      "Progress:13.6% Speed(reviews/sec):3379. #Correct:24 #Trained:53 Training Accuracy:45.2%\r",
      "Progress:13.9% Speed(reviews/sec):3388. #Correct:24 #Trained:54 Training Accuracy:44.4%\r",
      "Progress:14.1% Speed(reviews/sec):3403. #Correct:25 #Trained:55 Training Accuracy:45.4%\r",
      "Progress:14.4% Speed(reviews/sec):3425. #Correct:25 #Trained:56 Training Accuracy:44.6%\r",
      "Progress:14.6% Speed(reviews/sec):3445. #Correct:25 #Trained:57 Training Accuracy:43.8%\r",
      "Progress:14.9% Speed(reviews/sec):3462. #Correct:26 #Trained:58 Training Accuracy:44.8%\r",
      "Progress:15.2% Speed(reviews/sec):3479. #Correct:27 #Trained:59 Training Accuracy:45.7%\r",
      "Progress:15.4% Speed(reviews/sec):3493. #Correct:27 #Trained:60 Training Accuracy:45.0%\r",
      "Progress:15.7% Speed(reviews/sec):3513. #Correct:28 #Trained:61 Training Accuracy:45.9%\r",
      "Progress:16.0% Speed(reviews/sec):3531. #Correct:28 #Trained:62 Training Accuracy:45.1%\r",
      "Progress:16.2% Speed(reviews/sec):3550. #Correct:29 #Trained:63 Training Accuracy:46.0%\r",
      "Progress:16.5% Speed(reviews/sec):3573. #Correct:30 #Trained:64 Training Accuracy:46.8%\r",
      "Progress:16.7% Speed(reviews/sec):3597. #Correct:30 #Trained:65 Training Accuracy:46.1%\r",
      "Progress:17.0% Speed(reviews/sec):3609. #Correct:31 #Trained:66 Training Accuracy:46.9%\r",
      "Progress:17.3% Speed(reviews/sec):3600. #Correct:31 #Trained:67 Training Accuracy:46.2%\r",
      "Progress:17.5% Speed(reviews/sec):3615. #Correct:31 #Trained:68 Training Accuracy:45.5%\r",
      "Progress:17.8% Speed(reviews/sec):3626. #Correct:32 #Trained:69 Training Accuracy:46.3%\r",
      "Progress:18.1% Speed(reviews/sec):3635. #Correct:33 #Trained:70 Training Accuracy:47.1%\r",
      "Progress:18.3% Speed(reviews/sec):3655. #Correct:33 #Trained:71 Training Accuracy:46.4%\r",
      "Progress:18.6% Speed(reviews/sec):3671. #Correct:34 #Trained:72 Training Accuracy:47.2%\r",
      "Progress:18.8% Speed(reviews/sec):3679. #Correct:34 #Trained:73 Training Accuracy:46.5%\r",
      "Progress:19.1% Speed(reviews/sec):3691. #Correct:35 #Trained:74 Training Accuracy:47.2%\r",
      "Progress:19.4% Speed(reviews/sec):3707. #Correct:36 #Trained:75 Training Accuracy:48.0%\r",
      "Progress:19.6% Speed(reviews/sec):3724. #Correct:37 #Trained:76 Training Accuracy:48.6%\r",
      "Progress:19.9% Speed(reviews/sec):3735. #Correct:38 #Trained:77 Training Accuracy:49.3%\r",
      "Progress:20.2% Speed(reviews/sec):3746. #Correct:38 #Trained:78 Training Accuracy:48.7%\r",
      "Progress:20.4% Speed(reviews/sec):3754. #Correct:38 #Trained:79 Training Accuracy:48.1%\r",
      "Progress:20.7% Speed(reviews/sec):3771. #Correct:39 #Trained:80 Training Accuracy:48.7%\r",
      "Progress:20.9% Speed(reviews/sec):3788. #Correct:40 #Trained:81 Training Accuracy:49.3%\r",
      "Progress:21.2% Speed(reviews/sec):3802. #Correct:41 #Trained:82 Training Accuracy:50.0%\r",
      "Progress:21.5% Speed(reviews/sec):3814. #Correct:41 #Trained:83 Training Accuracy:49.3%\r",
      "Progress:21.7% Speed(reviews/sec):3832. #Correct:42 #Trained:84 Training Accuracy:50.0%\r",
      "Progress:22.0% Speed(reviews/sec):3849. #Correct:43 #Trained:85 Training Accuracy:50.5%\r",
      "Progress:22.3% Speed(reviews/sec):3861. #Correct:43 #Trained:86 Training Accuracy:50.0%\r",
      "Progress:22.5% Speed(reviews/sec):3873. #Correct:43 #Trained:87 Training Accuracy:49.4%\r",
      "Progress:22.8% Speed(reviews/sec):3882. #Correct:43 #Trained:88 Training Accuracy:48.8%\r",
      "Progress:23.0% Speed(reviews/sec):3895. #Correct:44 #Trained:89 Training Accuracy:49.4%\r",
      "Progress:23.3% Speed(reviews/sec):3910. #Correct:45 #Trained:90 Training Accuracy:50.0%\r",
      "Progress:23.6% Speed(reviews/sec):3925. #Correct:46 #Trained:91 Training Accuracy:50.5%\r",
      "Progress:23.8% Speed(reviews/sec):3940. #Correct:47 #Trained:92 Training Accuracy:51.0%\r",
      "Progress:24.1% Speed(reviews/sec):3948. #Correct:47 #Trained:93 Training Accuracy:50.5%\r",
      "Progress:24.4% Speed(reviews/sec):3958. #Correct:48 #Trained:94 Training Accuracy:51.0%\r",
      "Progress:24.6% Speed(reviews/sec):3970. #Correct:48 #Trained:95 Training Accuracy:50.5%\r",
      "Progress:24.9% Speed(reviews/sec):3986. #Correct:49 #Trained:96 Training Accuracy:51.0%\r",
      "Progress:25.1% Speed(reviews/sec):3998. #Correct:49 #Trained:97 Training Accuracy:50.5%\r",
      "Progress:25.4% Speed(reviews/sec):4006. #Correct:49 #Trained:98 Training Accuracy:50.0%\r",
      "Progress:25.7% Speed(reviews/sec):4017. #Correct:49 #Trained:99 Training Accuracy:49.4%\r",
      "Progress:25.9% Speed(reviews/sec):4026. #Correct:50 #Trained:100 Training Accuracy:50.0%\r",
      "Progress:26.2% Speed(reviews/sec):4044. #Correct:51 #Trained:101 Training Accuracy:50.4%\r",
      "Progress:26.5% Speed(reviews/sec):4057. #Correct:51 #Trained:102 Training Accuracy:50.0%\r",
      "Progress:26.7% Speed(reviews/sec):4065. #Correct:51 #Trained:103 Training Accuracy:49.5%\r",
      "Progress:27.0% Speed(reviews/sec):4078. #Correct:51 #Trained:104 Training Accuracy:49.0%\r",
      "Progress:27.2% Speed(reviews/sec):4092. #Correct:52 #Trained:105 Training Accuracy:49.5%\r",
      "Progress:27.5% Speed(reviews/sec):4110. #Correct:52 #Trained:106 Training Accuracy:49.0%\r",
      "Progress:27.8% Speed(reviews/sec):4122. #Correct:52 #Trained:107 Training Accuracy:48.5%\r",
      "Progress:28.0% Speed(reviews/sec):4129. #Correct:53 #Trained:108 Training Accuracy:49.0%\r",
      "Progress:28.3% Speed(reviews/sec):4143. #Correct:53 #Trained:109 Training Accuracy:48.6%\r",
      "Progress:28.6% Speed(reviews/sec):4153. #Correct:54 #Trained:110 Training Accuracy:49.0%\r",
      "Progress:28.8% Speed(reviews/sec):4170. #Correct:54 #Trained:111 Training Accuracy:48.6%\r",
      "Progress:29.1% Speed(reviews/sec):4180. #Correct:55 #Trained:112 Training Accuracy:49.1%\r",
      "Progress:29.3% Speed(reviews/sec):4191. #Correct:55 #Trained:113 Training Accuracy:48.6%\r",
      "Progress:29.6% Speed(reviews/sec):4203. #Correct:55 #Trained:114 Training Accuracy:48.2%\r",
      "Progress:29.9% Speed(reviews/sec):4216. #Correct:56 #Trained:115 Training Accuracy:48.6%\r",
      "Progress:30.1% Speed(reviews/sec):4228. #Correct:57 #Trained:116 Training Accuracy:49.1%\r",
      "Progress:30.4% Speed(reviews/sec):4241. #Correct:58 #Trained:117 Training Accuracy:49.5%\r",
      "Progress:30.7% Speed(reviews/sec):4252. #Correct:58 #Trained:118 Training Accuracy:49.1%\r",
      "Progress:30.9% Speed(reviews/sec):4268. #Correct:59 #Trained:119 Training Accuracy:49.5%\r",
      "Progress:31.2% Speed(reviews/sec):4284. #Correct:60 #Trained:120 Training Accuracy:50.0%\r",
      "Progress:31.4% Speed(reviews/sec):4301. #Correct:61 #Trained:121 Training Accuracy:50.4%\r",
      "Progress:31.7% Speed(reviews/sec):4317. #Correct:61 #Trained:122 Training Accuracy:50.0%\r",
      "Progress:32.0% Speed(reviews/sec):4332. #Correct:61 #Trained:123 Training Accuracy:49.5%\r",
      "Progress:32.2% Speed(reviews/sec):4336. #Correct:61 #Trained:124 Training Accuracy:49.1%\r",
      "Progress:32.5% Speed(reviews/sec):4338. #Correct:62 #Trained:125 Training Accuracy:49.6%\r",
      "Progress:32.8% Speed(reviews/sec):4352. #Correct:63 #Trained:126 Training Accuracy:50.0%\r",
      "Progress:33.0% Speed(reviews/sec):4361. #Correct:64 #Trained:127 Training Accuracy:50.3%\r",
      "Progress:33.3% Speed(reviews/sec):4371. #Correct:65 #Trained:128 Training Accuracy:50.7%\r",
      "Progress:33.5% Speed(reviews/sec):4379. #Correct:66 #Trained:129 Training Accuracy:51.1%\r",
      "Progress:33.8% Speed(reviews/sec):4388. #Correct:67 #Trained:130 Training Accuracy:51.5%\r",
      "Progress:34.1% Speed(reviews/sec):4404. #Correct:68 #Trained:131 Training Accuracy:51.9%\r",
      "Progress:34.3% Speed(reviews/sec):4415. #Correct:68 #Trained:132 Training Accuracy:51.5%\r",
      "Progress:34.6% Speed(reviews/sec):4421. #Correct:69 #Trained:133 Training Accuracy:51.8%\r",
      "Progress:34.9% Speed(reviews/sec):4431. #Correct:70 #Trained:134 Training Accuracy:52.2%\r",
      "Progress:35.1% Speed(reviews/sec):4440. #Correct:71 #Trained:135 Training Accuracy:52.5%\r",
      "Progress:35.4% Speed(reviews/sec):4455. #Correct:72 #Trained:136 Training Accuracy:52.9%\r",
      "Progress:35.6% Speed(reviews/sec):4470. #Correct:73 #Trained:137 Training Accuracy:53.2%\r",
      "Progress:35.9% Speed(reviews/sec):4486. #Correct:74 #Trained:138 Training Accuracy:53.6%\r",
      "Progress:36.2% Speed(reviews/sec):4490. #Correct:74 #Trained:139 Training Accuracy:53.2%\r",
      "Progress:36.4% Speed(reviews/sec):4499. #Correct:75 #Trained:140 Training Accuracy:53.5%\r",
      "Progress:36.7% Speed(reviews/sec):4513. #Correct:76 #Trained:141 Training Accuracy:53.9%\r",
      "Progress:37.0% Speed(reviews/sec):4517. #Correct:76 #Trained:142 Training Accuracy:53.5%\r",
      "Progress:37.2% Speed(reviews/sec):4529. #Correct:77 #Trained:143 Training Accuracy:53.8%\r",
      "Progress:37.5% Speed(reviews/sec):4536. #Correct:78 #Trained:144 Training Accuracy:54.1%\r",
      "Progress:37.7% Speed(reviews/sec):4523. #Correct:78 #Trained:145 Training Accuracy:53.7%\r",
      "Progress:38.0% Speed(reviews/sec):4534. #Correct:78 #Trained:146 Training Accuracy:53.4%\r",
      "Progress:38.3% Speed(reviews/sec):4548. #Correct:78 #Trained:147 Training Accuracy:53.0%\r",
      "Progress:38.5% Speed(reviews/sec):4564. #Correct:79 #Trained:148 Training Accuracy:53.3%\r",
      "Progress:38.8% Speed(reviews/sec):4580. #Correct:79 #Trained:149 Training Accuracy:53.0%\r",
      "Progress:39.1% Speed(reviews/sec):4595. #Correct:80 #Trained:150 Training Accuracy:53.3%\r",
      "Progress:39.3% Speed(reviews/sec):4610. #Correct:81 #Trained:151 Training Accuracy:53.6%\r",
      "Progress:39.6% Speed(reviews/sec):4614. #Correct:81 #Trained:152 Training Accuracy:53.2%\r",
      "Progress:39.8% Speed(reviews/sec):4622. #Correct:82 #Trained:153 Training Accuracy:53.5%\r",
      "Progress:40.1% Speed(reviews/sec):4632. #Correct:82 #Trained:154 Training Accuracy:53.2%\r",
      "Progress:40.4% Speed(reviews/sec):4642. #Correct:83 #Trained:155 Training Accuracy:53.5%\r",
      "Progress:40.6% Speed(reviews/sec):4658. #Correct:84 #Trained:156 Training Accuracy:53.8%\r",
      "Progress:40.9% Speed(reviews/sec):4669. #Correct:85 #Trained:157 Training Accuracy:54.1%\r",
      "Progress:41.2% Speed(reviews/sec):4680. #Correct:86 #Trained:158 Training Accuracy:54.4%\r",
      "Progress:41.4% Speed(reviews/sec):4686. #Correct:87 #Trained:159 Training Accuracy:54.7%\r",
      "Progress:41.7% Speed(reviews/sec):4697. #Correct:88 #Trained:160 Training Accuracy:55.0%\r",
      "Progress:41.9% Speed(reviews/sec):4711. #Correct:89 #Trained:161 Training Accuracy:55.2%\r",
      "Progress:42.2% Speed(reviews/sec):4723. #Correct:90 #Trained:162 Training Accuracy:55.5%\r",
      "Progress:42.5% Speed(reviews/sec):4732. #Correct:90 #Trained:163 Training Accuracy:55.2%\r",
      "Progress:42.7% Speed(reviews/sec):4742. #Correct:90 #Trained:164 Training Accuracy:54.8%\r",
      "Progress:43.0% Speed(reviews/sec):4752. #Correct:90 #Trained:165 Training Accuracy:54.5%\r",
      "Progress:43.3% Speed(reviews/sec):4766. #Correct:91 #Trained:166 Training Accuracy:54.8%\r",
      "Progress:43.5% Speed(reviews/sec):4778. #Correct:92 #Trained:167 Training Accuracy:55.0%\r",
      "Progress:43.8% Speed(reviews/sec):4787. #Correct:93 #Trained:168 Training Accuracy:55.3%\r",
      "Progress:44.0% Speed(reviews/sec):4792. #Correct:94 #Trained:169 Training Accuracy:55.6%\r",
      "Progress:44.3% Speed(reviews/sec):4800. #Correct:95 #Trained:170 Training Accuracy:55.8%\r",
      "Progress:44.6% Speed(reviews/sec):4815. #Correct:96 #Trained:171 Training Accuracy:56.1%\r",
      "Progress:44.8% Speed(reviews/sec):4825. #Correct:97 #Trained:172 Training Accuracy:56.3%\r",
      "Progress:45.1% Speed(reviews/sec):4834. #Correct:97 #Trained:173 Training Accuracy:56.0%\r",
      "Progress:45.4% Speed(reviews/sec):4842. #Correct:98 #Trained:174 Training Accuracy:56.3%\r",
      "Progress:45.6% Speed(reviews/sec):4852. #Correct:99 #Trained:175 Training Accuracy:56.5%\r",
      "Progress:45.9% Speed(reviews/sec):4866. #Correct:99 #Trained:176 Training Accuracy:56.2%\r",
      "Progress:46.1% Speed(reviews/sec):4875. #Correct:100 #Trained:177 Training Accuracy:56.4%\r",
      "Progress:46.4% Speed(reviews/sec):4865. #Correct:101 #Trained:178 Training Accuracy:56.7%\r",
      "Progress:46.7% Speed(reviews/sec):4872. #Correct:102 #Trained:179 Training Accuracy:56.9%\r",
      "Progress:46.9% Speed(reviews/sec):4885. #Correct:103 #Trained:180 Training Accuracy:57.2%\r",
      "Progress:47.2% Speed(reviews/sec):4897. #Correct:104 #Trained:181 Training Accuracy:57.4%\r",
      "Progress:47.5% Speed(reviews/sec):4911. #Correct:105 #Trained:182 Training Accuracy:57.6%\r",
      "Progress:47.7% Speed(reviews/sec):4924. #Correct:106 #Trained:183 Training Accuracy:57.9%\r",
      "Progress:48.0% Speed(reviews/sec):4939. #Correct:107 #Trained:184 Training Accuracy:58.1%\r",
      "Progress:48.2% Speed(reviews/sec):4950. #Correct:107 #Trained:185 Training Accuracy:57.8%\r",
      "Progress:48.5% Speed(reviews/sec):4959. #Correct:108 #Trained:186 Training Accuracy:58.0%\r",
      "Progress:48.8% Speed(reviews/sec):4951. #Correct:108 #Trained:187 Training Accuracy:57.7%\r",
      "Progress:49.0% Speed(reviews/sec):4952. #Correct:109 #Trained:188 Training Accuracy:57.9%\r",
      "Progress:49.3% Speed(reviews/sec):4948. #Correct:109 #Trained:189 Training Accuracy:57.6%\r",
      "Progress:49.6% Speed(reviews/sec):4944. #Correct:110 #Trained:190 Training Accuracy:57.8%\r",
      "Progress:49.8% Speed(reviews/sec):4953. #Correct:111 #Trained:191 Training Accuracy:58.1%\r",
      "Progress:50.1% Speed(reviews/sec):4967. #Correct:112 #Trained:192 Training Accuracy:58.3%\r",
      "Progress:50.3% Speed(reviews/sec):4944. #Correct:113 #Trained:193 Training Accuracy:58.5%\r",
      "Progress:50.6% Speed(reviews/sec):4939. #Correct:113 #Trained:194 Training Accuracy:58.2%\r",
      "Progress:50.9% Speed(reviews/sec):4945. #Correct:113 #Trained:195 Training Accuracy:57.9%\r",
      "Progress:51.1% Speed(reviews/sec):4956. #Correct:114 #Trained:196 Training Accuracy:58.1%\r",
      "Progress:51.4% Speed(reviews/sec):4970. #Correct:115 #Trained:197 Training Accuracy:58.3%\r",
      "Progress:51.7% Speed(reviews/sec):4981. #Correct:115 #Trained:198 Training Accuracy:58.0%\r",
      "Progress:51.9% Speed(reviews/sec):4991. #Correct:116 #Trained:199 Training Accuracy:58.2%\r",
      "Progress:52.2% Speed(reviews/sec):4993. #Correct:116 #Trained:200 Training Accuracy:58.0%\r",
      "Progress:52.4% Speed(reviews/sec):5004. #Correct:117 #Trained:201 Training Accuracy:58.2%\r",
      "Progress:52.7% Speed(reviews/sec):5018. #Correct:117 #Trained:202 Training Accuracy:57.9%\r",
      "Progress:53.0% Speed(reviews/sec):5024. #Correct:118 #Trained:203 Training Accuracy:58.1%\r",
      "Progress:53.2% Speed(reviews/sec):5038. #Correct:118 #Trained:204 Training Accuracy:57.8%\r",
      "Progress:53.5% Speed(reviews/sec):5053. #Correct:119 #Trained:205 Training Accuracy:58.0%\r",
      "Progress:53.8% Speed(reviews/sec):5062. #Correct:120 #Trained:206 Training Accuracy:58.2%\r",
      "Progress:54.0% Speed(reviews/sec):5074. #Correct:121 #Trained:207 Training Accuracy:58.4%\r",
      "Progress:54.3% Speed(reviews/sec):5088. #Correct:122 #Trained:208 Training Accuracy:58.6%\r",
      "Progress:54.5% Speed(reviews/sec):5091. #Correct:122 #Trained:209 Training Accuracy:58.3%\r",
      "Progress:54.8% Speed(reviews/sec):5084. #Correct:122 #Trained:210 Training Accuracy:58.0%\r",
      "Progress:55.1% Speed(reviews/sec):5006. #Correct:122 #Trained:211 Training Accuracy:57.8%\r",
      "Progress:55.3% Speed(reviews/sec):4930. #Correct:123 #Trained:212 Training Accuracy:58.0%\r",
      "Progress:55.6% Speed(reviews/sec):4820. #Correct:123 #Trained:213 Training Accuracy:57.7%\r",
      "Progress:55.9% Speed(reviews/sec):4706. #Correct:124 #Trained:214 Training Accuracy:57.9%\r",
      "Progress:56.1% Speed(reviews/sec):4625. #Correct:124 #Trained:215 Training Accuracy:57.6%\r",
      "Progress:56.4% Speed(reviews/sec):4557. #Correct:125 #Trained:216 Training Accuracy:57.8%\r",
      "Progress:56.6% Speed(reviews/sec):4516. #Correct:126 #Trained:217 Training Accuracy:58.0%\r",
      "Progress:56.9% Speed(reviews/sec):4485. #Correct:127 #Trained:218 Training Accuracy:58.2%\r",
      "Progress:57.2% Speed(reviews/sec):4443. #Correct:128 #Trained:219 Training Accuracy:58.4%\r",
      "Progress:57.4% Speed(reviews/sec):4394. #Correct:128 #Trained:220 Training Accuracy:58.1%\r",
      "Progress:57.7% Speed(reviews/sec):4330. #Correct:129 #Trained:221 Training Accuracy:58.3%\r",
      "Progress:58.0% Speed(reviews/sec):4266. #Correct:129 #Trained:222 Training Accuracy:58.1%\r",
      "Progress:58.2% Speed(reviews/sec):4230. #Correct:130 #Trained:223 Training Accuracy:58.2%\r",
      "Progress:58.5% Speed(reviews/sec):4200. #Correct:131 #Trained:224 Training Accuracy:58.4%\r",
      "Progress:58.7% Speed(reviews/sec):4171. #Correct:132 #Trained:225 Training Accuracy:58.6%\r",
      "Progress:59.0% Speed(reviews/sec):4145. #Correct:132 #Trained:226 Training Accuracy:58.4%\r",
      "Progress:59.3% Speed(reviews/sec):4124. #Correct:133 #Trained:227 Training Accuracy:58.5%\r",
      "Progress:59.5% Speed(reviews/sec):4104. #Correct:134 #Trained:228 Training Accuracy:58.7%\r",
      "Progress:59.8% Speed(reviews/sec):4068. #Correct:135 #Trained:229 Training Accuracy:58.9%\r",
      "Progress:60.1% Speed(reviews/sec):4041. #Correct:136 #Trained:230 Training Accuracy:59.1%\r",
      "Progress:60.3% Speed(reviews/sec):4020. #Correct:137 #Trained:231 Training Accuracy:59.3%\r",
      "Progress:60.6% Speed(reviews/sec):4000. #Correct:138 #Trained:232 Training Accuracy:59.4%\r",
      "Progress:60.8% Speed(reviews/sec):3981. #Correct:139 #Trained:233 Training Accuracy:59.6%\r",
      "Progress:61.1% Speed(reviews/sec):3962. #Correct:140 #Trained:234 Training Accuracy:59.8%\r",
      "Progress:61.4% Speed(reviews/sec):3946. #Correct:140 #Trained:235 Training Accuracy:59.5%\r",
      "Progress:61.6% Speed(reviews/sec):3927. #Correct:141 #Trained:236 Training Accuracy:59.7%\r",
      "Progress:61.9% Speed(reviews/sec):3915. #Correct:142 #Trained:237 Training Accuracy:59.9%\r",
      "Progress:62.2% Speed(reviews/sec):3900. #Correct:143 #Trained:238 Training Accuracy:60.0%\r",
      "Progress:62.4% Speed(reviews/sec):3884. #Correct:143 #Trained:239 Training Accuracy:59.8%\r",
      "Progress:62.7% Speed(reviews/sec):3865. #Correct:144 #Trained:240 Training Accuracy:60.0%\r",
      "Progress:62.9% Speed(reviews/sec):3848. #Correct:145 #Trained:241 Training Accuracy:60.1%\r",
      "Progress:63.2% Speed(reviews/sec):3834. #Correct:146 #Trained:242 Training Accuracy:60.3%\r",
      "Progress:63.5% Speed(reviews/sec):3816. #Correct:147 #Trained:243 Training Accuracy:60.4%\r",
      "Progress:63.7% Speed(reviews/sec):3789. #Correct:147 #Trained:244 Training Accuracy:60.2%\r",
      "Progress:64.0% Speed(reviews/sec):3772. #Correct:147 #Trained:245 Training Accuracy:60.0%\r",
      "Progress:64.3% Speed(reviews/sec):3762. #Correct:148 #Trained:246 Training Accuracy:60.1%\r",
      "Progress:64.5% Speed(reviews/sec):3748. #Correct:148 #Trained:247 Training Accuracy:59.9%\r",
      "Progress:64.8% Speed(reviews/sec):3743. #Correct:149 #Trained:248 Training Accuracy:60.0%\r",
      "Progress:65.0% Speed(reviews/sec):3734. #Correct:149 #Trained:249 Training Accuracy:59.8%\r",
      "Progress:65.3% Speed(reviews/sec):3729. #Correct:150 #Trained:250 Training Accuracy:60.0%\r",
      "Progress:65.6% Speed(reviews/sec):3720. #Correct:151 #Trained:251 Training Accuracy:60.1%\r",
      "Progress:65.8% Speed(reviews/sec):3717. #Correct:152 #Trained:252 Training Accuracy:60.3%\r",
      "Progress:66.1% Speed(reviews/sec):3706. #Correct:153 #Trained:253 Training Accuracy:60.4%\r",
      "Progress:66.4% Speed(reviews/sec):3698. #Correct:154 #Trained:254 Training Accuracy:60.6%\r",
      "Progress:66.6% Speed(reviews/sec):3692. #Correct:155 #Trained:255 Training Accuracy:60.7%\r",
      "Progress:66.9% Speed(reviews/sec):3690. #Correct:156 #Trained:256 Training Accuracy:60.9%\r",
      "Progress:67.1% Speed(reviews/sec):3688. #Correct:157 #Trained:257 Training Accuracy:61.0%\r",
      "Progress:67.4% Speed(reviews/sec):3682. #Correct:158 #Trained:258 Training Accuracy:61.2%\r",
      "Progress:67.7% Speed(reviews/sec):3675. #Correct:159 #Trained:259 Training Accuracy:61.3%\r",
      "Progress:67.9% Speed(reviews/sec):3665. #Correct:160 #Trained:260 Training Accuracy:61.5%\r",
      "Progress:68.2% Speed(reviews/sec):3657. #Correct:161 #Trained:261 Training Accuracy:61.6%\r",
      "Progress:68.5% Speed(reviews/sec):3646. #Correct:162 #Trained:262 Training Accuracy:61.8%\r",
      "Progress:68.7% Speed(reviews/sec):3639. #Correct:163 #Trained:263 Training Accuracy:61.9%\r",
      "Progress:69.0% Speed(reviews/sec):3630. #Correct:164 #Trained:264 Training Accuracy:62.1%\r",
      "Progress:69.2% Speed(reviews/sec):3612. #Correct:165 #Trained:265 Training Accuracy:62.2%\r",
      "Progress:69.5% Speed(reviews/sec):3604. #Correct:166 #Trained:266 Training Accuracy:62.4%\r",
      "Progress:69.8% Speed(reviews/sec):3597. #Correct:166 #Trained:267 Training Accuracy:62.1%\r",
      "Progress:70.0% Speed(reviews/sec):3592. #Correct:166 #Trained:268 Training Accuracy:61.9%\r",
      "Progress:70.3% Speed(reviews/sec):3589. #Correct:167 #Trained:269 Training Accuracy:62.0%\r",
      "Progress:70.6% Speed(reviews/sec):3564. #Correct:168 #Trained:270 Training Accuracy:62.2%\r",
      "Progress:70.8% Speed(reviews/sec):3558. #Correct:169 #Trained:271 Training Accuracy:62.3%\r",
      "Progress:71.1% Speed(reviews/sec):3555. #Correct:170 #Trained:272 Training Accuracy:62.5%\r",
      "Progress:71.3% Speed(reviews/sec):3552. #Correct:171 #Trained:273 Training Accuracy:62.6%\r",
      "Progress:71.6% Speed(reviews/sec):3546. #Correct:171 #Trained:274 Training Accuracy:62.4%\r",
      "Progress:71.9% Speed(reviews/sec):3542. #Correct:172 #Trained:275 Training Accuracy:62.5%\r",
      "Progress:72.1% Speed(reviews/sec):3537. #Correct:172 #Trained:276 Training Accuracy:62.3%\r",
      "Progress:72.4% Speed(reviews/sec):3528. #Correct:172 #Trained:277 Training Accuracy:62.0%\r",
      "Progress:72.7% Speed(reviews/sec):3524. #Correct:173 #Trained:278 Training Accuracy:62.2%\r",
      "Progress:72.9% Speed(reviews/sec):3521. #Correct:173 #Trained:279 Training Accuracy:62.0%\r",
      "Progress:73.2% Speed(reviews/sec):3517. #Correct:173 #Trained:280 Training Accuracy:61.7%\r",
      "Progress:73.4% Speed(reviews/sec):3513. #Correct:174 #Trained:281 Training Accuracy:61.9%\r",
      "Progress:73.7% Speed(reviews/sec):3512. #Correct:175 #Trained:282 Training Accuracy:62.0%\r",
      "Progress:74.0% Speed(reviews/sec):3506. #Correct:176 #Trained:283 Training Accuracy:62.1%\r",
      "Progress:74.2% Speed(reviews/sec):3502. #Correct:177 #Trained:284 Training Accuracy:62.3%\r",
      "Progress:74.5% Speed(reviews/sec):3497. #Correct:177 #Trained:285 Training Accuracy:62.1%\r",
      "Progress:74.8% Speed(reviews/sec):3486. #Correct:178 #Trained:286 Training Accuracy:62.2%\r",
      "Progress:75.0% Speed(reviews/sec):3481. #Correct:179 #Trained:287 Training Accuracy:62.3%\r",
      "Progress:75.3% Speed(reviews/sec):3479. #Correct:179 #Trained:288 Training Accuracy:62.1%\r",
      "Progress:75.5% Speed(reviews/sec):3471. #Correct:179 #Trained:289 Training Accuracy:61.9%\r",
      "Progress:75.8% Speed(reviews/sec):3454. #Correct:180 #Trained:290 Training Accuracy:62.0%\r",
      "Progress:76.1% Speed(reviews/sec):3441. #Correct:180 #Trained:291 Training Accuracy:61.8%\r",
      "Progress:76.3% Speed(reviews/sec):3439. #Correct:180 #Trained:292 Training Accuracy:61.6%\r",
      "Progress:76.6% Speed(reviews/sec):3437. #Correct:181 #Trained:293 Training Accuracy:61.7%\r",
      "Progress:76.9% Speed(reviews/sec):3438. #Correct:182 #Trained:294 Training Accuracy:61.9%\r",
      "Progress:77.1% Speed(reviews/sec):3439. #Correct:183 #Trained:295 Training Accuracy:62.0%\r",
      "Progress:77.4% Speed(reviews/sec):3437. #Correct:183 #Trained:296 Training Accuracy:61.8%\r",
      "Progress:77.6% Speed(reviews/sec):3439. #Correct:184 #Trained:297 Training Accuracy:61.9%\r",
      "Progress:77.9% Speed(reviews/sec):3427. #Correct:185 #Trained:298 Training Accuracy:62.0%\r",
      "Progress:78.2% Speed(reviews/sec):3427. #Correct:185 #Trained:299 Training Accuracy:61.8%\r",
      "Progress:78.4% Speed(reviews/sec):3429. #Correct:186 #Trained:300 Training Accuracy:62.0%\r",
      "Progress:78.7% Speed(reviews/sec):3430. #Correct:187 #Trained:301 Training Accuracy:62.1%\r",
      "Progress:79.0% Speed(reviews/sec):3433. #Correct:187 #Trained:302 Training Accuracy:61.9%\r",
      "Progress:79.2% Speed(reviews/sec):3434. #Correct:187 #Trained:303 Training Accuracy:61.7%\r",
      "Progress:79.5% Speed(reviews/sec):3436. #Correct:188 #Trained:304 Training Accuracy:61.8%\r",
      "Progress:79.7% Speed(reviews/sec):3438. #Correct:188 #Trained:305 Training Accuracy:61.6%\r",
      "Progress:80.0% Speed(reviews/sec):3442. #Correct:189 #Trained:306 Training Accuracy:61.7%\r",
      "Progress:80.3% Speed(reviews/sec):3445. #Correct:189 #Trained:307 Training Accuracy:61.5%\r",
      "Progress:80.5% Speed(reviews/sec):3447. #Correct:190 #Trained:308 Training Accuracy:61.6%\r",
      "Progress:80.8% Speed(reviews/sec):3450. #Correct:191 #Trained:309 Training Accuracy:61.8%\r",
      "Progress:81.1% Speed(reviews/sec):3453. #Correct:192 #Trained:310 Training Accuracy:61.9%\r",
      "Progress:81.3% Speed(reviews/sec):3457. #Correct:193 #Trained:311 Training Accuracy:62.0%\r",
      "Progress:81.6% Speed(reviews/sec):3459. #Correct:194 #Trained:312 Training Accuracy:62.1%\r",
      "Progress:81.8% Speed(reviews/sec):3458. #Correct:195 #Trained:313 Training Accuracy:62.3%\r",
      "Progress:82.1% Speed(reviews/sec):3458. #Correct:196 #Trained:314 Training Accuracy:62.4%\r",
      "Progress:82.4% Speed(reviews/sec):3454. #Correct:197 #Trained:315 Training Accuracy:62.5%\r",
      "Progress:82.6% Speed(reviews/sec):3457. #Correct:198 #Trained:316 Training Accuracy:62.6%\r",
      "Progress:82.9% Speed(reviews/sec):3460. #Correct:199 #Trained:317 Training Accuracy:62.7%\r",
      "Progress:83.2% Speed(reviews/sec):3462. #Correct:200 #Trained:318 Training Accuracy:62.8%\r",
      "Progress:83.4% Speed(reviews/sec):3459. #Correct:201 #Trained:319 Training Accuracy:63.0%\r",
      "Progress:83.7% Speed(reviews/sec):3462. #Correct:202 #Trained:320 Training Accuracy:63.1%\r",
      "Progress:83.9% Speed(reviews/sec):3463. #Correct:203 #Trained:321 Training Accuracy:63.2%\r",
      "Progress:84.2% Speed(reviews/sec):3467. #Correct:204 #Trained:322 Training Accuracy:63.3%\r",
      "Progress:84.5% Speed(reviews/sec):3466. #Correct:205 #Trained:323 Training Accuracy:63.4%\r",
      "Progress:84.7% Speed(reviews/sec):3470. #Correct:206 #Trained:324 Training Accuracy:63.5%\r",
      "Progress:85.0% Speed(reviews/sec):3473. #Correct:207 #Trained:325 Training Accuracy:63.6%\r",
      "Progress:85.3% Speed(reviews/sec):3477. #Correct:207 #Trained:326 Training Accuracy:63.4%\r",
      "Progress:85.5% Speed(reviews/sec):3483. #Correct:208 #Trained:327 Training Accuracy:63.6%\r",
      "Progress:85.8% Speed(reviews/sec):3487. #Correct:208 #Trained:328 Training Accuracy:63.4%\r",
      "Progress:86.0% Speed(reviews/sec):3491. #Correct:209 #Trained:329 Training Accuracy:63.5%\r",
      "Progress:86.3% Speed(reviews/sec):3494. #Correct:210 #Trained:330 Training Accuracy:63.6%\r",
      "Progress:86.6% Speed(reviews/sec):3497. #Correct:211 #Trained:331 Training Accuracy:63.7%\r",
      "Progress:86.8% Speed(reviews/sec):3501. #Correct:212 #Trained:332 Training Accuracy:63.8%\r",
      "Progress:87.1% Speed(reviews/sec):3505. #Correct:213 #Trained:333 Training Accuracy:63.9%\r",
      "Progress:87.4% Speed(reviews/sec):3509. #Correct:214 #Trained:334 Training Accuracy:64.0%\r",
      "Progress:87.6% Speed(reviews/sec):3513. #Correct:215 #Trained:335 Training Accuracy:64.1%\r",
      "Progress:87.9% Speed(reviews/sec):3517. #Correct:215 #Trained:336 Training Accuracy:63.9%\r",
      "Progress:88.1% Speed(reviews/sec):3522. #Correct:215 #Trained:337 Training Accuracy:63.7%\r",
      "Progress:88.4% Speed(reviews/sec):3526. #Correct:215 #Trained:338 Training Accuracy:63.6%\r",
      "Progress:88.7% Speed(reviews/sec):3529. #Correct:216 #Trained:339 Training Accuracy:63.7%\r",
      "Progress:88.9% Speed(reviews/sec):3534. #Correct:217 #Trained:340 Training Accuracy:63.8%\r",
      "Progress:89.2% Speed(reviews/sec):3538. #Correct:217 #Trained:341 Training Accuracy:63.6%\r",
      "Progress:89.5% Speed(reviews/sec):3544. #Correct:218 #Trained:342 Training Accuracy:63.7%\r",
      "Progress:89.7% Speed(reviews/sec):3549. #Correct:219 #Trained:343 Training Accuracy:63.8%\r",
      "Progress:90.0% Speed(reviews/sec):3554. #Correct:220 #Trained:344 Training Accuracy:63.9%\r",
      "Progress:90.2% Speed(reviews/sec):3559. #Correct:220 #Trained:345 Training Accuracy:63.7%\r",
      "Progress:90.5% Speed(reviews/sec):3564. #Correct:220 #Trained:346 Training Accuracy:63.5%\r",
      "Progress:90.8% Speed(reviews/sec):3571. #Correct:221 #Trained:347 Training Accuracy:63.6%\r",
      "Progress:91.0% Speed(reviews/sec):3575. #Correct:221 #Trained:348 Training Accuracy:63.5%\r",
      "Progress:91.3% Speed(reviews/sec):3580. #Correct:222 #Trained:349 Training Accuracy:63.6%\r",
      "Progress:91.6% Speed(reviews/sec):3585. #Correct:223 #Trained:350 Training Accuracy:63.7%\r",
      "Progress:91.8% Speed(reviews/sec):3590. #Correct:223 #Trained:351 Training Accuracy:63.5%\r",
      "Progress:92.1% Speed(reviews/sec):3597. #Correct:224 #Trained:352 Training Accuracy:63.6%\r",
      "Progress:92.3% Speed(reviews/sec):3600. #Correct:225 #Trained:353 Training Accuracy:63.7%\r",
      "Progress:92.6% Speed(reviews/sec):3601. #Correct:226 #Trained:354 Training Accuracy:63.8%\r",
      "Progress:92.9% Speed(reviews/sec):3607. #Correct:226 #Trained:355 Training Accuracy:63.6%\r",
      "Progress:93.1% Speed(reviews/sec):3613. #Correct:227 #Trained:356 Training Accuracy:63.7%\r",
      "Progress:93.4% Speed(reviews/sec):3618. #Correct:228 #Trained:357 Training Accuracy:63.8%\r",
      "Progress:93.7% Speed(reviews/sec):3597. #Correct:229 #Trained:358 Training Accuracy:63.9%\r",
      "Progress:93.9% Speed(reviews/sec):3575. #Correct:230 #Trained:359 Training Accuracy:64.0%\r",
      "Progress:94.2% Speed(reviews/sec):3557. #Correct:231 #Trained:360 Training Accuracy:64.1%\r",
      "Progress:94.4% Speed(reviews/sec):3551. #Correct:231 #Trained:361 Training Accuracy:63.9%\r",
      "Progress:94.7% Speed(reviews/sec):3544. #Correct:232 #Trained:362 Training Accuracy:64.0%\r",
      "Progress:95.0% Speed(reviews/sec):3537. #Correct:233 #Trained:363 Training Accuracy:64.1%\r",
      "Progress:95.2% Speed(reviews/sec):3533. #Correct:234 #Trained:364 Training Accuracy:64.2%\r",
      "Progress:95.5% Speed(reviews/sec):3529. #Correct:235 #Trained:365 Training Accuracy:64.3%\r",
      "Progress:95.8% Speed(reviews/sec):3525. #Correct:236 #Trained:366 Training Accuracy:64.4%\r",
      "Progress:96.0% Speed(reviews/sec):3523. #Correct:237 #Trained:367 Training Accuracy:64.5%\r",
      "Progress:96.3% Speed(reviews/sec):3519. #Correct:238 #Trained:368 Training Accuracy:64.6%\r",
      "Progress:96.5% Speed(reviews/sec):3517. #Correct:239 #Trained:369 Training Accuracy:64.7%\r",
      "Progress:96.8% Speed(reviews/sec):3513. #Correct:240 #Trained:370 Training Accuracy:64.8%\r",
      "Progress:97.1% Speed(reviews/sec):3512. #Correct:241 #Trained:371 Training Accuracy:64.9%\r",
      "Progress:97.3% Speed(reviews/sec):3513. #Correct:242 #Trained:372 Training Accuracy:65.0%\r",
      "Progress:97.6% Speed(reviews/sec):3511. #Correct:243 #Trained:373 Training Accuracy:65.1%\r",
      "Progress:97.9% Speed(reviews/sec):3510. #Correct:243 #Trained:374 Training Accuracy:64.9%\r",
      "Progress:98.1% Speed(reviews/sec):3509. #Correct:244 #Trained:375 Training Accuracy:65.0%\r",
      "Progress:98.4% Speed(reviews/sec):3509. #Correct:244 #Trained:376 Training Accuracy:64.8%\r",
      "Progress:98.6% Speed(reviews/sec):3509. #Correct:245 #Trained:377 Training Accuracy:64.9%\r",
      "Progress:98.9% Speed(reviews/sec):3509. #Correct:246 #Trained:378 Training Accuracy:65.0%\r",
      "Progress:99.2% Speed(reviews/sec):3507. #Correct:246 #Trained:379 Training Accuracy:64.9%\r",
      "Progress:99.4% Speed(reviews/sec):3505. #Correct:247 #Trained:380 Training Accuracy:65.0%\r",
      "Progress:99.7% Speed(reviews/sec):3499. #Correct:247 #Trained:381 Training Accuracy:64.8%"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-140],labels[:-140], learning_rate=0.01)\n",
    "mlp.train(reviews[:-140],labels[:-140])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should have trained much better than the earlier attempts. Run the following cell to test your model with 1000 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Tested:1 Testing Accuracy:0.0%\r",
      "Progress:0.71% Speed(reviews/sec):1636. #Correct:0 #Tested:2 Testing Accuracy:0.0%\r",
      "Progress:1.42% Speed(reviews/sec):2493. #Correct:1 #Tested:3 Testing Accuracy:33.3%\r",
      "Progress:2.14% Speed(reviews/sec):3008. #Correct:1 #Tested:4 Testing Accuracy:25.0%\r",
      "Progress:2.85% Speed(reviews/sec):3454. #Correct:2 #Tested:5 Testing Accuracy:40.0%\r",
      "Progress:3.57% Speed(reviews/sec):3801. #Correct:3 #Tested:6 Testing Accuracy:50.0%\r",
      "Progress:4.28% Speed(reviews/sec):4118. #Correct:4 #Tested:7 Testing Accuracy:57.1%\r",
      "Progress:5.0% Speed(reviews/sec):4388. #Correct:4 #Tested:8 Testing Accuracy:50.0%\r",
      "Progress:5.71% Speed(reviews/sec):4230. #Correct:5 #Tested:9 Testing Accuracy:55.5%\r",
      "Progress:6.42% Speed(reviews/sec):4088. #Correct:6 #Tested:10 Testing Accuracy:60.0%\r",
      "Progress:7.14% Speed(reviews/sec):4267. #Correct:7 #Tested:11 Testing Accuracy:63.6%\r",
      "Progress:7.85% Speed(reviews/sec):4423. #Correct:8 #Tested:12 Testing Accuracy:66.6%\r",
      "Progress:8.57% Speed(reviews/sec):4470. #Correct:8 #Tested:13 Testing Accuracy:61.5%\r",
      "Progress:9.28% Speed(reviews/sec):4593. #Correct:9 #Tested:14 Testing Accuracy:64.2%\r",
      "Progress:10.0% Speed(reviews/sec):4699. #Correct:10 #Tested:15 Testing Accuracy:66.6%\r",
      "Progress:10.7% Speed(reviews/sec):4818. #Correct:11 #Tested:16 Testing Accuracy:68.7%\r",
      "Progress:11.4% Speed(reviews/sec):4907. #Correct:12 #Tested:17 Testing Accuracy:70.5%\r",
      "Progress:12.1% Speed(reviews/sec):4905. #Correct:12 #Tested:18 Testing Accuracy:66.6%\r",
      "Progress:12.8% Speed(reviews/sec):4719. #Correct:13 #Tested:19 Testing Accuracy:68.4%\r",
      "Progress:13.5% Speed(reviews/sec):4788. #Correct:14 #Tested:20 Testing Accuracy:70.0%\r",
      "Progress:14.2% Speed(reviews/sec):4847. #Correct:14 #Tested:21 Testing Accuracy:66.6%\r",
      "Progress:15.0% Speed(reviews/sec):4672. #Correct:15 #Tested:22 Testing Accuracy:68.1%\r",
      "Progress:15.7% Speed(reviews/sec):4744. #Correct:16 #Tested:23 Testing Accuracy:69.5%\r",
      "Progress:16.4% Speed(reviews/sec):4839. #Correct:17 #Tested:24 Testing Accuracy:70.8%\r",
      "Progress:17.1% Speed(reviews/sec):4914. #Correct:18 #Tested:25 Testing Accuracy:72.0%\r",
      "Progress:17.8% Speed(reviews/sec):4998. #Correct:19 #Tested:26 Testing Accuracy:73.0%\r",
      "Progress:18.5% Speed(reviews/sec):5062. #Correct:20 #Tested:27 Testing Accuracy:74.0%\r",
      "Progress:19.2% Speed(reviews/sec):5122. #Correct:21 #Tested:28 Testing Accuracy:75.0%\r",
      "Progress:20.0% Speed(reviews/sec):5204. #Correct:21 #Tested:29 Testing Accuracy:72.4%\r",
      "Progress:20.7% Speed(reviews/sec):5286. #Correct:22 #Tested:30 Testing Accuracy:73.3%\r",
      "Progress:21.4% Speed(reviews/sec):5118. #Correct:23 #Tested:31 Testing Accuracy:74.1%\r",
      "Progress:22.1% Speed(reviews/sec):5169. #Correct:24 #Tested:32 Testing Accuracy:75.0%\r",
      "Progress:22.8% Speed(reviews/sec):5236. #Correct:25 #Tested:33 Testing Accuracy:75.7%\r",
      "Progress:23.5% Speed(reviews/sec):5312. #Correct:26 #Tested:34 Testing Accuracy:76.4%\r",
      "Progress:24.2% Speed(reviews/sec):5377. #Correct:26 #Tested:35 Testing Accuracy:74.2%\r",
      "Progress:25.0% Speed(reviews/sec):5443. #Correct:27 #Tested:36 Testing Accuracy:75.0%\r",
      "Progress:25.7% Speed(reviews/sec):5504. #Correct:28 #Tested:37 Testing Accuracy:75.6%\r",
      "Progress:26.4% Speed(reviews/sec):5568. #Correct:29 #Tested:38 Testing Accuracy:76.3%\r",
      "Progress:27.1% Speed(reviews/sec):5632. #Correct:29 #Tested:39 Testing Accuracy:74.3%\r",
      "Progress:27.8% Speed(reviews/sec):5687. #Correct:30 #Tested:40 Testing Accuracy:75.0%\r",
      "Progress:28.5% Speed(reviews/sec):5488. #Correct:31 #Tested:41 Testing Accuracy:75.6%\r",
      "Progress:29.2% Speed(reviews/sec):5509. #Correct:32 #Tested:42 Testing Accuracy:76.1%\r",
      "Progress:30.0% Speed(reviews/sec):5520. #Correct:33 #Tested:43 Testing Accuracy:76.7%\r",
      "Progress:30.7% Speed(reviews/sec):5583. #Correct:34 #Tested:44 Testing Accuracy:77.2%\r",
      "Progress:31.4% Speed(reviews/sec):5613. #Correct:35 #Tested:45 Testing Accuracy:77.7%\r",
      "Progress:32.1% Speed(reviews/sec):5654. #Correct:36 #Tested:46 Testing Accuracy:78.2%\r",
      "Progress:32.8% Speed(reviews/sec):5668. #Correct:37 #Tested:47 Testing Accuracy:78.7%\r",
      "Progress:33.5% Speed(reviews/sec):5709. #Correct:37 #Tested:48 Testing Accuracy:77.0%\r",
      "Progress:34.2% Speed(reviews/sec):5779. #Correct:38 #Tested:49 Testing Accuracy:77.5%\r",
      "Progress:35.0% Speed(reviews/sec):5822. #Correct:39 #Tested:50 Testing Accuracy:78.0%\r",
      "Progress:35.7% Speed(reviews/sec):5868. #Correct:40 #Tested:51 Testing Accuracy:78.4%\r",
      "Progress:36.4% Speed(reviews/sec):5906. #Correct:40 #Tested:52 Testing Accuracy:76.9%\r",
      "Progress:37.1% Speed(reviews/sec):5947. #Correct:41 #Tested:53 Testing Accuracy:77.3%\r",
      "Progress:37.8% Speed(reviews/sec):6009. #Correct:41 #Tested:54 Testing Accuracy:75.9%\r",
      "Progress:38.5% Speed(reviews/sec):6050. #Correct:41 #Tested:55 Testing Accuracy:74.5%\r",
      "Progress:39.2% Speed(reviews/sec):6092. #Correct:41 #Tested:56 Testing Accuracy:73.2%\r",
      "Progress:40.0% Speed(reviews/sec):6128. #Correct:41 #Tested:57 Testing Accuracy:71.9%\r",
      "Progress:40.7% Speed(reviews/sec):6164. #Correct:42 #Tested:58 Testing Accuracy:72.4%\r",
      "Progress:41.4% Speed(reviews/sec):6200. #Correct:43 #Tested:59 Testing Accuracy:72.8%\r",
      "Progress:42.1% Speed(reviews/sec):6242. #Correct:43 #Tested:60 Testing Accuracy:71.6%\r",
      "Progress:42.8% Speed(reviews/sec):6293. #Correct:43 #Tested:61 Testing Accuracy:70.4%\r",
      "Progress:43.5% Speed(reviews/sec):6302. #Correct:44 #Tested:62 Testing Accuracy:70.9%\r",
      "Progress:44.2% Speed(reviews/sec):6353. #Correct:44 #Tested:63 Testing Accuracy:69.8%\r",
      "Progress:45.0% Speed(reviews/sec):6409. #Correct:45 #Tested:64 Testing Accuracy:70.3%\r",
      "Progress:45.7% Speed(reviews/sec):6404. #Correct:46 #Tested:65 Testing Accuracy:70.7%\r",
      "Progress:46.4% Speed(reviews/sec):6364. #Correct:47 #Tested:66 Testing Accuracy:71.2%\r",
      "Progress:47.1% Speed(reviews/sec):6364. #Correct:48 #Tested:67 Testing Accuracy:71.6%\r",
      "Progress:47.8% Speed(reviews/sec):6345. #Correct:49 #Tested:68 Testing Accuracy:72.0%\r",
      "Progress:48.5% Speed(reviews/sec):6396. #Correct:50 #Tested:69 Testing Accuracy:72.4%\r",
      "Progress:49.2% Speed(reviews/sec):6395. #Correct:50 #Tested:70 Testing Accuracy:71.4%\r",
      "Progress:50.0% Speed(reviews/sec):6362. #Correct:50 #Tested:71 Testing Accuracy:70.4%\r",
      "Progress:50.7% Speed(reviews/sec):6387. #Correct:50 #Tested:72 Testing Accuracy:69.4%\r",
      "Progress:51.4% Speed(reviews/sec):6206. #Correct:51 #Tested:73 Testing Accuracy:69.8%\r",
      "Progress:52.1% Speed(reviews/sec):6167. #Correct:51 #Tested:74 Testing Accuracy:68.9%\r",
      "Progress:52.8% Speed(reviews/sec):6093. #Correct:52 #Tested:75 Testing Accuracy:69.3%\r",
      "Progress:53.5% Speed(reviews/sec):6016. #Correct:52 #Tested:76 Testing Accuracy:68.4%\r",
      "Progress:54.2% Speed(reviews/sec):5860. #Correct:52 #Tested:77 Testing Accuracy:67.5%\r",
      "Progress:55.0% Speed(reviews/sec):5759. #Correct:53 #Tested:78 Testing Accuracy:67.9%\r",
      "Progress:55.7% Speed(reviews/sec):5620. #Correct:54 #Tested:79 Testing Accuracy:68.3%\r",
      "Progress:56.4% Speed(reviews/sec):5593. #Correct:55 #Tested:80 Testing Accuracy:68.7%\r",
      "Progress:57.1% Speed(reviews/sec):5572. #Correct:56 #Tested:81 Testing Accuracy:69.1%\r",
      "Progress:57.8% Speed(reviews/sec):5552. #Correct:57 #Tested:82 Testing Accuracy:69.5%\r",
      "Progress:58.5% Speed(reviews/sec):5513. #Correct:57 #Tested:83 Testing Accuracy:68.6%\r",
      "Progress:59.2% Speed(reviews/sec):5498. #Correct:58 #Tested:84 Testing Accuracy:69.0%\r",
      "Progress:60.0% Speed(reviews/sec):5479. #Correct:59 #Tested:85 Testing Accuracy:69.4%\r",
      "Progress:60.7% Speed(reviews/sec):5454. #Correct:60 #Tested:86 Testing Accuracy:69.7%\r",
      "Progress:61.4% Speed(reviews/sec):5407. #Correct:60 #Tested:87 Testing Accuracy:68.9%\r",
      "Progress:62.1% Speed(reviews/sec):5392. #Correct:61 #Tested:88 Testing Accuracy:69.3%\r",
      "Progress:62.8% Speed(reviews/sec):5386. #Correct:62 #Tested:89 Testing Accuracy:69.6%\r",
      "Progress:63.5% Speed(reviews/sec):5384. #Correct:62 #Tested:90 Testing Accuracy:68.8%\r",
      "Progress:64.2% Speed(reviews/sec):5376. #Correct:63 #Tested:91 Testing Accuracy:69.2%\r",
      "Progress:65.0% Speed(reviews/sec):5372. #Correct:64 #Tested:92 Testing Accuracy:69.5%\r",
      "Progress:65.7% Speed(reviews/sec):5361. #Correct:65 #Tested:93 Testing Accuracy:69.8%\r",
      "Progress:66.4% Speed(reviews/sec):5355. #Correct:66 #Tested:94 Testing Accuracy:70.2%\r",
      "Progress:67.1% Speed(reviews/sec):5326. #Correct:67 #Tested:95 Testing Accuracy:70.5%\r",
      "Progress:67.8% Speed(reviews/sec):5304. #Correct:68 #Tested:96 Testing Accuracy:70.8%\r",
      "Progress:68.5% Speed(reviews/sec):5272. #Correct:68 #Tested:97 Testing Accuracy:70.1%\r",
      "Progress:69.2% Speed(reviews/sec):5234. #Correct:69 #Tested:98 Testing Accuracy:70.4%\r",
      "Progress:70.0% Speed(reviews/sec):5191. #Correct:70 #Tested:99 Testing Accuracy:70.7%\r",
      "Progress:70.7% Speed(reviews/sec):5175. #Correct:71 #Tested:100 Testing Accuracy:71.0%\r",
      "Progress:71.4% Speed(reviews/sec):5138. #Correct:72 #Tested:101 Testing Accuracy:71.2%\r",
      "Progress:72.1% Speed(reviews/sec):5107. #Correct:72 #Tested:102 Testing Accuracy:70.5%\r",
      "Progress:72.8% Speed(reviews/sec):5070. #Correct:72 #Tested:103 Testing Accuracy:69.9%\r",
      "Progress:73.5% Speed(reviews/sec):5063. #Correct:73 #Tested:104 Testing Accuracy:70.1%\r",
      "Progress:74.2% Speed(reviews/sec):5029. #Correct:74 #Tested:105 Testing Accuracy:70.4%\r",
      "Progress:75.0% Speed(reviews/sec):4978. #Correct:75 #Tested:106 Testing Accuracy:70.7%\r",
      "Progress:75.7% Speed(reviews/sec):4963. #Correct:76 #Tested:107 Testing Accuracy:71.0%\r",
      "Progress:76.4% Speed(reviews/sec):4951. #Correct:77 #Tested:108 Testing Accuracy:71.2%\r",
      "Progress:77.1% Speed(reviews/sec):4945. #Correct:78 #Tested:109 Testing Accuracy:71.5%\r",
      "Progress:77.8% Speed(reviews/sec):4934. #Correct:78 #Tested:110 Testing Accuracy:70.9%\r",
      "Progress:78.5% Speed(reviews/sec):4916. #Correct:79 #Tested:111 Testing Accuracy:71.1%\r",
      "Progress:79.2% Speed(reviews/sec):4882. #Correct:80 #Tested:112 Testing Accuracy:71.4%\r",
      "Progress:80.0% Speed(reviews/sec):4875. #Correct:81 #Tested:113 Testing Accuracy:71.6%\r",
      "Progress:80.7% Speed(reviews/sec):4875. #Correct:82 #Tested:114 Testing Accuracy:71.9%\r",
      "Progress:81.4% Speed(reviews/sec):4864. #Correct:83 #Tested:115 Testing Accuracy:72.1%\r",
      "Progress:82.1% Speed(reviews/sec):4846. #Correct:83 #Tested:116 Testing Accuracy:71.5%\r",
      "Progress:82.8% Speed(reviews/sec):4840. #Correct:84 #Tested:117 Testing Accuracy:71.7%\r",
      "Progress:83.5% Speed(reviews/sec):4834. #Correct:85 #Tested:118 Testing Accuracy:72.0%\r",
      "Progress:84.2% Speed(reviews/sec):4839. #Correct:86 #Tested:119 Testing Accuracy:72.2%\r",
      "Progress:85.0% Speed(reviews/sec):4810. #Correct:86 #Tested:120 Testing Accuracy:71.6%\r",
      "Progress:85.7% Speed(reviews/sec):4796. #Correct:87 #Tested:121 Testing Accuracy:71.9%\r",
      "Progress:86.4% Speed(reviews/sec):4788. #Correct:88 #Tested:122 Testing Accuracy:72.1%\r",
      "Progress:87.1% Speed(reviews/sec):4778. #Correct:89 #Tested:123 Testing Accuracy:72.3%\r",
      "Progress:87.8% Speed(reviews/sec):4779. #Correct:89 #Tested:124 Testing Accuracy:71.7%\r",
      "Progress:88.5% Speed(reviews/sec):4755. #Correct:90 #Tested:125 Testing Accuracy:72.0%\r",
      "Progress:89.2% Speed(reviews/sec):4744. #Correct:91 #Tested:126 Testing Accuracy:72.2%\r",
      "Progress:90.0% Speed(reviews/sec):4735. #Correct:91 #Tested:127 Testing Accuracy:71.6%\r",
      "Progress:90.7% Speed(reviews/sec):4714. #Correct:91 #Tested:128 Testing Accuracy:71.0%\r",
      "Progress:91.4% Speed(reviews/sec):4716. #Correct:91 #Tested:129 Testing Accuracy:70.5%\r",
      "Progress:92.1% Speed(reviews/sec):4711. #Correct:92 #Tested:130 Testing Accuracy:70.7%\r",
      "Progress:92.8% Speed(reviews/sec):4680. #Correct:93 #Tested:131 Testing Accuracy:70.9%\r",
      "Progress:93.5% Speed(reviews/sec):4678. #Correct:94 #Tested:132 Testing Accuracy:71.2%\r",
      "Progress:94.2% Speed(reviews/sec):4673. #Correct:94 #Tested:133 Testing Accuracy:70.6%\r",
      "Progress:95.0% Speed(reviews/sec):4676. #Correct:95 #Tested:134 Testing Accuracy:70.8%\r",
      "Progress:95.7% Speed(reviews/sec):4673. #Correct:96 #Tested:135 Testing Accuracy:71.1%\r",
      "Progress:96.4% Speed(reviews/sec):4630. #Correct:97 #Tested:136 Testing Accuracy:71.3%\r",
      "Progress:97.1% Speed(reviews/sec):4627. #Correct:97 #Tested:137 Testing Accuracy:70.8%\r",
      "Progress:97.8% Speed(reviews/sec):4632. #Correct:98 #Tested:138 Testing Accuracy:71.0%\r",
      "Progress:98.5% Speed(reviews/sec):4639. #Correct:99 #Tested:139 Testing Accuracy:71.2%\r",
      "Progress:99.2% Speed(reviews/sec):4645. #Correct:100 #Tested:140 Testing Accuracy:71.4%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-140:],labels[-140:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Project 5 solution. \n",
    "## Watch the next video to continue with Andrew's next lesson.\n",
    "# Further Noise Reduction<a id='lesson_6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sentiment_network_sparse_2.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-fdd6d9dbd122>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sentiment_network_sparse_2.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Apps\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename)\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sentiment_network_sparse_2.png'"
     ]
    }
   ],
   "source": [
    "Image(filename='sentiment_network_sparse_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bs', 2.3978952727983707),\n",
       " ('antixa', 2.1972245773362196),\n",
       " ('levophed', 2.0794415416798357),\n",
       " ('drip', 2.0053335695261141),\n",
       " ('ptt', 1.9459101490553132),\n",
       " ('infused', 1.8718021769015913),\n",
       " ('ebox', 1.791759469228055),\n",
       " ('programmed', 1.791759469228055),\n",
       " ('klonopin', 1.791759469228055),\n",
       " ('pump', 1.6582280766035324),\n",
       " ('2300', 1.6094379124341003),\n",
       " ('units/kg/hr', 1.6094379124341003),\n",
       " ('anti', 1.6094379124341003),\n",
       " ('parameters', 1.6094379124341003),\n",
       " ('infusing', 1.4350845252893227),\n",
       " ('hanging', 1.3862943611198906),\n",
       " ('initial', 1.3862943611198906),\n",
       " ('urgent', 1.3862943611198906),\n",
       " ('0700', 1.3862943611198906),\n",
       " ('13', 1.3862943611198906),\n",
       " ('pt/inr', 1.3862943611198906),\n",
       " ('k+', 1.3862943611198906),\n",
       " ('1230', 1.3862943611198906),\n",
       " ('port', 1.3862943611198906),\n",
       " ('6/19', 1.3862943611198906),\n",
       " ('definity', 1.3862943611198906),\n",
       " ('anti-xa', 1.3862943611198906),\n",
       " ('connected', 1.3862943611198906),\n",
       " ('>1', 1.3862943611198906),\n",
       " ('5712', 1.3862943611198906),\n",
       " ('xa', 1.3862943611198906),\n",
       " ('pneumonia', 1.3862943611198906),\n",
       " ('1ml/hr', 1.3862943611198906),\n",
       " ('settings', 1.3862943611198906),\n",
       " ('conjugate', 1.3862943611198906),\n",
       " ('lispro', 1.3862943611198906),\n",
       " ('tpn', 1.3862943611198906),\n",
       " ('diprivan', 1.3862943611198906),\n",
       " ('1700', 1.2992829841302609),\n",
       " ('witnessed', 1.2527629684953681),\n",
       " ('pumps', 1.2527629684953681),\n",
       " ('protonix', 1.2527629684953681),\n",
       " ('fluids', 1.1895840668738364),\n",
       " ('heparin', 1.1676051601550612),\n",
       " ('approx', 1.0986122886681098),\n",
       " ('#1', 1.0986122886681098),\n",
       " ('bedside', 1.0986122886681098),\n",
       " ('6500', 1.0986122886681098),\n",
       " ('tetanus', 1.0986122886681098),\n",
       " ('vaccination', 1.0986122886681098),\n",
       " ('member', 1.0986122886681098),\n",
       " ('myself', 1.0986122886681098),\n",
       " ('knowing', 1.0986122886681098),\n",
       " ('bupropion', 1.0986122886681098),\n",
       " ('pitocin', 1.0986122886681098),\n",
       " ('7/22/15', 1.0986122886681098),\n",
       " ('1330', 1.0986122886681098),\n",
       " ('15mg', 1.0986122886681098),\n",
       " ('misread', 1.0986122886681098),\n",
       " ('kvo', 1.0986122886681098),\n",
       " ('zyrtec', 1.0986122886681098),\n",
       " ('meq', 1.0986122886681098),\n",
       " ('kcl', 1.0986122886681098),\n",
       " ('ms', 1.0986122886681098),\n",
       " ('chamber', 1.0986122886681098),\n",
       " ('separate', 1.0986122886681098),\n",
       " ('18units/kg/hr', 1.0986122886681098),\n",
       " ('15units/kg/hr', 1.0986122886681098),\n",
       " ('14units/kg/hr', 1.0986122886681098),\n",
       " ('bronchoscopy', 1.0986122886681098),\n",
       " ('3%', 1.0986122886681098),\n",
       " ('hypertonic', 1.0986122886681098),\n",
       " ('height', 1.0986122886681098),\n",
       " ('activity', 1.0986122886681098),\n",
       " ('apparent', 1.0986122886681098),\n",
       " ('intensivist', 1.0986122886681098),\n",
       " ('discontinuation', 1.0986122886681098),\n",
       " ('05ml', 1.0986122886681098),\n",
       " ('mg/min', 1.0986122886681098),\n",
       " ('49', 1.0986122886681098),\n",
       " ('11mg', 1.0986122886681098),\n",
       " ('interval', 1.0986122886681098),\n",
       " ('setting', 1.0986122886681098),\n",
       " ('1224', 1.0986122886681098),\n",
       " ('8cc/hr', 1.0986122886681098),\n",
       " ('2348', 1.0986122886681098),\n",
       " ('oxyir', 1.0986122886681098),\n",
       " ('precedex', 1.0986122886681098),\n",
       " ('protocol', 1.0608719606852626),\n",
       " ('gtt', 1.0116009116784799),\n",
       " ('bolus', 0.99852883011112725),\n",
       " ('weight', 0.96940055718810347),\n",
       " ('units', 0.95551144502743635),\n",
       " ('guardian', 0.91629073187415511),\n",
       " ('drawn', 0.91629073187415511),\n",
       " ('infuse', 0.91629073187415511),\n",
       " ('notice', 0.91629073187415511),\n",
       " ('sliding', 0.91629073187415511),\n",
       " ('occurred', 0.91629073187415511),\n",
       " ('policy', 0.91629073187415511),\n",
       " ('injections', 0.91629073187415511),\n",
       " ('happened', 0.78845736036427028),\n",
       " ('antibiotic', 0.69314718055994529),\n",
       " ('potassium', 0.69314718055994529),\n",
       " ('three', 0.69314718055994529),\n",
       " ('end', 0.69314718055994529),\n",
       " ('passed', 0.69314718055994529),\n",
       " ('pole', 0.69314718055994529),\n",
       " ('aprn', 0.69314718055994529),\n",
       " ('component', 0.69314718055994529),\n",
       " ('cap', 0.69314718055994529),\n",
       " ('reflect', 0.69314718055994529),\n",
       " ('determined', 0.69314718055994529),\n",
       " ('nothing', 0.69314718055994529),\n",
       " ('higher', 0.69314718055994529),\n",
       " ('understood', 0.69314718055994529),\n",
       " ('ultimately', 0.69314718055994529),\n",
       " ('vanco', 0.69314718055994529),\n",
       " ('teh', 0.69314718055994529),\n",
       " ('id', 0.69314718055994529),\n",
       " ('ekg', 0.69314718055994529),\n",
       " ('revealed', 0.69314718055994529),\n",
       " ('.6', 0.69314718055994529),\n",
       " ('26', 0.69314718055994529),\n",
       " ('.8', 0.69314718055994529),\n",
       " ('hospitalized', 0.69314718055994529),\n",
       " ('temporary', 0.69314718055994529),\n",
       " ('0653', 0.69314718055994529),\n",
       " ('naproxen', 0.69314718055994529),\n",
       " ('prilosec', 0.69314718055994529),\n",
       " ('forgotten', 0.69314718055994529),\n",
       " ('kaexalate', 0.69314718055994529),\n",
       " ('7/23/15', 0.69314718055994529),\n",
       " ('1840', 0.69314718055994529),\n",
       " ('penicillin', 0.69314718055994529),\n",
       " ('sdcu', 0.69314718055994529),\n",
       " ('10gm', 0.69314718055994529),\n",
       " ('pod', 0.69314718055994529),\n",
       " ('0745', 0.69314718055994529),\n",
       " ('g', 0.69314718055994529),\n",
       " ('brough', 0.69314718055994529),\n",
       " ('4/23/15', 0.69314718055994529),\n",
       " ('benefit', 0.69314718055994529),\n",
       " ('meclizine', 0.69314718055994529),\n",
       " ('31', 0.69314718055994529),\n",
       " ('inserted', 0.69314718055994529),\n",
       " ('g-tube', 0.69314718055994529),\n",
       " ('bulb', 0.69314718055994529),\n",
       " ('recognized', 0.69314718055994529),\n",
       " ('remembered', 0.69314718055994529),\n",
       " ('20meq', 0.69314718055994529),\n",
       " ('adn', 0.69314718055994529),\n",
       " ('trazodone', 0.69314718055994529),\n",
       " ('continuously', 0.69314718055994529),\n",
       " ('6/20', 0.69314718055994529),\n",
       " ('.25', 0.69314718055994529),\n",
       " ('codeine', 0.69314718055994529),\n",
       " ('meropenem', 0.69314718055994529),\n",
       " ('re-timed', 0.69314718055994529),\n",
       " ('runs', 0.69314718055994529),\n",
       " ('kayexlate', 0.69314718055994529),\n",
       " ('7/27', 0.69314718055994529),\n",
       " ('oxycodone/apap', 0.69314718055994529),\n",
       " ('igg', 0.69314718055994529),\n",
       " ('rabies', 0.69314718055994529),\n",
       " ('vacine', 0.69314718055994529),\n",
       " ('dorsogluteal', 0.69314718055994529),\n",
       " ('milrinone', 0.69314718055994529),\n",
       " ('granddaughter', 0.69314718055994529),\n",
       " ('pharmaceutical', 0.69314718055994529),\n",
       " ('company', 0.69314718055994529),\n",
       " ('restricted', 0.69314718055994529),\n",
       " ('cvtu', 0.69314718055994529),\n",
       " ('transfered', 0.69314718055994529),\n",
       " ('hx', 0.69314718055994529),\n",
       " ('stevens-johnson', 0.69314718055994529),\n",
       " ('syndrome', 0.69314718055994529),\n",
       " ('6/18', 0.69314718055994529),\n",
       " ('perflutren', 0.69314718055994529),\n",
       " ('microsphere', 0.69314718055994529),\n",
       " ('suspected', 0.69314718055994529),\n",
       " ('right-to-left', 0.69314718055994529),\n",
       " ('important', 0.69314718055994529),\n",
       " ('serious', 0.69314718055994529),\n",
       " ('cardiopulmonary', 0.69314718055994529),\n",
       " ('[see', 0.69314718055994529),\n",
       " ('precautions', 0.69314718055994529),\n",
       " (')]', 0.69314718055994529),\n",
       " ('discovery', 0.69314718055994529),\n",
       " ('1530', 0.69314718055994529),\n",
       " ('124', 0.69314718055994529),\n",
       " ('126', 0.69314718055994529),\n",
       " ('cvicu', 0.69314718055994529),\n",
       " ('committee', 0.69314718055994529),\n",
       " ('infusions', 0.69314718055994529),\n",
       " ('careful', 0.69314718055994529),\n",
       " ('c-section', 0.69314718055994529),\n",
       " ('inquired', 0.69314718055994529),\n",
       " ('mean', 0.69314718055994529),\n",
       " ('183', 0.69314718055994529),\n",
       " ('recheck', 0.69314718055994529),\n",
       " ('indicates', 0.69314718055994529),\n",
       " ('drew', 0.69314718055994529),\n",
       " ('5mg/hr', 0.69314718055994529),\n",
       " ('adrenal', 0.69314718055994529),\n",
       " ('crisis', 0.69314718055994529),\n",
       " ('negative', 0.69314718055994529),\n",
       " ('temp', 0.69314718055994529),\n",
       " ('pulm', 0.69314718055994529),\n",
       " ('2330', 0.69314718055994529),\n",
       " ('flowsheet', 0.69314718055994529),\n",
       " ('5mg/min', 0.69314718055994529),\n",
       " ('113kg', 0.69314718055994529),\n",
       " ('metoporol', 0.69314718055994529),\n",
       " ('sepsis', 0.69314718055994529),\n",
       " ('plum', 0.69314718055994529),\n",
       " ('5kg', 0.69314718055994529),\n",
       " ('105', 0.69314718055994529),\n",
       " ('8kg', 0.69314718055994529),\n",
       " ('1958', 0.69314718055994529),\n",
       " ('<0', 0.69314718055994529),\n",
       " ('identified', 0.69314718055994529),\n",
       " ('regards', 0.69314718055994529),\n",
       " ('amt', 0.69314718055994529),\n",
       " ('positive', 0.69314718055994529),\n",
       " ('clamped', 0.69314718055994529),\n",
       " ('uncharted', 0.69314718055994529),\n",
       " ('lowest', 0.69314718055994529),\n",
       " ('quadrupled', 0.69314718055994529),\n",
       " ('alarm', 0.69314718055994529),\n",
       " ('transplant', 0.69314718055994529),\n",
       " ('frequent', 0.69314718055994529),\n",
       " ('utis', 0.69314718055994529),\n",
       " ('septic', 0.69314718055994529),\n",
       " ('shock', 0.69314718055994529),\n",
       " ('slept', 0.69314718055994529),\n",
       " ('wnl', 0.69314718055994529),\n",
       " ('obs', 0.69314718055994529),\n",
       " ('pulling', 0.69314718055994529),\n",
       " ('observe', 0.69314718055994529),\n",
       " ('sterile', 0.69314718055994529),\n",
       " ('mencyw-135', 0.69314718055994529),\n",
       " ('generated', 0.69314718055994529),\n",
       " ('cow', 0.69314718055994529),\n",
       " ('accucheck', 0.69314718055994529),\n",
       " ('405', 0.69314718055994529),\n",
       " ('17:00', 0.69314718055994529),\n",
       " ('visiting', 0.69314718055994529),\n",
       " ('intreglin', 0.69314718055994529),\n",
       " ('100cc/hr', 0.69314718055994529),\n",
       " ('sigma', 0.69314718055994529),\n",
       " ('self', 0.69314718055994529),\n",
       " ('dressing', 0.69314718055994529),\n",
       " ('allergen', 0.69314718055994529),\n",
       " ('11/24/15', 0.69314718055994529),\n",
       " ('264', 0.69314718055994529),\n",
       " ('mins', 0.69314718055994529),\n",
       " ('sub', 0.69314718055994529),\n",
       " ('4/14', 0.69314718055994529),\n",
       " ('37', 0.69314718055994529),\n",
       " ('11/23/15', 0.69314718055994529),\n",
       " ('synthroid', 0.69314718055994529),\n",
       " ('12/4', 0.69314718055994529),\n",
       " ('outgoing', 0.69314718055994529),\n",
       " ('maximum', 0.69314718055994529),\n",
       " ('reprogrammed', 0.69314718055994529),\n",
       " ('8/9/15', 0.69314718055994529),\n",
       " ('mls', 0.69314718055994529),\n",
       " ('turning', 0.69314718055994529),\n",
       " ('7am', 0.69314718055994529),\n",
       " ('lactulose', 0.69314718055994529),\n",
       " (\"it's\", 0.69314718055994529),\n",
       " ('refuse', 0.69314718055994529),\n",
       " ('connector', 0.69314718055994529),\n",
       " ('5ml/hr', 0.69314718055994529),\n",
       " ('alarmed', 0.69314718055994529),\n",
       " ('alerted', 0.69314718055994529),\n",
       " ('marinol', 0.69314718055994529),\n",
       " ('preparing', 0.69314718055994529),\n",
       " ('ineffective', 0.69314718055994529),\n",
       " ('channel', 0.69314718055994529),\n",
       " ('insulin', 0.64662716492505246),\n",
       " ('running', 0.63598876671999671),\n",
       " ('realized', 0.61903920840622351),\n",
       " ('situation', 0.60613580357031549),\n",
       " ('hung', 0.5753641449035618),\n",
       " ('2100', 0.5389965007326869),\n",
       " ('mar', 0.52324814376454787),\n",
       " ('charted', 0.51082562376599072),\n",
       " ('needs', 0.51082562376599072),\n",
       " ('according', 0.51082562376599072),\n",
       " ('0930', 0.51082562376599072),\n",
       " ('decrease', 0.51082562376599072),\n",
       " ('rocephin', 0.51082562376599072),\n",
       " ('proper', 0.51082562376599072),\n",
       " ('antibiotics', 0.51082562376599072),\n",
       " ('forgot', 0.51082562376599072),\n",
       " ('fluid', 0.47000362924573563),\n",
       " (\"didn't\", 0.40546510810816438),\n",
       " ('75', 0.40546510810816438),\n",
       " ('pass', 0.40546510810816438),\n",
       " ('oriented', 0.40546510810816438),\n",
       " ('cut', 0.40546510810816438),\n",
       " ('shot', 0.40546510810816438),\n",
       " ('task', 0.40546510810816438),\n",
       " ('recieving', 0.40546510810816438),\n",
       " ('future', 0.40546510810816438),\n",
       " ('cta', 0.40546510810816438),\n",
       " ('assumed', 0.40546510810816438),\n",
       " ('1600', 0.40546510810816438),\n",
       " ('arrive', 0.40546510810816438),\n",
       " ('ambien', 0.40546510810816438),\n",
       " ('empty', 0.40546510810816438),\n",
       " ('prbc', 0.40546510810816438),\n",
       " ('baseline', 0.40546510810816438),\n",
       " ('assess', 0.40546510810816438),\n",
       " ('cm', 0.40546510810816438),\n",
       " ('tl', 0.40546510810816438),\n",
       " ('previously', 0.40546510810816438),\n",
       " ('anesthesiologist', 0.40546510810816438),\n",
       " ('properly', 0.40546510810816438),\n",
       " ('paperwork', 0.40546510810816438),\n",
       " ('hep', 0.40546510810816438),\n",
       " ('unclear', 0.40546510810816438),\n",
       " (\".'s\", 0.40546510810816438),\n",
       " ('expiration', 0.40546510810816438),\n",
       " ('shows', 0.40546510810816438),\n",
       " ('lower', 0.40546510810816438),\n",
       " ('afib', 0.40546510810816438),\n",
       " ('window', 0.40546510810816438),\n",
       " ('student', 0.40546510810816438),\n",
       " ('report', 0.37156355643248301),\n",
       " (\"wasn't\", 0.33647223662121289),\n",
       " ('tubing', 0.33647223662121289),\n",
       " ('count', 0.33647223662121289),\n",
       " ('1/2', 0.33647223662121289),\n",
       " ('site', 0.33647223662121289),\n",
       " ('im', 0.28768207245178085),\n",
       " ('line', 0.28768207245178085),\n",
       " ('secondary', 0.28768207245178085),\n",
       " ('whom', 0.28768207245178085),\n",
       " ('knew', 0.28768207245178085),\n",
       " ('long', 0.28768207245178085),\n",
       " ('1500', 0.28768207245178085),\n",
       " ('d5w', 0.28768207245178085),\n",
       " ('1900', 0.28768207245178085),\n",
       " ('east', 0.28768207245178085),\n",
       " ('anything', 0.28768207245178085),\n",
       " ('dye', 0.28768207245178085),\n",
       " ('present', 0.28768207245178085),\n",
       " ('wrist', 0.28768207245178085),\n",
       " ('admin', 0.28768207245178085),\n",
       " ('should', 0.25131442828090617),\n",
       " ('half', 0.25131442828090617),\n",
       " ('bag', 0.22314355131420976),\n",
       " ('rate', 0.22314355131420976),\n",
       " ('unknown', 0.22314355131420976),\n",
       " ('1800', 0.22314355131420976),\n",
       " ('glucose', 0.22314355131420976),\n",
       " ('80mg', 0.22314355131420976),\n",
       " ('tramadol', 0.22314355131420976),\n",
       " ('restart', 0.22314355131420976),\n",
       " ('incident', 0.22314355131420976),\n",
       " ('scale', 0.22314355131420976),\n",
       " ('night', 0.20067069546215124),\n",
       " (\"pt's\", 0.1941560144409574),\n",
       " ('writer', 0.18232155679395459),\n",
       " ('second', 0.18232155679395459),\n",
       " ('primary', 0.18232155679395459),\n",
       " ('route', 0.18232155679395459),\n",
       " ('vitals', 0.18232155679395459),\n",
       " ('shift', 0.17435338714477774),\n",
       " ('0800', 0.15415067982725836),\n",
       " ('missed', 0.13353139262452257),\n",
       " ('administration', 0.13353139262452257),\n",
       " ('.(', 0.13353139262452257),\n",
       " ('mcg', 0.13353139262452257),\n",
       " ('infusion', 0.11778303565638346),\n",
       " ('receive', 0.11778303565638346),\n",
       " ('discontinued', 0.087011376989629699),\n",
       " ('care', 0.080042707673536356),\n",
       " ('charge', 0.080042707673536356),\n",
       " ('reported', 0.080042707673536356),\n",
       " ('scanned', 0.068992871486951421),\n",
       " ('5mg', 0.06062462181643484),\n",
       " ('pca', 0.057158413839948623),\n",
       " ('new', 0.009950330853168092),\n",
       " ('2mg', 0.009950330853168092),\n",
       " ('&', 0.009950330853168092),\n",
       " ('very', 0.009950330853168092),\n",
       " ('pulled', 0.009950330853168092),\n",
       " ('24', 0.009950330853168092),\n",
       " ('lpn', 0.009950330853168092),\n",
       " ('lasix', 0.009950330853168092),\n",
       " ('along', 0.009950330853168092),\n",
       " ('dosage', 0.009950330853168092),\n",
       " ('low', 0.009950330853168092),\n",
       " ('ativan', 0.009950330853168092),\n",
       " ('wasted', 0.009950330853168092),\n",
       " ('surgeon', 0.009950330853168092),\n",
       " ('rash', 0.009950330853168092),\n",
       " ('speaking', 0.009950330853168092),\n",
       " ('supposed', 0.009950330853168092),\n",
       " ('ml/hr', 0.009950330853168092),\n",
       " ('preop', 0.009950330853168092),\n",
       " ('ivig', 0.009950330853168092),\n",
       " ('based', 0.009950330853168092),\n",
       " ('40', 0.009950330853168092),\n",
       " ('trying', 0.009950330853168092),\n",
       " ('period', 0.009950330853168092),\n",
       " ('meant', 0.009950330853168092),\n",
       " ('gotten', 0.009950330853168092),\n",
       " ('rather', 0.009950330853168092),\n",
       " ('best', 0.009950330853168092),\n",
       " ('controlled', 0.009950330853168092),\n",
       " ('0630', 0.009950330853168092),\n",
       " ('timed', 0.009950330853168092),\n",
       " ('early', 0.009950330853168092),\n",
       " ('discrepancy', 0.009950330853168092),\n",
       " ('followed', 0.009950330853168092),\n",
       " ('adjusted', 0.009950330853168092),\n",
       " ('cause', 0.009950330853168092),\n",
       " ('vistaril', 0.009950330853168092),\n",
       " ('talked', 0.009950330853168092),\n",
       " ('1300', 0.009950330853168092),\n",
       " ('probably', 0.009950330853168092),\n",
       " ('explain', 0.009950330853168092),\n",
       " ('sodium', 0.009950330853168092),\n",
       " ('therefore', 0.009950330853168092),\n",
       " ('most', 0.009950330853168092),\n",
       " ('rns', 0.009950330853168092),\n",
       " ('remove', 0.009950330853168092),\n",
       " ('attached', 0.009950330853168092),\n",
       " ('catheter', 0.009950330853168092),\n",
       " ('regular', 0.009950330853168092),\n",
       " ('okay', 0.009950330853168092),\n",
       " ('necessary', 0.009950330853168092),\n",
       " ('entire', 0.009950330853168092),\n",
       " ('6/19/15', 0.009950330853168092),\n",
       " ('immediatley', 0.009950330853168092),\n",
       " ('abd', 0.009950330853168092),\n",
       " ('lr', 0.009950330853168092),\n",
       " ('causing', 0.009950330853168092),\n",
       " ('narc', 0.009950330853168092),\n",
       " ('witness', 0.009950330853168092),\n",
       " ('levels', 0.009950330853168092),\n",
       " ('hooked', 0.009950330853168092),\n",
       " ('inadvertently', 0.009950330853168092),\n",
       " ('23', 0.009950330853168092),\n",
       " ('significantly', 0.009950330853168092),\n",
       " ('2000', 0.009950330853168092),\n",
       " ('omeprazole', 0.009950330853168092),\n",
       " ('possibly', 0.009950330853168092),\n",
       " ('imdur', 0.009950330853168092),\n",
       " ('4/17', 0.009950330853168092),\n",
       " ('.25mg', 0.009950330853168092),\n",
       " ('noon', 0.009950330853168092),\n",
       " ('hang', 0.009950330853168092),\n",
       " ('0200', 0.009950330853168092),\n",
       " ('asap', 0.009950330853168092),\n",
       " ('subq', 0.009950330853168092),\n",
       " ('alprazolam', 0.009950330853168092),\n",
       " ('1000', 0.009950330853168092),\n",
       " ('female', 0.009950330853168092),\n",
       " ('1930', 0.009950330853168092),\n",
       " ('measures', 0.009950330853168092),\n",
       " ('bleed', 0.009950330853168092),\n",
       " ('octreotide', 0.009950330853168092),\n",
       " ('ventricular', 0.009950330853168092),\n",
       " ('solution', 0.009950330853168092),\n",
       " ('body', 0.009950330853168092),\n",
       " ('reactions', 0.009950330853168092),\n",
       " ('draw', 0.009950330853168092),\n",
       " ('fix', 0.009950330853168092),\n",
       " ('addition', 0.009950330853168092),\n",
       " ('talk', 0.009950330853168092),\n",
       " ('locked', 0.009950330853168092),\n",
       " ('attempts', 0.009950330853168092),\n",
       " ('cc/hr', 0.009950330853168092),\n",
       " ('lead', 0.009950330853168092),\n",
       " ('pe', 0.009950330853168092),\n",
       " ('six', 0.009950330853168092),\n",
       " ('gone', 0.009950330853168092),\n",
       " ('agitated', 0.009950330853168092),\n",
       " ('repeat', 0.009950330853168092),\n",
       " ('diluent', 0.009950330853168092),\n",
       " ('follow-up', 0.009950330853168092),\n",
       " ('5-fu', 0.009950330853168092),\n",
       " ('d/t', 0.009950330853168092),\n",
       " ('admit', 0.009950330853168092),\n",
       " ('shoulder', 0.009950330853168092),\n",
       " ('titrate', 0.009950330853168092),\n",
       " ('hour', -0.043566986636409621),\n",
       " ('while', -0.050055670467200608),\n",
       " ('given', -0.061005983833861945),\n",
       " ('already', -0.063396316558794116),\n",
       " ('instead', -0.066218944604226199),\n",
       " ('over', -0.076161360965564029),\n",
       " ('monitor', -0.076161360965564029),\n",
       " ('hours', -0.080078940213985011),\n",
       " ('noticed', -0.084370239765990521),\n",
       " ('verify', -0.084370239765990521),\n",
       " ('previous', -0.084370239765990521),\n",
       " ('looked', -0.09431067947124129),\n",
       " ('documentation', -0.10659584626581911),\n",
       " ('tab', -0.12216763397420753),\n",
       " ('vial', -0.12216763397420753),\n",
       " ('transfer', -0.12216763397420753),\n",
       " ('adverse', -0.12216763397420753),\n",
       " ('total', -0.12216763397420753),\n",
       " ('procedure', -0.12216763397420753),\n",
       " ('current', -0.14255154398390646),\n",
       " ('nurse', -0.14462595378050636),\n",
       " ('scheduled', -0.15082288973458366),\n",
       " ('information', -0.15530519217408328),\n",
       " ('7', -0.15530519217408328),\n",
       " ('ns', -0.15530519217408328),\n",
       " ('per', -0.15730379381866677),\n",
       " ('2200', -0.17039298592868077),\n",
       " ('full', -0.17039298592868077),\n",
       " ('want', -0.17039298592868077),\n",
       " ('12', -0.17039298592868077),\n",
       " ('related', -0.17039298592868077),\n",
       " ('much', -0.17039298592868077),\n",
       " ('appears', -0.17039298592868077),\n",
       " ('remained', -0.17039298592868077),\n",
       " ('error', -0.18852256152650351),\n",
       " ('1mg', -0.18852256152650351),\n",
       " ('set', -0.21072103131565253),\n",
       " ('15', -0.21072103131565253),\n",
       " ('you', -0.21072103131565253),\n",
       " ('ask', -0.21072103131565253),\n",
       " ('few', -0.21072103131565253),\n",
       " ('nor', -0.21072103131565253),\n",
       " ('ran', -0.21072103131565253),\n",
       " ('icu', -0.23853923679218322),\n",
       " ('follow', -0.23853923679218322),\n",
       " ('4mg', -0.23853923679218322),\n",
       " ('solumedrol', -0.23853923679218322),\n",
       " ('vaccine', -0.24944803920094466),\n",
       " ('last', -0.24944803920094466),\n",
       " ('pt', -0.25439609481831421),\n",
       " ('only', -0.25889410197583829),\n",
       " ('morning', -0.25889410197583829),\n",
       " ('about', -0.26136476413440751),\n",
       " ('when', -0.2744368457017603),\n",
       " ('my', -0.2744368457017603),\n",
       " ('what', -0.2744368457017603),\n",
       " ('never', -0.2744368457017603),\n",
       " ('every', -0.2744368457017603),\n",
       " ('pill', -0.2744368457017603),\n",
       " ('dosing', -0.2744368457017603),\n",
       " ('stable', -0.2744368457017603),\n",
       " ('0730', -0.2744368457017603),\n",
       " ('including', -0.2744368457017603),\n",
       " ('think', -0.2744368457017603),\n",
       " ('suppose', -0.2744368457017603),\n",
       " ('attention', -0.2744368457017603),\n",
       " ('initially', -0.2744368457017603),\n",
       " ('accidentally', -0.2744368457017603),\n",
       " ('administering', -0.2744368457017603),\n",
       " ('gi', -0.2744368457017603),\n",
       " ('verifying', -0.2744368457017603),\n",
       " ('vital', -0.2744368457017603),\n",
       " ('notify', -0.2744368457017603),\n",
       " ('notifed', -0.2744368457017603),\n",
       " ('off', -0.28884216538931151),\n",
       " ('found', -0.29661070319608235),\n",
       " ('later', -0.29661070319608235),\n",
       " ('med', -0.29950799625569546),\n",
       " ('due', -0.30147038959163674),\n",
       " ('read', -0.30479740467104893),\n",
       " ('around', -0.30479740467104893),\n",
       " ('i', -0.31684095467199835),\n",
       " ('effects', -0.3225693314522215),\n",
       " ('decreased', -0.3225693314522215),\n",
       " ('monitored', -0.3225693314522215),\n",
       " ('give', -0.32696204662022071),\n",
       " ('at', -0.33401372278300556),\n",
       " ('iv', -0.33831551858048403),\n",
       " ('levaquin', -0.34249030894677601),\n",
       " ('alert', -0.34249030894677601),\n",
       " ('hr', -0.35338366285465966),\n",
       " ('50', -0.35338366285465966),\n",
       " ('event', -0.35338366285465966),\n",
       " ('one', -0.35599490311007687),\n",
       " ('who', -0.35716767614875056),\n",
       " ('with', -0.36067752721394608),\n",
       " ('change', -0.36498001243721717),\n",
       " ('came', -0.3710636813908319),\n",
       " ('notified', -0.37553296257312901),\n",
       " ('which', -0.37735053903303395),\n",
       " ('1', -0.38325099219405839),\n",
       " ('[redacted]', -0.38618782886714587),\n",
       " ('gave', -0.39057649561441377),\n",
       " ('blood', -0.39057649561441377),\n",
       " ('until', -0.39057649561441377),\n",
       " ('aware', -0.39057649561441377),\n",
       " ('x', -0.39057649561441377),\n",
       " ('done', -0.39057649561441377),\n",
       " ('than', -0.39057649561441377),\n",
       " ('note', -0.39057649561441377),\n",
       " ('sugar', -0.39057649561441377),\n",
       " ('attempted', -0.39057649561441377),\n",
       " ('inform', -0.39057649561441377),\n",
       " ('eye', -0.39057649561441377),\n",
       " ('plavix', -0.39057649561441377),\n",
       " ('refused', -0.39057649561441377),\n",
       " ('appropriate', -0.39057649561441377),\n",
       " ('flush', -0.39057649561441377),\n",
       " ('pts', -0.39057649561441377),\n",
       " ('run', -0.39057649561441377),\n",
       " ('16', -0.39057649561441377),\n",
       " ('each', -0.39057649561441377),\n",
       " ('help', -0.39057649561441377),\n",
       " (\"physician's\", -0.39057649561441377),\n",
       " ('carried', -0.39057649561441377),\n",
       " ('immunization', -0.39057649561441377),\n",
       " ('appear', -0.39057649561441377),\n",
       " ('regardless', -0.39057649561441377),\n",
       " ('find', -0.39057649561441377),\n",
       " ('b/c', -0.39057649561441377),\n",
       " ('control', -0.39057649561441377),\n",
       " ('tpa', -0.39057649561441377),\n",
       " ('education', -0.39057649561441377),\n",
       " ('showing', -0.39057649561441377),\n",
       " ('labs', -0.39057649561441377),\n",
       " ('failed', -0.39057649561441377),\n",
       " ('supervisor', -0.39057649561441377),\n",
       " ('assessment', -0.39057649561441377),\n",
       " ('hypoglycemia', -0.39057649561441377),\n",
       " ('1gm', -0.39057649561441377),\n",
       " ('effect', -0.39057649561441377),\n",
       " ('schedule', -0.39057649561441377),\n",
       " ('resolved', -0.39057649561441377),\n",
       " ('charges', -0.39057649561441377),\n",
       " ('0935', -0.39057649561441377),\n",
       " ('exactly', -0.39057649561441377),\n",
       " (\"rn's\", -0.39057649561441377),\n",
       " ('completely', -0.39057649561441377),\n",
       " ('drugs', -0.39057649561441377),\n",
       " ('created', -0.39057649561441377),\n",
       " ('year', -0.39057649561441377),\n",
       " ('central', -0.39057649561441377),\n",
       " ('calling', -0.39057649561441377),\n",
       " ('believed', -0.39057649561441377),\n",
       " ('300', -0.39057649561441377),\n",
       " ('clarified', -0.39057649561441377),\n",
       " ('systolic', -0.39057649561441377),\n",
       " ('together', -0.39057649561441377),\n",
       " ('steroid', -0.39057649561441377),\n",
       " ('against', -0.39057649561441377),\n",
       " ('bilateral', -0.39057649561441377),\n",
       " ('18', -0.39057649561441377),\n",
       " ('whether', -0.39057649561441377),\n",
       " ('max', -0.39057649561441377),\n",
       " ('f/u', -0.39057649561441377),\n",
       " ('strength', -0.39057649561441377),\n",
       " ('equal', -0.39057649561441377),\n",
       " ('looking', -0.39057649561441377),\n",
       " ('abilify', -0.39057649561441377),\n",
       " ('states', -0.40475107737450733),\n",
       " ('be', -0.40770900306883634),\n",
       " ('there', -0.41088794842961773),\n",
       " ('again', -0.41998173097510666),\n",
       " ('xxxx', -0.42639694414919987),\n",
       " ('been', -0.43009171164122656),\n",
       " ('left', -0.43078291609245423),\n",
       " ('or', -0.43179225253948589),\n",
       " ('level', -0.43639302898322102),\n",
       " ('of', -0.44852174042983584),\n",
       " ('er', -0.45413028008944539),\n",
       " ('increased', -0.45413028008944539),\n",
       " ('down', -0.45413028008944539),\n",
       " ('seen', -0.45413028008944539),\n",
       " ('0900', -0.45413028008944539),\n",
       " ('waste', -0.45413028008944539),\n",
       " ('by', -0.46840490788203853),\n",
       " ('once', -0.46938843390181745),\n",
       " ('it', -0.47167945125602956),\n",
       " ('am', -0.47336410804472312),\n",
       " ('removed', -0.47336410804472312),\n",
       " ('started', -0.48014180382738864),\n",
       " ('ordered', -0.48126682152444628),\n",
       " ('so', -0.48570520368246339),\n",
       " ('0', -0.49429632181478012),\n",
       " ('went', -0.49429632181478012),\n",
       " ('saline', -0.49429632181478012),\n",
       " ('ivpb', -0.49429632181478012),\n",
       " ('issue', -0.49429632181478012),\n",
       " ('thinking', -0.49429632181478012),\n",
       " ('busy', -0.49429632181478012),\n",
       " ('quickmar', -0.49429632181478012),\n",
       " ('metformin', -0.49429632181478012),\n",
       " ('delay', -0.49429632181478012),\n",
       " ('access', -0.49429632181478012),\n",
       " ('held', -0.49429632181478012),\n",
       " ('.5mg', -0.49429632181478012),\n",
       " ('hs', -0.49429632181478012),\n",
       " ('stating', -0.49429632181478012),\n",
       " ('decided', -0.49429632181478012),\n",
       " ('versed', -0.49429632181478012),\n",
       " ('no', -0.51377113399574748),\n",
       " ('start', -0.51377113399574748),\n",
       " ('is', -0.51761948318739881),\n",
       " ('noted', -0.52199892436411588),\n",
       " ('does', -0.52199892436411588),\n",
       " ('mistake', -0.52199892436411588),\n",
       " ('available', -0.52941845684260658),\n",
       " ('that', -0.533972820956642),\n",
       " ('have', -0.53428711044498867),\n",
       " ('doctor', -0.537053101602876),\n",
       " ('was', -0.53717907268260212),\n",
       " ('staff', -0.54226714960080968),\n",
       " ('labeled', -0.54226714960080968),\n",
       " ('heart', -0.54226714960080968),\n",
       " ('issues', -0.54226714960080968),\n",
       " ('harm', -0.54226714960080968),\n",
       " ('kept', -0.54226714960080968),\n",
       " ('checking', -0.54226714960080968),\n",
       " ('either', -0.54226714960080968),\n",
       " ('double', -0.54226714960080968),\n",
       " ('mom', -0.54226714960080968),\n",
       " ('dr', -0.54429979456758359),\n",
       " ('day', -0.55300723780228545),\n",
       " ('said', -0.55494721551898296),\n",
       " ('documented', -0.55774254355374231),\n",
       " ('had', -0.56538823042391328),\n",
       " ('times', -0.56994674677378798),\n",
       " ('manager', -0.56994674677378798),\n",
       " ('emergency', -0.56994674677378798),\n",
       " ('showed', -0.56994674677378798),\n",
       " ('into', -0.57513025412948648),\n",
       " ('emar', -0.57981849525294205),\n",
       " ('dose', -0.58270283529702838),\n",
       " ('stated', -0.58796849961486664),\n",
       " ('recieved', -0.58796849961486664),\n",
       " ('time', -0.59084396526464977),\n",
       " ('well', -0.60063812303533215),\n",
       " ('just', -0.60063812303533215),\n",
       " ('continuous', -0.60063812303533215),\n",
       " ('do', -0.6100322738494387),\n",
       " ('continue', -0.6100322738494387),\n",
       " ('thought', -0.6100322738494387),\n",
       " ('use', -0.6100322738494387),\n",
       " ('however', -0.61727605778784256),\n",
       " ('unit', -0.61727605778784256),\n",
       " ('.', -0.61914695172256906),\n",
       " ('not', -0.62855024991328956),\n",
       " ('morphine', -0.63330718020392829),\n",
       " ('another', -0.64009681004550301),\n",
       " ('floor', -0.64220878785222379),\n",
       " ('as', -0.64371451176866157),\n",
       " ('administered', -0.65080076716144541),\n",
       " ('then', -0.65881785969403395),\n",
       " ('the', -0.66515026607338834),\n",
       " ('bp', -0.67334455326376563),\n",
       " ('two', -0.67334455326376563),\n",
       " ('next', -0.67334455326376563),\n",
       " ('made', -0.67334455326376563),\n",
       " ('discovered', -0.67334455326376563),\n",
       " ('check', -0.67334455326376563),\n",
       " ('need', -0.67334455326376563),\n",
       " ('bottle', -0.67334455326376563),\n",
       " ('10mg', -0.67334455326376563),\n",
       " ('transferred', -0.67334455326376563),\n",
       " ('normal', -0.67334455326376563),\n",
       " ('further', -0.67334455326376563),\n",
       " ('actually', -0.67334455326376563),\n",
       " ('administer', -0.67334455326376563),\n",
       " ('drawer', -0.67334455326376563),\n",
       " ('review', -0.67334455326376563),\n",
       " ('unable', -0.67334455326376563),\n",
       " ('anesthesia', -0.67334455326376563),\n",
       " ('syringe', -0.67334455326376563),\n",
       " ('fentanyl', -0.67334455326376563),\n",
       " ('verbal', -0.67334455326376563),\n",
       " ('their', -0.67334455326376563),\n",
       " ('make', -0.67334455326376563),\n",
       " ('liquid', -0.67334455326376563),\n",
       " ('within', -0.67334455326376563),\n",
       " ('arrival', -0.67334455326376563),\n",
       " ('dropped', -0.67334455326376563),\n",
       " ('restarted', -0.67334455326376563),\n",
       " ('old', -0.67334455326376563),\n",
       " ('concerns', -0.67334455326376563),\n",
       " ('yet', -0.67334455326376563),\n",
       " ('questioned', -0.67334455326376563),\n",
       " ('between', -0.67334455326376563),\n",
       " ('kg', -0.67334455326376563),\n",
       " ('k', -0.67334455326376563),\n",
       " ('close', -0.67334455326376563),\n",
       " ('zosyn', -0.67334455326376563),\n",
       " ('levothyroxine', -0.67334455326376563),\n",
       " ('cerner', -0.67334455326376563),\n",
       " ('area', -0.67334455326376563),\n",
       " ('patches', -0.67334455326376563),\n",
       " ('weighed', -0.67334455326376563),\n",
       " ('11', -0.67334455326376563),\n",
       " ('grabbed', -0.67334455326376563),\n",
       " ('hypotension', -0.67334455326376563),\n",
       " ('stop', -0.67334455326376563),\n",
       " ('cart', -0.67334455326376563),\n",
       " ('250mg', -0.67334455326376563),\n",
       " ('femoral', -0.67334455326376563),\n",
       " ('b/p', -0.67334455326376563),\n",
       " ('qam', -0.67334455326376563),\n",
       " ('caring', -0.67334455326376563),\n",
       " ('apologized', -0.67334455326376563),\n",
       " ('none', -0.67334455326376563),\n",
       " ('tube', -0.67334455326376563),\n",
       " ('opened', -0.67334455326376563),\n",
       " ('60mg', -0.67334455326376563),\n",
       " ('recorded', -0.67334455326376563),\n",
       " ('q12h', -0.67334455326376563),\n",
       " ('anxiety', -0.67334455326376563),\n",
       " ('confusion', -0.67334455326376563),\n",
       " ('chloride', -0.67334455326376563),\n",
       " ('located', -0.67334455326376563),\n",
       " ('5/325mg', -0.67334455326376563),\n",
       " (\"don't\", -0.67334455326376563),\n",
       " ('speak', -0.67334455326376563),\n",
       " ('original', -0.67334455326376563),\n",
       " ('onto', -0.67334455326376563),\n",
       " ('currently', -0.67334455326376563),\n",
       " ('actual', -0.67334455326376563),\n",
       " ('range', -0.67334455326376563),\n",
       " ('abdominal', -0.67334455326376563),\n",
       " ('above', -0.67334455326376563),\n",
       " ('table', -0.67334455326376563),\n",
       " ('communicated', -0.67334455326376563),\n",
       " ('reached', -0.67334455326376563),\n",
       " ('resumed', -0.67334455326376563),\n",
       " ('upset', -0.67334455326376563),\n",
       " ('us', -0.67334455326376563),\n",
       " ('norco', -0.67334455326376563),\n",
       " ('inquire', -0.67334455326376563),\n",
       " ('m', -0.67334455326376563),\n",
       " ('pounds', -0.67334455326376563),\n",
       " ('kilograms', -0.67334455326376563),\n",
       " ('adult', -0.67334455326376563),\n",
       " ('calculated', -0.67334455326376563),\n",
       " ('wellbutrin', -0.67334455326376563),\n",
       " ('92', -0.67334455326376563),\n",
       " ('apn', -0.67334455326376563),\n",
       " ('hib', -0.67334455326376563),\n",
       " ('labeling', -0.67334455326376563),\n",
       " ('originally', -0.67334455326376563),\n",
       " ('thrombolytic', -0.67334455326376563),\n",
       " ('drawing', -0.67334455326376563),\n",
       " ('catch', -0.67334455326376563),\n",
       " ('sheets', -0.67334455326376563),\n",
       " ('60', -0.67334455326376563),\n",
       " ('decreasing', -0.67334455326376563),\n",
       " ('noc', -0.67334455326376563),\n",
       " ('325mg', -0.67334455326376563),\n",
       " ('cephalosporins', -0.67334455326376563),\n",
       " ('o', -0.67334455326376563),\n",
       " ('delivering', -0.67334455326376563),\n",
       " ('meningococcal', -0.67334455326376563),\n",
       " ('menveo', -0.67334455326376563),\n",
       " ('reconstituted', -0.67334455326376563),\n",
       " ('reverse', -0.67334455326376563),\n",
       " ('anticipated', -0.67334455326376563),\n",
       " ('rounding', -0.67334455326376563),\n",
       " ('show', -0.67334455326376563),\n",
       " ('couple', -0.67334455326376563),\n",
       " ('anxious', -0.67334455326376563),\n",
       " ('follows:', -0.67334455326376563),\n",
       " ('phenergan', -0.67334455326376563),\n",
       " ('closing', -0.67334455326376563),\n",
       " ('1830-1845', -0.67334455326376563),\n",
       " ('alteplase', -0.67334455326376563),\n",
       " ('[hospital]', -0.67334455326376563),\n",
       " ('s/p', -0.67334455326376563),\n",
       " ('dispensing', -0.67334455326376563),\n",
       " ('platelet', -0.67334455326376563),\n",
       " ('dvt', -0.67334455326376563),\n",
       " ('platelets', -0.67334455326376563),\n",
       " ('encephalopathy', -0.67334455326376563),\n",
       " ('simvastatin', -0.67334455326376563),\n",
       " ('caps', -0.67334455326376563),\n",
       " ('miss', -0.67334455326376563),\n",
       " ('fish', -0.67334455326376563),\n",
       " ('oil', -0.67334455326376563),\n",
       " (',rn', -0.67334455326376563),\n",
       " ('atarax', -0.67334455326376563),\n",
       " ('2/22', -0.67334455326376563),\n",
       " ('activated', -0.67334455326376563),\n",
       " ('6/14/15', -0.67334455326376563),\n",
       " ('2/15/15', -0.67334455326376563),\n",
       " ('authenticated', -0.67334455326376563),\n",
       " ('q4h', -0.67334455326376563),\n",
       " ('dated', -0.67334455326376563),\n",
       " ('5/31/15', -0.67334455326376563),\n",
       " ('diltiazem', -0.67334455326376563),\n",
       " ('1427', -0.67334455326376563),\n",
       " ('x4', -0.67334455326376563),\n",
       " ('surg', -0.67334455326376563),\n",
       " ('crna', -0.67334455326376563),\n",
       " ('alone', -0.67334455326376563),\n",
       " ('96', -0.67334455326376563),\n",
       " ('flonase', -0.67334455326376563),\n",
       " ('r/t', -0.67334455326376563),\n",
       " ('type', -0.67334455326376563),\n",
       " ('q6', -0.67334455326376563),\n",
       " ('3pm', -0.67334455326376563),\n",
       " ('recevied', -0.67334455326376563),\n",
       " ('somehow', -0.67334455326376563),\n",
       " ('conversation', -0.67334455326376563),\n",
       " ('0926', -0.67334455326376563),\n",
       " ('108', -0.67334455326376563),\n",
       " ('10/10', -0.67334455326376563),\n",
       " ('1020', -0.67334455326376563),\n",
       " ('vomit', -0.67334455326376563),\n",
       " ('81', -0.67334455326376563),\n",
       " ('awake', -0.67334455326376563),\n",
       " ('decompression', -0.67334455326376563),\n",
       " ('associated', -0.67334455326376563),\n",
       " ('slowed', -0.67334455326376563),\n",
       " ('seemed', -0.67334455326376563),\n",
       " ('helping', -0.67334455326376563),\n",
       " ('explaining', -0.67334455326376563),\n",
       " ('dosed', -0.67334455326376563),\n",
       " ('expect', -0.67334455326376563),\n",
       " ('provide', -0.67334455326376563),\n",
       " ('6/17', -0.67334455326376563),\n",
       " ('raised', -0.67334455326376563),\n",
       " ('agent', -0.67334455326376563),\n",
       " ('improve', -0.67334455326376563),\n",
       " ('hypersensitivity', -0.67334455326376563),\n",
       " ('warnings', -0.67334455326376563),\n",
       " ('contraindications', -0.67334455326376563),\n",
       " ('isolation', -0.67334455326376563),\n",
       " ('others', -0.67334455326376563),\n",
       " ('awaiting', -0.67334455326376563),\n",
       " ('emergent', -0.67334455326376563),\n",
       " ('cared', -0.67334455326376563),\n",
       " ('1101', -0.67334455326376563),\n",
       " ('final', -0.67334455326376563),\n",
       " ('cv', -0.67334455326376563),\n",
       " ('<', -0.67334455326376563),\n",
       " ('diastolic', -0.67334455326376563),\n",
       " ('911', -0.67334455326376563),\n",
       " ('1226', -0.67334455326376563),\n",
       " ('least', -0.67334455326376563),\n",
       " ('despite', -0.67334455326376563),\n",
       " ('communicate', -0.67334455326376563),\n",
       " ('meditech', -0.67334455326376563),\n",
       " ('address', -0.67334455326376563),\n",
       " ('1257', -0.67334455326376563),\n",
       " ('on-call', -0.67334455326376563),\n",
       " ('metabolic', -0.67334455326376563),\n",
       " (\"'did\", -0.67334455326376563),\n",
       " ('likely', -0.67334455326376563),\n",
       " ('contributing', -0.67334455326376563),\n",
       " ('include', -0.67334455326376563),\n",
       " ('effective', -0.67334455326376563),\n",
       " ('41/19', -0.67334455326376563),\n",
       " ('yyy', -0.67334455326376563),\n",
       " ('resume', -0.67334455326376563),\n",
       " ('2-3', -0.67334455326376563),\n",
       " ('life', -0.67334455326376563),\n",
       " ('unsuccessful', -0.67334455326376563),\n",
       " ('#', -0.67334455326376563),\n",
       " ('fellow', -0.67334455326376563),\n",
       " ('st', -0.67334455326376563),\n",
       " ('surgical', -0.67334455326376563),\n",
       " ('1915', -0.67334455326376563),\n",
       " ('updated', -0.67334455326376563),\n",
       " ('comfortably', -0.67334455326376563),\n",
       " ('admitting', -0.67334455326376563),\n",
       " ('progress', -0.67334455326376563),\n",
       " ('turn', -0.67334455326376563),\n",
       " ('14', -0.67334455326376563),\n",
       " ('board', -0.67334455326376563),\n",
       " ('comfort', -0.67334455326376563),\n",
       " ('ad', -0.67334455326376563),\n",
       " ('finishing', -0.67334455326376563),\n",
       " ('9/8/15', -0.67334455326376563),\n",
       " ('tachycardic', -0.67334455326376563),\n",
       " (\"shouldn't\", -0.67334455326376563),\n",
       " ('tele', -0.67334455326376563),\n",
       " ('sugars', -0.67334455326376563),\n",
       " ('occasions', -0.67334455326376563),\n",
       " ('spoken', -0.67334455326376563),\n",
       " ('8/6/15', -0.67334455326376563),\n",
       " ('8/8/15', -0.67334455326376563),\n",
       " ('trouble', -0.67334455326376563),\n",
       " ('lasted', -0.67334455326376563),\n",
       " ('leaving', -0.67334455326376563),\n",
       " ('asleep', -0.67334455326376563),\n",
       " ('contained', -0.67334455326376563),\n",
       " ('complications', -0.67334455326376563),\n",
       " ('transport', -0.67334455326376563),\n",
       " ('1303', -0.67334455326376563),\n",
       " ('w/', -0.67334455326376563),\n",
       " ('0547', -0.67334455326376563),\n",
       " ('ibuprofen', -0.67334455326376563),\n",
       " ('28', -0.67334455326376563),\n",
       " ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words most frequently seen in a review with a \"POSITIVE\" label\n",
    "pos_neg_ratios.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('400mg/5ml', -4.6051701859880909),\n",
       " ('azithromycin', -4.6051701859880909),\n",
       " ('tolerated', -4.6051701859880909),\n",
       " (\"dc'd\", -4.6051701859880909),\n",
       " ('co', -4.6051701859880909),\n",
       " ('mail', -4.6051701859880909),\n",
       " ('encounter', -4.6051701859880909),\n",
       " ('145', -4.6051701859880909),\n",
       " ('176', -4.6051701859880909),\n",
       " ('creat', -4.6051701859880909),\n",
       " ('lbs', -4.6051701859880909),\n",
       " ('delated', -4.6051701859880909),\n",
       " ('preterm', -4.6051701859880909),\n",
       " ('mg/kg', -4.6051701859880909),\n",
       " (\"inr's\", -4.6051701859880909),\n",
       " ('7/23', -4.6051701859880909),\n",
       " ('depo-medrol', -4.6051701859880909),\n",
       " ('7/28/15', -4.6051701859880909),\n",
       " ('add', -4.6051701859880909),\n",
       " ('06/05/15', -4.6051701859880909),\n",
       " ('5mcg/kg/hr', -4.6051701859880909),\n",
       " ('freezer', -4.6051701859880909),\n",
       " ('letter', -4.6051701859880909),\n",
       " ('2s', -4.6051701859880909),\n",
       " ('infection', -4.6051701859880909),\n",
       " ('hr64', -4.6051701859880909),\n",
       " ('nebivolol', -4.6051701859880909),\n",
       " ('98-99%', -4.6051701859880909),\n",
       " ('wheezing', -4.6051701859880909),\n",
       " ('lpm', -4.6051701859880909)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words most frequently seen in a review with a \"NEGATIVE\" label\n",
    "list(reversed(pos_neg_ratios.most_common()))[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"e95da0ca-c449-4b7e-b734-5e2994ad02af\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = \"1\";\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      Bokeh.$(\"#e95da0ca-c449-4b7e-b734-5e2994ad02af\").text(\"BokehJS successfully loaded.\");\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"e95da0ca-c449-4b7e-b734-5e2994ad02af\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'e95da0ca-c449-4b7e-b734-5e2994ad02af' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.12.3.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.3.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      Bokeh.$(\"#e95da0ca-c449-4b7e-b734-5e2994ad02af\").text(\"BokehJS is loading...\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.3.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.3.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === \"1\")) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === \"1\") {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (!force) {\n",
       "      var cell = $(\"#e95da0ca-c449-4b7e-b734-5e2994ad02af\").parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "range parameter must be finite.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-393be0b15318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_neg_ratios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m p = figure(tools=\"pan,wheel_zoom,reset,save\",\n\u001b[1;32m      4\u001b[0m            \u001b[0mtoolbar_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"above\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            title=\"Word Positive/Negative Affinity Distribution\")\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         raise ValueError(\n\u001b[0;32m--> 669\u001b[0;31m             'range parameter must be finite.')\n\u001b[0m\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mmn\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: range parameter must be finite."
     ]
    }
   ],
   "source": [
    "hist, edges = np.histogram(list(map(lambda x:x[1],pos_neg_ratios.most_common())), density=True, bins=100, normed=True)\n",
    "\n",
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"Word Positive/Negative Affinity Distribution\")\n",
    "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency_frequency = Counter()\n",
    "\n",
    "for word, cnt in total_counts.most_common():\n",
    "    frequency_frequency[cnt] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <div class=\"plotdiv\" id=\"6a21ce79-2748-467e-9bb8-0b45daab4e46\"></div>\n",
       "    </div>\n",
       "<script type=\"text/javascript\">\n",
       "  \n",
       "  (function(global) {\n",
       "    function now() {\n",
       "      return new Date();\n",
       "    }\n",
       "  \n",
       "    var force = \"\";\n",
       "  \n",
       "    if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "      window._bokeh_onload_callbacks = [];\n",
       "      window._bokeh_is_loading = undefined;\n",
       "    }\n",
       "  \n",
       "  \n",
       "    \n",
       "    if (typeof (window._bokeh_timeout) === \"undefined\" || force !== \"\") {\n",
       "      window._bokeh_timeout = Date.now() + 0;\n",
       "      window._bokeh_failed_load = false;\n",
       "    }\n",
       "  \n",
       "    var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "       \"<div style='background-color: #fdd'>\\n\"+\n",
       "       \"<p>\\n\"+\n",
       "       \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "       \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "       \"</p>\\n\"+\n",
       "       \"<ul>\\n\"+\n",
       "       \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "       \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "       \"</ul>\\n\"+\n",
       "       \"<code>\\n\"+\n",
       "       \"from bokeh.resources import INLINE\\n\"+\n",
       "       \"output_notebook(resources=INLINE)\\n\"+\n",
       "       \"</code>\\n\"+\n",
       "       \"</div>\"}};\n",
       "  \n",
       "    function display_loaded() {\n",
       "      if (window.Bokeh !== undefined) {\n",
       "        Bokeh.$(\"#6a21ce79-2748-467e-9bb8-0b45daab4e46\").text(\"BokehJS successfully loaded.\");\n",
       "      } else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(display_loaded, 100)\n",
       "      }\n",
       "    }\n",
       "  \n",
       "    function run_callbacks() {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "      delete window._bokeh_onload_callbacks\n",
       "      console.info(\"Bokeh: all callbacks have finished\");\n",
       "    }\n",
       "  \n",
       "    function load_libs(js_urls, callback) {\n",
       "      window._bokeh_onload_callbacks.push(callback);\n",
       "      if (window._bokeh_is_loading > 0) {\n",
       "        console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "        return null;\n",
       "      }\n",
       "      if (js_urls == null || js_urls.length === 0) {\n",
       "        run_callbacks();\n",
       "        return null;\n",
       "      }\n",
       "      console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      window._bokeh_is_loading = js_urls.length;\n",
       "      for (var i = 0; i < js_urls.length; i++) {\n",
       "        var url = js_urls[i];\n",
       "        var s = document.createElement('script');\n",
       "        s.src = url;\n",
       "        s.async = false;\n",
       "        s.onreadystatechange = s.onload = function() {\n",
       "          window._bokeh_is_loading--;\n",
       "          if (window._bokeh_is_loading === 0) {\n",
       "            console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "            run_callbacks()\n",
       "          }\n",
       "        };\n",
       "        s.onerror = function() {\n",
       "          console.warn(\"failed to load library \" + url);\n",
       "        };\n",
       "        console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      }\n",
       "    };var element = document.getElementById(\"6a21ce79-2748-467e-9bb8-0b45daab4e46\");\n",
       "    if (element == null) {\n",
       "      console.log(\"Bokeh: ERROR: autoload.js configured with elementid '6a21ce79-2748-467e-9bb8-0b45daab4e46' but no matching script tag was found. \")\n",
       "      return false;\n",
       "    }\n",
       "  \n",
       "    var js_urls = [];\n",
       "  \n",
       "    var inline_js = [\n",
       "      function(Bokeh) {\n",
       "        Bokeh.$(function() {\n",
       "            var docs_json = {\"6cacc291-5900-478a-a7d9-9241b96791df\":{\"roots\":{\"references\":[{\"attributes\":{\"plot\":{\"id\":\"965c01f5-3e9b-40b3-90bc-a0cea95ac488\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"55c6cca6-67da-4dca-a583-ec14783bd767\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"plot\":{\"id\":\"965c01f5-3e9b-40b3-90bc-a0cea95ac488\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"090c247b-6986-47b2-badb-c6551d500629\",\"type\":\"ResetTool\"},{\"attributes\":{\"plot\":{\"id\":\"965c01f5-3e9b-40b3-90bc-a0cea95ac488\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"e0ff7302-e217-47bd-a195-007cc24e1dfb\",\"type\":\"SaveTool\"},{\"attributes\":{\"data_source\":{\"id\":\"562d14a2-678f-4112-8acf-83e9031582c4\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"3f25dde0-4c27-4278-a6f1-3e9c82ccf918\",\"type\":\"Quad\"},\"hover_glyph\":null,\"nonselection_glyph\":{\"id\":\"39eb2ab3-7407-443f-95e9-5fbedb2eaa71\",\"type\":\"Quad\"},\"selection_glyph\":null},\"id\":\"ca9ac881-3b54-4b8b-a681-57177b5fe4aa\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"below\":[{\"id\":\"4d6f9fee-0ddd-4ab1-bc20-e7c38a87e763\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"bcda0d65-9a41-41f8-adab-530cdc202b4b\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"4d6f9fee-0ddd-4ab1-bc20-e7c38a87e763\",\"type\":\"LinearAxis\"},{\"id\":\"7a5a7c4b-3d13-4ade-85a3-6190fa3a27f0\",\"type\":\"Grid\"},{\"id\":\"bcda0d65-9a41-41f8-adab-530cdc202b4b\",\"type\":\"LinearAxis\"},{\"id\":\"5c5c5ebd-02fe-45b1-8335-1a77b32a31af\",\"type\":\"Grid\"},{\"id\":\"ca9ac881-3b54-4b8b-a681-57177b5fe4aa\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"3fd16249-998c-43d2-b371-131a8f0b33da\",\"type\":\"Title\"},\"tool_events\":{\"id\":\"52e9971e-06a5-49d8-a32f-b2d49102e3c1\",\"type\":\"ToolEvents\"},\"toolbar\":{\"id\":\"9e86f4bc-02a8-4e6a-afc9-43d68f4cca2a\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"f842c9c8-5bd1-47be-9647-0522f4d42984\",\"type\":\"DataRange1d\"},\"y_range\":{\"id\":\"e399f89b-72dc-489f-bb29-a2a15c7bdd14\",\"type\":\"DataRange1d\"}},\"id\":\"965c01f5-3e9b-40b3-90bc-a0cea95ac488\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"top\",\"left\",\"right\"],\"data\":{\"left\":[1.0,27.69,54.38,81.07000000000001,107.76,134.45000000000002,161.14000000000001,187.83,214.52,241.21,267.90000000000003,294.59000000000003,321.28000000000003,347.97,374.66,401.35,428.04,454.73,481.42,508.11,534.8000000000001,561.49,588.1800000000001,614.87,641.5600000000001,668.25,694.94,721.63,748.32,775.01,801.7,828.39,855.08,881.7700000000001,908.46,935.1500000000001,961.84,988.5300000000001,1015.22,1041.91,1068.6000000000001,1095.29,1121.98,1148.67,1175.3600000000001,1202.05,1228.74,1255.43,1282.1200000000001,1308.8100000000002,1335.5,1362.19,1388.88,1415.5700000000002,1442.26,1468.95,1495.64,1522.3300000000002,1549.02,1575.71,1602.4,1629.0900000000001,1655.78,1682.47,1709.16,1735.8500000000001,1762.5400000000002,1789.23,1815.92,1842.6100000000001,1869.3000000000002,1895.99,1922.68,1949.3700000000001,1976.0600000000002,2002.75,2029.44,2056.13,2082.82,2109.51,2136.2000000000003,2162.8900000000003,2189.58,2216.27,2242.96,2269.65,2296.34,2323.03,2349.7200000000003,2376.4100000000003,2403.1,2429.79,2456.48,2483.17,2509.86,2536.55,2563.2400000000002,2589.9300000000003,2616.6200000000003,2643.31],\"right\":[27.69,54.38,81.07000000000001,107.76,134.45000000000002,161.14000000000001,187.83,214.52,241.21,267.90000000000003,294.59000000000003,321.28000000000003,347.97,374.66,401.35,428.04,454.73,481.42,508.11,534.8000000000001,561.49,588.1800000000001,614.87,641.5600000000001,668.25,694.94,721.63,748.32,775.01,801.7,828.39,855.08,881.7700000000001,908.46,935.1500000000001,961.84,988.5300000000001,1015.22,1041.91,1068.6000000000001,1095.29,1121.98,1148.67,1175.3600000000001,1202.05,1228.74,1255.43,1282.1200000000001,1308.8100000000002,1335.5,1362.19,1388.88,1415.5700000000002,1442.26,1468.95,1495.64,1522.3300000000002,1549.02,1575.71,1602.4,1629.0900000000001,1655.78,1682.47,1709.16,1735.8500000000001,1762.5400000000002,1789.23,1815.92,1842.6100000000001,1869.3000000000002,1895.99,1922.68,1949.3700000000001,1976.0600000000002,2002.75,2029.44,2056.13,2082.82,2109.51,2136.2000000000003,2162.8900000000003,2189.58,2216.27,2242.96,2269.65,2296.34,2323.03,2349.7200000000003,2376.4100000000003,2403.1,2429.79,2456.48,2483.17,2509.86,2536.55,2563.2400000000002,2589.9300000000003,2616.6200000000003,2643.31,2670.0],\"top\":[0.03403711892938749,0.0010554145404461238,0.0007915609053345926,0.0,0.00026385363511153084,0.0,0.000263853635111531,0.0,0.000263853635111531,0.0,0.0,0.0,0.0,0.000263853635111531,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0002638536351115304,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0002638536351115304]}},\"id\":\"562d14a2-678f-4112-8acf-83e9031582c4\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"39eb2ab3-7407-443f-95e9-5fbedb2eaa71\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"52e9971e-06a5-49d8-a32f-b2d49102e3c1\",\"type\":\"ToolEvents\"},{\"attributes\":{\"plot\":null,\"text\":\"The frequency distribution of the words in our corpus\"},\"id\":\"3fd16249-998c-43d2-b371-131a8f0b33da\",\"type\":\"Title\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"24773690-ba0d-4d32-8718-1d06e15d03fe\",\"type\":\"PanTool\"},{\"id\":\"55c6cca6-67da-4dca-a583-ec14783bd767\",\"type\":\"WheelZoomTool\"},{\"id\":\"090c247b-6986-47b2-badb-c6551d500629\",\"type\":\"ResetTool\"},{\"id\":\"e0ff7302-e217-47bd-a195-007cc24e1dfb\",\"type\":\"SaveTool\"}]},\"id\":\"9e86f4bc-02a8-4e6a-afc9-43d68f4cca2a\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"c60b50ab-61de-4083-a616-d85cf2477dd9\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null},\"id\":\"f842c9c8-5bd1-47be-9647-0522f4d42984\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null},\"id\":\"e399f89b-72dc-489f-bb29-a2a15c7bdd14\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"2459fa76-614e-4a7a-9aa7-0117679e9966\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"c60b50ab-61de-4083-a616-d85cf2477dd9\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"965c01f5-3e9b-40b3-90bc-a0cea95ac488\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a32360e2-1ec1-4b98-afd1-965a9d5cee5a\",\"type\":\"BasicTicker\"}},\"id\":\"4d6f9fee-0ddd-4ab1-bc20-e7c38a87e763\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"a32360e2-1ec1-4b98-afd1-965a9d5cee5a\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"965c01f5-3e9b-40b3-90bc-a0cea95ac488\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a32360e2-1ec1-4b98-afd1-965a9d5cee5a\",\"type\":\"BasicTicker\"}},\"id\":\"7a5a7c4b-3d13-4ade-85a3-6190fa3a27f0\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"2459fa76-614e-4a7a-9aa7-0117679e9966\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"965c01f5-3e9b-40b3-90bc-a0cea95ac488\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"7af38da7-ec8b-4e07-88f5-60231db24cb3\",\"type\":\"BasicTicker\"}},\"id\":\"bcda0d65-9a41-41f8-adab-530cdc202b4b\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"7af38da7-ec8b-4e07-88f5-60231db24cb3\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"965c01f5-3e9b-40b3-90bc-a0cea95ac488\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"7af38da7-ec8b-4e07-88f5-60231db24cb3\",\"type\":\"BasicTicker\"}},\"id\":\"5c5c5ebd-02fe-45b1-8335-1a77b32a31af\",\"type\":\"Grid\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"3f25dde0-4c27-4278-a6f1-3e9c82ccf918\",\"type\":\"Quad\"},{\"attributes\":{\"plot\":{\"id\":\"965c01f5-3e9b-40b3-90bc-a0cea95ac488\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"24773690-ba0d-4d32-8718-1d06e15d03fe\",\"type\":\"PanTool\"}],\"root_ids\":[\"965c01f5-3e9b-40b3-90bc-a0cea95ac488\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.3\"}};\n",
       "            var render_items = [{\"docid\":\"6cacc291-5900-478a-a7d9-9241b96791df\",\"elementid\":\"6a21ce79-2748-467e-9bb8-0b45daab4e46\",\"modelid\":\"965c01f5-3e9b-40b3-90bc-a0cea95ac488\"}];\n",
       "            \n",
       "            Bokeh.embed.embed_items(docs_json, render_items);\n",
       "        });\n",
       "      },\n",
       "      function(Bokeh) {\n",
       "      }\n",
       "    ];\n",
       "  \n",
       "    function run_inline_js() {\n",
       "      \n",
       "      if ((window.Bokeh !== undefined) || (force === \"1\")) {\n",
       "        for (var i = 0; i < inline_js.length; i++) {\n",
       "          inline_js[i](window.Bokeh);\n",
       "        }if (force === \"1\") {\n",
       "          display_loaded();\n",
       "        }} else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(run_inline_js, 100);\n",
       "      } else if (!window._bokeh_failed_load) {\n",
       "        console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "        window._bokeh_failed_load = true;\n",
       "      } else if (!force) {\n",
       "        var cell = $(\"#6a21ce79-2748-467e-9bb8-0b45daab4e46\").parents('.cell').data().cell;\n",
       "        cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "      }\n",
       "  \n",
       "    }\n",
       "  \n",
       "    if (window._bokeh_is_loading === 0) {\n",
       "      console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "      run_inline_js();\n",
       "    } else {\n",
       "      load_libs(js_urls, function() {\n",
       "        console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }(this));\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, edges = np.histogram(list(map(lambda x:x[1],frequency_frequency.most_common())), density=True, bins=100, normed=True)\n",
    "\n",
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"The frequency distribution of the words in our corpus\")\n",
    "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 6: Reducing Noise by Strategically Reducing the Vocabulary<a id='project_6'></a>\n",
    "\n",
    "**TODO:** Improve `SentimentNetwork`'s performance by reducing more noise in the vocabulary. Specifically, do the following:\n",
    "* Copy the `SentimentNetwork` class from the previous project into the following cell.\n",
    "* Modify `pre_process_data`:\n",
    ">* Add two additional parameters: `min_count` and `polarity_cutoff`\n",
    ">* Calculate the positive-to-negative ratios of words used in the reviews. (You can use code you've written elsewhere in the notebook, but we are moving it into the class like we did with other helper code earlier.)\n",
    ">* Andrew's solution only calculates a postive-to-negative ratio for words that occur at least 50 times. This keeps the network from attributing too much sentiment to rarer words. You can choose to add this to your solution if you would like.  \n",
    ">* Change so words are only added to the vocabulary if they occur in the vocabulary more than `min_count` times.\n",
    ">* Change so words are only added to the vocabulary if the absolute value of their postive-to-negative ratio is at least `polarity_cutoff`\n",
    "* Modify `__init__`:\n",
    ">* Add the same two parameters (`min_count` and `polarity_cutoff`) and use them when you call `pre_process_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is the same as the previous project, with project-specific changes marked with `\"New for Project 6\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Encapsulate our neural network in a class\n",
    "class SentimentNetwork:\n",
    "    ## New for Project 6: added min_count and polarity_cutoff parameters\n",
    "    def __init__(self, reviews,labels,min_count = 10,polarity_cutoff = 0.1,hidden_nodes = 10, learning_rate = 0.1):\n",
    "        \"\"\"Create a SentimenNetwork with the given settings\n",
    "        Args:\n",
    "            reviews(list) - List of reviews used for training\n",
    "            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n",
    "            min_count(int) - Words should only be added to the vocabulary \n",
    "                             if they occur more than this many times\n",
    "            polarity_cutoff(float) - The absolute value of a word's positive-to-negative\n",
    "                                     ratio must be at least this big to be considered.\n",
    "            hidden_nodes(int) - Number of nodes to create in the hidden layer\n",
    "            learning_rate(float) - Learning rate to use while training\n",
    "        \n",
    "        \"\"\"\n",
    "        # Assign a seed to our random number generator to ensure we get\n",
    "        # reproducable results during development \n",
    "        np.random.seed(1)\n",
    "\n",
    "        # process the reviews and their associated labels so that everything\n",
    "        # is ready for training\n",
    "        ## New for Project 6: added min_count and polarity_cutoff arguments to pre_process_data call\n",
    "        self.pre_process_data(reviews, labels, polarity_cutoff, min_count)\n",
    "        \n",
    "        # Build the network to have the number of hidden nodes and the learning rate that\n",
    "        # were passed into this initializer. Make the same number of input nodes as\n",
    "        # there are vocabulary words and create a single output node.\n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    ## New for Project 6: added min_count and polarity_cutoff parameters\n",
    "    def pre_process_data(self, reviews, labels, polarity_cutoff, min_count):\n",
    "        \n",
    "        ## ----------------------------------------\n",
    "        ## New for Project 6: Calculate positive-to-negative ratios for words before\n",
    "        #                     building vocabulary\n",
    "        #\n",
    "        positive_counts = Counter()\n",
    "        negative_counts = Counter()\n",
    "        total_counts = Counter()\n",
    "\n",
    "        for i in range(len(reviews)):\n",
    "            if(labels[i] == 'ADMINISTER/MONITOR'):\n",
    "                for word in reviews[i].split(\" \"):\n",
    "                    positive_counts[word] += 1\n",
    "                    total_counts[word] += 1\n",
    "            else:\n",
    "                for word in reviews[i].split(\" \"):\n",
    "                    negative_counts[word] += 1\n",
    "                    total_counts[word] += 1\n",
    "\n",
    "        pos_neg_ratios = Counter()\n",
    "\n",
    "        for term,cnt in list(total_counts.most_common()):\n",
    "            if(cnt >= 2):\n",
    "                pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "                pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "        for word,ratio in pos_neg_ratios.most_common():\n",
    "            if(ratio > 1):\n",
    "                pos_neg_ratios[word] = np.log(ratio)\n",
    "            else:\n",
    "                pos_neg_ratios[word] = -np.log((1 / (ratio + 0.01)))\n",
    "        #\n",
    "        ## end New for Project 6\n",
    "        ## ----------------------------------------\n",
    "\n",
    "        # populate review_vocab with all of the words in the given reviews\n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                ## New for Project 6: only add words that occur at least min_count times\n",
    "                #                     and for words with pos/neg ratios, only add words\n",
    "                #                     that meet the polarity_cutoff\n",
    "                if(total_counts[word] > min_count):\n",
    "                    if(word in pos_neg_ratios.keys()):\n",
    "                        if((pos_neg_ratios[word] >= polarity_cutoff) or (pos_neg_ratios[word] <= -polarity_cutoff)):\n",
    "                            review_vocab.add(word)\n",
    "                    else:\n",
    "                        review_vocab.add(word)\n",
    "\n",
    "        # Convert the vocabulary set to a list so we can access words via indices\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        # populate label_vocab with all of the words in the given labels.\n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of the review and label vocabularies.\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        # Create a dictionary of labels mapped to index positions\n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "\n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Store the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "\n",
    "        # These are the weights between the input layer and the hidden layer.\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "\n",
    "        # These are the weights between the hidden layer and the output layer.\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        ## New for Project 5: Removed self.layer_0; added self.layer_1\n",
    "        # The input layer, a two-dimensional matrix with shape 1 x hidden_nodes\n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "    \n",
    "    ## New for Project 5: Removed update_input_layer function\n",
    "    \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'ADMINISTER/MONITOR'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    ## New for Project 5: changed name of first parameter form 'training_reviews' \n",
    "    #                     to 'training_reviews_raw'\n",
    "    def train(self, training_reviews_raw, training_labels):\n",
    "\n",
    "        ## New for Project 5: pre-process training reviews so we can deal \n",
    "        #                     directly with the indices of non-zero inputs\n",
    "        training_reviews = list()\n",
    "        for review in training_reviews_raw:\n",
    "            indices = set()\n",
    "            for word in review.split(\" \"):\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_reviews.append(list(indices))\n",
    "\n",
    "        # make sure out we have a matching number of reviews and labels\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        # Keep track of correct predictions to display accuracy during training \n",
    "        correct_so_far = 0\n",
    "\n",
    "        # Remember when we started for printing time statistics\n",
    "        start = time.time()\n",
    "        \n",
    "        # loop through all the given reviews and run a forward and backward pass,\n",
    "        # updating weights for every item\n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            # Get the next review and its correct label\n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #### Implement the forward pass here ####\n",
    "            ### Forward pass ###\n",
    "\n",
    "            ## New for Project 5: Removed call to 'update_input_layer' function\n",
    "            #                     because 'layer_0' is no longer used\n",
    "\n",
    "            # Hidden layer\n",
    "            ## New for Project 5: Add in only the weights for non-zero items\n",
    "            self.layer_1 *= 0\n",
    "            for index in review:\n",
    "                self.layer_1 += self.weights_0_1[index]\n",
    "\n",
    "            # Output layer\n",
    "            ## New for Project 5: changed to use 'self.layer_1' instead of 'local layer_1'\n",
    "            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))            \n",
    "            \n",
    "            #### Implement the backward pass here ####\n",
    "            ### Backward pass ###\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # Update the weights\n",
    "            ## New for Project 5: changed to use 'self.layer_1' instead of local 'layer_1'\n",
    "            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            \n",
    "            ## New for Project 5: Only update the weights that were used in the forward pass\n",
    "            for index in review:\n",
    "                self.weights_0_1[index] -= layer_1_delta[0] * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            # Keep track of correct predictions.\n",
    "            if(layer_2 >= 0.5 and label == 'ADMINISTER/MONITOR'):\n",
    "                correct_so_far += 1\n",
    "            elif(layer_2 < 0.5 and label == 'NOTADMINISTER/MONITOR'):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the training process. \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \"\"\"\n",
    "        Attempts to predict the labels for the given testing_reviews,\n",
    "        and uses the test_labels to calculate the accuracy of those predictions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # keep track of how many correct predictions we make\n",
    "        correct = 0\n",
    "\n",
    "        # we'll time how many predictions per second we make\n",
    "        start = time.time()\n",
    "\n",
    "        # Loop through each of the given reviews and call run to predict\n",
    "        # its label. \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the prediction process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \"\"\"\n",
    "        Returns a POSITIVE or NEGATIVE prediction for the given review.\n",
    "        \"\"\"\n",
    "        # Run a forward pass through the network, like in the \"train\" function.\n",
    "        \n",
    "        ## New for Project 5: Removed call to update_input_layer function\n",
    "        #                     because layer_0 is no longer used\n",
    "\n",
    "        # Hidden layer\n",
    "        ## New for Project 5: Identify the indices used in the review and then add\n",
    "        #                     just those weights to layer_1 \n",
    "        self.layer_1 *= 0\n",
    "        unique_indices = set()\n",
    "        for word in review.lower().split(\" \"):\n",
    "            if word in self.word2index.keys():\n",
    "                unique_indices.add(self.word2index[word])\n",
    "        for index in unique_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "        \n",
    "        # Output layer\n",
    "        ## New for Project 5: changed to use self.layer_1 instead of local layer_1\n",
    "        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "         \n",
    "        # Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;\n",
    "        # return NEGATIVE for other values\n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"ADMINISTER/MONITOR\"\n",
    "        else:\n",
    "            return \"NOTADMINISTER/MONITOR\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to train your network with a small polarity cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "\r",
      "Progress:0.26% Speed(reviews/sec):788.1 #Correct:1 #Trained:2 Training Accuracy:50.0%\r",
      "Progress:0.53% Speed(reviews/sec):1213. #Correct:1 #Trained:3 Training Accuracy:33.3%\r",
      "Progress:0.80% Speed(reviews/sec):1503. #Correct:2 #Trained:4 Training Accuracy:50.0%\r",
      "Progress:1.07% Speed(reviews/sec):1614. #Correct:3 #Trained:5 Training Accuracy:60.0%\r",
      "Progress:1.34% Speed(reviews/sec):1777. #Correct:3 #Trained:6 Training Accuracy:50.0%\r",
      "Progress:1.61% Speed(reviews/sec):1918. #Correct:3 #Trained:7 Training Accuracy:42.8%\r",
      "Progress:1.88% Speed(reviews/sec):2030. #Correct:3 #Trained:8 Training Accuracy:37.5%\r",
      "Progress:2.15% Speed(reviews/sec):2066. #Correct:3 #Trained:9 Training Accuracy:33.3%\r",
      "Progress:2.42% Speed(reviews/sec):2153. #Correct:3 #Trained:10 Training Accuracy:30.0%\r",
      "Progress:2.69% Speed(reviews/sec):2260. #Correct:4 #Trained:11 Training Accuracy:36.3%\r",
      "Progress:2.96% Speed(reviews/sec):2360. #Correct:5 #Trained:12 Training Accuracy:41.6%\r",
      "Progress:3.23% Speed(reviews/sec):2441. #Correct:6 #Trained:13 Training Accuracy:46.1%\r",
      "Progress:3.50% Speed(reviews/sec):2514. #Correct:6 #Trained:14 Training Accuracy:42.8%\r",
      "Progress:3.77% Speed(reviews/sec):2581. #Correct:6 #Trained:15 Training Accuracy:40.0%\r",
      "Progress:4.04% Speed(reviews/sec):2639. #Correct:7 #Trained:16 Training Accuracy:43.7%\r",
      "Progress:4.31% Speed(reviews/sec):2705. #Correct:8 #Trained:17 Training Accuracy:47.0%\r",
      "Progress:4.58% Speed(reviews/sec):2666. #Correct:9 #Trained:18 Training Accuracy:50.0%\r",
      "Progress:4.85% Speed(reviews/sec):2647. #Correct:9 #Trained:19 Training Accuracy:47.3%\r",
      "Progress:5.12% Speed(reviews/sec):2634. #Correct:10 #Trained:20 Training Accuracy:50.0%\r",
      "Progress:5.39% Speed(reviews/sec):2618. #Correct:10 #Trained:21 Training Accuracy:47.6%\r",
      "Progress:5.66% Speed(reviews/sec):2625. #Correct:10 #Trained:22 Training Accuracy:45.4%\r",
      "Progress:5.92% Speed(reviews/sec):2630. #Correct:10 #Trained:23 Training Accuracy:43.4%\r",
      "Progress:6.19% Speed(reviews/sec):2608. #Correct:11 #Trained:24 Training Accuracy:45.8%\r",
      "Progress:6.46% Speed(reviews/sec):2643. #Correct:11 #Trained:25 Training Accuracy:44.0%\r",
      "Progress:6.73% Speed(reviews/sec):2678. #Correct:11 #Trained:26 Training Accuracy:42.3%\r",
      "Progress:7.00% Speed(reviews/sec):2714. #Correct:11 #Trained:27 Training Accuracy:40.7%\r",
      "Progress:7.27% Speed(reviews/sec):2754. #Correct:12 #Trained:28 Training Accuracy:42.8%\r",
      "Progress:7.54% Speed(reviews/sec):2764. #Correct:12 #Trained:29 Training Accuracy:41.3%\r",
      "Progress:7.81% Speed(reviews/sec):2804. #Correct:13 #Trained:30 Training Accuracy:43.3%\r",
      "Progress:8.08% Speed(reviews/sec):2841. #Correct:14 #Trained:31 Training Accuracy:45.1%\r",
      "Progress:8.35% Speed(reviews/sec):2816. #Correct:15 #Trained:32 Training Accuracy:46.8%\r",
      "Progress:8.62% Speed(reviews/sec):2811. #Correct:15 #Trained:33 Training Accuracy:45.4%\r",
      "Progress:8.89% Speed(reviews/sec):2826. #Correct:15 #Trained:34 Training Accuracy:44.1%\r",
      "Progress:9.16% Speed(reviews/sec):2855. #Correct:15 #Trained:35 Training Accuracy:42.8%\r",
      "Progress:9.43% Speed(reviews/sec):2886. #Correct:15 #Trained:36 Training Accuracy:41.6%\r",
      "Progress:9.70% Speed(reviews/sec):2922. #Correct:15 #Trained:37 Training Accuracy:40.5%\r",
      "Progress:9.97% Speed(reviews/sec):2928. #Correct:15 #Trained:38 Training Accuracy:39.4%\r",
      "Progress:10.2% Speed(reviews/sec):2942. #Correct:16 #Trained:39 Training Accuracy:41.0%\r",
      "Progress:10.5% Speed(reviews/sec):2952. #Correct:16 #Trained:40 Training Accuracy:40.0%\r",
      "Progress:10.7% Speed(reviews/sec):2968. #Correct:16 #Trained:41 Training Accuracy:39.0%\r",
      "Progress:11.0% Speed(reviews/sec):2973. #Correct:17 #Trained:42 Training Accuracy:40.4%\r",
      "Progress:11.3% Speed(reviews/sec):2976. #Correct:18 #Trained:43 Training Accuracy:41.8%\r",
      "Progress:11.5% Speed(reviews/sec):2976. #Correct:19 #Trained:44 Training Accuracy:43.1%\r",
      "Progress:11.8% Speed(reviews/sec):2990. #Correct:19 #Trained:45 Training Accuracy:42.2%\r",
      "Progress:12.1% Speed(reviews/sec):3017. #Correct:20 #Trained:46 Training Accuracy:43.4%\r",
      "Progress:12.3% Speed(reviews/sec):3031. #Correct:21 #Trained:47 Training Accuracy:44.6%\r",
      "Progress:12.6% Speed(reviews/sec):3039. #Correct:21 #Trained:48 Training Accuracy:43.7%\r",
      "Progress:12.9% Speed(reviews/sec):3050. #Correct:22 #Trained:49 Training Accuracy:44.8%\r",
      "Progress:13.2% Speed(reviews/sec):3061. #Correct:22 #Trained:50 Training Accuracy:44.0%\r",
      "Progress:13.4% Speed(reviews/sec):3086. #Correct:22 #Trained:51 Training Accuracy:43.1%\r",
      "Progress:13.7% Speed(reviews/sec):3111. #Correct:23 #Trained:52 Training Accuracy:44.2%\r",
      "Progress:14.0% Speed(reviews/sec):3121. #Correct:23 #Trained:53 Training Accuracy:43.3%\r",
      "Progress:14.2% Speed(reviews/sec):3126. #Correct:23 #Trained:54 Training Accuracy:42.5%\r",
      "Progress:14.5% Speed(reviews/sec):3145. #Correct:24 #Trained:55 Training Accuracy:43.6%\r",
      "Progress:14.8% Speed(reviews/sec):3171. #Correct:24 #Trained:56 Training Accuracy:42.8%\r",
      "Progress:15.0% Speed(reviews/sec):3185. #Correct:24 #Trained:57 Training Accuracy:42.1%\r",
      "Progress:15.3% Speed(reviews/sec):3210. #Correct:25 #Trained:58 Training Accuracy:43.1%\r",
      "Progress:15.6% Speed(reviews/sec):3221. #Correct:26 #Trained:59 Training Accuracy:44.0%\r",
      "Progress:15.9% Speed(reviews/sec):3249. #Correct:26 #Trained:60 Training Accuracy:43.3%\r",
      "Progress:16.1% Speed(reviews/sec):3260. #Correct:27 #Trained:61 Training Accuracy:44.2%\r",
      "Progress:16.4% Speed(reviews/sec):3276. #Correct:27 #Trained:62 Training Accuracy:43.5%\r",
      "Progress:16.7% Speed(reviews/sec):3298. #Correct:28 #Trained:63 Training Accuracy:44.4%\r",
      "Progress:16.9% Speed(reviews/sec):3298. #Correct:29 #Trained:64 Training Accuracy:45.3%\r",
      "Progress:17.2% Speed(reviews/sec):3296. #Correct:29 #Trained:65 Training Accuracy:44.6%\r",
      "Progress:17.5% Speed(reviews/sec):3318. #Correct:30 #Trained:66 Training Accuracy:45.4%\r",
      "Progress:17.7% Speed(reviews/sec):3337. #Correct:30 #Trained:67 Training Accuracy:44.7%\r",
      "Progress:18.0% Speed(reviews/sec):3354. #Correct:30 #Trained:68 Training Accuracy:44.1%\r",
      "Progress:18.3% Speed(reviews/sec):3366. #Correct:31 #Trained:69 Training Accuracy:44.9%\r",
      "Progress:18.5% Speed(reviews/sec):3376. #Correct:32 #Trained:70 Training Accuracy:45.7%\r",
      "Progress:18.8% Speed(reviews/sec):3391. #Correct:32 #Trained:71 Training Accuracy:45.0%\r",
      "Progress:19.1% Speed(reviews/sec):3408. #Correct:33 #Trained:72 Training Accuracy:45.8%\r",
      "Progress:19.4% Speed(reviews/sec):3423. #Correct:33 #Trained:73 Training Accuracy:45.2%\r",
      "Progress:19.6% Speed(reviews/sec):3434. #Correct:34 #Trained:74 Training Accuracy:45.9%\r",
      "Progress:19.9% Speed(reviews/sec):3449. #Correct:35 #Trained:75 Training Accuracy:46.6%\r",
      "Progress:20.2% Speed(reviews/sec):3468. #Correct:36 #Trained:76 Training Accuracy:47.3%\r",
      "Progress:20.4% Speed(reviews/sec):3477. #Correct:37 #Trained:77 Training Accuracy:48.0%\r",
      "Progress:20.7% Speed(reviews/sec):3487. #Correct:38 #Trained:78 Training Accuracy:48.7%\r",
      "Progress:21.0% Speed(reviews/sec):3502. #Correct:38 #Trained:79 Training Accuracy:48.1%\r",
      "Progress:21.2% Speed(reviews/sec):3520. #Correct:39 #Trained:80 Training Accuracy:48.7%\r",
      "Progress:21.5% Speed(reviews/sec):3539. #Correct:40 #Trained:81 Training Accuracy:49.3%\r",
      "Progress:21.8% Speed(reviews/sec):3555. #Correct:41 #Trained:82 Training Accuracy:50.0%\r",
      "Progress:22.1% Speed(reviews/sec):3568. #Correct:41 #Trained:83 Training Accuracy:49.3%\r",
      "Progress:22.3% Speed(reviews/sec):3581. #Correct:42 #Trained:84 Training Accuracy:50.0%\r",
      "Progress:22.6% Speed(reviews/sec):3597. #Correct:43 #Trained:85 Training Accuracy:50.5%\r",
      "Progress:22.9% Speed(reviews/sec):3614. #Correct:43 #Trained:86 Training Accuracy:50.0%\r",
      "Progress:23.1% Speed(reviews/sec):3627. #Correct:43 #Trained:87 Training Accuracy:49.4%\r",
      "Progress:23.4% Speed(reviews/sec):3635. #Correct:43 #Trained:88 Training Accuracy:48.8%\r",
      "Progress:23.7% Speed(reviews/sec):3650. #Correct:44 #Trained:89 Training Accuracy:49.4%\r",
      "Progress:23.9% Speed(reviews/sec):3667. #Correct:45 #Trained:90 Training Accuracy:50.0%\r",
      "Progress:24.2% Speed(reviews/sec):3678. #Correct:46 #Trained:91 Training Accuracy:50.5%\r",
      "Progress:24.5% Speed(reviews/sec):3693. #Correct:47 #Trained:92 Training Accuracy:51.0%\r",
      "Progress:24.7% Speed(reviews/sec):3707. #Correct:47 #Trained:93 Training Accuracy:50.5%\r",
      "Progress:25.0% Speed(reviews/sec):3718. #Correct:48 #Trained:94 Training Accuracy:51.0%\r",
      "Progress:25.3% Speed(reviews/sec):3731. #Correct:48 #Trained:95 Training Accuracy:50.5%\r",
      "Progress:25.6% Speed(reviews/sec):3746. #Correct:49 #Trained:96 Training Accuracy:51.0%\r",
      "Progress:25.8% Speed(reviews/sec):3757. #Correct:49 #Trained:97 Training Accuracy:50.5%\r",
      "Progress:26.1% Speed(reviews/sec):3764. #Correct:49 #Trained:98 Training Accuracy:50.0%\r",
      "Progress:26.4% Speed(reviews/sec):3776. #Correct:49 #Trained:99 Training Accuracy:49.4%\r",
      "Progress:26.6% Speed(reviews/sec):3790. #Correct:50 #Trained:100 Training Accuracy:50.0%\r",
      "Progress:26.9% Speed(reviews/sec):3808. #Correct:51 #Trained:101 Training Accuracy:50.4%\r",
      "Progress:27.2% Speed(reviews/sec):3820. #Correct:51 #Trained:102 Training Accuracy:50.0%\r",
      "Progress:27.4% Speed(reviews/sec):3830. #Correct:51 #Trained:103 Training Accuracy:49.5%\r",
      "Progress:27.7% Speed(reviews/sec):3842. #Correct:52 #Trained:104 Training Accuracy:50.0%\r",
      "Progress:28.0% Speed(reviews/sec):3843. #Correct:53 #Trained:105 Training Accuracy:50.4%\r",
      "Progress:28.3% Speed(reviews/sec):3860. #Correct:53 #Trained:106 Training Accuracy:50.0%\r",
      "Progress:28.5% Speed(reviews/sec):3877. #Correct:53 #Trained:107 Training Accuracy:49.5%\r",
      "Progress:28.8% Speed(reviews/sec):3894. #Correct:53 #Trained:108 Training Accuracy:49.0%\r",
      "Progress:29.1% Speed(reviews/sec):3914. #Correct:53 #Trained:109 Training Accuracy:48.6%\r",
      "Progress:29.3% Speed(reviews/sec):3930. #Correct:54 #Trained:110 Training Accuracy:49.0%\r",
      "Progress:29.6% Speed(reviews/sec):3943. #Correct:54 #Trained:111 Training Accuracy:48.6%\r",
      "Progress:29.9% Speed(reviews/sec):3930. #Correct:55 #Trained:112 Training Accuracy:49.1%\r",
      "Progress:30.1% Speed(reviews/sec):3929. #Correct:55 #Trained:113 Training Accuracy:48.6%\r",
      "Progress:30.4% Speed(reviews/sec):3945. #Correct:55 #Trained:114 Training Accuracy:48.2%\r",
      "Progress:30.7% Speed(reviews/sec):3962. #Correct:56 #Trained:115 Training Accuracy:48.6%\r",
      "Progress:30.9% Speed(reviews/sec):3978. #Correct:57 #Trained:116 Training Accuracy:49.1%\r",
      "Progress:31.2% Speed(reviews/sec):3995. #Correct:58 #Trained:117 Training Accuracy:49.5%\r",
      "Progress:31.5% Speed(reviews/sec):4004. #Correct:58 #Trained:118 Training Accuracy:49.1%\r",
      "Progress:31.8% Speed(reviews/sec):4014. #Correct:58 #Trained:119 Training Accuracy:48.7%\r",
      "Progress:32.0% Speed(reviews/sec):4029. #Correct:59 #Trained:120 Training Accuracy:49.1%\r",
      "Progress:32.3% Speed(reviews/sec):4044. #Correct:60 #Trained:121 Training Accuracy:49.5%\r",
      "Progress:32.6% Speed(reviews/sec):4057. #Correct:60 #Trained:122 Training Accuracy:49.1%\r",
      "Progress:32.8% Speed(reviews/sec):4068. #Correct:60 #Trained:123 Training Accuracy:48.7%\r",
      "Progress:33.1% Speed(reviews/sec):4078. #Correct:60 #Trained:124 Training Accuracy:48.3%\r",
      "Progress:33.4% Speed(reviews/sec):4092. #Correct:61 #Trained:125 Training Accuracy:48.8%\r",
      "Progress:33.6% Speed(reviews/sec):4092. #Correct:62 #Trained:126 Training Accuracy:49.2%\r",
      "Progress:33.9% Speed(reviews/sec):4103. #Correct:63 #Trained:127 Training Accuracy:49.6%\r",
      "Progress:34.2% Speed(reviews/sec):4106. #Correct:64 #Trained:128 Training Accuracy:50.0%\r",
      "Progress:34.5% Speed(reviews/sec):4119. #Correct:65 #Trained:129 Training Accuracy:50.3%\r",
      "Progress:34.7% Speed(reviews/sec):4131. #Correct:66 #Trained:130 Training Accuracy:50.7%\r",
      "Progress:35.0% Speed(reviews/sec):4147. #Correct:67 #Trained:131 Training Accuracy:51.1%\r",
      "Progress:35.3% Speed(reviews/sec):4150. #Correct:67 #Trained:132 Training Accuracy:50.7%\r",
      "Progress:35.5% Speed(reviews/sec):4164. #Correct:68 #Trained:133 Training Accuracy:51.1%\r",
      "Progress:35.8% Speed(reviews/sec):4155. #Correct:69 #Trained:134 Training Accuracy:51.4%\r",
      "Progress:36.1% Speed(reviews/sec):4155. #Correct:70 #Trained:135 Training Accuracy:51.8%\r",
      "Progress:36.3% Speed(reviews/sec):4160. #Correct:71 #Trained:136 Training Accuracy:52.2%\r",
      "Progress:36.6% Speed(reviews/sec):4169. #Correct:72 #Trained:137 Training Accuracy:52.5%\r",
      "Progress:36.9% Speed(reviews/sec):4179. #Correct:73 #Trained:138 Training Accuracy:52.8%\r",
      "Progress:37.1% Speed(reviews/sec):4186. #Correct:73 #Trained:139 Training Accuracy:52.5%\r",
      "Progress:37.4% Speed(reviews/sec):4198. #Correct:74 #Trained:140 Training Accuracy:52.8%\r",
      "Progress:37.7% Speed(reviews/sec):4212. #Correct:75 #Trained:141 Training Accuracy:53.1%\r",
      "Progress:38.0% Speed(reviews/sec):4219. #Correct:75 #Trained:142 Training Accuracy:52.8%\r",
      "Progress:38.2% Speed(reviews/sec):4231. #Correct:76 #Trained:143 Training Accuracy:53.1%\r",
      "Progress:38.5% Speed(reviews/sec):4242. #Correct:77 #Trained:144 Training Accuracy:53.4%\r",
      "Progress:38.8% Speed(reviews/sec):4255. #Correct:77 #Trained:145 Training Accuracy:53.1%\r",
      "Progress:39.0% Speed(reviews/sec):4270. #Correct:78 #Trained:146 Training Accuracy:53.4%\r",
      "Progress:39.3% Speed(reviews/sec):4281. #Correct:78 #Trained:147 Training Accuracy:53.0%\r",
      "Progress:39.6% Speed(reviews/sec):4292. #Correct:79 #Trained:148 Training Accuracy:53.3%\r",
      "Progress:39.8% Speed(reviews/sec):4303. #Correct:79 #Trained:149 Training Accuracy:53.0%\r",
      "Progress:40.1% Speed(reviews/sec):4313. #Correct:80 #Trained:150 Training Accuracy:53.3%\r",
      "Progress:40.4% Speed(reviews/sec):4324. #Correct:81 #Trained:151 Training Accuracy:53.6%\r",
      "Progress:40.7% Speed(reviews/sec):4334. #Correct:81 #Trained:152 Training Accuracy:53.2%\r",
      "Progress:40.9% Speed(reviews/sec):4345. #Correct:82 #Trained:153 Training Accuracy:53.5%\r",
      "Progress:41.2% Speed(reviews/sec):4356. #Correct:82 #Trained:154 Training Accuracy:53.2%\r",
      "Progress:41.5% Speed(reviews/sec):4367. #Correct:83 #Trained:155 Training Accuracy:53.5%\r",
      "Progress:41.7% Speed(reviews/sec):4384. #Correct:84 #Trained:156 Training Accuracy:53.8%\r",
      "Progress:42.0% Speed(reviews/sec):4397. #Correct:85 #Trained:157 Training Accuracy:54.1%\r",
      "Progress:42.3% Speed(reviews/sec):4408. #Correct:86 #Trained:158 Training Accuracy:54.4%\r",
      "Progress:42.5% Speed(reviews/sec):4418. #Correct:87 #Trained:159 Training Accuracy:54.7%\r",
      "Progress:42.8% Speed(reviews/sec):4426. #Correct:88 #Trained:160 Training Accuracy:55.0%\r",
      "Progress:43.1% Speed(reviews/sec):4438. #Correct:89 #Trained:161 Training Accuracy:55.2%\r",
      "Progress:43.3% Speed(reviews/sec):4451. #Correct:90 #Trained:162 Training Accuracy:55.5%\r",
      "Progress:43.6% Speed(reviews/sec):4462. #Correct:90 #Trained:163 Training Accuracy:55.2%\r",
      "Progress:43.9% Speed(reviews/sec):4472. #Correct:90 #Trained:164 Training Accuracy:54.8%\r",
      "Progress:44.2% Speed(reviews/sec):4482. #Correct:90 #Trained:165 Training Accuracy:54.5%\r",
      "Progress:44.4% Speed(reviews/sec):4498. #Correct:91 #Trained:166 Training Accuracy:54.8%\r",
      "Progress:44.7% Speed(reviews/sec):4514. #Correct:92 #Trained:167 Training Accuracy:55.0%\r",
      "Progress:45.0% Speed(reviews/sec):4528. #Correct:93 #Trained:168 Training Accuracy:55.3%\r",
      "Progress:45.2% Speed(reviews/sec):4542. #Correct:94 #Trained:169 Training Accuracy:55.6%\r",
      "Progress:45.5% Speed(reviews/sec):4554. #Correct:95 #Trained:170 Training Accuracy:55.8%\r",
      "Progress:45.8% Speed(reviews/sec):4560. #Correct:96 #Trained:171 Training Accuracy:56.1%\r",
      "Progress:46.0% Speed(reviews/sec):4568. #Correct:97 #Trained:172 Training Accuracy:56.3%\r",
      "Progress:46.3% Speed(reviews/sec):4575. #Correct:97 #Trained:173 Training Accuracy:56.0%\r",
      "Progress:46.6% Speed(reviews/sec):4580. #Correct:98 #Trained:174 Training Accuracy:56.3%\r",
      "Progress:46.9% Speed(reviews/sec):4578. #Correct:99 #Trained:175 Training Accuracy:56.5%\r",
      "Progress:47.1% Speed(reviews/sec):4583. #Correct:99 #Trained:176 Training Accuracy:56.2%\r",
      "Progress:47.4% Speed(reviews/sec):4584. #Correct:100 #Trained:177 Training Accuracy:56.4%\r",
      "Progress:47.7% Speed(reviews/sec):4563. #Correct:101 #Trained:178 Training Accuracy:56.7%\r",
      "Progress:47.9% Speed(reviews/sec):4559. #Correct:102 #Trained:179 Training Accuracy:56.9%\r",
      "Progress:48.2% Speed(reviews/sec):4566. #Correct:103 #Trained:180 Training Accuracy:57.2%\r",
      "Progress:48.5% Speed(reviews/sec):4576. #Correct:104 #Trained:181 Training Accuracy:57.4%\r",
      "Progress:48.7% Speed(reviews/sec):4575. #Correct:105 #Trained:182 Training Accuracy:57.6%\r",
      "Progress:49.0% Speed(reviews/sec):4575. #Correct:106 #Trained:183 Training Accuracy:57.9%\r",
      "Progress:49.3% Speed(reviews/sec):4572. #Correct:107 #Trained:184 Training Accuracy:58.1%\r",
      "Progress:49.5% Speed(reviews/sec):4564. #Correct:107 #Trained:185 Training Accuracy:57.8%\r",
      "Progress:49.8% Speed(reviews/sec):4571. #Correct:108 #Trained:186 Training Accuracy:58.0%\r",
      "Progress:50.1% Speed(reviews/sec):4556. #Correct:108 #Trained:187 Training Accuracy:57.7%\r",
      "Progress:50.4% Speed(reviews/sec):4567. #Correct:109 #Trained:188 Training Accuracy:57.9%\r",
      "Progress:50.6% Speed(reviews/sec):4580. #Correct:109 #Trained:189 Training Accuracy:57.6%\r",
      "Progress:50.9% Speed(reviews/sec):4594. #Correct:110 #Trained:190 Training Accuracy:57.8%\r",
      "Progress:51.2% Speed(reviews/sec):4608. #Correct:111 #Trained:191 Training Accuracy:58.1%\r",
      "Progress:51.4% Speed(reviews/sec):4613. #Correct:112 #Trained:192 Training Accuracy:58.3%\r",
      "Progress:51.7% Speed(reviews/sec):4621. #Correct:113 #Trained:193 Training Accuracy:58.5%\r",
      "Progress:52.0% Speed(reviews/sec):4629. #Correct:113 #Trained:194 Training Accuracy:58.2%\r",
      "Progress:52.2% Speed(reviews/sec):4639. #Correct:114 #Trained:195 Training Accuracy:58.4%\r",
      "Progress:52.5% Speed(reviews/sec):4652. #Correct:115 #Trained:196 Training Accuracy:58.6%\r",
      "Progress:52.8% Speed(reviews/sec):4663. #Correct:116 #Trained:197 Training Accuracy:58.8%\r",
      "Progress:53.0% Speed(reviews/sec):4673. #Correct:116 #Trained:198 Training Accuracy:58.5%\r",
      "Progress:53.3% Speed(reviews/sec):4683. #Correct:117 #Trained:199 Training Accuracy:58.7%\r",
      "Progress:53.6% Speed(reviews/sec):4691. #Correct:117 #Trained:200 Training Accuracy:58.5%\r",
      "Progress:53.9% Speed(reviews/sec):4704. #Correct:118 #Trained:201 Training Accuracy:58.7%\r",
      "Progress:54.1% Speed(reviews/sec):4711. #Correct:118 #Trained:202 Training Accuracy:58.4%\r",
      "Progress:54.4% Speed(reviews/sec):4717. #Correct:119 #Trained:203 Training Accuracy:58.6%\r",
      "Progress:54.7% Speed(reviews/sec):4727. #Correct:119 #Trained:204 Training Accuracy:58.3%\r",
      "Progress:54.9% Speed(reviews/sec):4742. #Correct:120 #Trained:205 Training Accuracy:58.5%\r",
      "Progress:55.2% Speed(reviews/sec):4738. #Correct:121 #Trained:206 Training Accuracy:58.7%\r",
      "Progress:55.5% Speed(reviews/sec):4744. #Correct:122 #Trained:207 Training Accuracy:58.9%\r",
      "Progress:55.7% Speed(reviews/sec):4756. #Correct:123 #Trained:208 Training Accuracy:59.1%\r",
      "Progress:56.0% Speed(reviews/sec):4747. #Correct:123 #Trained:209 Training Accuracy:58.8%\r",
      "Progress:56.3% Speed(reviews/sec):4735. #Correct:123 #Trained:210 Training Accuracy:58.5%\r",
      "Progress:56.6% Speed(reviews/sec):4669. #Correct:123 #Trained:211 Training Accuracy:58.2%\r",
      "Progress:56.8% Speed(reviews/sec):4608. #Correct:124 #Trained:212 Training Accuracy:58.4%\r",
      "Progress:57.1% Speed(reviews/sec):4551. #Correct:124 #Trained:213 Training Accuracy:58.2%\r",
      "Progress:57.4% Speed(reviews/sec):4505. #Correct:125 #Trained:214 Training Accuracy:58.4%\r",
      "Progress:57.6% Speed(reviews/sec):4459. #Correct:125 #Trained:215 Training Accuracy:58.1%\r",
      "Progress:57.9% Speed(reviews/sec):4417. #Correct:126 #Trained:216 Training Accuracy:58.3%\r",
      "Progress:58.2% Speed(reviews/sec):4381. #Correct:127 #Trained:217 Training Accuracy:58.5%\r",
      "Progress:58.4% Speed(reviews/sec):4339. #Correct:128 #Trained:218 Training Accuracy:58.7%\r",
      "Progress:58.7% Speed(reviews/sec):4312. #Correct:129 #Trained:219 Training Accuracy:58.9%\r",
      "Progress:59.0% Speed(reviews/sec):4292. #Correct:129 #Trained:220 Training Accuracy:58.6%\r",
      "Progress:59.2% Speed(reviews/sec):4256. #Correct:130 #Trained:221 Training Accuracy:58.8%\r",
      "Progress:59.5% Speed(reviews/sec):4230. #Correct:130 #Trained:222 Training Accuracy:58.5%\r",
      "Progress:59.8% Speed(reviews/sec):4207. #Correct:131 #Trained:223 Training Accuracy:58.7%\r",
      "Progress:60.1% Speed(reviews/sec):4182. #Correct:132 #Trained:224 Training Accuracy:58.9%\r",
      "Progress:60.3% Speed(reviews/sec):4159. #Correct:133 #Trained:225 Training Accuracy:59.1%\r",
      "Progress:60.6% Speed(reviews/sec):4142. #Correct:133 #Trained:226 Training Accuracy:58.8%\r",
      "Progress:60.9% Speed(reviews/sec):4125. #Correct:134 #Trained:227 Training Accuracy:59.0%\r",
      "Progress:61.1% Speed(reviews/sec):4110. #Correct:135 #Trained:228 Training Accuracy:59.2%\r",
      "Progress:61.4% Speed(reviews/sec):4088. #Correct:136 #Trained:229 Training Accuracy:59.3%\r",
      "Progress:61.7% Speed(reviews/sec):4069. #Correct:137 #Trained:230 Training Accuracy:59.5%\r",
      "Progress:61.9% Speed(reviews/sec):4054. #Correct:138 #Trained:231 Training Accuracy:59.7%\r",
      "Progress:62.2% Speed(reviews/sec):4037. #Correct:139 #Trained:232 Training Accuracy:59.9%\r",
      "Progress:62.5% Speed(reviews/sec):4023. #Correct:140 #Trained:233 Training Accuracy:60.0%\r",
      "Progress:62.8% Speed(reviews/sec):4011. #Correct:141 #Trained:234 Training Accuracy:60.2%\r",
      "Progress:63.0% Speed(reviews/sec):3999. #Correct:141 #Trained:235 Training Accuracy:60.0%\r",
      "Progress:63.3% Speed(reviews/sec):3988. #Correct:142 #Trained:236 Training Accuracy:60.1%\r",
      "Progress:63.6% Speed(reviews/sec):3978. #Correct:143 #Trained:237 Training Accuracy:60.3%\r",
      "Progress:63.8% Speed(reviews/sec):3967. #Correct:144 #Trained:238 Training Accuracy:60.5%\r",
      "Progress:64.1% Speed(reviews/sec):3954. #Correct:144 #Trained:239 Training Accuracy:60.2%\r",
      "Progress:64.4% Speed(reviews/sec):3940. #Correct:145 #Trained:240 Training Accuracy:60.4%\r",
      "Progress:64.6% Speed(reviews/sec):3929. #Correct:146 #Trained:241 Training Accuracy:60.5%\r",
      "Progress:64.9% Speed(reviews/sec):3918. #Correct:147 #Trained:242 Training Accuracy:60.7%\r",
      "Progress:65.2% Speed(reviews/sec):3912. #Correct:148 #Trained:243 Training Accuracy:60.9%\r",
      "Progress:65.4% Speed(reviews/sec):3902. #Correct:148 #Trained:244 Training Accuracy:60.6%\r",
      "Progress:65.7% Speed(reviews/sec):3894. #Correct:148 #Trained:245 Training Accuracy:60.4%\r",
      "Progress:66.0% Speed(reviews/sec):3885. #Correct:149 #Trained:246 Training Accuracy:60.5%\r",
      "Progress:66.3% Speed(reviews/sec):3877. #Correct:149 #Trained:247 Training Accuracy:60.3%\r",
      "Progress:66.5% Speed(reviews/sec):3873. #Correct:150 #Trained:248 Training Accuracy:60.4%\r",
      "Progress:66.8% Speed(reviews/sec):3863. #Correct:150 #Trained:249 Training Accuracy:60.2%\r",
      "Progress:67.1% Speed(reviews/sec):3836. #Correct:151 #Trained:250 Training Accuracy:60.4%\r",
      "Progress:67.3% Speed(reviews/sec):3827. #Correct:152 #Trained:251 Training Accuracy:60.5%\r",
      "Progress:67.6% Speed(reviews/sec):3826. #Correct:153 #Trained:252 Training Accuracy:60.7%\r",
      "Progress:67.9% Speed(reviews/sec):3815. #Correct:154 #Trained:253 Training Accuracy:60.8%\r",
      "Progress:68.1% Speed(reviews/sec):3809. #Correct:155 #Trained:254 Training Accuracy:61.0%\r",
      "Progress:68.4% Speed(reviews/sec):3803. #Correct:156 #Trained:255 Training Accuracy:61.1%\r",
      "Progress:68.7% Speed(reviews/sec):3801. #Correct:157 #Trained:256 Training Accuracy:61.3%\r",
      "Progress:69.0% Speed(reviews/sec):3782. #Correct:158 #Trained:257 Training Accuracy:61.4%\r",
      "Progress:69.2% Speed(reviews/sec):3772. #Correct:159 #Trained:258 Training Accuracy:61.6%\r",
      "Progress:69.5% Speed(reviews/sec):3763. #Correct:160 #Trained:259 Training Accuracy:61.7%\r",
      "Progress:69.8% Speed(reviews/sec):3753. #Correct:160 #Trained:260 Training Accuracy:61.5%\r",
      "Progress:70.0% Speed(reviews/sec):3745. #Correct:161 #Trained:261 Training Accuracy:61.6%\r",
      "Progress:70.3% Speed(reviews/sec):3740. #Correct:162 #Trained:262 Training Accuracy:61.8%\r",
      "Progress:70.6% Speed(reviews/sec):3733. #Correct:163 #Trained:263 Training Accuracy:61.9%\r",
      "Progress:70.8% Speed(reviews/sec):3725. #Correct:164 #Trained:264 Training Accuracy:62.1%\r",
      "Progress:71.1% Speed(reviews/sec):3716. #Correct:165 #Trained:265 Training Accuracy:62.2%\r",
      "Progress:71.4% Speed(reviews/sec):3710. #Correct:166 #Trained:266 Training Accuracy:62.4%\r",
      "Progress:71.6% Speed(reviews/sec):3703. #Correct:166 #Trained:267 Training Accuracy:62.1%\r",
      "Progress:71.9% Speed(reviews/sec):3695. #Correct:166 #Trained:268 Training Accuracy:61.9%\r",
      "Progress:72.2% Speed(reviews/sec):3690. #Correct:167 #Trained:269 Training Accuracy:62.0%\r",
      "Progress:72.5% Speed(reviews/sec):3684. #Correct:168 #Trained:270 Training Accuracy:62.2%\r",
      "Progress:72.7% Speed(reviews/sec):3680. #Correct:169 #Trained:271 Training Accuracy:62.3%\r",
      "Progress:73.0% Speed(reviews/sec):3676. #Correct:170 #Trained:272 Training Accuracy:62.5%\r",
      "Progress:73.3% Speed(reviews/sec):3673. #Correct:171 #Trained:273 Training Accuracy:62.6%\r",
      "Progress:73.5% Speed(reviews/sec):3665. #Correct:172 #Trained:274 Training Accuracy:62.7%\r",
      "Progress:73.8% Speed(reviews/sec):3659. #Correct:173 #Trained:275 Training Accuracy:62.9%\r",
      "Progress:74.1% Speed(reviews/sec):3640. #Correct:173 #Trained:276 Training Accuracy:62.6%\r",
      "Progress:74.3% Speed(reviews/sec):3634. #Correct:173 #Trained:277 Training Accuracy:62.4%\r",
      "Progress:74.6% Speed(reviews/sec):3625. #Correct:174 #Trained:278 Training Accuracy:62.5%\r",
      "Progress:74.9% Speed(reviews/sec):3624. #Correct:174 #Trained:279 Training Accuracy:62.3%\r",
      "Progress:75.2% Speed(reviews/sec):3620. #Correct:174 #Trained:280 Training Accuracy:62.1%\r",
      "Progress:75.4% Speed(reviews/sec):3616. #Correct:175 #Trained:281 Training Accuracy:62.2%\r",
      "Progress:75.7% Speed(reviews/sec):3614. #Correct:176 #Trained:282 Training Accuracy:62.4%\r",
      "Progress:76.0% Speed(reviews/sec):3611. #Correct:177 #Trained:283 Training Accuracy:62.5%\r",
      "Progress:76.2% Speed(reviews/sec):3608. #Correct:178 #Trained:284 Training Accuracy:62.6%\r",
      "Progress:76.5% Speed(reviews/sec):3606. #Correct:178 #Trained:285 Training Accuracy:62.4%\r",
      "Progress:76.8% Speed(reviews/sec):3602. #Correct:179 #Trained:286 Training Accuracy:62.5%\r",
      "Progress:77.0% Speed(reviews/sec):3598. #Correct:180 #Trained:287 Training Accuracy:62.7%\r",
      "Progress:77.3% Speed(reviews/sec):3597. #Correct:180 #Trained:288 Training Accuracy:62.5%\r",
      "Progress:77.6% Speed(reviews/sec):3593. #Correct:180 #Trained:289 Training Accuracy:62.2%\r",
      "Progress:77.8% Speed(reviews/sec):3592. #Correct:181 #Trained:290 Training Accuracy:62.4%\r",
      "Progress:78.1% Speed(reviews/sec):3567. #Correct:181 #Trained:291 Training Accuracy:62.1%\r",
      "Progress:78.4% Speed(reviews/sec):3564. #Correct:181 #Trained:292 Training Accuracy:61.9%\r",
      "Progress:78.7% Speed(reviews/sec):3561. #Correct:182 #Trained:293 Training Accuracy:62.1%\r",
      "Progress:78.9% Speed(reviews/sec):3561. #Correct:183 #Trained:294 Training Accuracy:62.2%\r",
      "Progress:79.2% Speed(reviews/sec):3560. #Correct:184 #Trained:295 Training Accuracy:62.3%\r",
      "Progress:79.5% Speed(reviews/sec):3552. #Correct:184 #Trained:296 Training Accuracy:62.1%\r",
      "Progress:79.7% Speed(reviews/sec):3552. #Correct:185 #Trained:297 Training Accuracy:62.2%\r",
      "Progress:80.0% Speed(reviews/sec):3550. #Correct:186 #Trained:298 Training Accuracy:62.4%\r",
      "Progress:80.3% Speed(reviews/sec):3548. #Correct:186 #Trained:299 Training Accuracy:62.2%\r",
      "Progress:80.5% Speed(reviews/sec):3549. #Correct:187 #Trained:300 Training Accuracy:62.3%\r",
      "Progress:80.8% Speed(reviews/sec):3550. #Correct:188 #Trained:301 Training Accuracy:62.4%\r",
      "Progress:81.1% Speed(reviews/sec):3551. #Correct:188 #Trained:302 Training Accuracy:62.2%\r",
      "Progress:81.4% Speed(reviews/sec):3552. #Correct:188 #Trained:303 Training Accuracy:62.0%\r",
      "Progress:81.6% Speed(reviews/sec):3552. #Correct:189 #Trained:304 Training Accuracy:62.1%\r",
      "Progress:81.9% Speed(reviews/sec):3555. #Correct:189 #Trained:305 Training Accuracy:61.9%\r",
      "Progress:82.2% Speed(reviews/sec):3542. #Correct:190 #Trained:306 Training Accuracy:62.0%\r",
      "Progress:82.4% Speed(reviews/sec):3544. #Correct:190 #Trained:307 Training Accuracy:61.8%\r",
      "Progress:82.7% Speed(reviews/sec):3536. #Correct:191 #Trained:308 Training Accuracy:62.0%\r",
      "Progress:83.0% Speed(reviews/sec):3538. #Correct:192 #Trained:309 Training Accuracy:62.1%\r",
      "Progress:83.2% Speed(reviews/sec):3539. #Correct:193 #Trained:310 Training Accuracy:62.2%\r",
      "Progress:83.5% Speed(reviews/sec):3542. #Correct:194 #Trained:311 Training Accuracy:62.3%\r",
      "Progress:83.8% Speed(reviews/sec):3544. #Correct:195 #Trained:312 Training Accuracy:62.5%\r",
      "Progress:84.0% Speed(reviews/sec):3537. #Correct:195 #Trained:313 Training Accuracy:62.3%\r",
      "Progress:84.3% Speed(reviews/sec):3532. #Correct:196 #Trained:314 Training Accuracy:62.4%\r",
      "Progress:84.6% Speed(reviews/sec):3534. #Correct:197 #Trained:315 Training Accuracy:62.5%\r",
      "Progress:84.9% Speed(reviews/sec):3532. #Correct:198 #Trained:316 Training Accuracy:62.6%\r",
      "Progress:85.1% Speed(reviews/sec):3534. #Correct:199 #Trained:317 Training Accuracy:62.7%\r",
      "Progress:85.4% Speed(reviews/sec):3536. #Correct:199 #Trained:318 Training Accuracy:62.5%\r",
      "Progress:85.7% Speed(reviews/sec):3539. #Correct:200 #Trained:319 Training Accuracy:62.6%\r",
      "Progress:85.9% Speed(reviews/sec):3539. #Correct:201 #Trained:320 Training Accuracy:62.8%\r",
      "Progress:86.2% Speed(reviews/sec):3535. #Correct:202 #Trained:321 Training Accuracy:62.9%\r",
      "Progress:86.5% Speed(reviews/sec):3538. #Correct:203 #Trained:322 Training Accuracy:63.0%\r",
      "Progress:86.7% Speed(reviews/sec):3537. #Correct:204 #Trained:323 Training Accuracy:63.1%\r",
      "Progress:87.0% Speed(reviews/sec):3540. #Correct:205 #Trained:324 Training Accuracy:63.2%\r",
      "Progress:87.3% Speed(reviews/sec):3543. #Correct:206 #Trained:325 Training Accuracy:63.3%\r",
      "Progress:87.6% Speed(reviews/sec):3542. #Correct:206 #Trained:326 Training Accuracy:63.1%\r",
      "Progress:87.8% Speed(reviews/sec):3544. #Correct:207 #Trained:327 Training Accuracy:63.3%\r",
      "Progress:88.1% Speed(reviews/sec):3548. #Correct:207 #Trained:328 Training Accuracy:63.1%\r",
      "Progress:88.4% Speed(reviews/sec):3548. #Correct:208 #Trained:329 Training Accuracy:63.2%\r",
      "Progress:88.6% Speed(reviews/sec):3550. #Correct:209 #Trained:330 Training Accuracy:63.3%\r",
      "Progress:88.9% Speed(reviews/sec):3550. #Correct:210 #Trained:331 Training Accuracy:63.4%\r",
      "Progress:89.2% Speed(reviews/sec):3551. #Correct:211 #Trained:332 Training Accuracy:63.5%\r",
      "Progress:89.4% Speed(reviews/sec):3552. #Correct:212 #Trained:333 Training Accuracy:63.6%\r",
      "Progress:89.7% Speed(reviews/sec):3553. #Correct:212 #Trained:334 Training Accuracy:63.4%\r",
      "Progress:90.0% Speed(reviews/sec):3556. #Correct:213 #Trained:335 Training Accuracy:63.5%\r",
      "Progress:90.2% Speed(reviews/sec):3558. #Correct:213 #Trained:336 Training Accuracy:63.3%\r",
      "Progress:90.5% Speed(reviews/sec):3558. #Correct:214 #Trained:337 Training Accuracy:63.5%\r",
      "Progress:90.8% Speed(reviews/sec):3560. #Correct:214 #Trained:338 Training Accuracy:63.3%\r",
      "Progress:91.1% Speed(reviews/sec):3561. #Correct:215 #Trained:339 Training Accuracy:63.4%\r",
      "Progress:91.3% Speed(reviews/sec):3567. #Correct:216 #Trained:340 Training Accuracy:63.5%\r",
      "Progress:91.6% Speed(reviews/sec):3572. #Correct:217 #Trained:341 Training Accuracy:63.6%\r",
      "Progress:91.9% Speed(reviews/sec):3577. #Correct:218 #Trained:342 Training Accuracy:63.7%\r",
      "Progress:92.1% Speed(reviews/sec):3581. #Correct:219 #Trained:343 Training Accuracy:63.8%\r",
      "Progress:92.4% Speed(reviews/sec):3580. #Correct:220 #Trained:344 Training Accuracy:63.9%\r",
      "Progress:92.7% Speed(reviews/sec):3585. #Correct:220 #Trained:345 Training Accuracy:63.7%\r",
      "Progress:92.9% Speed(reviews/sec):3588. #Correct:220 #Trained:346 Training Accuracy:63.5%\r",
      "Progress:93.2% Speed(reviews/sec):3594. #Correct:221 #Trained:347 Training Accuracy:63.6%\r",
      "Progress:93.5% Speed(reviews/sec):3600. #Correct:221 #Trained:348 Training Accuracy:63.5%\r",
      "Progress:93.8% Speed(reviews/sec):3602. #Correct:222 #Trained:349 Training Accuracy:63.6%\r",
      "Progress:94.0% Speed(reviews/sec):3604. #Correct:223 #Trained:350 Training Accuracy:63.7%\r",
      "Progress:94.3% Speed(reviews/sec):3607. #Correct:223 #Trained:351 Training Accuracy:63.5%\r",
      "Progress:94.6% Speed(reviews/sec):3607. #Correct:224 #Trained:352 Training Accuracy:63.6%\r",
      "Progress:94.8% Speed(reviews/sec):3612. #Correct:225 #Trained:353 Training Accuracy:63.7%\r",
      "Progress:95.1% Speed(reviews/sec):3613. #Correct:226 #Trained:354 Training Accuracy:63.8%\r",
      "Progress:95.4% Speed(reviews/sec):3616. #Correct:226 #Trained:355 Training Accuracy:63.6%\r",
      "Progress:95.6% Speed(reviews/sec):3619. #Correct:227 #Trained:356 Training Accuracy:63.7%\r",
      "Progress:95.9% Speed(reviews/sec):3622. #Correct:228 #Trained:357 Training Accuracy:63.8%\r",
      "Progress:96.2% Speed(reviews/sec):3608. #Correct:229 #Trained:358 Training Accuracy:63.9%\r",
      "Progress:96.4% Speed(reviews/sec):3588. #Correct:230 #Trained:359 Training Accuracy:64.0%\r",
      "Progress:96.7% Speed(reviews/sec):3573. #Correct:231 #Trained:360 Training Accuracy:64.1%\r",
      "Progress:97.0% Speed(reviews/sec):3561. #Correct:231 #Trained:361 Training Accuracy:63.9%\r",
      "Progress:97.3% Speed(reviews/sec):3551. #Correct:232 #Trained:362 Training Accuracy:64.0%\r",
      "Progress:97.5% Speed(reviews/sec):3543. #Correct:233 #Trained:363 Training Accuracy:64.1%\r",
      "Progress:97.8% Speed(reviews/sec):3537. #Correct:234 #Trained:364 Training Accuracy:64.2%\r",
      "Progress:98.1% Speed(reviews/sec):3534. #Correct:235 #Trained:365 Training Accuracy:64.3%\r",
      "Progress:98.3% Speed(reviews/sec):3529. #Correct:236 #Trained:366 Training Accuracy:64.4%\r",
      "Progress:98.6% Speed(reviews/sec):3525. #Correct:237 #Trained:367 Training Accuracy:64.5%\r",
      "Progress:98.9% Speed(reviews/sec):3524. #Correct:238 #Trained:368 Training Accuracy:64.6%\r",
      "Progress:99.1% Speed(reviews/sec):3520. #Correct:239 #Trained:369 Training Accuracy:64.7%\r",
      "Progress:99.4% Speed(reviews/sec):3518. #Correct:240 #Trained:370 Training Accuracy:64.8%\r",
      "Progress:99.7% Speed(reviews/sec):3517. #Correct:241 #Trained:371 Training Accuracy:64.9%"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-150],labels[:-150],min_count=1,polarity_cutoff=0.05,learning_rate=0.01)\n",
    "mlp.train(reviews[:-150],labels[:-150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the following cell to test it's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Tested:1 Testing Accuracy:100.%\r",
      "Progress:0.66% Speed(reviews/sec):1280. #Correct:2 #Tested:2 Testing Accuracy:100.%\r",
      "Progress:1.33% Speed(reviews/sec):1987. #Correct:2 #Tested:3 Testing Accuracy:66.6%\r",
      "Progress:2.0% Speed(reviews/sec):2471. #Correct:3 #Tested:4 Testing Accuracy:75.0%\r",
      "Progress:2.66% Speed(reviews/sec):2838. #Correct:3 #Tested:5 Testing Accuracy:60.0%\r",
      "Progress:3.33% Speed(reviews/sec):3144. #Correct:4 #Tested:6 Testing Accuracy:66.6%\r",
      "Progress:4.0% Speed(reviews/sec):3307. #Correct:5 #Tested:7 Testing Accuracy:71.4%\r",
      "Progress:4.66% Speed(reviews/sec):3451. #Correct:5 #Tested:8 Testing Accuracy:62.5%\r",
      "Progress:5.33% Speed(reviews/sec):3606. #Correct:6 #Tested:9 Testing Accuracy:66.6%\r",
      "Progress:6.0% Speed(reviews/sec):3770. #Correct:7 #Tested:10 Testing Accuracy:70.0%\r",
      "Progress:6.66% Speed(reviews/sec):3909. #Correct:7 #Tested:11 Testing Accuracy:63.6%\r",
      "Progress:7.33% Speed(reviews/sec):4057. #Correct:7 #Tested:12 Testing Accuracy:58.3%\r",
      "Progress:8.0% Speed(reviews/sec):4171. #Correct:8 #Tested:13 Testing Accuracy:61.5%\r",
      "Progress:8.66% Speed(reviews/sec):4042. #Correct:8 #Tested:14 Testing Accuracy:57.1%\r",
      "Progress:9.33% Speed(reviews/sec):4129. #Correct:9 #Tested:15 Testing Accuracy:60.0%\r",
      "Progress:10.0% Speed(reviews/sec):4214. #Correct:10 #Tested:16 Testing Accuracy:62.5%\r",
      "Progress:10.6% Speed(reviews/sec):4320. #Correct:11 #Tested:17 Testing Accuracy:64.7%\r",
      "Progress:11.3% Speed(reviews/sec):4429. #Correct:11 #Tested:18 Testing Accuracy:61.1%\r",
      "Progress:12.0% Speed(reviews/sec):4523. #Correct:12 #Tested:19 Testing Accuracy:63.1%\r",
      "Progress:12.6% Speed(reviews/sec):4628. #Correct:13 #Tested:20 Testing Accuracy:65.0%\r",
      "Progress:13.3% Speed(reviews/sec):4588. #Correct:14 #Tested:21 Testing Accuracy:66.6%\r",
      "Progress:14.0% Speed(reviews/sec):4597. #Correct:15 #Tested:22 Testing Accuracy:68.1%\r",
      "Progress:14.6% Speed(reviews/sec):4670. #Correct:16 #Tested:23 Testing Accuracy:69.5%\r",
      "Progress:15.3% Speed(reviews/sec):4679. #Correct:17 #Tested:24 Testing Accuracy:70.8%\r",
      "Progress:16.0% Speed(reviews/sec):4744. #Correct:18 #Tested:25 Testing Accuracy:72.0%\r",
      "Progress:16.6% Speed(reviews/sec):4817. #Correct:19 #Tested:26 Testing Accuracy:73.0%\r",
      "Progress:17.3% Speed(reviews/sec):4888. #Correct:20 #Tested:27 Testing Accuracy:74.0%\r",
      "Progress:18.0% Speed(reviews/sec):4778. #Correct:20 #Tested:28 Testing Accuracy:71.4%\r",
      "Progress:18.6% Speed(reviews/sec):4826. #Correct:21 #Tested:29 Testing Accuracy:72.4%\r",
      "Progress:19.3% Speed(reviews/sec):4890. #Correct:22 #Tested:30 Testing Accuracy:73.3%\r",
      "Progress:20.0% Speed(reviews/sec):4958. #Correct:22 #Tested:31 Testing Accuracy:70.9%\r",
      "Progress:20.6% Speed(reviews/sec):4972. #Correct:23 #Tested:32 Testing Accuracy:71.8%\r",
      "Progress:21.3% Speed(reviews/sec):4996. #Correct:24 #Tested:33 Testing Accuracy:72.7%\r",
      "Progress:22.0% Speed(reviews/sec):5068. #Correct:25 #Tested:34 Testing Accuracy:73.5%\r",
      "Progress:22.6% Speed(reviews/sec):5104. #Correct:26 #Tested:35 Testing Accuracy:74.2%\r",
      "Progress:23.3% Speed(reviews/sec):5137. #Correct:27 #Tested:36 Testing Accuracy:75.0%\r",
      "Progress:24.0% Speed(reviews/sec):5159. #Correct:28 #Tested:37 Testing Accuracy:75.6%\r",
      "Progress:24.6% Speed(reviews/sec):5162. #Correct:29 #Tested:38 Testing Accuracy:76.3%\r",
      "Progress:25.3% Speed(reviews/sec):5221. #Correct:29 #Tested:39 Testing Accuracy:74.3%\r",
      "Progress:26.0% Speed(reviews/sec):5261. #Correct:30 #Tested:40 Testing Accuracy:75.0%\r",
      "Progress:26.6% Speed(reviews/sec):5287. #Correct:31 #Tested:41 Testing Accuracy:75.6%\r",
      "Progress:27.3% Speed(reviews/sec):5316. #Correct:32 #Tested:42 Testing Accuracy:76.1%\r",
      "Progress:28.0% Speed(reviews/sec):5352. #Correct:33 #Tested:43 Testing Accuracy:76.7%\r",
      "Progress:28.6% Speed(reviews/sec):5412. #Correct:34 #Tested:44 Testing Accuracy:77.2%\r",
      "Progress:29.3% Speed(reviews/sec):5444. #Correct:34 #Tested:45 Testing Accuracy:75.5%\r",
      "Progress:30.0% Speed(reviews/sec):5475. #Correct:35 #Tested:46 Testing Accuracy:76.0%\r",
      "Progress:30.6% Speed(reviews/sec):5494. #Correct:36 #Tested:47 Testing Accuracy:76.5%\r",
      "Progress:31.3% Speed(reviews/sec):5524. #Correct:36 #Tested:48 Testing Accuracy:75.0%\r",
      "Progress:32.0% Speed(reviews/sec):5573. #Correct:36 #Tested:49 Testing Accuracy:73.4%\r",
      "Progress:32.6% Speed(reviews/sec):5602. #Correct:37 #Tested:50 Testing Accuracy:74.0%\r",
      "Progress:33.3% Speed(reviews/sec):5652. #Correct:38 #Tested:51 Testing Accuracy:74.5%\r",
      "Progress:34.0% Speed(reviews/sec):5702. #Correct:39 #Tested:52 Testing Accuracy:75.0%\r",
      "Progress:34.6% Speed(reviews/sec):5719. #Correct:40 #Tested:53 Testing Accuracy:75.4%\r",
      "Progress:35.3% Speed(reviews/sec):5775. #Correct:41 #Tested:54 Testing Accuracy:75.9%\r",
      "Progress:36.0% Speed(reviews/sec):5795. #Correct:42 #Tested:55 Testing Accuracy:76.3%\r",
      "Progress:36.6% Speed(reviews/sec):5850. #Correct:43 #Tested:56 Testing Accuracy:76.7%\r",
      "Progress:37.3% Speed(reviews/sec):5901. #Correct:44 #Tested:57 Testing Accuracy:77.1%\r",
      "Progress:38.0% Speed(reviews/sec):5919. #Correct:44 #Tested:58 Testing Accuracy:75.8%\r",
      "Progress:38.6% Speed(reviews/sec):5979. #Correct:45 #Tested:59 Testing Accuracy:76.2%\r",
      "Progress:39.3% Speed(reviews/sec):6037. #Correct:46 #Tested:60 Testing Accuracy:76.6%\r",
      "Progress:40.0% Speed(reviews/sec):6098. #Correct:47 #Tested:61 Testing Accuracy:77.0%\r",
      "Progress:40.6% Speed(reviews/sec):6120. #Correct:47 #Tested:62 Testing Accuracy:75.8%\r",
      "Progress:41.3% Speed(reviews/sec):6118. #Correct:48 #Tested:63 Testing Accuracy:76.1%\r",
      "Progress:42.0% Speed(reviews/sec):6161. #Correct:48 #Tested:64 Testing Accuracy:75.0%\r",
      "Progress:42.6% Speed(reviews/sec):6176. #Correct:48 #Tested:65 Testing Accuracy:73.8%\r",
      "Progress:43.3% Speed(reviews/sec):6168. #Correct:49 #Tested:66 Testing Accuracy:74.2%\r",
      "Progress:44.0% Speed(reviews/sec):6135. #Correct:49 #Tested:67 Testing Accuracy:73.1%\r",
      "Progress:44.6% Speed(reviews/sec):6108. #Correct:50 #Tested:68 Testing Accuracy:73.5%\r",
      "Progress:45.3% Speed(reviews/sec):6155. #Correct:51 #Tested:69 Testing Accuracy:73.9%\r",
      "Progress:46.0% Speed(reviews/sec):6207. #Correct:51 #Tested:70 Testing Accuracy:72.8%\r",
      "Progress:46.6% Speed(reviews/sec):6224. #Correct:52 #Tested:71 Testing Accuracy:73.2%\r",
      "Progress:47.3% Speed(reviews/sec):6251. #Correct:53 #Tested:72 Testing Accuracy:73.6%\r",
      "Progress:48.0% Speed(reviews/sec):6283. #Correct:53 #Tested:73 Testing Accuracy:72.6%\r",
      "Progress:48.6% Speed(reviews/sec):6333. #Correct:54 #Tested:74 Testing Accuracy:72.9%\r",
      "Progress:49.3% Speed(reviews/sec):6363. #Correct:55 #Tested:75 Testing Accuracy:73.3%\r",
      "Progress:50.0% Speed(reviews/sec):6394. #Correct:56 #Tested:76 Testing Accuracy:73.6%\r",
      "Progress:50.6% Speed(reviews/sec):6421. #Correct:57 #Tested:77 Testing Accuracy:74.0%\r",
      "Progress:51.3% Speed(reviews/sec):6451. #Correct:58 #Tested:78 Testing Accuracy:74.3%\r",
      "Progress:52.0% Speed(reviews/sec):6502. #Correct:59 #Tested:79 Testing Accuracy:74.6%\r",
      "Progress:52.6% Speed(reviews/sec):6526. #Correct:59 #Tested:80 Testing Accuracy:73.7%\r",
      "Progress:53.3% Speed(reviews/sec):6562. #Correct:59 #Tested:81 Testing Accuracy:72.8%\r",
      "Progress:54.0% Speed(reviews/sec):6601. #Correct:59 #Tested:82 Testing Accuracy:71.9%\r",
      "Progress:54.6% Speed(reviews/sec):6526. #Correct:60 #Tested:83 Testing Accuracy:72.2%\r",
      "Progress:55.3% Speed(reviews/sec):6496. #Correct:60 #Tested:84 Testing Accuracy:71.4%\r",
      "Progress:56.0% Speed(reviews/sec):6443. #Correct:61 #Tested:85 Testing Accuracy:71.7%\r",
      "Progress:56.6% Speed(reviews/sec):6368. #Correct:61 #Tested:86 Testing Accuracy:70.9%\r",
      "Progress:57.3% Speed(reviews/sec):6304. #Correct:61 #Tested:87 Testing Accuracy:70.1%\r",
      "Progress:58.0% Speed(reviews/sec):6261. #Correct:62 #Tested:88 Testing Accuracy:70.4%\r",
      "Progress:58.6% Speed(reviews/sec):6146. #Correct:63 #Tested:89 Testing Accuracy:70.7%\r",
      "Progress:59.3% Speed(reviews/sec):6064. #Correct:64 #Tested:90 Testing Accuracy:71.1%\r",
      "Progress:60.0% Speed(reviews/sec):6034. #Correct:65 #Tested:91 Testing Accuracy:71.4%\r",
      "Progress:60.6% Speed(reviews/sec):6014. #Correct:66 #Tested:92 Testing Accuracy:71.7%\r",
      "Progress:61.3% Speed(reviews/sec):5963. #Correct:66 #Tested:93 Testing Accuracy:70.9%\r",
      "Progress:62.0% Speed(reviews/sec):5939. #Correct:67 #Tested:94 Testing Accuracy:71.2%\r",
      "Progress:62.6% Speed(reviews/sec):5915. #Correct:68 #Tested:95 Testing Accuracy:71.5%\r",
      "Progress:63.3% Speed(reviews/sec):5857. #Correct:69 #Tested:96 Testing Accuracy:71.8%\r",
      "Progress:64.0% Speed(reviews/sec):5833. #Correct:69 #Tested:97 Testing Accuracy:71.1%\r",
      "Progress:64.6% Speed(reviews/sec):5813. #Correct:70 #Tested:98 Testing Accuracy:71.4%\r",
      "Progress:65.3% Speed(reviews/sec):5804. #Correct:71 #Tested:99 Testing Accuracy:71.7%\r",
      "Progress:66.0% Speed(reviews/sec):5796. #Correct:71 #Tested:100 Testing Accuracy:71.0%\r",
      "Progress:66.6% Speed(reviews/sec):5784. #Correct:72 #Tested:101 Testing Accuracy:71.2%\r",
      "Progress:67.3% Speed(reviews/sec):5774. #Correct:73 #Tested:102 Testing Accuracy:71.5%\r",
      "Progress:68.0% Speed(reviews/sec):5733. #Correct:74 #Tested:103 Testing Accuracy:71.8%\r",
      "Progress:68.6% Speed(reviews/sec):5722. #Correct:75 #Tested:104 Testing Accuracy:72.1%\r",
      "Progress:69.3% Speed(reviews/sec):5687. #Correct:76 #Tested:105 Testing Accuracy:72.3%\r",
      "Progress:70.0% Speed(reviews/sec):5666. #Correct:77 #Tested:106 Testing Accuracy:72.6%\r",
      "Progress:70.6% Speed(reviews/sec):5632. #Correct:77 #Tested:107 Testing Accuracy:71.9%\r",
      "Progress:71.3% Speed(reviews/sec):5615. #Correct:78 #Tested:108 Testing Accuracy:72.2%\r",
      "Progress:72.0% Speed(reviews/sec):5607. #Correct:79 #Tested:109 Testing Accuracy:72.4%\r",
      "Progress:72.6% Speed(reviews/sec):5576. #Correct:80 #Tested:110 Testing Accuracy:72.7%\r",
      "Progress:73.3% Speed(reviews/sec):5556. #Correct:81 #Tested:111 Testing Accuracy:72.9%\r",
      "Progress:74.0% Speed(reviews/sec):5492. #Correct:81 #Tested:112 Testing Accuracy:72.3%\r",
      "Progress:74.6% Speed(reviews/sec):5470. #Correct:81 #Tested:113 Testing Accuracy:71.6%\r",
      "Progress:75.3% Speed(reviews/sec):5466. #Correct:82 #Tested:114 Testing Accuracy:71.9%\r",
      "Progress:76.0% Speed(reviews/sec):5430. #Correct:83 #Tested:115 Testing Accuracy:72.1%\r",
      "Progress:76.6% Speed(reviews/sec):5420. #Correct:84 #Tested:116 Testing Accuracy:72.4%\r",
      "Progress:77.3% Speed(reviews/sec):5413. #Correct:85 #Tested:117 Testing Accuracy:72.6%\r",
      "Progress:78.0% Speed(reviews/sec):5410. #Correct:86 #Tested:118 Testing Accuracy:72.8%\r",
      "Progress:78.6% Speed(reviews/sec):5404. #Correct:87 #Tested:119 Testing Accuracy:73.1%\r",
      "Progress:79.3% Speed(reviews/sec):5400. #Correct:87 #Tested:120 Testing Accuracy:72.5%\r",
      "Progress:80.0% Speed(reviews/sec):5397. #Correct:88 #Tested:121 Testing Accuracy:72.7%\r",
      "Progress:80.6% Speed(reviews/sec):5394. #Correct:89 #Tested:122 Testing Accuracy:72.9%\r",
      "Progress:81.3% Speed(reviews/sec):5394. #Correct:90 #Tested:123 Testing Accuracy:73.1%\r",
      "Progress:82.0% Speed(reviews/sec):5392. #Correct:91 #Tested:124 Testing Accuracy:73.3%\r",
      "Progress:82.6% Speed(reviews/sec):5389. #Correct:92 #Tested:125 Testing Accuracy:73.6%\r",
      "Progress:83.3% Speed(reviews/sec):5387. #Correct:92 #Tested:126 Testing Accuracy:73.0%\r",
      "Progress:84.0% Speed(reviews/sec):5319. #Correct:93 #Tested:127 Testing Accuracy:73.2%\r",
      "Progress:84.6% Speed(reviews/sec):5274. #Correct:94 #Tested:128 Testing Accuracy:73.4%\r",
      "Progress:85.3% Speed(reviews/sec):5272. #Correct:95 #Tested:129 Testing Accuracy:73.6%\r",
      "Progress:86.0% Speed(reviews/sec):5238. #Correct:95 #Tested:130 Testing Accuracy:73.0%\r",
      "Progress:86.6% Speed(reviews/sec):5228. #Correct:96 #Tested:131 Testing Accuracy:73.2%\r",
      "Progress:87.3% Speed(reviews/sec):5205. #Correct:97 #Tested:132 Testing Accuracy:73.4%\r",
      "Progress:88.0% Speed(reviews/sec):5181. #Correct:98 #Tested:133 Testing Accuracy:73.6%\r",
      "Progress:88.6% Speed(reviews/sec):5180. #Correct:98 #Tested:134 Testing Accuracy:73.1%\r",
      "Progress:89.3% Speed(reviews/sec):5162. #Correct:99 #Tested:135 Testing Accuracy:73.3%\r",
      "Progress:90.0% Speed(reviews/sec):5156. #Correct:100 #Tested:136 Testing Accuracy:73.5%\r",
      "Progress:90.6% Speed(reviews/sec):5141. #Correct:100 #Tested:137 Testing Accuracy:72.9%\r",
      "Progress:91.3% Speed(reviews/sec):5124. #Correct:100 #Tested:138 Testing Accuracy:72.4%\r",
      "Progress:92.0% Speed(reviews/sec):5126. #Correct:100 #Tested:139 Testing Accuracy:71.9%\r",
      "Progress:92.6% Speed(reviews/sec):5119. #Correct:101 #Tested:140 Testing Accuracy:72.1%\r",
      "Progress:93.3% Speed(reviews/sec):5096. #Correct:102 #Tested:141 Testing Accuracy:72.3%\r",
      "Progress:94.0% Speed(reviews/sec):5070. #Correct:103 #Tested:142 Testing Accuracy:72.5%\r",
      "Progress:94.6% Speed(reviews/sec):5056. #Correct:103 #Tested:143 Testing Accuracy:72.0%\r",
      "Progress:95.3% Speed(reviews/sec):5057. #Correct:104 #Tested:144 Testing Accuracy:72.2%\r",
      "Progress:96.0% Speed(reviews/sec):5040. #Correct:105 #Tested:145 Testing Accuracy:72.4%\r",
      "Progress:96.6% Speed(reviews/sec):5033. #Correct:106 #Tested:146 Testing Accuracy:72.6%\r",
      "Progress:97.3% Speed(reviews/sec):5030. #Correct:106 #Tested:147 Testing Accuracy:72.1%\r",
      "Progress:98.0% Speed(reviews/sec):5006. #Correct:107 #Tested:148 Testing Accuracy:72.2%\r",
      "Progress:98.6% Speed(reviews/sec):5008. #Correct:108 #Tested:149 Testing Accuracy:72.4%\r",
      "Progress:99.3% Speed(reviews/sec):4986. #Correct:109 #Tested:150 Testing Accuracy:72.6%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-150:],labels[-150:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to train your network with a much larger polarity cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "\r",
      "Progress:0.23% Speed(reviews/sec):1151. #Correct:1 #Trained:2 Training Accuracy:50.0%\r",
      "Progress:0.47% Speed(reviews/sec):1857. #Correct:1 #Trained:3 Training Accuracy:33.3%\r",
      "Progress:0.71% Speed(reviews/sec):2405. #Correct:2 #Trained:4 Training Accuracy:50.0%\r",
      "Progress:0.95% Speed(reviews/sec):2879. #Correct:3 #Trained:5 Training Accuracy:60.0%\r",
      "Progress:1.18% Speed(reviews/sec):3274. #Correct:3 #Trained:6 Training Accuracy:50.0%\r",
      "Progress:1.42% Speed(reviews/sec):3608. #Correct:3 #Trained:7 Training Accuracy:42.8%\r",
      "Progress:1.66% Speed(reviews/sec):3847. #Correct:3 #Trained:8 Training Accuracy:37.5%\r",
      "Progress:1.90% Speed(reviews/sec):4119. #Correct:3 #Trained:9 Training Accuracy:33.3%\r",
      "Progress:2.13% Speed(reviews/sec):4316. #Correct:3 #Trained:10 Training Accuracy:30.0%\r",
      "Progress:2.37% Speed(reviews/sec):4510. #Correct:4 #Trained:11 Training Accuracy:36.3%\r",
      "Progress:2.61% Speed(reviews/sec):4734. #Correct:5 #Trained:12 Training Accuracy:41.6%\r",
      "Progress:2.85% Speed(reviews/sec):4710. #Correct:6 #Trained:13 Training Accuracy:46.1%\r",
      "Progress:3.08% Speed(reviews/sec):4737. #Correct:6 #Trained:14 Training Accuracy:42.8%\r",
      "Progress:3.32% Speed(reviews/sec):4862. #Correct:6 #Trained:15 Training Accuracy:40.0%\r",
      "Progress:3.56% Speed(reviews/sec):4895. #Correct:7 #Trained:16 Training Accuracy:43.7%\r",
      "Progress:3.80% Speed(reviews/sec):4982. #Correct:7 #Trained:17 Training Accuracy:41.1%\r",
      "Progress:4.03% Speed(reviews/sec):5063. #Correct:8 #Trained:18 Training Accuracy:44.4%\r",
      "Progress:4.27% Speed(reviews/sec):5053. #Correct:9 #Trained:19 Training Accuracy:47.3%\r",
      "Progress:4.51% Speed(reviews/sec):5172. #Correct:10 #Trained:20 Training Accuracy:50.0%\r",
      "Progress:4.75% Speed(reviews/sec):5181. #Correct:10 #Trained:21 Training Accuracy:47.6%\r",
      "Progress:4.98% Speed(reviews/sec):5036. #Correct:11 #Trained:22 Training Accuracy:50.0%\r",
      "Progress:5.22% Speed(reviews/sec):5099. #Correct:12 #Trained:23 Training Accuracy:52.1%\r",
      "Progress:5.46% Speed(reviews/sec):5198. #Correct:13 #Trained:24 Training Accuracy:54.1%\r",
      "Progress:5.70% Speed(reviews/sec):5307. #Correct:13 #Trained:25 Training Accuracy:52.0%\r",
      "Progress:5.93% Speed(reviews/sec):5399. #Correct:13 #Trained:26 Training Accuracy:50.0%\r",
      "Progress:6.17% Speed(reviews/sec):5471. #Correct:13 #Trained:27 Training Accuracy:48.1%\r",
      "Progress:6.41% Speed(reviews/sec):5481. #Correct:14 #Trained:28 Training Accuracy:50.0%\r",
      "Progress:6.65% Speed(reviews/sec):5554. #Correct:14 #Trained:29 Training Accuracy:48.2%\r",
      "Progress:6.88% Speed(reviews/sec):5627. #Correct:15 #Trained:30 Training Accuracy:50.0%\r",
      "Progress:7.12% Speed(reviews/sec):5640. #Correct:16 #Trained:31 Training Accuracy:51.6%\r",
      "Progress:7.36% Speed(reviews/sec):5670. #Correct:17 #Trained:32 Training Accuracy:53.1%\r",
      "Progress:7.60% Speed(reviews/sec):5722. #Correct:17 #Trained:33 Training Accuracy:51.5%\r",
      "Progress:7.83% Speed(reviews/sec):5762. #Correct:17 #Trained:34 Training Accuracy:50.0%\r",
      "Progress:8.07% Speed(reviews/sec):5839. #Correct:18 #Trained:35 Training Accuracy:51.4%\r",
      "Progress:8.31% Speed(reviews/sec):5878. #Correct:18 #Trained:36 Training Accuracy:50.0%\r",
      "Progress:8.55% Speed(reviews/sec):5946. #Correct:18 #Trained:37 Training Accuracy:48.6%\r",
      "Progress:8.78% Speed(reviews/sec):5992. #Correct:19 #Trained:38 Training Accuracy:50.0%\r",
      "Progress:9.02% Speed(reviews/sec):6034. #Correct:20 #Trained:39 Training Accuracy:51.2%\r",
      "Progress:9.26% Speed(reviews/sec):6125. #Correct:20 #Trained:40 Training Accuracy:50.0%\r",
      "Progress:9.50% Speed(reviews/sec):6139. #Correct:20 #Trained:41 Training Accuracy:48.7%\r",
      "Progress:9.73% Speed(reviews/sec):6175. #Correct:21 #Trained:42 Training Accuracy:50.0%\r",
      "Progress:9.97% Speed(reviews/sec):6198. #Correct:21 #Trained:43 Training Accuracy:48.8%\r",
      "Progress:10.2% Speed(reviews/sec):6243. #Correct:21 #Trained:44 Training Accuracy:47.7%\r",
      "Progress:10.4% Speed(reviews/sec):6288. #Correct:22 #Trained:45 Training Accuracy:48.8%\r",
      "Progress:10.6% Speed(reviews/sec):6310. #Correct:23 #Trained:46 Training Accuracy:50.0%\r",
      "Progress:10.9% Speed(reviews/sec):6325. #Correct:24 #Trained:47 Training Accuracy:51.0%\r",
      "Progress:11.1% Speed(reviews/sec):6352. #Correct:24 #Trained:48 Training Accuracy:50.0%\r",
      "Progress:11.4% Speed(reviews/sec):6371. #Correct:25 #Trained:49 Training Accuracy:51.0%\r",
      "Progress:11.6% Speed(reviews/sec):6407. #Correct:25 #Trained:50 Training Accuracy:50.0%\r",
      "Progress:11.8% Speed(reviews/sec):6416. #Correct:25 #Trained:51 Training Accuracy:49.0%\r",
      "Progress:12.1% Speed(reviews/sec):6437. #Correct:25 #Trained:52 Training Accuracy:48.0%\r",
      "Progress:12.3% Speed(reviews/sec):6472. #Correct:26 #Trained:53 Training Accuracy:49.0%\r",
      "Progress:12.5% Speed(reviews/sec):6479. #Correct:27 #Trained:54 Training Accuracy:50.0%\r",
      "Progress:12.8% Speed(reviews/sec):6532. #Correct:27 #Trained:55 Training Accuracy:49.0%\r",
      "Progress:13.0% Speed(reviews/sec):6551. #Correct:28 #Trained:56 Training Accuracy:50.0%\r",
      "Progress:13.3% Speed(reviews/sec):6580. #Correct:28 #Trained:57 Training Accuracy:49.1%\r",
      "Progress:13.5% Speed(reviews/sec):6600. #Correct:28 #Trained:58 Training Accuracy:48.2%\r",
      "Progress:13.7% Speed(reviews/sec):6619. #Correct:29 #Trained:59 Training Accuracy:49.1%\r",
      "Progress:14.0% Speed(reviews/sec):6660. #Correct:30 #Trained:60 Training Accuracy:50.0%\r",
      "Progress:14.2% Speed(reviews/sec):6636. #Correct:30 #Trained:61 Training Accuracy:49.1%\r",
      "Progress:14.4% Speed(reviews/sec):6653. #Correct:30 #Trained:62 Training Accuracy:48.3%\r",
      "Progress:14.7% Speed(reviews/sec):6676. #Correct:31 #Trained:63 Training Accuracy:49.2%\r",
      "Progress:14.9% Speed(reviews/sec):6702. #Correct:32 #Trained:64 Training Accuracy:50.0%\r",
      "Progress:15.2% Speed(reviews/sec):6731. #Correct:33 #Trained:65 Training Accuracy:50.7%\r",
      "Progress:15.4% Speed(reviews/sec):6757. #Correct:33 #Trained:66 Training Accuracy:50.0%\r",
      "Progress:15.6% Speed(reviews/sec):6776. #Correct:33 #Trained:67 Training Accuracy:49.2%\r",
      "Progress:15.9% Speed(reviews/sec):6793. #Correct:33 #Trained:68 Training Accuracy:48.5%\r",
      "Progress:16.1% Speed(reviews/sec):6818. #Correct:34 #Trained:69 Training Accuracy:49.2%\r",
      "Progress:16.3% Speed(reviews/sec):6853. #Correct:35 #Trained:70 Training Accuracy:50.0%\r",
      "Progress:16.6% Speed(reviews/sec):6847. #Correct:36 #Trained:71 Training Accuracy:50.7%\r",
      "Progress:16.8% Speed(reviews/sec):6875. #Correct:36 #Trained:72 Training Accuracy:50.0%\r",
      "Progress:17.1% Speed(reviews/sec):6878. #Correct:37 #Trained:73 Training Accuracy:50.6%\r",
      "Progress:17.3% Speed(reviews/sec):6882. #Correct:38 #Trained:74 Training Accuracy:51.3%\r",
      "Progress:17.5% Speed(reviews/sec):6902. #Correct:39 #Trained:75 Training Accuracy:52.0%\r",
      "Progress:17.8% Speed(reviews/sec):6898. #Correct:39 #Trained:76 Training Accuracy:51.3%\r",
      "Progress:18.0% Speed(reviews/sec):6912. #Correct:39 #Trained:77 Training Accuracy:50.6%\r",
      "Progress:18.2% Speed(reviews/sec):6919. #Correct:40 #Trained:78 Training Accuracy:51.2%\r",
      "Progress:18.5% Speed(reviews/sec):6944. #Correct:41 #Trained:79 Training Accuracy:51.8%\r",
      "Progress:18.7% Speed(reviews/sec):6993. #Correct:42 #Trained:80 Training Accuracy:52.5%\r",
      "Progress:19.0% Speed(reviews/sec):6993. #Correct:43 #Trained:81 Training Accuracy:53.0%\r",
      "Progress:19.2% Speed(reviews/sec):7006. #Correct:44 #Trained:82 Training Accuracy:53.6%\r",
      "Progress:19.4% Speed(reviews/sec):7026. #Correct:45 #Trained:83 Training Accuracy:54.2%\r",
      "Progress:19.7% Speed(reviews/sec):7047. #Correct:46 #Trained:84 Training Accuracy:54.7%\r",
      "Progress:19.9% Speed(reviews/sec):7093. #Correct:47 #Trained:85 Training Accuracy:55.2%\r",
      "Progress:20.1% Speed(reviews/sec):7114. #Correct:47 #Trained:86 Training Accuracy:54.6%\r",
      "Progress:20.4% Speed(reviews/sec):7133. #Correct:47 #Trained:87 Training Accuracy:54.0%\r",
      "Progress:20.6% Speed(reviews/sec):7145. #Correct:47 #Trained:88 Training Accuracy:53.4%\r",
      "Progress:20.9% Speed(reviews/sec):7160. #Correct:48 #Trained:89 Training Accuracy:53.9%\r",
      "Progress:21.1% Speed(reviews/sec):7188. #Correct:49 #Trained:90 Training Accuracy:54.4%\r",
      "Progress:21.3% Speed(reviews/sec):7194. #Correct:50 #Trained:91 Training Accuracy:54.9%\r",
      "Progress:21.6% Speed(reviews/sec):7225. #Correct:51 #Trained:92 Training Accuracy:55.4%\r",
      "Progress:21.8% Speed(reviews/sec):7230. #Correct:51 #Trained:93 Training Accuracy:54.8%\r",
      "Progress:22.0% Speed(reviews/sec):7231. #Correct:52 #Trained:94 Training Accuracy:55.3%\r",
      "Progress:22.3% Speed(reviews/sec):7273. #Correct:52 #Trained:95 Training Accuracy:54.7%\r",
      "Progress:22.5% Speed(reviews/sec):7274. #Correct:53 #Trained:96 Training Accuracy:55.2%\r",
      "Progress:22.8% Speed(reviews/sec):7310. #Correct:54 #Trained:97 Training Accuracy:55.6%\r",
      "Progress:23.0% Speed(reviews/sec):7342. #Correct:54 #Trained:98 Training Accuracy:55.1%\r",
      "Progress:23.2% Speed(reviews/sec):7316. #Correct:54 #Trained:99 Training Accuracy:54.5%\r",
      "Progress:23.5% Speed(reviews/sec):7348. #Correct:54 #Trained:100 Training Accuracy:54.0%\r",
      "Progress:23.7% Speed(reviews/sec):7348. #Correct:55 #Trained:101 Training Accuracy:54.4%\r",
      "Progress:23.9% Speed(reviews/sec):7366. #Correct:55 #Trained:102 Training Accuracy:53.9%\r",
      "Progress:24.2% Speed(reviews/sec):7374. #Correct:56 #Trained:103 Training Accuracy:54.3%\r",
      "Progress:24.4% Speed(reviews/sec):7276. #Correct:57 #Trained:104 Training Accuracy:54.8%\r",
      "Progress:24.7% Speed(reviews/sec):7288. #Correct:58 #Trained:105 Training Accuracy:55.2%\r",
      "Progress:24.9% Speed(reviews/sec):7311. #Correct:58 #Trained:106 Training Accuracy:54.7%\r",
      "Progress:25.1% Speed(reviews/sec):7272. #Correct:58 #Trained:107 Training Accuracy:54.2%\r",
      "Progress:25.4% Speed(reviews/sec):7223. #Correct:59 #Trained:108 Training Accuracy:54.6%\r",
      "Progress:25.6% Speed(reviews/sec):7220. #Correct:59 #Trained:109 Training Accuracy:54.1%\r",
      "Progress:25.8% Speed(reviews/sec):7245. #Correct:60 #Trained:110 Training Accuracy:54.5%\r",
      "Progress:26.1% Speed(reviews/sec):7172. #Correct:60 #Trained:111 Training Accuracy:54.0%\r",
      "Progress:26.3% Speed(reviews/sec):7191. #Correct:61 #Trained:112 Training Accuracy:54.4%\r",
      "Progress:26.6% Speed(reviews/sec):7209. #Correct:61 #Trained:113 Training Accuracy:53.9%\r",
      "Progress:26.8% Speed(reviews/sec):7199. #Correct:61 #Trained:114 Training Accuracy:53.5%\r",
      "Progress:27.0% Speed(reviews/sec):7213. #Correct:62 #Trained:115 Training Accuracy:53.9%\r",
      "Progress:27.3% Speed(reviews/sec):7198. #Correct:63 #Trained:116 Training Accuracy:54.3%\r",
      "Progress:27.5% Speed(reviews/sec):7155. #Correct:64 #Trained:117 Training Accuracy:54.7%\r",
      "Progress:27.7% Speed(reviews/sec):7148. #Correct:64 #Trained:118 Training Accuracy:54.2%\r",
      "Progress:28.0% Speed(reviews/sec):7115. #Correct:64 #Trained:119 Training Accuracy:53.7%\r",
      "Progress:28.2% Speed(reviews/sec):7138. #Correct:65 #Trained:120 Training Accuracy:54.1%\r",
      "Progress:28.5% Speed(reviews/sec):7122. #Correct:66 #Trained:121 Training Accuracy:54.5%\r",
      "Progress:28.7% Speed(reviews/sec):7123. #Correct:66 #Trained:122 Training Accuracy:54.0%\r",
      "Progress:28.9% Speed(reviews/sec):7143. #Correct:66 #Trained:123 Training Accuracy:53.6%\r",
      "Progress:29.2% Speed(reviews/sec):7132. #Correct:66 #Trained:124 Training Accuracy:53.2%\r",
      "Progress:29.4% Speed(reviews/sec):7157. #Correct:66 #Trained:125 Training Accuracy:52.8%\r",
      "Progress:29.6% Speed(reviews/sec):7176. #Correct:67 #Trained:126 Training Accuracy:53.1%\r",
      "Progress:29.9% Speed(reviews/sec):7159. #Correct:68 #Trained:127 Training Accuracy:53.5%\r",
      "Progress:30.1% Speed(reviews/sec):7152. #Correct:68 #Trained:128 Training Accuracy:53.1%\r",
      "Progress:30.4% Speed(reviews/sec):7161. #Correct:69 #Trained:129 Training Accuracy:53.4%\r",
      "Progress:30.6% Speed(reviews/sec):7175. #Correct:70 #Trained:130 Training Accuracy:53.8%\r",
      "Progress:30.8% Speed(reviews/sec):7156. #Correct:71 #Trained:131 Training Accuracy:54.1%\r",
      "Progress:31.1% Speed(reviews/sec):7150. #Correct:71 #Trained:132 Training Accuracy:53.7%\r",
      "Progress:31.3% Speed(reviews/sec):7151. #Correct:72 #Trained:133 Training Accuracy:54.1%\r",
      "Progress:31.5% Speed(reviews/sec):7156. #Correct:73 #Trained:134 Training Accuracy:54.4%\r",
      "Progress:31.8% Speed(reviews/sec):7179. #Correct:74 #Trained:135 Training Accuracy:54.8%\r",
      "Progress:32.0% Speed(reviews/sec):7196. #Correct:74 #Trained:136 Training Accuracy:54.4%\r",
      "Progress:32.3% Speed(reviews/sec):7206. #Correct:74 #Trained:137 Training Accuracy:54.0%\r",
      "Progress:32.5% Speed(reviews/sec):7147. #Correct:75 #Trained:138 Training Accuracy:54.3%\r",
      "Progress:32.7% Speed(reviews/sec):7085. #Correct:76 #Trained:139 Training Accuracy:54.6%\r",
      "Progress:33.0% Speed(reviews/sec):7104. #Correct:77 #Trained:140 Training Accuracy:55.0%\r",
      "Progress:33.2% Speed(reviews/sec):7089. #Correct:78 #Trained:141 Training Accuracy:55.3%\r",
      "Progress:33.4% Speed(reviews/sec):7085. #Correct:78 #Trained:142 Training Accuracy:54.9%\r",
      "Progress:33.7% Speed(reviews/sec):7081. #Correct:79 #Trained:143 Training Accuracy:55.2%\r",
      "Progress:33.9% Speed(reviews/sec):7096. #Correct:79 #Trained:144 Training Accuracy:54.8%\r",
      "Progress:34.2% Speed(reviews/sec):7097. #Correct:80 #Trained:145 Training Accuracy:55.1%\r",
      "Progress:34.4% Speed(reviews/sec):7087. #Correct:80 #Trained:146 Training Accuracy:54.7%\r",
      "Progress:34.6% Speed(reviews/sec):7070. #Correct:81 #Trained:147 Training Accuracy:55.1%\r",
      "Progress:34.9% Speed(reviews/sec):7065. #Correct:82 #Trained:148 Training Accuracy:55.4%\r",
      "Progress:35.1% Speed(reviews/sec):7086. #Correct:83 #Trained:149 Training Accuracy:55.7%\r",
      "Progress:35.3% Speed(reviews/sec):7109. #Correct:83 #Trained:150 Training Accuracy:55.3%\r",
      "Progress:35.6% Speed(reviews/sec):7133. #Correct:83 #Trained:151 Training Accuracy:54.9%\r",
      "Progress:35.8% Speed(reviews/sec):7127. #Correct:83 #Trained:152 Training Accuracy:54.6%\r",
      "Progress:36.1% Speed(reviews/sec):7127. #Correct:84 #Trained:153 Training Accuracy:54.9%\r",
      "Progress:36.3% Speed(reviews/sec):7131. #Correct:85 #Trained:154 Training Accuracy:55.1%\r",
      "Progress:36.5% Speed(reviews/sec):7159. #Correct:86 #Trained:155 Training Accuracy:55.4%\r",
      "Progress:36.8% Speed(reviews/sec):7169. #Correct:87 #Trained:156 Training Accuracy:55.7%\r",
      "Progress:37.0% Speed(reviews/sec):7181. #Correct:88 #Trained:157 Training Accuracy:56.0%\r",
      "Progress:37.2% Speed(reviews/sec):7195. #Correct:88 #Trained:158 Training Accuracy:55.6%\r",
      "Progress:37.5% Speed(reviews/sec):7209. #Correct:88 #Trained:159 Training Accuracy:55.3%\r",
      "Progress:37.7% Speed(reviews/sec):7231. #Correct:89 #Trained:160 Training Accuracy:55.6%\r",
      "Progress:38.0% Speed(reviews/sec):7239. #Correct:90 #Trained:161 Training Accuracy:55.9%\r",
      "Progress:38.2% Speed(reviews/sec):7252. #Correct:91 #Trained:162 Training Accuracy:56.1%\r",
      "Progress:38.4% Speed(reviews/sec):7264. #Correct:92 #Trained:163 Training Accuracy:56.4%\r",
      "Progress:38.7% Speed(reviews/sec):7279. #Correct:93 #Trained:164 Training Accuracy:56.7%\r",
      "Progress:38.9% Speed(reviews/sec):7303. #Correct:93 #Trained:165 Training Accuracy:56.3%\r",
      "Progress:39.1% Speed(reviews/sec):7317. #Correct:94 #Trained:166 Training Accuracy:56.6%\r",
      "Progress:39.4% Speed(reviews/sec):7320. #Correct:95 #Trained:167 Training Accuracy:56.8%\r",
      "Progress:39.6% Speed(reviews/sec):7331. #Correct:96 #Trained:168 Training Accuracy:57.1%\r",
      "Progress:39.9% Speed(reviews/sec):7345. #Correct:97 #Trained:169 Training Accuracy:57.3%\r",
      "Progress:40.1% Speed(reviews/sec):7356. #Correct:98 #Trained:170 Training Accuracy:57.6%\r",
      "Progress:40.3% Speed(reviews/sec):7353. #Correct:99 #Trained:171 Training Accuracy:57.8%\r",
      "Progress:40.6% Speed(reviews/sec):7365. #Correct:100 #Trained:172 Training Accuracy:58.1%\r",
      "Progress:40.8% Speed(reviews/sec):7378. #Correct:100 #Trained:173 Training Accuracy:57.8%\r",
      "Progress:41.0% Speed(reviews/sec):7390. #Correct:101 #Trained:174 Training Accuracy:58.0%\r",
      "Progress:41.3% Speed(reviews/sec):7410. #Correct:102 #Trained:175 Training Accuracy:58.2%\r",
      "Progress:41.5% Speed(reviews/sec):7425. #Correct:103 #Trained:176 Training Accuracy:58.5%\r",
      "Progress:41.8% Speed(reviews/sec):7438. #Correct:103 #Trained:177 Training Accuracy:58.1%\r",
      "Progress:42.0% Speed(reviews/sec):7449. #Correct:104 #Trained:178 Training Accuracy:58.4%\r",
      "Progress:42.2% Speed(reviews/sec):7454. #Correct:104 #Trained:179 Training Accuracy:58.1%\r",
      "Progress:42.5% Speed(reviews/sec):7479. #Correct:105 #Trained:180 Training Accuracy:58.3%\r",
      "Progress:42.7% Speed(reviews/sec):7488. #Correct:105 #Trained:181 Training Accuracy:58.0%\r",
      "Progress:42.9% Speed(reviews/sec):7471. #Correct:105 #Trained:182 Training Accuracy:57.6%\r",
      "Progress:43.2% Speed(reviews/sec):7459. #Correct:106 #Trained:183 Training Accuracy:57.9%\r",
      "Progress:43.4% Speed(reviews/sec):7478. #Correct:106 #Trained:184 Training Accuracy:57.6%\r",
      "Progress:43.7% Speed(reviews/sec):7497. #Correct:106 #Trained:185 Training Accuracy:57.2%\r",
      "Progress:43.9% Speed(reviews/sec):7499. #Correct:107 #Trained:186 Training Accuracy:57.5%\r",
      "Progress:44.1% Speed(reviews/sec):7504. #Correct:108 #Trained:187 Training Accuracy:57.7%\r",
      "Progress:44.4% Speed(reviews/sec):7516. #Correct:108 #Trained:188 Training Accuracy:57.4%\r",
      "Progress:44.6% Speed(reviews/sec):7528. #Correct:109 #Trained:189 Training Accuracy:57.6%\r",
      "Progress:44.8% Speed(reviews/sec):7552. #Correct:110 #Trained:190 Training Accuracy:57.8%\r",
      "Progress:45.1% Speed(reviews/sec):7559. #Correct:111 #Trained:191 Training Accuracy:58.1%\r",
      "Progress:45.3% Speed(reviews/sec):7569. #Correct:112 #Trained:192 Training Accuracy:58.3%\r",
      "Progress:45.6% Speed(reviews/sec):7583. #Correct:112 #Trained:193 Training Accuracy:58.0%\r",
      "Progress:45.8% Speed(reviews/sec):7592. #Correct:113 #Trained:194 Training Accuracy:58.2%\r",
      "Progress:46.0% Speed(reviews/sec):7609. #Correct:113 #Trained:195 Training Accuracy:57.9%\r",
      "Progress:46.3% Speed(reviews/sec):7618. #Correct:113 #Trained:196 Training Accuracy:57.6%\r",
      "Progress:46.5% Speed(reviews/sec):7642. #Correct:114 #Trained:197 Training Accuracy:57.8%\r",
      "Progress:46.7% Speed(reviews/sec):7645. #Correct:115 #Trained:198 Training Accuracy:58.0%\r",
      "Progress:47.0% Speed(reviews/sec):7668. #Correct:116 #Trained:199 Training Accuracy:58.2%\r",
      "Progress:47.2% Speed(reviews/sec):7679. #Correct:116 #Trained:200 Training Accuracy:58.0%\r",
      "Progress:47.5% Speed(reviews/sec):7680. #Correct:117 #Trained:201 Training Accuracy:58.2%\r",
      "Progress:47.7% Speed(reviews/sec):7680. #Correct:117 #Trained:202 Training Accuracy:57.9%\r",
      "Progress:47.9% Speed(reviews/sec):7677. #Correct:118 #Trained:203 Training Accuracy:58.1%\r",
      "Progress:48.2% Speed(reviews/sec):7653. #Correct:119 #Trained:204 Training Accuracy:58.3%\r",
      "Progress:48.4% Speed(reviews/sec):7672. #Correct:120 #Trained:205 Training Accuracy:58.5%\r",
      "Progress:48.6% Speed(reviews/sec):7678. #Correct:120 #Trained:206 Training Accuracy:58.2%\r",
      "Progress:48.9% Speed(reviews/sec):7675. #Correct:120 #Trained:207 Training Accuracy:57.9%\r",
      "Progress:49.1% Speed(reviews/sec):7670. #Correct:120 #Trained:208 Training Accuracy:57.6%\r",
      "Progress:49.4% Speed(reviews/sec):7684. #Correct:121 #Trained:209 Training Accuracy:57.8%\r",
      "Progress:49.6% Speed(reviews/sec):7705. #Correct:121 #Trained:210 Training Accuracy:57.6%\r",
      "Progress:49.8% Speed(reviews/sec):7597. #Correct:122 #Trained:211 Training Accuracy:57.8%\r",
      "Progress:50.1% Speed(reviews/sec):7515. #Correct:122 #Trained:212 Training Accuracy:57.5%\r",
      "Progress:50.3% Speed(reviews/sec):7413. #Correct:122 #Trained:213 Training Accuracy:57.2%\r",
      "Progress:50.5% Speed(reviews/sec):7318. #Correct:123 #Trained:214 Training Accuracy:57.4%\r",
      "Progress:50.8% Speed(reviews/sec):7253. #Correct:124 #Trained:215 Training Accuracy:57.6%\r",
      "Progress:51.0% Speed(reviews/sec):7180. #Correct:125 #Trained:216 Training Accuracy:57.8%\r",
      "Progress:51.3% Speed(reviews/sec):7155. #Correct:126 #Trained:217 Training Accuracy:58.0%\r",
      "Progress:51.5% Speed(reviews/sec):7122. #Correct:127 #Trained:218 Training Accuracy:58.2%\r",
      "Progress:51.7% Speed(reviews/sec):7073. #Correct:128 #Trained:219 Training Accuracy:58.4%\r",
      "Progress:52.0% Speed(reviews/sec):7056. #Correct:128 #Trained:220 Training Accuracy:58.1%\r",
      "Progress:52.2% Speed(reviews/sec):6996. #Correct:129 #Trained:221 Training Accuracy:58.3%\r",
      "Progress:52.4% Speed(reviews/sec):6960. #Correct:129 #Trained:222 Training Accuracy:58.1%\r",
      "Progress:52.7% Speed(reviews/sec):6893. #Correct:130 #Trained:223 Training Accuracy:58.2%\r",
      "Progress:52.9% Speed(reviews/sec):6845. #Correct:131 #Trained:224 Training Accuracy:58.4%\r",
      "Progress:53.2% Speed(reviews/sec):6812. #Correct:132 #Trained:225 Training Accuracy:58.6%\r",
      "Progress:53.4% Speed(reviews/sec):6800. #Correct:132 #Trained:226 Training Accuracy:58.4%\r",
      "Progress:53.6% Speed(reviews/sec):6764. #Correct:133 #Trained:227 Training Accuracy:58.5%\r",
      "Progress:53.9% Speed(reviews/sec):6736. #Correct:134 #Trained:228 Training Accuracy:58.7%\r",
      "Progress:54.1% Speed(reviews/sec):6704. #Correct:135 #Trained:229 Training Accuracy:58.9%\r",
      "Progress:54.3% Speed(reviews/sec):6669. #Correct:136 #Trained:230 Training Accuracy:59.1%\r",
      "Progress:54.6% Speed(reviews/sec):6637. #Correct:137 #Trained:231 Training Accuracy:59.3%\r",
      "Progress:54.8% Speed(reviews/sec):6613. #Correct:138 #Trained:232 Training Accuracy:59.4%\r",
      "Progress:55.1% Speed(reviews/sec):6594. #Correct:139 #Trained:233 Training Accuracy:59.6%\r",
      "Progress:55.3% Speed(reviews/sec):6560. #Correct:140 #Trained:234 Training Accuracy:59.8%\r",
      "Progress:55.5% Speed(reviews/sec):6549. #Correct:140 #Trained:235 Training Accuracy:59.5%\r",
      "Progress:55.8% Speed(reviews/sec):6523. #Correct:141 #Trained:236 Training Accuracy:59.7%\r",
      "Progress:56.0% Speed(reviews/sec):6505. #Correct:142 #Trained:237 Training Accuracy:59.9%\r",
      "Progress:56.2% Speed(reviews/sec):6485. #Correct:143 #Trained:238 Training Accuracy:60.0%\r",
      "Progress:56.5% Speed(reviews/sec):6474. #Correct:144 #Trained:239 Training Accuracy:60.2%\r",
      "Progress:56.7% Speed(reviews/sec):6464. #Correct:145 #Trained:240 Training Accuracy:60.4%\r",
      "Progress:57.0% Speed(reviews/sec):6436. #Correct:146 #Trained:241 Training Accuracy:60.5%\r",
      "Progress:57.2% Speed(reviews/sec):6417. #Correct:147 #Trained:242 Training Accuracy:60.7%\r",
      "Progress:57.4% Speed(reviews/sec):6399. #Correct:148 #Trained:243 Training Accuracy:60.9%\r",
      "Progress:57.7% Speed(reviews/sec):6387. #Correct:148 #Trained:244 Training Accuracy:60.6%\r",
      "Progress:57.9% Speed(reviews/sec):6391. #Correct:148 #Trained:245 Training Accuracy:60.4%\r",
      "Progress:58.1% Speed(reviews/sec):6376. #Correct:149 #Trained:246 Training Accuracy:60.5%\r",
      "Progress:58.4% Speed(reviews/sec):6368. #Correct:149 #Trained:247 Training Accuracy:60.3%\r",
      "Progress:58.6% Speed(reviews/sec):6354. #Correct:150 #Trained:248 Training Accuracy:60.4%\r",
      "Progress:58.9% Speed(reviews/sec):6344. #Correct:150 #Trained:249 Training Accuracy:60.2%\r",
      "Progress:59.1% Speed(reviews/sec):6340. #Correct:151 #Trained:250 Training Accuracy:60.4%\r",
      "Progress:59.3% Speed(reviews/sec):6327. #Correct:152 #Trained:251 Training Accuracy:60.5%\r",
      "Progress:59.6% Speed(reviews/sec):6319. #Correct:153 #Trained:252 Training Accuracy:60.7%\r",
      "Progress:59.8% Speed(reviews/sec):6300. #Correct:154 #Trained:253 Training Accuracy:60.8%\r",
      "Progress:60.0% Speed(reviews/sec):6300. #Correct:154 #Trained:254 Training Accuracy:60.6%\r",
      "Progress:60.3% Speed(reviews/sec):6288. #Correct:155 #Trained:255 Training Accuracy:60.7%\r",
      "Progress:60.5% Speed(reviews/sec):6290. #Correct:156 #Trained:256 Training Accuracy:60.9%\r",
      "Progress:60.8% Speed(reviews/sec):6287. #Correct:157 #Trained:257 Training Accuracy:61.0%\r",
      "Progress:61.0% Speed(reviews/sec):6280. #Correct:158 #Trained:258 Training Accuracy:61.2%\r",
      "Progress:61.2% Speed(reviews/sec):6267. #Correct:159 #Trained:259 Training Accuracy:61.3%\r",
      "Progress:61.5% Speed(reviews/sec):6265. #Correct:159 #Trained:260 Training Accuracy:61.1%\r",
      "Progress:61.7% Speed(reviews/sec):6258. #Correct:160 #Trained:261 Training Accuracy:61.3%\r",
      "Progress:61.9% Speed(reviews/sec):6254. #Correct:161 #Trained:262 Training Accuracy:61.4%\r",
      "Progress:62.2% Speed(reviews/sec):6257. #Correct:162 #Trained:263 Training Accuracy:61.5%\r",
      "Progress:62.4% Speed(reviews/sec):6251. #Correct:163 #Trained:264 Training Accuracy:61.7%\r",
      "Progress:62.7% Speed(reviews/sec):6249. #Correct:164 #Trained:265 Training Accuracy:61.8%\r",
      "Progress:62.9% Speed(reviews/sec):6245. #Correct:165 #Trained:266 Training Accuracy:62.0%\r",
      "Progress:63.1% Speed(reviews/sec):6246. #Correct:165 #Trained:267 Training Accuracy:61.7%\r",
      "Progress:63.4% Speed(reviews/sec):6240. #Correct:165 #Trained:268 Training Accuracy:61.5%\r",
      "Progress:63.6% Speed(reviews/sec):6230. #Correct:166 #Trained:269 Training Accuracy:61.7%\r",
      "Progress:63.8% Speed(reviews/sec):6235. #Correct:166 #Trained:270 Training Accuracy:61.4%\r",
      "Progress:64.1% Speed(reviews/sec):6222. #Correct:167 #Trained:271 Training Accuracy:61.6%\r",
      "Progress:64.3% Speed(reviews/sec):6199. #Correct:168 #Trained:272 Training Accuracy:61.7%\r",
      "Progress:64.6% Speed(reviews/sec):6183. #Correct:169 #Trained:273 Training Accuracy:61.9%\r",
      "Progress:64.8% Speed(reviews/sec):6184. #Correct:169 #Trained:274 Training Accuracy:61.6%\r",
      "Progress:65.0% Speed(reviews/sec):6177. #Correct:170 #Trained:275 Training Accuracy:61.8%\r",
      "Progress:65.3% Speed(reviews/sec):6179. #Correct:170 #Trained:276 Training Accuracy:61.5%\r",
      "Progress:65.5% Speed(reviews/sec):6176. #Correct:171 #Trained:277 Training Accuracy:61.7%\r",
      "Progress:65.7% Speed(reviews/sec):6152. #Correct:172 #Trained:278 Training Accuracy:61.8%\r",
      "Progress:66.0% Speed(reviews/sec):6150. #Correct:172 #Trained:279 Training Accuracy:61.6%\r",
      "Progress:66.2% Speed(reviews/sec):6150. #Correct:173 #Trained:280 Training Accuracy:61.7%\r",
      "Progress:66.5% Speed(reviews/sec):6146. #Correct:174 #Trained:281 Training Accuracy:61.9%\r",
      "Progress:66.7% Speed(reviews/sec):6142. #Correct:175 #Trained:282 Training Accuracy:62.0%\r",
      "Progress:66.9% Speed(reviews/sec):6137. #Correct:176 #Trained:283 Training Accuracy:62.1%\r",
      "Progress:67.2% Speed(reviews/sec):6109. #Correct:177 #Trained:284 Training Accuracy:62.3%\r",
      "Progress:67.4% Speed(reviews/sec):6110. #Correct:177 #Trained:285 Training Accuracy:62.1%\r",
      "Progress:67.6% Speed(reviews/sec):6092. #Correct:178 #Trained:286 Training Accuracy:62.2%\r",
      "Progress:67.9% Speed(reviews/sec):6065. #Correct:179 #Trained:287 Training Accuracy:62.3%\r",
      "Progress:68.1% Speed(reviews/sec):6058. #Correct:179 #Trained:288 Training Accuracy:62.1%\r",
      "Progress:68.4% Speed(reviews/sec):6042. #Correct:179 #Trained:289 Training Accuracy:61.9%\r",
      "Progress:68.6% Speed(reviews/sec):6041. #Correct:180 #Trained:290 Training Accuracy:62.0%\r",
      "Progress:68.8% Speed(reviews/sec):6043. #Correct:180 #Trained:291 Training Accuracy:61.8%\r",
      "Progress:69.1% Speed(reviews/sec):6042. #Correct:180 #Trained:292 Training Accuracy:61.6%\r",
      "Progress:69.3% Speed(reviews/sec):6042. #Correct:181 #Trained:293 Training Accuracy:61.7%\r",
      "Progress:69.5% Speed(reviews/sec):6039. #Correct:182 #Trained:294 Training Accuracy:61.9%\r",
      "Progress:69.8% Speed(reviews/sec):6042. #Correct:183 #Trained:295 Training Accuracy:62.0%\r",
      "Progress:70.0% Speed(reviews/sec):6039. #Correct:183 #Trained:296 Training Accuracy:61.8%\r",
      "Progress:70.3% Speed(reviews/sec):6040. #Correct:184 #Trained:297 Training Accuracy:61.9%\r",
      "Progress:70.5% Speed(reviews/sec):6038. #Correct:185 #Trained:298 Training Accuracy:62.0%\r",
      "Progress:70.7% Speed(reviews/sec):6039. #Correct:185 #Trained:299 Training Accuracy:61.8%\r",
      "Progress:71.0% Speed(reviews/sec):6047. #Correct:185 #Trained:300 Training Accuracy:61.6%\r",
      "Progress:71.2% Speed(reviews/sec):6047. #Correct:186 #Trained:301 Training Accuracy:61.7%\r",
      "Progress:71.4% Speed(reviews/sec):6046. #Correct:187 #Trained:302 Training Accuracy:61.9%\r",
      "Progress:71.7% Speed(reviews/sec):6051. #Correct:188 #Trained:303 Training Accuracy:62.0%\r",
      "Progress:71.9% Speed(reviews/sec):6047. #Correct:189 #Trained:304 Training Accuracy:62.1%\r",
      "Progress:72.2% Speed(reviews/sec):6057. #Correct:190 #Trained:305 Training Accuracy:62.2%\r",
      "Progress:72.4% Speed(reviews/sec):6059. #Correct:191 #Trained:306 Training Accuracy:62.4%\r",
      "Progress:72.6% Speed(reviews/sec):6062. #Correct:191 #Trained:307 Training Accuracy:62.2%\r",
      "Progress:72.9% Speed(reviews/sec):6066. #Correct:191 #Trained:308 Training Accuracy:62.0%\r",
      "Progress:73.1% Speed(reviews/sec):6068. #Correct:192 #Trained:309 Training Accuracy:62.1%\r",
      "Progress:73.3% Speed(reviews/sec):6073. #Correct:193 #Trained:310 Training Accuracy:62.2%\r",
      "Progress:73.6% Speed(reviews/sec):6075. #Correct:194 #Trained:311 Training Accuracy:62.3%\r",
      "Progress:73.8% Speed(reviews/sec):6078. #Correct:195 #Trained:312 Training Accuracy:62.5%\r",
      "Progress:74.1% Speed(reviews/sec):6080. #Correct:195 #Trained:313 Training Accuracy:62.3%\r",
      "Progress:74.3% Speed(reviews/sec):6086. #Correct:196 #Trained:314 Training Accuracy:62.4%\r",
      "Progress:74.5% Speed(reviews/sec):6092. #Correct:197 #Trained:315 Training Accuracy:62.5%\r",
      "Progress:74.8% Speed(reviews/sec):6095. #Correct:198 #Trained:316 Training Accuracy:62.6%\r",
      "Progress:75.0% Speed(reviews/sec):6101. #Correct:199 #Trained:317 Training Accuracy:62.7%\r",
      "Progress:75.2% Speed(reviews/sec):6104. #Correct:199 #Trained:318 Training Accuracy:62.5%\r",
      "Progress:75.5% Speed(reviews/sec):6107. #Correct:200 #Trained:319 Training Accuracy:62.6%\r",
      "Progress:75.7% Speed(reviews/sec):6115. #Correct:200 #Trained:320 Training Accuracy:62.5%\r",
      "Progress:76.0% Speed(reviews/sec):6117. #Correct:201 #Trained:321 Training Accuracy:62.6%\r",
      "Progress:76.2% Speed(reviews/sec):6120. #Correct:202 #Trained:322 Training Accuracy:62.7%\r",
      "Progress:76.4% Speed(reviews/sec):6119. #Correct:203 #Trained:323 Training Accuracy:62.8%\r",
      "Progress:76.7% Speed(reviews/sec):6126. #Correct:203 #Trained:324 Training Accuracy:62.6%\r",
      "Progress:76.9% Speed(reviews/sec):6134. #Correct:204 #Trained:325 Training Accuracy:62.7%\r",
      "Progress:77.1% Speed(reviews/sec):6137. #Correct:204 #Trained:326 Training Accuracy:62.5%\r",
      "Progress:77.4% Speed(reviews/sec):6145. #Correct:205 #Trained:327 Training Accuracy:62.6%\r",
      "Progress:77.6% Speed(reviews/sec):6154. #Correct:205 #Trained:328 Training Accuracy:62.5%\r",
      "Progress:77.9% Speed(reviews/sec):6152. #Correct:206 #Trained:329 Training Accuracy:62.6%\r",
      "Progress:78.1% Speed(reviews/sec):6162. #Correct:206 #Trained:330 Training Accuracy:62.4%\r",
      "Progress:78.3% Speed(reviews/sec):6173. #Correct:207 #Trained:331 Training Accuracy:62.5%\r",
      "Progress:78.6% Speed(reviews/sec):6185. #Correct:207 #Trained:332 Training Accuracy:62.3%\r",
      "Progress:78.8% Speed(reviews/sec):6184. #Correct:208 #Trained:333 Training Accuracy:62.4%\r",
      "Progress:79.0% Speed(reviews/sec):6185. #Correct:209 #Trained:334 Training Accuracy:62.5%\r",
      "Progress:79.3% Speed(reviews/sec):6189. #Correct:210 #Trained:335 Training Accuracy:62.6%\r",
      "Progress:79.5% Speed(reviews/sec):6196. #Correct:211 #Trained:336 Training Accuracy:62.7%\r",
      "Progress:79.8% Speed(reviews/sec):6197. #Correct:211 #Trained:337 Training Accuracy:62.6%\r",
      "Progress:80.0% Speed(reviews/sec):6206. #Correct:211 #Trained:338 Training Accuracy:62.4%\r",
      "Progress:80.2% Speed(reviews/sec):6217. #Correct:212 #Trained:339 Training Accuracy:62.5%\r",
      "Progress:80.5% Speed(reviews/sec):6227. #Correct:213 #Trained:340 Training Accuracy:62.6%\r",
      "Progress:80.7% Speed(reviews/sec):6238. #Correct:213 #Trained:341 Training Accuracy:62.4%\r",
      "Progress:80.9% Speed(reviews/sec):6248. #Correct:213 #Trained:342 Training Accuracy:62.2%\r",
      "Progress:81.2% Speed(reviews/sec):6258. #Correct:214 #Trained:343 Training Accuracy:62.3%\r",
      "Progress:81.4% Speed(reviews/sec):6267. #Correct:215 #Trained:344 Training Accuracy:62.5%\r",
      "Progress:81.7% Speed(reviews/sec):6277. #Correct:215 #Trained:345 Training Accuracy:62.3%\r",
      "Progress:81.9% Speed(reviews/sec):6286. #Correct:216 #Trained:346 Training Accuracy:62.4%\r",
      "Progress:82.1% Speed(reviews/sec):6292. #Correct:217 #Trained:347 Training Accuracy:62.5%\r",
      "Progress:82.4% Speed(reviews/sec):6283. #Correct:218 #Trained:348 Training Accuracy:62.6%\r",
      "Progress:82.6% Speed(reviews/sec):6293. #Correct:218 #Trained:349 Training Accuracy:62.4%\r",
      "Progress:82.8% Speed(reviews/sec):6295. #Correct:218 #Trained:350 Training Accuracy:62.2%\r",
      "Progress:83.1% Speed(reviews/sec):6306. #Correct:219 #Trained:351 Training Accuracy:62.3%\r",
      "Progress:83.3% Speed(reviews/sec):6316. #Correct:219 #Trained:352 Training Accuracy:62.2%\r",
      "Progress:83.6% Speed(reviews/sec):6312. #Correct:220 #Trained:353 Training Accuracy:62.3%\r",
      "Progress:83.8% Speed(reviews/sec):6307. #Correct:220 #Trained:354 Training Accuracy:62.1%\r",
      "Progress:84.0% Speed(reviews/sec):6304. #Correct:221 #Trained:355 Training Accuracy:62.2%\r",
      "Progress:84.3% Speed(reviews/sec):6307. #Correct:222 #Trained:356 Training Accuracy:62.3%\r",
      "Progress:84.5% Speed(reviews/sec):6304. #Correct:223 #Trained:357 Training Accuracy:62.4%\r",
      "Progress:84.7% Speed(reviews/sec):6258. #Correct:224 #Trained:358 Training Accuracy:62.5%\r",
      "Progress:85.0% Speed(reviews/sec):6225. #Correct:225 #Trained:359 Training Accuracy:62.6%\r",
      "Progress:85.2% Speed(reviews/sec):6175. #Correct:226 #Trained:360 Training Accuracy:62.7%\r",
      "Progress:85.5% Speed(reviews/sec):6172. #Correct:226 #Trained:361 Training Accuracy:62.6%\r",
      "Progress:85.7% Speed(reviews/sec):6160. #Correct:227 #Trained:362 Training Accuracy:62.7%\r",
      "Progress:85.9% Speed(reviews/sec):6152. #Correct:228 #Trained:363 Training Accuracy:62.8%\r",
      "Progress:86.2% Speed(reviews/sec):6151. #Correct:229 #Trained:364 Training Accuracy:62.9%\r",
      "Progress:86.4% Speed(reviews/sec):6150. #Correct:230 #Trained:365 Training Accuracy:63.0%\r",
      "Progress:86.6% Speed(reviews/sec):6146. #Correct:231 #Trained:366 Training Accuracy:63.1%\r",
      "Progress:86.9% Speed(reviews/sec):6137. #Correct:232 #Trained:367 Training Accuracy:63.2%\r",
      "Progress:87.1% Speed(reviews/sec):6138. #Correct:232 #Trained:368 Training Accuracy:63.0%\r",
      "Progress:87.4% Speed(reviews/sec):6132. #Correct:233 #Trained:369 Training Accuracy:63.1%\r",
      "Progress:87.6% Speed(reviews/sec):6128. #Correct:234 #Trained:370 Training Accuracy:63.2%\r",
      "Progress:87.8% Speed(reviews/sec):6129. #Correct:235 #Trained:371 Training Accuracy:63.3%\r",
      "Progress:88.1% Speed(reviews/sec):6128. #Correct:236 #Trained:372 Training Accuracy:63.4%\r",
      "Progress:88.3% Speed(reviews/sec):6125. #Correct:237 #Trained:373 Training Accuracy:63.5%\r",
      "Progress:88.5% Speed(reviews/sec):6127. #Correct:237 #Trained:374 Training Accuracy:63.3%\r",
      "Progress:88.8% Speed(reviews/sec):6127. #Correct:238 #Trained:375 Training Accuracy:63.4%\r",
      "Progress:89.0% Speed(reviews/sec):6133. #Correct:238 #Trained:376 Training Accuracy:63.2%\r",
      "Progress:89.3% Speed(reviews/sec):6130. #Correct:239 #Trained:377 Training Accuracy:63.3%\r",
      "Progress:89.5% Speed(reviews/sec):6129. #Correct:240 #Trained:378 Training Accuracy:63.4%\r",
      "Progress:89.7% Speed(reviews/sec):6127. #Correct:240 #Trained:379 Training Accuracy:63.3%\r",
      "Progress:90.0% Speed(reviews/sec):6127. #Correct:241 #Trained:380 Training Accuracy:63.4%\r",
      "Progress:90.2% Speed(reviews/sec):6129. #Correct:242 #Trained:381 Training Accuracy:63.5%\r",
      "Progress:90.4% Speed(reviews/sec):6130. #Correct:242 #Trained:382 Training Accuracy:63.3%\r",
      "Progress:90.7% Speed(reviews/sec):6133. #Correct:242 #Trained:383 Training Accuracy:63.1%\r",
      "Progress:90.9% Speed(reviews/sec):6129. #Correct:243 #Trained:384 Training Accuracy:63.2%\r",
      "Progress:91.2% Speed(reviews/sec):6131. #Correct:243 #Trained:385 Training Accuracy:63.1%\r",
      "Progress:91.4% Speed(reviews/sec):6136. #Correct:244 #Trained:386 Training Accuracy:63.2%\r",
      "Progress:91.6% Speed(reviews/sec):6133. #Correct:245 #Trained:387 Training Accuracy:63.3%\r",
      "Progress:91.9% Speed(reviews/sec):6136. #Correct:246 #Trained:388 Training Accuracy:63.4%\r",
      "Progress:92.1% Speed(reviews/sec):6140. #Correct:246 #Trained:389 Training Accuracy:63.2%\r",
      "Progress:92.3% Speed(reviews/sec):6141. #Correct:247 #Trained:390 Training Accuracy:63.3%\r",
      "Progress:92.6% Speed(reviews/sec):6148. #Correct:248 #Trained:391 Training Accuracy:63.4%\r",
      "Progress:92.8% Speed(reviews/sec):6153. #Correct:249 #Trained:392 Training Accuracy:63.5%\r",
      "Progress:93.1% Speed(reviews/sec):6154. #Correct:250 #Trained:393 Training Accuracy:63.6%\r",
      "Progress:93.3% Speed(reviews/sec):6161. #Correct:251 #Trained:394 Training Accuracy:63.7%\r",
      "Progress:93.5% Speed(reviews/sec):6164. #Correct:252 #Trained:395 Training Accuracy:63.7%\r",
      "Progress:93.8% Speed(reviews/sec):6171. #Correct:253 #Trained:396 Training Accuracy:63.8%\r",
      "Progress:94.0% Speed(reviews/sec):6150. #Correct:254 #Trained:397 Training Accuracy:63.9%\r",
      "Progress:94.2% Speed(reviews/sec):6153. #Correct:255 #Trained:398 Training Accuracy:64.0%\r",
      "Progress:94.5% Speed(reviews/sec):6158. #Correct:255 #Trained:399 Training Accuracy:63.9%\r",
      "Progress:94.7% Speed(reviews/sec):6165. #Correct:255 #Trained:400 Training Accuracy:63.7%\r",
      "Progress:95.0% Speed(reviews/sec):6173. #Correct:255 #Trained:401 Training Accuracy:63.5%\r",
      "Progress:95.2% Speed(reviews/sec):6174. #Correct:256 #Trained:402 Training Accuracy:63.6%\r",
      "Progress:95.4% Speed(reviews/sec):6175. #Correct:257 #Trained:403 Training Accuracy:63.7%\r",
      "Progress:95.7% Speed(reviews/sec):6177. #Correct:258 #Trained:404 Training Accuracy:63.8%\r",
      "Progress:95.9% Speed(reviews/sec):6175. #Correct:259 #Trained:405 Training Accuracy:63.9%\r",
      "Progress:96.1% Speed(reviews/sec):6183. #Correct:260 #Trained:406 Training Accuracy:64.0%\r",
      "Progress:96.4% Speed(reviews/sec):6188. #Correct:260 #Trained:407 Training Accuracy:63.8%\r",
      "Progress:96.6% Speed(reviews/sec):6191. #Correct:261 #Trained:408 Training Accuracy:63.9%\r",
      "Progress:96.9% Speed(reviews/sec):6192. #Correct:262 #Trained:409 Training Accuracy:64.0%\r",
      "Progress:97.1% Speed(reviews/sec):6196. #Correct:262 #Trained:410 Training Accuracy:63.9%\r",
      "Progress:97.3% Speed(reviews/sec):6205. #Correct:263 #Trained:411 Training Accuracy:63.9%\r",
      "Progress:97.6% Speed(reviews/sec):6206. #Correct:264 #Trained:412 Training Accuracy:64.0%\r",
      "Progress:97.8% Speed(reviews/sec):6209. #Correct:265 #Trained:413 Training Accuracy:64.1%\r",
      "Progress:98.0% Speed(reviews/sec):6212. #Correct:266 #Trained:414 Training Accuracy:64.2%\r",
      "Progress:98.3% Speed(reviews/sec):6201. #Correct:267 #Trained:415 Training Accuracy:64.3%\r",
      "Progress:98.5% Speed(reviews/sec):6191. #Correct:267 #Trained:416 Training Accuracy:64.1%\r",
      "Progress:98.8% Speed(reviews/sec):6195. #Correct:268 #Trained:417 Training Accuracy:64.2%\r",
      "Progress:99.0% Speed(reviews/sec):6195. #Correct:269 #Trained:418 Training Accuracy:64.3%\r",
      "Progress:99.2% Speed(reviews/sec):6200. #Correct:270 #Trained:419 Training Accuracy:64.4%\r",
      "Progress:99.5% Speed(reviews/sec):6207. #Correct:270 #Trained:420 Training Accuracy:64.2%\r",
      "Progress:99.7% Speed(reviews/sec):6215. #Correct:270 #Trained:421 Training Accuracy:64.1%"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-100],labels[:-100],min_count=2,polarity_cutoff=0.8,learning_rate=0.01)\n",
    "mlp.train(reviews[:-100],labels[:-100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the following cell to test it's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Tested:1 Testing Accuracy:100.%\r",
      "Progress:1.0% Speed(reviews/sec):4100. #Correct:2 #Tested:2 Testing Accuracy:100.%\r",
      "Progress:2.0% Speed(reviews/sec):4568. #Correct:3 #Tested:3 Testing Accuracy:100.%\r",
      "Progress:3.0% Speed(reviews/sec):5793. #Correct:3 #Tested:4 Testing Accuracy:75.0%\r",
      "Progress:4.0% Speed(reviews/sec):6861. #Correct:3 #Tested:5 Testing Accuracy:60.0%\r",
      "Progress:5.0% Speed(reviews/sec):6767. #Correct:4 #Tested:6 Testing Accuracy:66.6%\r",
      "Progress:6.0% Speed(reviews/sec):7317. #Correct:5 #Tested:7 Testing Accuracy:71.4%\r",
      "Progress:7.0% Speed(reviews/sec):8000. #Correct:6 #Tested:8 Testing Accuracy:75.0%\r",
      "Progress:8.0% Speed(reviews/sec):8603. #Correct:7 #Tested:9 Testing Accuracy:77.7%\r",
      "Progress:9.0% Speed(reviews/sec):9129. #Correct:8 #Tested:10 Testing Accuracy:80.0%\r",
      "Progress:10.0% Speed(reviews/sec):9526. #Correct:9 #Tested:11 Testing Accuracy:81.8%\r",
      "Progress:11.0% Speed(reviews/sec):9936. #Correct:10 #Tested:12 Testing Accuracy:83.3%\r",
      "Progress:12.0% Speed(reviews/sec):9775. #Correct:10 #Tested:13 Testing Accuracy:76.9%\r",
      "Progress:13.0% Speed(reviews/sec):9991. #Correct:11 #Tested:14 Testing Accuracy:78.5%\r",
      "Progress:14.0% Speed(reviews/sec):10242 #Correct:11 #Tested:15 Testing Accuracy:73.3%\r",
      "Progress:15.0% Speed(reviews/sec):10310 #Correct:12 #Tested:16 Testing Accuracy:75.0%\r",
      "Progress:16.0% Speed(reviews/sec):10223 #Correct:13 #Tested:17 Testing Accuracy:76.4%\r",
      "Progress:17.0% Speed(reviews/sec):8696. #Correct:14 #Tested:18 Testing Accuracy:77.7%\r",
      "Progress:18.0% Speed(reviews/sec):8879. #Correct:15 #Tested:19 Testing Accuracy:78.9%\r",
      "Progress:19.0% Speed(reviews/sec):9162. #Correct:16 #Tested:20 Testing Accuracy:80.0%\r",
      "Progress:20.0% Speed(reviews/sec):9422. #Correct:17 #Tested:21 Testing Accuracy:80.9%\r",
      "Progress:21.0% Speed(reviews/sec):9259. #Correct:18 #Tested:22 Testing Accuracy:81.8%\r",
      "Progress:22.0% Speed(reviews/sec):9035. #Correct:18 #Tested:23 Testing Accuracy:78.2%\r",
      "Progress:23.0% Speed(reviews/sec):9141. #Correct:19 #Tested:24 Testing Accuracy:79.1%\r",
      "Progress:24.0% Speed(reviews/sec):7869. #Correct:20 #Tested:25 Testing Accuracy:80.0%\r",
      "Progress:25.0% Speed(reviews/sec):8000. #Correct:21 #Tested:26 Testing Accuracy:80.7%\r",
      "Progress:26.0% Speed(reviews/sec):8168. #Correct:22 #Tested:27 Testing Accuracy:81.4%\r",
      "Progress:27.0% Speed(reviews/sec):8352. #Correct:23 #Tested:28 Testing Accuracy:82.1%\r",
      "Progress:28.0% Speed(reviews/sec):8544. #Correct:23 #Tested:29 Testing Accuracy:79.3%\r",
      "Progress:29.0% Speed(reviews/sec):8740. #Correct:23 #Tested:30 Testing Accuracy:76.6%\r",
      "Progress:30.0% Speed(reviews/sec):8928. #Correct:24 #Tested:31 Testing Accuracy:77.4%\r",
      "Progress:31.0% Speed(reviews/sec):9104. #Correct:25 #Tested:32 Testing Accuracy:78.1%\r",
      "Progress:32.0% Speed(reviews/sec):8463. #Correct:26 #Tested:33 Testing Accuracy:78.7%\r",
      "Progress:33.0% Speed(reviews/sec):8172. #Correct:26 #Tested:34 Testing Accuracy:76.4%\r",
      "Progress:34.0% Speed(reviews/sec):8047. #Correct:27 #Tested:35 Testing Accuracy:77.1%\r",
      "Progress:35.0% Speed(reviews/sec):7936. #Correct:27 #Tested:36 Testing Accuracy:75.0%\r",
      "Progress:36.0% Speed(reviews/sec):7830. #Correct:27 #Tested:37 Testing Accuracy:72.9%\r",
      "Progress:37.0% Speed(reviews/sec):7776. #Correct:27 #Tested:38 Testing Accuracy:71.0%\r",
      "Progress:38.0% Speed(reviews/sec):7785. #Correct:27 #Tested:39 Testing Accuracy:69.2%\r",
      "Progress:39.0% Speed(reviews/sec):7721. #Correct:28 #Tested:40 Testing Accuracy:70.0%\r",
      "Progress:40.0% Speed(reviews/sec):7679. #Correct:28 #Tested:41 Testing Accuracy:68.2%\r",
      "Progress:41.0% Speed(reviews/sec):7646. #Correct:29 #Tested:42 Testing Accuracy:69.0%\r",
      "Progress:42.0% Speed(reviews/sec):7586. #Correct:29 #Tested:43 Testing Accuracy:67.4%\r",
      "Progress:43.0% Speed(reviews/sec):7602. #Correct:30 #Tested:44 Testing Accuracy:68.1%\r",
      "Progress:44.0% Speed(reviews/sec):7530. #Correct:31 #Tested:45 Testing Accuracy:68.8%\r",
      "Progress:45.0% Speed(reviews/sec):7474. #Correct:32 #Tested:46 Testing Accuracy:69.5%\r",
      "Progress:46.0% Speed(reviews/sec):7430. #Correct:32 #Tested:47 Testing Accuracy:68.0%\r",
      "Progress:47.0% Speed(reviews/sec):7358. #Correct:33 #Tested:48 Testing Accuracy:68.7%\r",
      "Progress:48.0% Speed(reviews/sec):7355. #Correct:34 #Tested:49 Testing Accuracy:69.3%\r",
      "Progress:49.0% Speed(reviews/sec):7365. #Correct:34 #Tested:50 Testing Accuracy:68.0%\r",
      "Progress:50.0% Speed(reviews/sec):7384. #Correct:34 #Tested:51 Testing Accuracy:66.6%\r",
      "Progress:51.0% Speed(reviews/sec):7414. #Correct:35 #Tested:52 Testing Accuracy:67.3%\r",
      "Progress:52.0% Speed(reviews/sec):7414. #Correct:36 #Tested:53 Testing Accuracy:67.9%\r",
      "Progress:53.0% Speed(reviews/sec):7356. #Correct:37 #Tested:54 Testing Accuracy:68.5%\r",
      "Progress:54.0% Speed(reviews/sec):7365. #Correct:38 #Tested:55 Testing Accuracy:69.0%\r",
      "Progress:55.0% Speed(reviews/sec):7390. #Correct:39 #Tested:56 Testing Accuracy:69.6%\r",
      "Progress:56.0% Speed(reviews/sec):7379. #Correct:39 #Tested:57 Testing Accuracy:68.4%\r",
      "Progress:57.0% Speed(reviews/sec):7404. #Correct:40 #Tested:58 Testing Accuracy:68.9%\r",
      "Progress:58.0% Speed(reviews/sec):7420. #Correct:41 #Tested:59 Testing Accuracy:69.4%\r",
      "Progress:59.0% Speed(reviews/sec):7422. #Correct:42 #Tested:60 Testing Accuracy:70.0%\r",
      "Progress:60.0% Speed(reviews/sec):7362. #Correct:43 #Tested:61 Testing Accuracy:70.4%\r",
      "Progress:61.0% Speed(reviews/sec):7323. #Correct:43 #Tested:62 Testing Accuracy:69.3%\r",
      "Progress:62.0% Speed(reviews/sec):7287. #Correct:43 #Tested:63 Testing Accuracy:68.2%\r",
      "Progress:63.0% Speed(reviews/sec):7307. #Correct:44 #Tested:64 Testing Accuracy:68.7%\r",
      "Progress:64.0% Speed(reviews/sec):7292. #Correct:45 #Tested:65 Testing Accuracy:69.2%\r",
      "Progress:65.0% Speed(reviews/sec):7272. #Correct:46 #Tested:66 Testing Accuracy:69.6%\r",
      "Progress:66.0% Speed(reviews/sec):7248. #Correct:47 #Tested:67 Testing Accuracy:70.1%\r",
      "Progress:67.0% Speed(reviews/sec):7236. #Correct:48 #Tested:68 Testing Accuracy:70.5%\r",
      "Progress:68.0% Speed(reviews/sec):7255. #Correct:49 #Tested:69 Testing Accuracy:71.0%\r",
      "Progress:69.0% Speed(reviews/sec):7252. #Correct:49 #Tested:70 Testing Accuracy:70.0%\r",
      "Progress:70.0% Speed(reviews/sec):7244. #Correct:50 #Tested:71 Testing Accuracy:70.4%\r",
      "Progress:71.0% Speed(reviews/sec):7218. #Correct:51 #Tested:72 Testing Accuracy:70.8%\r",
      "Progress:72.0% Speed(reviews/sec):7172. #Correct:52 #Tested:73 Testing Accuracy:71.2%\r",
      "Progress:73.0% Speed(reviews/sec):7168. #Correct:53 #Tested:74 Testing Accuracy:71.6%\r",
      "Progress:74.0% Speed(reviews/sec):7137. #Correct:53 #Tested:75 Testing Accuracy:70.6%\r",
      "Progress:75.0% Speed(reviews/sec):7082. #Correct:54 #Tested:76 Testing Accuracy:71.0%\r",
      "Progress:76.0% Speed(reviews/sec):7056. #Correct:55 #Tested:77 Testing Accuracy:71.4%\r",
      "Progress:77.0% Speed(reviews/sec):6995. #Correct:56 #Tested:78 Testing Accuracy:71.7%\r",
      "Progress:78.0% Speed(reviews/sec):6979. #Correct:57 #Tested:79 Testing Accuracy:72.1%\r",
      "Progress:79.0% Speed(reviews/sec):6982. #Correct:57 #Tested:80 Testing Accuracy:71.2%\r",
      "Progress:80.0% Speed(reviews/sec):6983. #Correct:58 #Tested:81 Testing Accuracy:71.6%\r",
      "Progress:81.0% Speed(reviews/sec):6978. #Correct:59 #Tested:82 Testing Accuracy:71.9%\r",
      "Progress:82.0% Speed(reviews/sec):6967. #Correct:60 #Tested:83 Testing Accuracy:72.2%\r",
      "Progress:83.0% Speed(reviews/sec):6980. #Correct:60 #Tested:84 Testing Accuracy:71.4%\r",
      "Progress:84.0% Speed(reviews/sec):6979. #Correct:61 #Tested:85 Testing Accuracy:71.7%\r",
      "Progress:85.0% Speed(reviews/sec):6975. #Correct:62 #Tested:86 Testing Accuracy:72.0%\r",
      "Progress:86.0% Speed(reviews/sec):6877. #Correct:62 #Tested:87 Testing Accuracy:71.2%\r",
      "Progress:87.0% Speed(reviews/sec):6880. #Correct:62 #Tested:88 Testing Accuracy:70.4%\r",
      "Progress:88.0% Speed(reviews/sec):6900. #Correct:62 #Tested:89 Testing Accuracy:69.6%\r",
      "Progress:89.0% Speed(reviews/sec):6906. #Correct:63 #Tested:90 Testing Accuracy:70.0%\r",
      "Progress:90.0% Speed(reviews/sec):6924. #Correct:64 #Tested:91 Testing Accuracy:70.3%\r",
      "Progress:91.0% Speed(reviews/sec):6948. #Correct:65 #Tested:92 Testing Accuracy:70.6%\r",
      "Progress:92.0% Speed(reviews/sec):6970. #Correct:65 #Tested:93 Testing Accuracy:69.8%\r",
      "Progress:93.0% Speed(reviews/sec):6983. #Correct:66 #Tested:94 Testing Accuracy:70.2%\r",
      "Progress:94.0% Speed(reviews/sec):7001. #Correct:67 #Tested:95 Testing Accuracy:70.5%\r",
      "Progress:95.0% Speed(reviews/sec):7017. #Correct:68 #Tested:96 Testing Accuracy:70.8%\r",
      "Progress:96.0% Speed(reviews/sec):6929. #Correct:69 #Tested:97 Testing Accuracy:71.1%\r",
      "Progress:97.0% Speed(reviews/sec):6943. #Correct:70 #Tested:98 Testing Accuracy:71.4%\r",
      "Progress:98.0% Speed(reviews/sec):6962. #Correct:71 #Tested:99 Testing Accuracy:71.7%\r",
      "Progress:99.0% Speed(reviews/sec):6926. #Correct:72 #Tested:100 Testing Accuracy:72.0%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-100:],labels[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Project 6 solution. \n",
    "## Watch the next video to continue with Andrew's next lesson.\n",
    "# Analysis: What's Going on in the Weights?<a id='lesson_7'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_full = SentimentNetwork(reviews[:-100],labels[:-100],min_count=0,polarity_cutoff=0,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "\r",
      "Progress:0.23% Speed(reviews/sec):645.1 #Correct:1 #Trained:2 Training Accuracy:50.0%\r",
      "Progress:0.47% Speed(reviews/sec):955.0 #Correct:2 #Trained:3 Training Accuracy:66.6%\r",
      "Progress:0.71% Speed(reviews/sec):1144. #Correct:3 #Trained:4 Training Accuracy:75.0%\r",
      "Progress:0.95% Speed(reviews/sec):1339. #Correct:4 #Trained:5 Training Accuracy:80.0%\r",
      "Progress:1.18% Speed(reviews/sec):1490. #Correct:4 #Trained:6 Training Accuracy:66.6%\r",
      "Progress:1.42% Speed(reviews/sec):1637. #Correct:4 #Trained:7 Training Accuracy:57.1%\r",
      "Progress:1.66% Speed(reviews/sec):1743. #Correct:4 #Trained:8 Training Accuracy:50.0%\r",
      "Progress:1.90% Speed(reviews/sec):1849. #Correct:4 #Trained:9 Training Accuracy:44.4%\r",
      "Progress:2.13% Speed(reviews/sec):1935. #Correct:4 #Trained:10 Training Accuracy:40.0%\r",
      "Progress:2.37% Speed(reviews/sec):1921. #Correct:5 #Trained:11 Training Accuracy:45.4%\r",
      "Progress:2.61% Speed(reviews/sec):1939. #Correct:6 #Trained:12 Training Accuracy:50.0%\r",
      "Progress:2.85% Speed(reviews/sec):2000. #Correct:7 #Trained:13 Training Accuracy:53.8%\r",
      "Progress:3.08% Speed(reviews/sec):2057. #Correct:7 #Trained:14 Training Accuracy:50.0%\r",
      "Progress:3.32% Speed(reviews/sec):2118. #Correct:7 #Trained:15 Training Accuracy:46.6%\r",
      "Progress:3.56% Speed(reviews/sec):2170. #Correct:8 #Trained:16 Training Accuracy:50.0%\r",
      "Progress:3.80% Speed(reviews/sec):2231. #Correct:9 #Trained:17 Training Accuracy:52.9%\r",
      "Progress:4.03% Speed(reviews/sec):2233. #Correct:10 #Trained:18 Training Accuracy:55.5%\r",
      "Progress:4.27% Speed(reviews/sec):2251. #Correct:10 #Trained:19 Training Accuracy:52.6%\r",
      "Progress:4.51% Speed(reviews/sec):2296. #Correct:11 #Trained:20 Training Accuracy:55.0%\r",
      "Progress:4.75% Speed(reviews/sec):2333. #Correct:11 #Trained:21 Training Accuracy:52.3%\r",
      "Progress:4.98% Speed(reviews/sec):2364. #Correct:11 #Trained:22 Training Accuracy:50.0%\r",
      "Progress:5.22% Speed(reviews/sec):2399. #Correct:11 #Trained:23 Training Accuracy:47.8%\r",
      "Progress:5.46% Speed(reviews/sec):2431. #Correct:12 #Trained:24 Training Accuracy:50.0%\r",
      "Progress:5.70% Speed(reviews/sec):2472. #Correct:12 #Trained:25 Training Accuracy:48.0%\r",
      "Progress:5.93% Speed(reviews/sec):2503. #Correct:12 #Trained:26 Training Accuracy:46.1%\r",
      "Progress:6.17% Speed(reviews/sec):2524. #Correct:12 #Trained:27 Training Accuracy:44.4%\r",
      "Progress:6.41% Speed(reviews/sec):2552. #Correct:13 #Trained:28 Training Accuracy:46.4%\r",
      "Progress:6.65% Speed(reviews/sec):2567. #Correct:13 #Trained:29 Training Accuracy:44.8%\r",
      "Progress:6.88% Speed(reviews/sec):2607. #Correct:14 #Trained:30 Training Accuracy:46.6%\r",
      "Progress:7.12% Speed(reviews/sec):2632. #Correct:15 #Trained:31 Training Accuracy:48.3%\r",
      "Progress:7.36% Speed(reviews/sec):2649. #Correct:16 #Trained:32 Training Accuracy:50.0%\r",
      "Progress:7.60% Speed(reviews/sec):2672. #Correct:16 #Trained:33 Training Accuracy:48.4%\r",
      "Progress:7.83% Speed(reviews/sec):2698. #Correct:16 #Trained:34 Training Accuracy:47.0%\r",
      "Progress:8.07% Speed(reviews/sec):2728. #Correct:16 #Trained:35 Training Accuracy:45.7%\r",
      "Progress:8.31% Speed(reviews/sec):2750. #Correct:16 #Trained:36 Training Accuracy:44.4%\r",
      "Progress:8.55% Speed(reviews/sec):2768. #Correct:16 #Trained:37 Training Accuracy:43.2%\r",
      "Progress:8.78% Speed(reviews/sec):2786. #Correct:16 #Trained:38 Training Accuracy:42.1%\r",
      "Progress:9.02% Speed(reviews/sec):2812. #Correct:17 #Trained:39 Training Accuracy:43.5%\r",
      "Progress:9.26% Speed(reviews/sec):2847. #Correct:17 #Trained:40 Training Accuracy:42.5%\r",
      "Progress:9.50% Speed(reviews/sec):2864. #Correct:17 #Trained:41 Training Accuracy:41.4%\r",
      "Progress:9.73% Speed(reviews/sec):2880. #Correct:18 #Trained:42 Training Accuracy:42.8%\r",
      "Progress:9.97% Speed(reviews/sec):2900. #Correct:19 #Trained:43 Training Accuracy:44.1%\r",
      "Progress:10.2% Speed(reviews/sec):2920. #Correct:20 #Trained:44 Training Accuracy:45.4%\r",
      "Progress:10.4% Speed(reviews/sec):2947. #Correct:20 #Trained:45 Training Accuracy:44.4%\r",
      "Progress:10.6% Speed(reviews/sec):2972. #Correct:21 #Trained:46 Training Accuracy:45.6%\r",
      "Progress:10.9% Speed(reviews/sec):2993. #Correct:22 #Trained:47 Training Accuracy:46.8%\r",
      "Progress:11.1% Speed(reviews/sec):3006. #Correct:22 #Trained:48 Training Accuracy:45.8%\r",
      "Progress:11.4% Speed(reviews/sec):3019. #Correct:23 #Trained:49 Training Accuracy:46.9%\r",
      "Progress:11.6% Speed(reviews/sec):3044. #Correct:23 #Trained:50 Training Accuracy:46.0%\r",
      "Progress:11.8% Speed(reviews/sec):3061. #Correct:23 #Trained:51 Training Accuracy:45.0%\r",
      "Progress:12.1% Speed(reviews/sec):3080. #Correct:24 #Trained:52 Training Accuracy:46.1%\r",
      "Progress:12.3% Speed(reviews/sec):3099. #Correct:24 #Trained:53 Training Accuracy:45.2%\r",
      "Progress:12.5% Speed(reviews/sec):3111. #Correct:24 #Trained:54 Training Accuracy:44.4%\r",
      "Progress:12.8% Speed(reviews/sec):3132. #Correct:25 #Trained:55 Training Accuracy:45.4%\r",
      "Progress:13.0% Speed(reviews/sec):3148. #Correct:25 #Trained:56 Training Accuracy:44.6%\r",
      "Progress:13.3% Speed(reviews/sec):3166. #Correct:25 #Trained:57 Training Accuracy:43.8%\r",
      "Progress:13.5% Speed(reviews/sec):3182. #Correct:26 #Trained:58 Training Accuracy:44.8%\r",
      "Progress:13.7% Speed(reviews/sec):3198. #Correct:27 #Trained:59 Training Accuracy:45.7%\r",
      "Progress:14.0% Speed(reviews/sec):3217. #Correct:27 #Trained:60 Training Accuracy:45.0%\r",
      "Progress:14.2% Speed(reviews/sec):3229. #Correct:28 #Trained:61 Training Accuracy:45.9%\r",
      "Progress:14.4% Speed(reviews/sec):3246. #Correct:28 #Trained:62 Training Accuracy:45.1%\r",
      "Progress:14.7% Speed(reviews/sec):3264. #Correct:29 #Trained:63 Training Accuracy:46.0%\r",
      "Progress:14.9% Speed(reviews/sec):3280. #Correct:30 #Trained:64 Training Accuracy:46.8%\r",
      "Progress:15.2% Speed(reviews/sec):3301. #Correct:30 #Trained:65 Training Accuracy:46.1%\r",
      "Progress:15.4% Speed(reviews/sec):3308. #Correct:31 #Trained:66 Training Accuracy:46.9%\r",
      "Progress:15.6% Speed(reviews/sec):3332. #Correct:31 #Trained:67 Training Accuracy:46.2%\r",
      "Progress:15.9% Speed(reviews/sec):3328. #Correct:31 #Trained:68 Training Accuracy:45.5%\r",
      "Progress:16.1% Speed(reviews/sec):3336. #Correct:32 #Trained:69 Training Accuracy:46.3%\r",
      "Progress:16.3% Speed(reviews/sec):3350. #Correct:33 #Trained:70 Training Accuracy:47.1%\r",
      "Progress:16.6% Speed(reviews/sec):3357. #Correct:33 #Trained:71 Training Accuracy:46.4%\r",
      "Progress:16.8% Speed(reviews/sec):3373. #Correct:34 #Trained:72 Training Accuracy:47.2%\r",
      "Progress:17.1% Speed(reviews/sec):3384. #Correct:34 #Trained:73 Training Accuracy:46.5%\r",
      "Progress:17.3% Speed(reviews/sec):3395. #Correct:35 #Trained:74 Training Accuracy:47.2%\r",
      "Progress:17.5% Speed(reviews/sec):3415. #Correct:36 #Trained:75 Training Accuracy:48.0%\r",
      "Progress:17.8% Speed(reviews/sec):3432. #Correct:37 #Trained:76 Training Accuracy:48.6%\r",
      "Progress:18.0% Speed(reviews/sec):3434. #Correct:38 #Trained:77 Training Accuracy:49.3%\r",
      "Progress:18.2% Speed(reviews/sec):3446. #Correct:38 #Trained:78 Training Accuracy:48.7%\r",
      "Progress:18.5% Speed(reviews/sec):3464. #Correct:38 #Trained:79 Training Accuracy:48.1%\r",
      "Progress:18.7% Speed(reviews/sec):3485. #Correct:39 #Trained:80 Training Accuracy:48.7%\r",
      "Progress:19.0% Speed(reviews/sec):3503. #Correct:40 #Trained:81 Training Accuracy:49.3%\r",
      "Progress:19.2% Speed(reviews/sec):3521. #Correct:41 #Trained:82 Training Accuracy:50.0%\r",
      "Progress:19.4% Speed(reviews/sec):3527. #Correct:41 #Trained:83 Training Accuracy:49.3%\r",
      "Progress:19.7% Speed(reviews/sec):3542. #Correct:42 #Trained:84 Training Accuracy:50.0%\r",
      "Progress:19.9% Speed(reviews/sec):3563. #Correct:43 #Trained:85 Training Accuracy:50.5%\r",
      "Progress:20.1% Speed(reviews/sec):3573. #Correct:43 #Trained:86 Training Accuracy:50.0%\r",
      "Progress:20.4% Speed(reviews/sec):3585. #Correct:43 #Trained:87 Training Accuracy:49.4%\r",
      "Progress:20.6% Speed(reviews/sec):3592. #Correct:43 #Trained:88 Training Accuracy:48.8%\r",
      "Progress:20.9% Speed(reviews/sec):3600. #Correct:44 #Trained:89 Training Accuracy:49.4%\r",
      "Progress:21.1% Speed(reviews/sec):3609. #Correct:45 #Trained:90 Training Accuracy:50.0%\r",
      "Progress:21.3% Speed(reviews/sec):3615. #Correct:46 #Trained:91 Training Accuracy:50.5%\r",
      "Progress:21.6% Speed(reviews/sec):3624. #Correct:47 #Trained:92 Training Accuracy:51.0%\r",
      "Progress:21.8% Speed(reviews/sec):3631. #Correct:47 #Trained:93 Training Accuracy:50.5%\r",
      "Progress:22.0% Speed(reviews/sec):3636. #Correct:48 #Trained:94 Training Accuracy:51.0%\r",
      "Progress:22.3% Speed(reviews/sec):3648. #Correct:48 #Trained:95 Training Accuracy:50.5%\r",
      "Progress:22.5% Speed(reviews/sec):3630. #Correct:49 #Trained:96 Training Accuracy:51.0%\r",
      "Progress:22.8% Speed(reviews/sec):3638. #Correct:49 #Trained:97 Training Accuracy:50.5%\r",
      "Progress:23.0% Speed(reviews/sec):3651. #Correct:49 #Trained:98 Training Accuracy:50.0%\r",
      "Progress:23.2% Speed(reviews/sec):3664. #Correct:49 #Trained:99 Training Accuracy:49.4%\r",
      "Progress:23.5% Speed(reviews/sec):3682. #Correct:50 #Trained:100 Training Accuracy:50.0%\r",
      "Progress:23.7% Speed(reviews/sec):3699. #Correct:51 #Trained:101 Training Accuracy:50.4%\r",
      "Progress:23.9% Speed(reviews/sec):3715. #Correct:51 #Trained:102 Training Accuracy:50.0%\r",
      "Progress:24.2% Speed(reviews/sec):3718. #Correct:51 #Trained:103 Training Accuracy:49.5%\r",
      "Progress:24.4% Speed(reviews/sec):3729. #Correct:51 #Trained:104 Training Accuracy:49.0%\r",
      "Progress:24.7% Speed(reviews/sec):3747. #Correct:52 #Trained:105 Training Accuracy:49.5%\r",
      "Progress:24.9% Speed(reviews/sec):3758. #Correct:52 #Trained:106 Training Accuracy:49.0%\r",
      "Progress:25.1% Speed(reviews/sec):3770. #Correct:52 #Trained:107 Training Accuracy:48.5%\r",
      "Progress:25.4% Speed(reviews/sec):3780. #Correct:53 #Trained:108 Training Accuracy:49.0%\r",
      "Progress:25.6% Speed(reviews/sec):3793. #Correct:53 #Trained:109 Training Accuracy:48.6%\r",
      "Progress:25.8% Speed(reviews/sec):3803. #Correct:54 #Trained:110 Training Accuracy:49.0%\r",
      "Progress:26.1% Speed(reviews/sec):3814. #Correct:54 #Trained:111 Training Accuracy:48.6%\r",
      "Progress:26.3% Speed(reviews/sec):3823. #Correct:55 #Trained:112 Training Accuracy:49.1%\r",
      "Progress:26.6% Speed(reviews/sec):3834. #Correct:55 #Trained:113 Training Accuracy:48.6%\r",
      "Progress:26.8% Speed(reviews/sec):3844. #Correct:55 #Trained:114 Training Accuracy:48.2%\r",
      "Progress:27.0% Speed(reviews/sec):3861. #Correct:56 #Trained:115 Training Accuracy:48.6%\r",
      "Progress:27.3% Speed(reviews/sec):3873. #Correct:57 #Trained:116 Training Accuracy:49.1%\r",
      "Progress:27.5% Speed(reviews/sec):3881. #Correct:58 #Trained:117 Training Accuracy:49.5%\r",
      "Progress:27.7% Speed(reviews/sec):3892. #Correct:58 #Trained:118 Training Accuracy:49.1%\r",
      "Progress:28.0% Speed(reviews/sec):3902. #Correct:59 #Trained:119 Training Accuracy:49.5%\r",
      "Progress:28.2% Speed(reviews/sec):3917. #Correct:60 #Trained:120 Training Accuracy:50.0%\r",
      "Progress:28.5% Speed(reviews/sec):3928. #Correct:61 #Trained:121 Training Accuracy:50.4%\r",
      "Progress:28.7% Speed(reviews/sec):3937. #Correct:61 #Trained:122 Training Accuracy:50.0%\r",
      "Progress:28.9% Speed(reviews/sec):3948. #Correct:61 #Trained:123 Training Accuracy:49.5%\r",
      "Progress:29.2% Speed(reviews/sec):3953. #Correct:61 #Trained:124 Training Accuracy:49.1%\r",
      "Progress:29.4% Speed(reviews/sec):3967. #Correct:62 #Trained:125 Training Accuracy:49.6%\r",
      "Progress:29.6% Speed(reviews/sec):3976. #Correct:63 #Trained:126 Training Accuracy:50.0%\r",
      "Progress:29.9% Speed(reviews/sec):3986. #Correct:64 #Trained:127 Training Accuracy:50.3%\r",
      "Progress:30.1% Speed(reviews/sec):3995. #Correct:65 #Trained:128 Training Accuracy:50.7%\r",
      "Progress:30.4% Speed(reviews/sec):4004. #Correct:66 #Trained:129 Training Accuracy:51.1%\r",
      "Progress:30.6% Speed(reviews/sec):4016. #Correct:67 #Trained:130 Training Accuracy:51.5%\r",
      "Progress:30.8% Speed(reviews/sec):4024. #Correct:68 #Trained:131 Training Accuracy:51.9%\r",
      "Progress:31.1% Speed(reviews/sec):4034. #Correct:68 #Trained:132 Training Accuracy:51.5%\r",
      "Progress:31.3% Speed(reviews/sec):4045. #Correct:69 #Trained:133 Training Accuracy:51.8%\r",
      "Progress:31.5% Speed(reviews/sec):4055. #Correct:70 #Trained:134 Training Accuracy:52.2%\r",
      "Progress:31.8% Speed(reviews/sec):4069. #Correct:71 #Trained:135 Training Accuracy:52.5%\r",
      "Progress:32.0% Speed(reviews/sec):4058. #Correct:72 #Trained:136 Training Accuracy:52.9%\r",
      "Progress:32.3% Speed(reviews/sec):4069. #Correct:73 #Trained:137 Training Accuracy:53.2%\r",
      "Progress:32.5% Speed(reviews/sec):4079. #Correct:74 #Trained:138 Training Accuracy:53.6%\r",
      "Progress:32.7% Speed(reviews/sec):4080. #Correct:74 #Trained:139 Training Accuracy:53.2%\r",
      "Progress:33.0% Speed(reviews/sec):4092. #Correct:75 #Trained:140 Training Accuracy:53.5%\r",
      "Progress:33.2% Speed(reviews/sec):4104. #Correct:76 #Trained:141 Training Accuracy:53.9%\r",
      "Progress:33.4% Speed(reviews/sec):4117. #Correct:76 #Trained:142 Training Accuracy:53.5%\r",
      "Progress:33.7% Speed(reviews/sec):4133. #Correct:77 #Trained:143 Training Accuracy:53.8%\r",
      "Progress:33.9% Speed(reviews/sec):4139. #Correct:78 #Trained:144 Training Accuracy:54.1%\r",
      "Progress:34.2% Speed(reviews/sec):4153. #Correct:78 #Trained:145 Training Accuracy:53.7%\r",
      "Progress:34.4% Speed(reviews/sec):4156. #Correct:78 #Trained:146 Training Accuracy:53.4%\r",
      "Progress:34.6% Speed(reviews/sec):4165. #Correct:78 #Trained:147 Training Accuracy:53.0%\r",
      "Progress:34.9% Speed(reviews/sec):4176. #Correct:79 #Trained:148 Training Accuracy:53.3%\r",
      "Progress:35.1% Speed(reviews/sec):4187. #Correct:79 #Trained:149 Training Accuracy:53.0%\r",
      "Progress:35.3% Speed(reviews/sec):4201. #Correct:80 #Trained:150 Training Accuracy:53.3%\r",
      "Progress:35.6% Speed(reviews/sec):4212. #Correct:81 #Trained:151 Training Accuracy:53.6%\r",
      "Progress:35.8% Speed(reviews/sec):4221. #Correct:81 #Trained:152 Training Accuracy:53.2%\r",
      "Progress:36.1% Speed(reviews/sec):4232. #Correct:82 #Trained:153 Training Accuracy:53.5%\r",
      "Progress:36.3% Speed(reviews/sec):4238. #Correct:82 #Trained:154 Training Accuracy:53.2%\r",
      "Progress:36.5% Speed(reviews/sec):4252. #Correct:83 #Trained:155 Training Accuracy:53.5%\r",
      "Progress:36.8% Speed(reviews/sec):4263. #Correct:84 #Trained:156 Training Accuracy:53.8%\r",
      "Progress:37.0% Speed(reviews/sec):4276. #Correct:85 #Trained:157 Training Accuracy:54.1%\r",
      "Progress:37.2% Speed(reviews/sec):4288. #Correct:86 #Trained:158 Training Accuracy:54.4%\r",
      "Progress:37.5% Speed(reviews/sec):4303. #Correct:87 #Trained:159 Training Accuracy:54.7%\r",
      "Progress:37.7% Speed(reviews/sec):4318. #Correct:88 #Trained:160 Training Accuracy:55.0%\r",
      "Progress:38.0% Speed(reviews/sec):4331. #Correct:89 #Trained:161 Training Accuracy:55.2%\r",
      "Progress:38.2% Speed(reviews/sec):4347. #Correct:90 #Trained:162 Training Accuracy:55.5%\r",
      "Progress:38.4% Speed(reviews/sec):4353. #Correct:90 #Trained:163 Training Accuracy:55.2%\r",
      "Progress:38.7% Speed(reviews/sec):4358. #Correct:90 #Trained:164 Training Accuracy:54.8%\r",
      "Progress:38.9% Speed(reviews/sec):4371. #Correct:90 #Trained:165 Training Accuracy:54.5%\r",
      "Progress:39.1% Speed(reviews/sec):4381. #Correct:91 #Trained:166 Training Accuracy:54.8%\r",
      "Progress:39.4% Speed(reviews/sec):4396. #Correct:92 #Trained:167 Training Accuracy:55.0%\r",
      "Progress:39.6% Speed(reviews/sec):4410. #Correct:93 #Trained:168 Training Accuracy:55.3%\r",
      "Progress:39.9% Speed(reviews/sec):4423. #Correct:94 #Trained:169 Training Accuracy:55.6%\r",
      "Progress:40.1% Speed(reviews/sec):4436. #Correct:95 #Trained:170 Training Accuracy:55.8%\r",
      "Progress:40.3% Speed(reviews/sec):4448. #Correct:96 #Trained:171 Training Accuracy:56.1%\r",
      "Progress:40.6% Speed(reviews/sec):4454. #Correct:97 #Trained:172 Training Accuracy:56.3%\r",
      "Progress:40.8% Speed(reviews/sec):4462. #Correct:97 #Trained:173 Training Accuracy:56.0%\r",
      "Progress:41.0% Speed(reviews/sec):4466. #Correct:98 #Trained:174 Training Accuracy:56.3%\r",
      "Progress:41.3% Speed(reviews/sec):4478. #Correct:99 #Trained:175 Training Accuracy:56.5%\r",
      "Progress:41.5% Speed(reviews/sec):4487. #Correct:99 #Trained:176 Training Accuracy:56.2%\r",
      "Progress:41.8% Speed(reviews/sec):4496. #Correct:100 #Trained:177 Training Accuracy:56.4%\r",
      "Progress:42.0% Speed(reviews/sec):4508. #Correct:101 #Trained:178 Training Accuracy:56.7%\r",
      "Progress:42.2% Speed(reviews/sec):4517. #Correct:102 #Trained:179 Training Accuracy:56.9%\r",
      "Progress:42.5% Speed(reviews/sec):4530. #Correct:103 #Trained:180 Training Accuracy:57.2%\r",
      "Progress:42.7% Speed(reviews/sec):4538. #Correct:104 #Trained:181 Training Accuracy:57.4%\r",
      "Progress:42.9% Speed(reviews/sec):4546. #Correct:105 #Trained:182 Training Accuracy:57.6%\r",
      "Progress:43.2% Speed(reviews/sec):4551. #Correct:106 #Trained:183 Training Accuracy:57.9%\r",
      "Progress:43.4% Speed(reviews/sec):4561. #Correct:107 #Trained:184 Training Accuracy:58.1%\r",
      "Progress:43.7% Speed(reviews/sec):4573. #Correct:107 #Trained:185 Training Accuracy:57.8%\r",
      "Progress:43.9% Speed(reviews/sec):4582. #Correct:108 #Trained:186 Training Accuracy:58.0%\r",
      "Progress:44.1% Speed(reviews/sec):4590. #Correct:108 #Trained:187 Training Accuracy:57.7%\r",
      "Progress:44.4% Speed(reviews/sec):4601. #Correct:109 #Trained:188 Training Accuracy:57.9%\r",
      "Progress:44.6% Speed(reviews/sec):4611. #Correct:109 #Trained:189 Training Accuracy:57.6%\r",
      "Progress:44.8% Speed(reviews/sec):4625. #Correct:110 #Trained:190 Training Accuracy:57.8%\r",
      "Progress:45.1% Speed(reviews/sec):4634. #Correct:111 #Trained:191 Training Accuracy:58.1%\r",
      "Progress:45.3% Speed(reviews/sec):4643. #Correct:112 #Trained:192 Training Accuracy:58.3%\r",
      "Progress:45.6% Speed(reviews/sec):4650. #Correct:113 #Trained:193 Training Accuracy:58.5%\r",
      "Progress:45.8% Speed(reviews/sec):4659. #Correct:113 #Trained:194 Training Accuracy:58.2%\r",
      "Progress:46.0% Speed(reviews/sec):4672. #Correct:113 #Trained:195 Training Accuracy:57.9%\r",
      "Progress:46.3% Speed(reviews/sec):4680. #Correct:114 #Trained:196 Training Accuracy:58.1%\r",
      "Progress:46.5% Speed(reviews/sec):4691. #Correct:115 #Trained:197 Training Accuracy:58.3%\r",
      "Progress:46.7% Speed(reviews/sec):4701. #Correct:115 #Trained:198 Training Accuracy:58.0%\r",
      "Progress:47.0% Speed(reviews/sec):4711. #Correct:116 #Trained:199 Training Accuracy:58.2%\r",
      "Progress:47.2% Speed(reviews/sec):4725. #Correct:116 #Trained:200 Training Accuracy:58.0%\r",
      "Progress:47.5% Speed(reviews/sec):4735. #Correct:117 #Trained:201 Training Accuracy:58.2%\r",
      "Progress:47.7% Speed(reviews/sec):4745. #Correct:117 #Trained:202 Training Accuracy:57.9%\r",
      "Progress:47.9% Speed(reviews/sec):4752. #Correct:118 #Trained:203 Training Accuracy:58.1%\r",
      "Progress:48.2% Speed(reviews/sec):4762. #Correct:118 #Trained:204 Training Accuracy:57.8%\r",
      "Progress:48.4% Speed(reviews/sec):4776. #Correct:119 #Trained:205 Training Accuracy:58.0%\r",
      "Progress:48.6% Speed(reviews/sec):4786. #Correct:120 #Trained:206 Training Accuracy:58.2%\r",
      "Progress:48.9% Speed(reviews/sec):4798. #Correct:121 #Trained:207 Training Accuracy:58.4%\r",
      "Progress:49.1% Speed(reviews/sec):4809. #Correct:122 #Trained:208 Training Accuracy:58.6%\r",
      "Progress:49.4% Speed(reviews/sec):4821. #Correct:122 #Trained:209 Training Accuracy:58.3%\r",
      "Progress:49.6% Speed(reviews/sec):4838. #Correct:122 #Trained:210 Training Accuracy:58.0%\r",
      "Progress:49.8% Speed(reviews/sec):4761. #Correct:122 #Trained:211 Training Accuracy:57.8%\r",
      "Progress:50.1% Speed(reviews/sec):4697. #Correct:123 #Trained:212 Training Accuracy:58.0%\r",
      "Progress:50.3% Speed(reviews/sec):4623. #Correct:123 #Trained:213 Training Accuracy:57.7%\r",
      "Progress:50.5% Speed(reviews/sec):4561. #Correct:124 #Trained:214 Training Accuracy:57.9%\r",
      "Progress:50.8% Speed(reviews/sec):4510. #Correct:124 #Trained:215 Training Accuracy:57.6%\r",
      "Progress:51.0% Speed(reviews/sec):4455. #Correct:125 #Trained:216 Training Accuracy:57.8%\r",
      "Progress:51.3% Speed(reviews/sec):4414. #Correct:126 #Trained:217 Training Accuracy:58.0%\r",
      "Progress:51.5% Speed(reviews/sec):4378. #Correct:127 #Trained:218 Training Accuracy:58.2%\r",
      "Progress:51.7% Speed(reviews/sec):4333. #Correct:128 #Trained:219 Training Accuracy:58.4%\r",
      "Progress:52.0% Speed(reviews/sec):4291. #Correct:128 #Trained:220 Training Accuracy:58.1%\r",
      "Progress:52.2% Speed(reviews/sec):4242. #Correct:129 #Trained:221 Training Accuracy:58.3%\r",
      "Progress:52.4% Speed(reviews/sec):4193. #Correct:129 #Trained:222 Training Accuracy:58.1%\r",
      "Progress:52.7% Speed(reviews/sec):4139. #Correct:130 #Trained:223 Training Accuracy:58.2%\r",
      "Progress:52.9% Speed(reviews/sec):4103. #Correct:131 #Trained:224 Training Accuracy:58.4%\r",
      "Progress:53.2% Speed(reviews/sec):4075. #Correct:132 #Trained:225 Training Accuracy:58.6%\r",
      "Progress:53.4% Speed(reviews/sec):4050. #Correct:132 #Trained:226 Training Accuracy:58.4%\r",
      "Progress:53.6% Speed(reviews/sec):4030. #Correct:133 #Trained:227 Training Accuracy:58.5%\r",
      "Progress:53.9% Speed(reviews/sec):4011. #Correct:134 #Trained:228 Training Accuracy:58.7%\r",
      "Progress:54.1% Speed(reviews/sec):3983. #Correct:135 #Trained:229 Training Accuracy:58.9%\r",
      "Progress:54.3% Speed(reviews/sec):3956. #Correct:136 #Trained:230 Training Accuracy:59.1%\r",
      "Progress:54.6% Speed(reviews/sec):3934. #Correct:137 #Trained:231 Training Accuracy:59.3%\r",
      "Progress:54.8% Speed(reviews/sec):3912. #Correct:138 #Trained:232 Training Accuracy:59.4%\r",
      "Progress:55.1% Speed(reviews/sec):3892. #Correct:139 #Trained:233 Training Accuracy:59.6%\r",
      "Progress:55.3% Speed(reviews/sec):3879. #Correct:140 #Trained:234 Training Accuracy:59.8%\r",
      "Progress:55.5% Speed(reviews/sec):3863. #Correct:140 #Trained:235 Training Accuracy:59.5%\r",
      "Progress:55.8% Speed(reviews/sec):3850. #Correct:141 #Trained:236 Training Accuracy:59.7%\r",
      "Progress:56.0% Speed(reviews/sec):3838. #Correct:142 #Trained:237 Training Accuracy:59.9%\r",
      "Progress:56.2% Speed(reviews/sec):3824. #Correct:143 #Trained:238 Training Accuracy:60.0%\r",
      "Progress:56.5% Speed(reviews/sec):3807. #Correct:143 #Trained:239 Training Accuracy:59.8%\r",
      "Progress:56.7% Speed(reviews/sec):3794. #Correct:144 #Trained:240 Training Accuracy:60.0%\r",
      "Progress:57.0% Speed(reviews/sec):3780. #Correct:145 #Trained:241 Training Accuracy:60.1%\r",
      "Progress:57.2% Speed(reviews/sec):3768. #Correct:146 #Trained:242 Training Accuracy:60.3%\r",
      "Progress:57.4% Speed(reviews/sec):3756. #Correct:147 #Trained:243 Training Accuracy:60.4%\r",
      "Progress:57.7% Speed(reviews/sec):3741. #Correct:147 #Trained:244 Training Accuracy:60.2%\r",
      "Progress:57.9% Speed(reviews/sec):3726. #Correct:147 #Trained:245 Training Accuracy:60.0%\r",
      "Progress:58.1% Speed(reviews/sec):3694. #Correct:148 #Trained:246 Training Accuracy:60.1%\r",
      "Progress:58.4% Speed(reviews/sec):3678. #Correct:148 #Trained:247 Training Accuracy:59.9%\r",
      "Progress:58.6% Speed(reviews/sec):3671. #Correct:149 #Trained:248 Training Accuracy:60.0%\r",
      "Progress:58.9% Speed(reviews/sec):3661. #Correct:149 #Trained:249 Training Accuracy:59.8%\r",
      "Progress:59.1% Speed(reviews/sec):3654. #Correct:150 #Trained:250 Training Accuracy:60.0%\r",
      "Progress:59.3% Speed(reviews/sec):3645. #Correct:151 #Trained:251 Training Accuracy:60.1%\r",
      "Progress:59.6% Speed(reviews/sec):3643. #Correct:152 #Trained:252 Training Accuracy:60.3%\r",
      "Progress:59.8% Speed(reviews/sec):3629. #Correct:153 #Trained:253 Training Accuracy:60.4%\r",
      "Progress:60.0% Speed(reviews/sec):3611. #Correct:154 #Trained:254 Training Accuracy:60.6%\r",
      "Progress:60.3% Speed(reviews/sec):3602. #Correct:155 #Trained:255 Training Accuracy:60.7%\r",
      "Progress:60.5% Speed(reviews/sec):3597. #Correct:156 #Trained:256 Training Accuracy:60.9%\r",
      "Progress:60.8% Speed(reviews/sec):3592. #Correct:157 #Trained:257 Training Accuracy:61.0%\r",
      "Progress:61.0% Speed(reviews/sec):3584. #Correct:158 #Trained:258 Training Accuracy:61.2%\r",
      "Progress:61.2% Speed(reviews/sec):3575. #Correct:159 #Trained:259 Training Accuracy:61.3%\r",
      "Progress:61.5% Speed(reviews/sec):3565. #Correct:160 #Trained:260 Training Accuracy:61.5%\r",
      "Progress:61.7% Speed(reviews/sec):3557. #Correct:161 #Trained:261 Training Accuracy:61.6%\r",
      "Progress:61.9% Speed(reviews/sec):3552. #Correct:162 #Trained:262 Training Accuracy:61.8%\r",
      "Progress:62.2% Speed(reviews/sec):3534. #Correct:163 #Trained:263 Training Accuracy:61.9%\r",
      "Progress:62.4% Speed(reviews/sec):3524. #Correct:164 #Trained:264 Training Accuracy:62.1%\r",
      "Progress:62.7% Speed(reviews/sec):3516. #Correct:165 #Trained:265 Training Accuracy:62.2%\r",
      "Progress:62.9% Speed(reviews/sec):3503. #Correct:166 #Trained:266 Training Accuracy:62.4%\r",
      "Progress:63.1% Speed(reviews/sec):3495. #Correct:166 #Trained:267 Training Accuracy:62.1%\r",
      "Progress:63.4% Speed(reviews/sec):3480. #Correct:166 #Trained:268 Training Accuracy:61.9%\r",
      "Progress:63.6% Speed(reviews/sec):3475. #Correct:167 #Trained:269 Training Accuracy:62.0%\r",
      "Progress:63.8% Speed(reviews/sec):3463. #Correct:168 #Trained:270 Training Accuracy:62.2%\r",
      "Progress:64.1% Speed(reviews/sec):3449. #Correct:169 #Trained:271 Training Accuracy:62.3%\r",
      "Progress:64.3% Speed(reviews/sec):3427. #Correct:170 #Trained:272 Training Accuracy:62.5%\r",
      "Progress:64.6% Speed(reviews/sec):3422. #Correct:171 #Trained:273 Training Accuracy:62.6%\r",
      "Progress:64.8% Speed(reviews/sec):3413. #Correct:171 #Trained:274 Training Accuracy:62.4%\r",
      "Progress:65.0% Speed(reviews/sec):3395. #Correct:172 #Trained:275 Training Accuracy:62.5%\r",
      "Progress:65.3% Speed(reviews/sec):3385. #Correct:172 #Trained:276 Training Accuracy:62.3%\r",
      "Progress:65.5% Speed(reviews/sec):3379. #Correct:172 #Trained:277 Training Accuracy:62.0%\r",
      "Progress:65.7% Speed(reviews/sec):3361. #Correct:173 #Trained:278 Training Accuracy:62.2%\r",
      "Progress:66.0% Speed(reviews/sec):3355. #Correct:173 #Trained:279 Training Accuracy:62.0%\r",
      "Progress:66.2% Speed(reviews/sec):3344. #Correct:173 #Trained:280 Training Accuracy:61.7%\r",
      "Progress:66.5% Speed(reviews/sec):3330. #Correct:174 #Trained:281 Training Accuracy:61.9%\r",
      "Progress:66.7% Speed(reviews/sec):3326. #Correct:175 #Trained:282 Training Accuracy:62.0%\r",
      "Progress:66.9% Speed(reviews/sec):3319. #Correct:176 #Trained:283 Training Accuracy:62.1%\r",
      "Progress:67.2% Speed(reviews/sec):3313. #Correct:177 #Trained:284 Training Accuracy:62.3%\r",
      "Progress:67.4% Speed(reviews/sec):3307. #Correct:177 #Trained:285 Training Accuracy:62.1%\r",
      "Progress:67.6% Speed(reviews/sec):3298. #Correct:178 #Trained:286 Training Accuracy:62.2%\r",
      "Progress:67.9% Speed(reviews/sec):3290. #Correct:179 #Trained:287 Training Accuracy:62.3%\r",
      "Progress:68.1% Speed(reviews/sec):3286. #Correct:179 #Trained:288 Training Accuracy:62.1%\r",
      "Progress:68.4% Speed(reviews/sec):3281. #Correct:179 #Trained:289 Training Accuracy:61.9%\r",
      "Progress:68.6% Speed(reviews/sec):3273. #Correct:180 #Trained:290 Training Accuracy:62.0%\r",
      "Progress:68.8% Speed(reviews/sec):3268. #Correct:180 #Trained:291 Training Accuracy:61.8%\r",
      "Progress:69.1% Speed(reviews/sec):3264. #Correct:180 #Trained:292 Training Accuracy:61.6%\r",
      "Progress:69.3% Speed(reviews/sec):3257. #Correct:181 #Trained:293 Training Accuracy:61.7%\r",
      "Progress:69.5% Speed(reviews/sec):3256. #Correct:182 #Trained:294 Training Accuracy:61.9%\r",
      "Progress:69.8% Speed(reviews/sec):3256. #Correct:183 #Trained:295 Training Accuracy:62.0%\r",
      "Progress:70.0% Speed(reviews/sec):3255. #Correct:183 #Trained:296 Training Accuracy:61.8%\r",
      "Progress:70.3% Speed(reviews/sec):3251. #Correct:184 #Trained:297 Training Accuracy:61.9%\r",
      "Progress:70.5% Speed(reviews/sec):3250. #Correct:185 #Trained:298 Training Accuracy:62.0%\r",
      "Progress:70.7% Speed(reviews/sec):3247. #Correct:185 #Trained:299 Training Accuracy:61.8%\r",
      "Progress:71.0% Speed(reviews/sec):3241. #Correct:186 #Trained:300 Training Accuracy:62.0%\r",
      "Progress:71.2% Speed(reviews/sec):3237. #Correct:187 #Trained:301 Training Accuracy:62.1%\r",
      "Progress:71.4% Speed(reviews/sec):3236. #Correct:187 #Trained:302 Training Accuracy:61.9%\r",
      "Progress:71.7% Speed(reviews/sec):3231. #Correct:187 #Trained:303 Training Accuracy:61.7%\r",
      "Progress:71.9% Speed(reviews/sec):3232. #Correct:188 #Trained:304 Training Accuracy:61.8%\r",
      "Progress:72.2% Speed(reviews/sec):3231. #Correct:188 #Trained:305 Training Accuracy:61.6%\r",
      "Progress:72.4% Speed(reviews/sec):3234. #Correct:189 #Trained:306 Training Accuracy:61.7%\r",
      "Progress:72.6% Speed(reviews/sec):3232. #Correct:189 #Trained:307 Training Accuracy:61.5%\r",
      "Progress:72.9% Speed(reviews/sec):3233. #Correct:190 #Trained:308 Training Accuracy:61.6%\r",
      "Progress:73.1% Speed(reviews/sec):3236. #Correct:191 #Trained:309 Training Accuracy:61.8%\r",
      "Progress:73.3% Speed(reviews/sec):3237. #Correct:192 #Trained:310 Training Accuracy:61.9%\r",
      "Progress:73.6% Speed(reviews/sec):3238. #Correct:193 #Trained:311 Training Accuracy:62.0%\r",
      "Progress:73.8% Speed(reviews/sec):3238. #Correct:194 #Trained:312 Training Accuracy:62.1%\r",
      "Progress:74.1% Speed(reviews/sec):3238. #Correct:195 #Trained:313 Training Accuracy:62.3%\r",
      "Progress:74.3% Speed(reviews/sec):3240. #Correct:196 #Trained:314 Training Accuracy:62.4%\r",
      "Progress:74.5% Speed(reviews/sec):3239. #Correct:197 #Trained:315 Training Accuracy:62.5%\r",
      "Progress:74.8% Speed(reviews/sec):3240. #Correct:198 #Trained:316 Training Accuracy:62.6%\r",
      "Progress:75.0% Speed(reviews/sec):3241. #Correct:199 #Trained:317 Training Accuracy:62.7%\r",
      "Progress:75.2% Speed(reviews/sec):3242. #Correct:200 #Trained:318 Training Accuracy:62.8%\r",
      "Progress:75.5% Speed(reviews/sec):3244. #Correct:201 #Trained:319 Training Accuracy:63.0%\r",
      "Progress:75.7% Speed(reviews/sec):3246. #Correct:202 #Trained:320 Training Accuracy:63.1%\r",
      "Progress:76.0% Speed(reviews/sec):3249. #Correct:203 #Trained:321 Training Accuracy:63.2%\r",
      "Progress:76.2% Speed(reviews/sec):3252. #Correct:204 #Trained:322 Training Accuracy:63.3%\r",
      "Progress:76.4% Speed(reviews/sec):3256. #Correct:205 #Trained:323 Training Accuracy:63.4%\r",
      "Progress:76.7% Speed(reviews/sec):3260. #Correct:206 #Trained:324 Training Accuracy:63.5%\r",
      "Progress:76.9% Speed(reviews/sec):3262. #Correct:207 #Trained:325 Training Accuracy:63.6%\r",
      "Progress:77.1% Speed(reviews/sec):3265. #Correct:207 #Trained:326 Training Accuracy:63.4%\r",
      "Progress:77.4% Speed(reviews/sec):3267. #Correct:208 #Trained:327 Training Accuracy:63.6%\r",
      "Progress:77.6% Speed(reviews/sec):3269. #Correct:208 #Trained:328 Training Accuracy:63.4%\r",
      "Progress:77.9% Speed(reviews/sec):3273. #Correct:209 #Trained:329 Training Accuracy:63.5%\r",
      "Progress:78.1% Speed(reviews/sec):3276. #Correct:210 #Trained:330 Training Accuracy:63.6%\r",
      "Progress:78.3% Speed(reviews/sec):3279. #Correct:211 #Trained:331 Training Accuracy:63.7%\r",
      "Progress:78.6% Speed(reviews/sec):3282. #Correct:212 #Trained:332 Training Accuracy:63.8%\r",
      "Progress:78.8% Speed(reviews/sec):3285. #Correct:213 #Trained:333 Training Accuracy:63.9%\r",
      "Progress:79.0% Speed(reviews/sec):3290. #Correct:214 #Trained:334 Training Accuracy:64.0%\r",
      "Progress:79.3% Speed(reviews/sec):3294. #Correct:215 #Trained:335 Training Accuracy:64.1%\r",
      "Progress:79.5% Speed(reviews/sec):3298. #Correct:215 #Trained:336 Training Accuracy:63.9%\r",
      "Progress:79.8% Speed(reviews/sec):3302. #Correct:215 #Trained:337 Training Accuracy:63.7%\r",
      "Progress:80.0% Speed(reviews/sec):3306. #Correct:215 #Trained:338 Training Accuracy:63.6%\r",
      "Progress:80.2% Speed(reviews/sec):3309. #Correct:216 #Trained:339 Training Accuracy:63.7%\r",
      "Progress:80.5% Speed(reviews/sec):3309. #Correct:217 #Trained:340 Training Accuracy:63.8%\r",
      "Progress:80.7% Speed(reviews/sec):3314. #Correct:217 #Trained:341 Training Accuracy:63.6%\r",
      "Progress:80.9% Speed(reviews/sec):3319. #Correct:218 #Trained:342 Training Accuracy:63.7%\r",
      "Progress:81.2% Speed(reviews/sec):3324. #Correct:219 #Trained:343 Training Accuracy:63.8%\r",
      "Progress:81.4% Speed(reviews/sec):3328. #Correct:220 #Trained:344 Training Accuracy:63.9%\r",
      "Progress:81.7% Speed(reviews/sec):3334. #Correct:220 #Trained:345 Training Accuracy:63.7%\r",
      "Progress:81.9% Speed(reviews/sec):3337. #Correct:220 #Trained:346 Training Accuracy:63.5%\r",
      "Progress:82.1% Speed(reviews/sec):3341. #Correct:221 #Trained:347 Training Accuracy:63.6%\r",
      "Progress:82.4% Speed(reviews/sec):3345. #Correct:221 #Trained:348 Training Accuracy:63.5%\r",
      "Progress:82.6% Speed(reviews/sec):3351. #Correct:222 #Trained:349 Training Accuracy:63.6%\r",
      "Progress:82.8% Speed(reviews/sec):3355. #Correct:223 #Trained:350 Training Accuracy:63.7%\r",
      "Progress:83.1% Speed(reviews/sec):3360. #Correct:223 #Trained:351 Training Accuracy:63.5%\r",
      "Progress:83.3% Speed(reviews/sec):3365. #Correct:224 #Trained:352 Training Accuracy:63.6%\r",
      "Progress:83.6% Speed(reviews/sec):3370. #Correct:225 #Trained:353 Training Accuracy:63.7%\r",
      "Progress:83.8% Speed(reviews/sec):3376. #Correct:226 #Trained:354 Training Accuracy:63.8%\r",
      "Progress:84.0% Speed(reviews/sec):3382. #Correct:226 #Trained:355 Training Accuracy:63.6%\r",
      "Progress:84.3% Speed(reviews/sec):3387. #Correct:227 #Trained:356 Training Accuracy:63.7%\r",
      "Progress:84.5% Speed(reviews/sec):3391. #Correct:228 #Trained:357 Training Accuracy:63.8%\r",
      "Progress:84.7% Speed(reviews/sec):3375. #Correct:229 #Trained:358 Training Accuracy:63.9%\r",
      "Progress:85.0% Speed(reviews/sec):3356. #Correct:230 #Trained:359 Training Accuracy:64.0%\r",
      "Progress:85.2% Speed(reviews/sec):3340. #Correct:231 #Trained:360 Training Accuracy:64.1%\r",
      "Progress:85.5% Speed(reviews/sec):3336. #Correct:231 #Trained:361 Training Accuracy:63.9%\r",
      "Progress:85.7% Speed(reviews/sec):3312. #Correct:232 #Trained:362 Training Accuracy:64.0%\r",
      "Progress:85.9% Speed(reviews/sec):3295. #Correct:233 #Trained:363 Training Accuracy:64.1%\r",
      "Progress:86.2% Speed(reviews/sec):3286. #Correct:234 #Trained:364 Training Accuracy:64.2%\r",
      "Progress:86.4% Speed(reviews/sec):3281. #Correct:235 #Trained:365 Training Accuracy:64.3%\r",
      "Progress:86.6% Speed(reviews/sec):3277. #Correct:236 #Trained:366 Training Accuracy:64.4%\r",
      "Progress:86.9% Speed(reviews/sec):3274. #Correct:237 #Trained:367 Training Accuracy:64.5%\r",
      "Progress:87.1% Speed(reviews/sec):3271. #Correct:238 #Trained:368 Training Accuracy:64.6%\r",
      "Progress:87.4% Speed(reviews/sec):3269. #Correct:239 #Trained:369 Training Accuracy:64.7%\r",
      "Progress:87.6% Speed(reviews/sec):3246. #Correct:240 #Trained:370 Training Accuracy:64.8%\r",
      "Progress:87.8% Speed(reviews/sec):3246. #Correct:241 #Trained:371 Training Accuracy:64.9%\r",
      "Progress:88.1% Speed(reviews/sec):3246. #Correct:242 #Trained:372 Training Accuracy:65.0%\r",
      "Progress:88.3% Speed(reviews/sec):3244. #Correct:243 #Trained:373 Training Accuracy:65.1%\r",
      "Progress:88.5% Speed(reviews/sec):3244. #Correct:243 #Trained:374 Training Accuracy:64.9%\r",
      "Progress:88.8% Speed(reviews/sec):3243. #Correct:244 #Trained:375 Training Accuracy:65.0%\r",
      "Progress:89.0% Speed(reviews/sec):3243. #Correct:244 #Trained:376 Training Accuracy:64.8%\r",
      "Progress:89.3% Speed(reviews/sec):3243. #Correct:245 #Trained:377 Training Accuracy:64.9%\r",
      "Progress:89.5% Speed(reviews/sec):3245. #Correct:246 #Trained:378 Training Accuracy:65.0%\r",
      "Progress:89.7% Speed(reviews/sec):3245. #Correct:246 #Trained:379 Training Accuracy:64.9%\r",
      "Progress:90.0% Speed(reviews/sec):3244. #Correct:247 #Trained:380 Training Accuracy:65.0%\r",
      "Progress:90.2% Speed(reviews/sec):3244. #Correct:247 #Trained:381 Training Accuracy:64.8%\r",
      "Progress:90.4% Speed(reviews/sec):3246. #Correct:247 #Trained:382 Training Accuracy:64.6%\r",
      "Progress:90.7% Speed(reviews/sec):3247. #Correct:247 #Trained:383 Training Accuracy:64.4%\r",
      "Progress:90.9% Speed(reviews/sec):3242. #Correct:248 #Trained:384 Training Accuracy:64.5%\r",
      "Progress:91.2% Speed(reviews/sec):3242. #Correct:248 #Trained:385 Training Accuracy:64.4%\r",
      "Progress:91.4% Speed(reviews/sec):3244. #Correct:248 #Trained:386 Training Accuracy:64.2%\r",
      "Progress:91.6% Speed(reviews/sec):3246. #Correct:249 #Trained:387 Training Accuracy:64.3%\r",
      "Progress:91.9% Speed(reviews/sec):3248. #Correct:250 #Trained:388 Training Accuracy:64.4%\r",
      "Progress:92.1% Speed(reviews/sec):3250. #Correct:250 #Trained:389 Training Accuracy:64.2%\r",
      "Progress:92.3% Speed(reviews/sec):3252. #Correct:251 #Trained:390 Training Accuracy:64.3%\r",
      "Progress:92.6% Speed(reviews/sec):3255. #Correct:252 #Trained:391 Training Accuracy:64.4%\r",
      "Progress:92.8% Speed(reviews/sec):3258. #Correct:252 #Trained:392 Training Accuracy:64.2%\r",
      "Progress:93.1% Speed(reviews/sec):3261. #Correct:253 #Trained:393 Training Accuracy:64.3%\r",
      "Progress:93.3% Speed(reviews/sec):3258. #Correct:253 #Trained:394 Training Accuracy:64.2%\r",
      "Progress:93.5% Speed(reviews/sec):3257. #Correct:254 #Trained:395 Training Accuracy:64.3%\r",
      "Progress:93.8% Speed(reviews/sec):3258. #Correct:255 #Trained:396 Training Accuracy:64.3%\r",
      "Progress:94.0% Speed(reviews/sec):3260. #Correct:256 #Trained:397 Training Accuracy:64.4%\r",
      "Progress:94.2% Speed(reviews/sec):3263. #Correct:257 #Trained:398 Training Accuracy:64.5%\r",
      "Progress:94.5% Speed(reviews/sec):3264. #Correct:257 #Trained:399 Training Accuracy:64.4%\r",
      "Progress:94.7% Speed(reviews/sec):3265. #Correct:258 #Trained:400 Training Accuracy:64.5%\r",
      "Progress:95.0% Speed(reviews/sec):3267. #Correct:259 #Trained:401 Training Accuracy:64.5%\r",
      "Progress:95.2% Speed(reviews/sec):3269. #Correct:259 #Trained:402 Training Accuracy:64.4%\r",
      "Progress:95.4% Speed(reviews/sec):3270. #Correct:260 #Trained:403 Training Accuracy:64.5%\r",
      "Progress:95.7% Speed(reviews/sec):3271. #Correct:261 #Trained:404 Training Accuracy:64.6%\r",
      "Progress:95.9% Speed(reviews/sec):3271. #Correct:262 #Trained:405 Training Accuracy:64.6%\r",
      "Progress:96.1% Speed(reviews/sec):3273. #Correct:263 #Trained:406 Training Accuracy:64.7%\r",
      "Progress:96.4% Speed(reviews/sec):3275. #Correct:263 #Trained:407 Training Accuracy:64.6%\r",
      "Progress:96.6% Speed(reviews/sec):3276. #Correct:264 #Trained:408 Training Accuracy:64.7%\r",
      "Progress:96.9% Speed(reviews/sec):3275. #Correct:265 #Trained:409 Training Accuracy:64.7%\r",
      "Progress:97.1% Speed(reviews/sec):3277. #Correct:265 #Trained:410 Training Accuracy:64.6%\r",
      "Progress:97.3% Speed(reviews/sec):3279. #Correct:266 #Trained:411 Training Accuracy:64.7%\r",
      "Progress:97.6% Speed(reviews/sec):3281. #Correct:267 #Trained:412 Training Accuracy:64.8%\r",
      "Progress:97.8% Speed(reviews/sec):3283. #Correct:268 #Trained:413 Training Accuracy:64.8%\r",
      "Progress:98.0% Speed(reviews/sec):3286. #Correct:269 #Trained:414 Training Accuracy:64.9%\r",
      "Progress:98.3% Speed(reviews/sec):3289. #Correct:270 #Trained:415 Training Accuracy:65.0%\r",
      "Progress:98.5% Speed(reviews/sec):3291. #Correct:270 #Trained:416 Training Accuracy:64.9%\r",
      "Progress:98.8% Speed(reviews/sec):3293. #Correct:271 #Trained:417 Training Accuracy:64.9%\r",
      "Progress:99.0% Speed(reviews/sec):3297. #Correct:272 #Trained:418 Training Accuracy:65.0%\r",
      "Progress:99.2% Speed(reviews/sec):3299. #Correct:273 #Trained:419 Training Accuracy:65.1%\r",
      "Progress:99.5% Speed(reviews/sec):3302. #Correct:273 #Trained:420 Training Accuracy:65.0%\r",
      "Progress:99.7% Speed(reviews/sec):3305. #Correct:273 #Trained:421 Training Accuracy:64.8%"
     ]
    }
   ],
   "source": [
    "mlp_full.train(reviews[:-100],labels[:-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAEoCAYAAACJsv/HAAAABGdBTUEAALGPC/xhBQAAACBjSFJN\nAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAB1WlUWHRYTUw6Y29tLmFkb2Jl\nLnhtcAAAAAAAPHg6eG1wbWV0YSB4bWxuczp4PSJhZG9iZTpuczptZXRhLyIgeDp4bXB0az0iWE1Q\nIENvcmUgNS40LjAiPgogICA8cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5\nOTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPgogICAgICA8cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91\ndD0iIgogICAgICAgICAgICB4bWxuczp0aWZmPSJodHRwOi8vbnMuYWRvYmUuY29tL3RpZmYvMS4w\nLyI+CiAgICAgICAgIDx0aWZmOkNvbXByZXNzaW9uPjE8L3RpZmY6Q29tcHJlc3Npb24+CiAgICAg\nICAgIDx0aWZmOk9yaWVudGF0aW9uPjE8L3RpZmY6T3JpZW50YXRpb24+CiAgICAgICAgIDx0aWZm\nOlBob3RvbWV0cmljSW50ZXJwcmV0YXRpb24+MjwvdGlmZjpQaG90b21ldHJpY0ludGVycHJldGF0\naW9uPgogICAgICA8L3JkZjpEZXNjcmlwdGlvbj4KICAgPC9yZGY6UkRGPgo8L3g6eG1wbWV0YT4K\nAtiABQAAQABJREFUeAHsvQv8HdPV/7+pKnVrUCSoS5A0ES1CCC2JpPh7KkLlaV1yafskoUk02hCh\njyhyERWXIMlTInFpRCVBCRIJQRJFtQRJCXVLUOLXoC7Vnv+8t67T9Z3Muc85Z+actV6v+c6cmX1Z\n+7NnZn++a63Ze4NMIM7EEDAEDAFDwBAwBAwBQ6DqCGxY9RqsAkPAEDAEDAFDwBAwBAwBj4ARL7sR\nDAFDwBAwBAwBQ8AQqBECRrxqBLRVYwgYAoaAIWAIGAKGgBEvuwcMAUPAEDAEDAFDwBCoEQJGvGoE\ntFVjCBgChoAhYAgYAoaAES+7BwwBQ8AQMAQMAUPAEKgRAka8agS0VWMIGAKGgCFgCBgChoARL7sH\nDAFDwBAwBAwBQ8AQqBECRrxqBLRVYwgYAoaAIWAIGAKGgBEvuwcMAUPAEDAEDAFDwBCoEQJGvGoE\ntFVjCBgChoAhYAgYAoaAES+7BwwBQ8AQMAQMAUPAEKgRAka8agS0VWMIGAKGgCFgCBgChoARL7sH\nDAFDwBAwBAwBQ8AQqBECRrxqBLRVYwg0GgLvvfee22CDDdzWW2+diqahZ+fOnVOhqylpCBgCjYuA\nEa/G7VtrmSFgCPwbgT59+jiIookhYAgYAvVGwIhXvXvA6jcEGgiB2267zbVt29ZbwrCGDRo0KNs6\nOf/kk09mz2GFIh3nIEYQJH6LJW38+PHrpZ06daq3so0cOTJ7LdcBaSgLvUwMAUPAEEgCAka8ktAL\npoMh0AAIQJwgWi+99FK2NZAkyBTSo0cPv1+wYEF2T57999/fbz179mxBkLgGcdLkjYyc41oxMm7c\nOJfJZNysWbOKSW5pDAFDwBCoOgJGvKoOsVVgCDQHAliVIEQDBw70ZGft2rWuVatWTojWiSee6IGQ\n32L54jwEjd+QM4gS2xNPPOF23333FmSMAiQNpMrEEDAEDIG0IWDEK209ZvoaAglFQAgXZAmrVNgy\nBWGCiAnhEgIG8RIrGefE1UggPOchc5KHpp999tkJRcDUMgQMAUOgMAJGvApjZCkMAUOgCAQgScRs\nCaGCgEG0tECyIFKkgUzhZiSdyJQpU7IWL7F8sSediSFgCBgCjYCAEa9G6EVrgyGQAARwF0KqIFe4\nASFU/NYicV7ylSFpESFflCHWL53Pjg0BQ8AQaBQEjHg1Sk9aOwyBOiMg1i2C4XEXQq7knKgG0eKc\nEDIhXrgpsWphBZOvH7XLUfLb3hAwBAyBtCNgxCvtPWj6GwIJQQDyJBYtyBVuQ7F66ekchGyRVixd\nNGH+/Pk+MF83hzI5b2IIGAKGQKMgsEEQP5FplMZYOwwBQyD5CDA3F4H3uCMtUD75/WUaGgKGQLwI\nmMUrXjytNEPAEMiBAG5E3IeQLixiWLMqEaxo4o6M2lOPiSFgCBgCSUNgo6QpZPoYAoZA4yOApSsc\n/1Vqq3FZmsG+VNQsvSFgCNQbAXM11rsHrH5DwBAwBAwBQ8AQaBoEzNXYNF1tDTUEDAFDwBAwBAyB\neiNgxKvePWD1GwKGgCFgCBgChkDTIGDEq2m62hpqCBgChoAhYAgYAvVGwIhXvXvA6jcEDAFDwBAw\nBAyBpkHAiFfTdLU11BAwBAwBQ8AQMATqjYARr3r3gNVvCBgChoAhYAgYAk2DgBGvpulqa6ghYAgY\nAoaAIWAI1BsBm0C13j1g9RsCTYTAgw8+6F555RW3/Nnn3RtvvOHWrH7DPfjgovUQ+MFJp7gtttjC\ndezYwX1t553c4Ycf7r7yla+sl85OGAKGgCGQNgRsAtW09ZjpawikDIG5c+e6hx9Z4u6+607Xuk0b\n981993e77b6b23PPPd1WW27puh7cpUWLnn1uhXv1tdfc6tVr3EsvveSeefpP7q475zrI2JHf6eF6\n9eplJKwFYvbDEDAE0oSAEa809ZbpagikBIH/9//+n5tx401uzuzZXuPeJ3zPHdG9u+vYoX1ZLVi9\n5k0379773WPLlrr/mzrZ/XzE2e4npw92u+66a1nlWSZDwBAwBOqFgBGveiFv9RoCDYrAlVde5a65\n+mq3X+cD3Kl9+7qjj+wZa0uxiP3619e5yydeagQsVmStMEPAEKgFAka8aoGy1WEINAECxG9dcMEv\n3RZbbuVOO/302AlXGEIhYPPuvsudM+oc169fv3AS+20IGAKGQOIQMOKVuC4xhQyB9CFw5VWT3DWT\nJrnThw5zw4acXtMGzLtvvrtk3NggfmzHwNJ2lcV/1RR9q8wQMARKRcCmkygVMUtfFgKdO3d2G2yw\ngXvyySfLyl+LTFOnTnVbb7211xNdx48fX4tqU10HsVyDBp/uFix4wF1/w/Saky7Aw5V58y23uO23\n38Ed1OUg98c//jHVmJryhoAh0NgI2HQSjd2/1roiEYAQDho0qEXqkSNH+t9nn312i/P243MEIF19\n+w1wm2++uZs8+VrXpvUOdYOGuideNsF/Lfn9//6+m3nrTPfNb36zbvpYxYaAIWAI5ELALF65kLHz\nVUWAaQJ69uyZtS5xzDmkT58+/ry2OElaOcceq5RskKb33ntvvfxY2tgKCdYu5MQTT3SZTMaNGzfO\n/16wYIHf25+WCAjpatt2D3fLzTfWlXRpzXBzjhg5ykG+zPKlkbFjQ8AQSAoCRryS0hNNpgfkSpMa\njiFXSI8ePfxeX8ci1apVKzdw4EBvmRJrlE8Y/IE4SX45Bzkr1rUp6SBeiOzlvJRpe+c06cLKlDT5\n0YC+Rr6S1immjyFgCGQRMOKVhcIOaoUAli0Izf777++tS1iYOJbzkCtIlpAeCBjWLNKwh2RxvGrV\nKp9/7dq1nqyRXpO13Xff3XHtiSeeKNg0sZZRLyJ7zsu1goU0SYIxYz+PfUsi6ZIugHwR6D98+Jme\nKMp52xsChoAhUG8ELMar3j3QhPVDiCBbECixXImbUeCAWEGi2ISAYYWSY/Zt27aV5Nm9XOcE6YVA\nZRPYQUUITJ8+3d05d45bGEwdkXTB7bj8mWfc6T8Z6t2hSdfX9DMEDIHmQMAsXs3Rz4lrJXFXEq+F\ncuJeFEW1qw/yBYGSc6TBKgZ5C2/lBsILQRMCKFYuzss10a1Z93/5y1/c2DFj3cRggtR6BtKXgv/o\n0ef79SAhjCaGgCFgCCQBASNeSeiFJtPhtttu85YryBZB7JAobakCDrFWQc4gXljAIEDsEcpgi0uk\nXOpCpGw5H1c9aS5n1Lm/cCf0+X7VJ0aNEyMI4lkjz/GEkdg0E0PAEDAE6o2AEa9690AT1i8WJFyN\nfJWIy1AsTAKHkCw5L9Yu3JQQNc7L14/yZSNzcEl6KafYPWUiEC7KExdo2BJXbHmNlo5Z6f/wxON+\nfcS0tY15vo4+5rtOYtPSpr/pawgYAo2FgBGvxurPVLQGMqNdghxr4iONELIFCZPrXJsyZYq3lAmB\n4xxlzp8/v2y3IJYtytVlYo3TelJPs8rU/7vOB6unxcUY7qcf//hHbsIl4xzuUhNDwBAwBOqJgC0Z\nVE/0re68COB+JBZMSFXexHaxaghg7Ro8aLBbsXJF1eqoRcHDzxzhvvjFjdwl48fWojqrwxAwBAyB\nSATM4hUJi52sNwK4DWXiU23tKkcv3I/ijozaSz3llN0MeW75za2u74Afpb6pWL34ItNivVLfldYA\nQyDVCJjFK9Xd17jKS7wW7sZZs2Y1bkMT3jJICu7X5c8+7zp2aJ9wbQurd2yv3u743r1c//79Cye2\nFIaAIWAIVAEBs3hVAVQrsnIEmPiUqSKMdFWOZSUlzJ071/3PwMENQbrAoUewOsKSpY9VAonlNQQM\nAUOgIgSMeFUEn2U2BBobAUjK3p06NUwjj+je3f3f1MkN0x5riCFgCKQPASNe6esz09gQqBkCix9c\n5Dr/e+60mlVaxYpwl3732OMcHwyYGAKGgCFQDwSMeNUDdavTEEgBAjL1QteDu6RA2+JVbNt2D/f0\n088Un8FSGgKGgCEQIwJGvGIE04oyBBoJAYjXfp0PaKQm+bbstvtu7rXX32i4dlmDDAFDIB0IGPFK\nRz+ZloZAzRHAHbf99jvUvN5qV7jnnnu6N94w4lVtnK18Q8AQiEZgo+jTdtYQMASaHYFWW2/jNt5k\ns2aHwdpvCBgChkCsCJjFK1Y4rTBDoHEQ+Ne//tU4jVEt+cY+ndxvbrlJnbFDQ8AQMARqh4ARr9ph\nbTUZAoZAAhBI63qTCYDOVDAEDIEYEDDiFQOIVoQhYAgYAoaAIWAIGALFIGDEqxiULI0hYAg0DAJM\nCttur3YN0x5riCFgCKQLASNe6eov09YQqAkCrNG4ukG//PvbunUNOU1GTW4Mq8QQMAQqRsC+aqwY\nQiug1ggwzcEf//hHvzHXFNsrr7zSQo2tttrKffOb33Rf+cpX/P7www93bCa5EYBsgSsCbh07dmjI\ndQ3ff//93CDYFUPAEDAEqoyAEa8qA2zFx4MAizXfcMMNfqkXSAEkCmLVv3//LLnSNQkhYw+Z+OlP\nf+r+9Kc/uV69ernjjjvOb5TT7CI4gYPgKphAxGbPuUN+Nsz+xRdXuS5dDmyY9lhDDAFDIF0IbJAJ\nJF0qm7bNggAD/+WXX+43SAHkCdK06667lgUB5QmBg4xR1ujRo8surywlEpBJky2wzIfnBhts4N5Y\nvcY10peAJ518qvtOzyM8aU9Ad5gKhoAh0GQIWIxXk3V4GpoLQRJChFsRsgRZgHjlIwmF2gZ5w0Im\nrkrS77bbbv4cdTayQDRpNxuCxZCtEJ4sKP3Io0t8nkb584cnHvdtb5T2WDsMAUMgXQgY8UpXfzW8\nthADXIjsIVzsIQhxC4QD1+XLL7/sIF38xrrWSAJ2stE+cGTjuFjpcuCBgYv26WKTJz7dvPvmu9Zt\n2pSEQeIbZQoaAoZAqhCwGK9UdVdjK4tFCzKEtYvjWggkRAieWMPQIa3xXxAtEUhWpXLMMUe74cPP\nrLSYxOR/5JFHXZsdd0qMPqaIIWAINB8CFuPVfH2euBZjcRKSAAkqxSITZ2PQA/KFWxPyheUt6YLO\n8iUiugqOcerdrVt3d9pPhrg+3zs+zmLrUlb7du3d5CmTIz/IqItCVqkhYAg0HQIbNl2LrcGJQkBI\nl7gX60W6AAUrF8QP8sKmCU2SQIMYiguRY9GXfTWk9/HHuwXz51ej6JqWed20GW6v9l/3eHGfaetg\nTRWxygwBQ6CpETCLV1N3f30br0kXFqYkCfrg7mRwToLlC4LFhkAa2GohkE8I3d/+9je3/NnnXccO\n7WtRbVXqwHI3dOhQd/zxvbPl07+0z8QQMAQMgVohYMSrVkhbPS0QSDLpEkXrTb4gPeCE1JJsSfsh\nJUy5AenaY489XbfuR7ipU66Vy6naY+26acYNbtGihevpbeRrPUjshCFgCFQRASNeVQTXis6NAAM6\npIJBL8kiVi/0rEXAvcYDS1st6ozCH9I5YMCAFpd23mlnN+XX17mjj+zZ4nzSf6xe86Y7+aST1rN2\nab3BvZ54a13s2BAwBBobASNejd2/iWwdXy0ysGPRqRexKAUYXFES/1VKvmLTarKVBLcXZPOKK67I\nqs/yS8S+4eqcPn2Gu/mWW1I1oeq5vxjtXn5plbvl5huzbYo64H7EspiGezJKfztnCBgC6UDAiFc6\n+qlhtGRw23fffd1TTz2ViNipYoDFMseADFnEUlepUB44iCSBbKELekG6pk+fLqq5XXbZxZOub3zj\nG45FLpj1ve0ee7qLLxydTZPkA+btGj5sqLv3vnt9HxbS1chXIYTsuiFgCFSKgBGvShG0/CUhAMlg\nw+qVJsHiI1NNlGMR0WSL/EkI2Nf4ox/9wnqWIpCtRYsWeQvQv/71L/fPf/7Tvfjii8F6l8e5kaPO\ncz8a0FeSJnL/7HMr3Am9j3Njxo5tEVBfSFkjX4UQsuuGgCFQCQJGvCpBz/KWhAAWIwgXA1s55KWk\nyqqQGGLCVixpxDXHhiSRbHnFgj/0B5a8V155RU65fv36uYkTJ3q9IVxs//jHP9ynn37qZs2a5X71\nq8vc9Bk3uq4Hd8nmSdIBcV2DB5/m2rdv7y4ZP7Zk1eQexdJpYggYAoZAnAgY8YoTTSsrLwIMYpAW\nLEdpFAZjiBdkKhdxJA3WI4T2siVZiC+TLxdFzzPOOMOTLn4L6YJwffTRR+7jjz92K1eudA8uetDN\nvHWmu/GmWxJHvoR07RgsDXTttVdLs0reC2lOeh+W3DDLYAgYAnVFwIhXXeFvnsrF2iWDWVpbDmlk\nINZWL0220vRlHH0S/nJx2rRp3tpFPBfuRbFyQbr+/ve/uw8//NDde++97pBDDnG/u+tud+usZJEv\nIV3cXzOmT8tJkIu9/+R+NfJVLGKWzhAwBAohsGGhBGm9PnXqVLfBBhv4rWfPnqlrhtafdmiRdrFf\nsGCBvlTwuG3btllcxo8fXzB9XAmEeMVVXr3KgXixmDaWItkYlLGEseWyhNVL31z1EkSvSRdfLhLP\nhYsR0oWlCyvXJ5984gnX+++/7+fzItaNjyPWrVvnDu92mPveCSe6Q7oe5Jgnq96yZOljWffinXfM\niaUv6FsEcm1iCBgChkAcCGwURyFWhiGQDwGsBg899JD/Oi5furRcY0JR3IlxfOFY6zajd74vFyWI\n/rPPPsuSLqxcEK9nnnnGbbPNNt7qBTnbeOON3dH/31Fu+x22c2MuusAtD66PGPGzukw1AfGbMG6M\nO33IEDds6JBYYYV8gRvkK2kfRcTaUCvMEDAEaoJAw1q8aoKeVVIUAlhJevXqFYsFoqgKq5gIqxZB\n57QpbQJ5QH89XQRfLjK1B3shXbgXcS1+8MEHnnBBNP2SQcuXu+22285bwkiLxXWjjTZyPXr0cNdf\nf737y19edid9/weOKRxqJXy5OHDQaZ50sfh13KRL2oElEwJmli9BxPaGgCFQLgJGvMpFrsr5Bg4c\n6F0+WBbY0iyQlLitQ08++aTDVdqnTx+HK1m7X+UYtyrXRo4c6W677Tb33nvvxQIj5CVtxEusNXq6\nCNyKMl0ErkWxcgnpwp0opOuuu+5yXbp08WkAEWvXJpts4rdNN93U7bXXXu6GadcF83yd5OfNYr6v\nahIwYrnGjJvgp4uAFC17bJknlbF0cI5CjHzlAMZOGwKGQEkINBXxYqCWQZn9oEGD3EsvvZQTMOKn\nSKPzbL311n7AzzWI67TkZ+vcubMvQ2KqikmTL8YrrDCkQuqgbI45V45EtRnygj7lCm5GyEocInjS\nRiFUnIsS+pZrQtAgYuTJ1XdRZUSdE3dTWqwfxKKBv54ugi8XCaSHTIS/XMStqEnX8sDS1bp1a5/u\nC1/4QpZsbb755o4N4vWlL33JffGLXwzixvq7JUuXBCTtwCwBm/Xb2VEwlnWOOK7hZ45w3YP2LH/m\naf9lJdNF0I5aiJAvMDUxBAwBQ6AsBAJrSkPKlClTMBP5LXCFZNjkt963atUqs2rVqvUwOPvssyPT\nS17yPfHEE+vlk+vsw2WMGzfOpy8mjdaf9Fp0/sAyllNPqU/n3X333bPpw9f5rcsOH1NXqRK4sTLB\n7OelZotMX0i/sL65foNBVJ9HVprjZOA6zQTEJcfV5JxGxzAOnAtchZmAcGUCt2Im+FoxE7ghM2vW\nrPG4BIQy8/DDD2fmzZuXmT17dmbw4MGZ3/zmN5mAzGcCy1dm4cKFmccffzzz/PPPZ1577bXMu+++\nmwniwDJBIH4msJr5skEgILiZ4KOKzOGHd8u026td5qfDf5659bbbM8uffb4kgO659/7MqPPOz5Yz\n4qyRmZdffrmkMqqROLAWVqNYK9MQMAQaHIGmCK7PZREJBiRv/cCqNX/+f+JSsJCIdYo0UYLVBEtQ\nMIC7gIRFJSlYBpkK1RNZsDqZzxKFdWf//ff3MTgqS+QhFjLS5xPqCkiLCwhlvmQtrmEVIjamUilG\nv2LrwBKGizIgzsVmWS8dVi8+Gkiy5Fpz8bDDDst+uainiyCmS+K6CKjH5Xj//fd7axnWLCxbm222\nmdtiiy38xrG2dmENE2suuGAdwp3Jxn2w+OFH3Nw5c9x/n3hCUGY317rNjm777XdwXw3ixsKCNQtd\n7rpzrvvusce5Aw88wJ1xxrDYXdbhekv5jRVRrIml5LO0hoAh0NwIbNgszYeAMNAGRNqtXbvWExJp\nuyZmECpNhiAakDLysRF7JRJOK+f1Xsdq5SIsxaTRZYaPA0tQVr/AUtbicj5iphNq0qWxglgSPC0C\nNrS7WIGcMEBVKrpPpCz0pO1s9FF4Y4Z1roEv/aiFGLFy3bGUA/FKqruJIHqmvdALXbPmIvpCugiM\nJ54L0sV0EfLVorgX2XPuz3/+s9ttt918PNeXv/xlT7aYdoINFyPniPMi3itMujTWgheB7yxUzXM0\nceJlbuD//MhtteVmbvMvb+I23WRjv20WHH/68YeuT0DOzhx+hk/L1BDnnTsqUaRL2ifkC8xNDAFD\nwBAoCoHgJdiQEnbVhV1LwSDdwgUTkDGPQzgf6cKi3Za4HLUEoGfLJV2UFJMmrIcuR+cPSIW+5I8D\nspHVgbTSNi7iZpP8pENwmco59mGsyE87JQ26FSvnn39+hq0SoX6pm30uN2+hOsK44AouV3AzBSSm\n3OxVyxeQ4kzwhWILvPgNhrgXcQXiEgysSZl33nkn8+qrr3qX4e9///vMAw88kLnzzjszAWH1rkVc\njLgagwlTM4888kgmCMz398abb76ZCYLuM4FFzLsqcVlSdjMLLnWwNzEEDAFDoBACTWHxwtoRtniE\nf4sVB0uICC5Ebe2R81hQRMin88h59lF59fVi04Tz6N8nnnii/umPw/Xm+4CADFp/rEhhbMBB11Oo\nPK0QVhYJRtfnSznW+pEPKxZ6lipYHHXbwuWWWl7S0uPOA+tyv1wkqJ4lgQi2X7x4sTvqqKO8ZWvL\nLbf0bkMsXbgZsXQRTM9UEoUsXUnDqFr6iOvZLF/VQtjKNQQaB4GmiPHSg22hrtOkItfgDhHRIqRN\nn+M4nC58vdg0UfnkXFTbwvXm0k/K0NchI8Tp5BOdPl86uRb3F2dRbZa6Cu3Jq/u4UPq0XIfglrLm\nIq5Eiediz3JAzFSPGzIImPeLS8tXi5Atjonpkq8XIV0bbvj5/22F7pe0YFipnpAviWmM+56vVDfL\nbwgYAslBoCksXsmB2zSJA4FyLVUQxnLzxqF3tcpgOaZu3br5ObekjuDLRT/Ra2Dy9hYs4rmwZgnh\nCsdzEesF6YJQvfXWW65Tp04+lgsrFxYviJfEcwnp0oH0Um+z78XylfQPL5q9n6z9hkA9ETDiFUJf\nW1NyDdJhi0/YwhQqsqo/o3QM66fbFKWM1h83JYN1vi2I8YoqJvIcXzRiBahEwq5TAu2jgu3z1YGV\ni69XNTbhcvPlT+q1ctdcZGJUXItYuiBd9DdfLgaxXu673/1uC9KFpSuKdCUVk3rrBflCjHzVuyes\nfkMgmQg0hauxFOi1e5FBmi8ewwO0/lIQ0qLzlFJXHGnRT8dfUab+ShP9ChEvrT9EjnZrMlaJnhCv\nOOJeaKN8hYh+fIXJRt/k6gPS0R5IV5R7MdyvlbSz1nnBtNw1FyFcuBexgPF1I5YrSJe2dEksl54u\nAtdipVYuyAhu0b+te9899tjvPWzowrQRSDDfl9uv8wH+uH27doG1bXPHl4NCZvyFFPzhvqetbByb\nGAKGgCEgCBjxEiT+vWeAZ0Bn0EawkmDhkUGa35rYhEnPv4up2S48txa/9dQQxegH8ZLYJ9rN/GS0\nWQiZlCmYcE1/YFCosXEQLwLjwV10kDqlL4SUyflCe/SX9hVKG3VdYnmirlX7HHhCRnQQPWstBl9a\n+iB4XIYEyIt7EauWTBkB6eJYgughUkwHQcB88OWjO+SQQ7LxXJAurlXqWgSr3919j3sg6L81q1d7\nYrV3p33cET16ujZtWnu4mDICYe3FV4MYM+Spp/7onnt+pbvjjjt9vm8Hc391PbiLnyrDJ0j4HyFf\ntD9txDHh0Jp6hkCqETDiFeo+rCcM8kJesJRARKKEtHxhV29BV9E3rAttKUZIB6lEsBKxJE+UQNBK\nIV0QhNGjR0cVVdI5SBKEL+wuLKmQfyeGjFbab/WyZDCIE0Svl/9hglIW7iagG8LFRqC8zNGFRYlN\nSBfXSIMFi2B5SBdz3FFu1PxcfLmIQNJKkdmz57irrrrKk6YT+nzfnTXyHHf0kdHPkpTbsUN7x4bo\ntBCyBxYudLPn3OHGjR3nTh8yxB373f9ykJskC/pBlI18JbmXTDdDoLYIWIxXBN6QkELkAtLFhJ3s\n6yn5iBXkopCbUXSnvYXICGXR5lKEgYe1GuMQCBMTutLmcnDHasmkqmzl5NdtYCCFVNZScNFRpyZd\npay5CPmCjEG6IFPEbUG0sHRhMZOvF7WlqxzSBeHq1q27J12n9O3vVqxc4S6+cHQLIlUqbpCxYUNO\nd1jGJl55lXv55Vf85K5XXjUpFld2qfqUkh5CzHPAPWNiCBgChoBZvHLcA+JexJUVjukSYlbp4J2j\n6pJOQ5ggRASbSxwT1iF0LMbNqCsjD+QEt50OXqd86uF6qcKAw6zpcf3HD+YQRDYsc+JqlL3WD71l\no11x9RcWDMhkLd1HfLk4YMAA3Ty/yDXWLgLjcS/q5X9wL2Lhkngulv/B0kVaXIeQLln+54UXXvAu\nRpmfi3gvCJfEdLWoNM8P+viSCb8KLFxvOAjXjwb0zZO6/EtYwth+/OMfuYsvvthdM2mSuyrYevbs\nUX6hVc6pyVct75sqN8uKNwQMgTIQ2CB4ETPLtYkhUDUE+gfL10DA4nA5Vk3JEgqeO3eub0utLBhx\nrLkI6ULCay5CXo855pi8ay4WA8306dPd2DFjXd8BP3L9+53q2rTeoZhssaSZ9dvZ7n+DJYW6dT/C\njR17sXe5xlJwFQoRt2OtraVVaIoVaQgYAmUiYK7GMoGzbMUjQOwQZKURREgXZLLawiBNPZWuuQjp\n0kH0uBSZn4sPFfbee++S1lyMavNZZ5/jSRcuwFEjR9SUdKFPn+8d7xb6LyXXub79BiTapYflC9KF\n29jEEDAEmhMBs3g1Z7/XvNUMOAw2aXezQIZwWTJBKVY8kbgtGNRDmXF/uUhMl8RyPf744+7oo48u\n+8tFdIToIJMnX1tzwiXY6/3wM0e4eXff5WbeOjPx9xrPQ9z3jcbCjg0BQyCZCBjxSma/NJxWuMsY\nqG8IYpXSLJdffrm33oUtFuHfEEzIZjmCC7MaXy5CumQWeiZKZS1GposgnqvUIPokki7B+rppM9yE\ncWOMfAkgtjcEDIFEIWDEK1Hd0bjKMP3CbrvtFnyN9nILS1HaWoyVC/IFMconkCfIiQj52AoJBI6y\nmVlehC8XmS4C4YtEJj3FfaiXAJIger3mImSK6SIIoteWrr/+9a/+/J577pmdo4uyS5ku4qSTT/VT\nVCTF0oX+WtJGvioh6rrddmwIGALJR8CIV/L7qGE0JF4JSavVC8LFBoksVcij82ENC7tdwaVaXy5C\nvNj4cnHp0qV+brpyvlyk3RddPCZYWujxxLgXc/XFub8Y7Z55+k9uxvRpZVsfc5Ud93mIOsS8XCtp\n3PpYeYaAIVA9BIx4VQ9bKzmEAMQDq9dTTz21HukIJU3cT6xXDIwE18cRl0N5+qtIXLE6novgd+o6\n7LDD/BQQWLr0dBHhSVFlugiAC3+5SEwXVi/m59KkCwtXKVYuyp4/f4EbGkxeevucudmJTjmfVMEy\nt1WwyPe1116dVBWzehn5ykJhB4ZAQyNgxKuhuzd5jWNKCQiFJh3J03J9jcS1iO5xCgQsvOYi5eNa\nxMUoy//gXsS1qJf/EfIVXnMRgiWuRUgXVi7OrVmzxpMy5jYrh3Sh60FdDnK/DCxefEmYBlm95k3X\nPfhIIenzfAmWPBdYvSD5JoaAIdCYCBjxasx+TXSrcLFBZNIyrxdkCzepWCTiAhcig/VMW7r0mous\nvSgxXVi72rZt6yc1lYlRIWFRay4K6WIvli6C6B955BHXvXv3skgXbR40+HRvfZs65dq4IKhJOTLP\n17LHlqXClScuaSNfNbk9rBJDoOYIGPGqOeRWIQQGwkFMk1iSkopKtXSlXNqul//JteaiWLpYT/Gt\nt97yVi+W/sEyss0227RYcxGyJV8uYulihnpI18MPP+yOOOIID3Op7kUyEfQ/eNBgP19WLSdHjeu+\nwOXYsUMHd+6558RVZFXLMfJVVXitcEOgrggY8aor/M1bOaQLFxsDejjIPCmoiEUKkkhQfVxCmyFd\npXy5KF8t4l788MMP/VeNb7/9tnv33Xc9sYJgffWrX3UsFyWWLr5oJN7r9ddf9+QMC0o5pIt2Q1z2\n7rSPnyA1LhxqWQ6LbO/d8eup+qrWyFct7xCryxCoHQJGvGqHtdUUQgAyg7sxieQL0sVEqVihIIlx\nCWWV8uUiJEtci5AuHUTPV4nEbsmai6z+xWANCYNwsSZjt27d3OLFi/2+3DbQP2m2dkm7mVx12222\nTo3VC73pT+7FpP5zItja3hAwBIpHwIhX8VhZyiogQOwUMVRJIl9i6cJChFUOi1ccQll6+Z9ivlwU\n0gUBg3QR64VArCBYEs+lv1wUSxfE7IILLmhBuhjAS52yYMRZI12rrbdJrbVL+m7J0sfcD/v3cytW\nrpBTqdhzP0LAjHylortMSUOgIAJGvApCZAmqjQBWIEgJ+3rHfEnslcSg0XYhhaUSFsGNgZP2sZC0\nyC677OIJJ8H0xXy5COki0B4hZkt/uSiuRc4J6dpwww19/BiuRQikCO1DHxGu6etyXvakxfK3/Nnn\nUzF9hOida39sr97u+N69HIQ/TWLkK029ZboaAvkR+ELg6hmdP4ldNQSqiwD/ye+www5u8ODB7s03\n3/RL2VS3xujScX0yII8cOdKNGzcumwhismLFCv8FYankiwETEnffffdly4NsMZ8W5UK6mCoCS5YE\n0eNSXLdund841l8uykz0WLgIomcP8SKQXpMuCBdfS4atJOBMvbKhH2QMiwobv0kjMnPmTPevzAbu\njGFD5FSq9399d6178sk/uO9+979S1Q6sm2zLli3zfZcq5U1ZQ8AQaIGAWbxawGE/6okABEAsEZAg\nCEstBMJBveyxuuWqV4hJmMzk0lGsZ6V8uQjREvci00Xw9SLkDAsWxAqCpd2L+stFXItsyEMPPZSz\nHbn05bwQMUlz2cQrXI+ePd2wIafLqVTvCbI/ofdxqXM3atCxwOa6R3U6OzYEDIFkIrBhMtUyrZoR\nAQiNkBVcjkKGqoUFJAMXILPpS935BjSxEjHwFRIZHDXpYkLUadM+X75G5ueCWOFGhHDxlSMb1i6x\ndEG6IFMSz4WVi9gwmTIC9yKuRwLphXRRJ7qWI1j0wEC299f9zXUOvpRsFOnYob1r3aaNK6YPk9pm\n+ibN+icVV9PLEKgVAka8aoW01VM0Ani/sS4hkCJIWJwzxotljdglyBcLd2NhK8aNKMSEgY+8UYLV\njK8J9XQREC5mo+fLQ1n+B9KFVQsLl5Au9pAurpEWMgW5wqUI4dKkCzImpAuLGO5FNrArl3jp9lDO\ngw8ucl0P7qJPp/74m/vu32L+tDQ2yMhXGnvNdDYEPkfAiJfdCYlEAIIDgXnvvfe8NQrLFGQCKxgk\nLBfpydUYiJKUwaBF+XPmzPGEqxySQhkQEzYt1KGni4AoMQM901II6fr00089sQqTLggY57iO8OUi\nrsQw6WL6iCjSRR7aiW5xCG37wUmnxFFUosr46nbb+Y8FEqVUGcrQz/R3qc9CGVVZFkPAEIgRAYvx\nihFMK6q6CGCpgoyxJ4aJLwMhTbgJo6xVMigRZE5AOwMVm/5yslKiAjlh4EMPSFetv1wUKxfICwlE\nlzgEK+Arr77hJl42IY7iElPGvPvmuxtnzHC33HxjYnSqRBGeB/o86hmopFzLawgYAtVBYKPqFGul\nGgLxIwDBggyIMOBAeiBPUQIRYjCCbOUSrlVCvhjwIDy4LbXoNRf1l4viXtRB9MzRxXlckBAp3Ic6\niF5PFxHlWpR60SNfWyVdsfsNNvyCwzpkkmwEJD7RyFey+8m0MwQEAbN4CRK2b1oEKrEUQf6woOkg\n+kJrLmrSVcmXi5A0kUrIo5QR3k+8/Ar30cefpn7i1HC7Vq950+3YprV3/Yavpfk39yL/aEDATAwB\nQyC5CGyYXNVMM0OgNggwUGE5KzVWRsiOJl2HHXaYD6JnAKzml4uadEEcbbAt/l5J4yLfxbQOyxci\n/0gUk8fSGAKGQO0RMOJVe8ytxgQiIO6aYlUj1izqy0UC6flK8qWXXvKTooprMe4vF7WeRrw0Gs19\nLATcyFdz3wfW+mQjYMQr2f1j2tUQgWLJV6EvFzt16uS/THziiSfWmy4iji8XNSRiddPn7Dg/Akyi\n2m6vdvkTpfiqka8Ud56p3hQIGPFqim62RhaDAO5BtlzWAlyRTGehF7rmy0rIDy5GHUS//fbbu222\n2cYtWLAgOykqpItAelnoWoLow5Oihmej118u6nagpwyy+nxcxzIha1zlJaWcV197ze3X+YCkqFMV\nPeS+IO7LxBAwBJKFgH3VmKz+MG2KQADCAdmRPVkgRUwbgcg0ExxjxWIQ4ms/iYHhfC4hLWWz10L5\nlCF1cK3Ql4sQpnbt2rnFixe71q1b+9nlK/1yUetE+9GpWrLlFpu75cufrVbxdSsXAtwMwj3MfQv5\nKubeL4QJ9xtlyUbZ+rljzjqpR5479tW8RwvpbNcNgSQiYF81JrFXTKf1EOBlT1yVTJ4qL3T2WKkQ\necGTVgYFGSTkHF8gyrZeJeoE5EuXV+mXiytXrvQz0GMJK2XNRR1Er9Tz5FD00+fjPAaDSy651N1z\nz+/iLLbuZY0ZN8Ft9uVNgoW/h9Zdl1oowLMAaeJZKVX0c8dHJFh2ue8gdWyI3IfyjHGOe4c62VM/\naeS5k+eVdCaGQDMiYMSrGXs9JW3mhQ3RYgkhhBc3rr5yBhDyMzAwEDAXGGUTqyVzfXFdiwxW7KlX\nL//Dmoss/4PIl4vMNv/xxx97VyIWFaaMYMO1yDVmrV+7dq13M+69997Zha5lji7IGDPVs+Yiy/8g\nuUgXAxoiA5//EdMfwQic7rjjDl8qujeSDBx0mnv7rTVlr1qQRiy4j+lbCFAxwj85PCfca0KY2Jcj\nlMFzTJkc8wzz3FXj/i1HP8tjCNQaASNetUbc6isKAV7SvJwhWbyo2eIUiAWEjsEoFwHjvI7non7W\nXJTlf4jpIl4LYsVC15AsSJcQL87J8j+y5iIkZvXq1d5yAOkinktIF2lkzcV8bUX3YgfQfOVwjYGQ\n8tgYHDXB5Pp+++7nLho7zh19ZE9+NoS0b9fezbx15nrxfHFhmmSQ6Od87eQe4L5HeD7ifu543iB0\nrPDAc8SxWcCSfMeYbtVAwIhXNVC1MstGgBczL3v+Q4d85Rskyq5EZWQgYoCBgDAIyH/1YdJF/AqD\nEq4WWXNRky49KSoEDNIlQfRYslhbEaLFuotsTz/9tNt///3ddsHM8FyHdOUKolfqeoJUCSbgSptp\nC3s9B5muR44hXkcd81138YWj5VSq90uWPubOHXVOsH7mwvXaAR4iWGMa1SJDO8P3EPc/z50QI46r\nKdTHM4YuPH9C9qpZp5VtCCQFASNeSekJ08MTn+HDh7vzzz/fv4xrCQkkj5c/xAtyIm420eGpp57y\nwfRYucS9iGuRmefF0iXuRUgXaRC+XNx0002zpEtci5wj7mvbbbd1u+22W1Gki8EKKZUQCMlikNMf\nB/jCIv4ce+yxfmBmcGY+skmTro4kKhFZE3/q3F+Mdv/49BN3yfixeXUFa8GbhGGikjdzCi5yL0ib\n5N6HbEGCammBQg/qxbKNHrWsOwXdZCo2KAJGvBq0Y9PULIiO/PcLSSg3hqvSNvPf/r777tuiGL5c\nxL3IgPC1r33NffbZZ96SJROjhi1dpa65+Oqrr3r3XrjeFkr8+4ceLKOuyznSycZi4oXk29/+th+E\nGYhlWgysekIyv/GNb7orA/LVCO7Gbt26B8T+f7OkoxA2ch08RSC+pZJfyZukPW3Cysue547+r4fw\n/EO+eP7q+fzXo+1WZ3MisFFzNttanRQEeOnKC58Xbz3/46VuXIoS56Sni1i4cKFr06aNj9kSS5cm\nXeWuuYi1i/oY/ASHqL7Jdx3cuC6b6B9VDudol3ydxp42i/tUiCMWO7HsHXPMMe7+++5PPfG6btoM\nD0k+nHNhpvNgCQNrhHumXv8oeAUq+IOFCcsu1tx6tgEMIVxY28AZbOupTwWQWlZDoCgEzOJVFEyW\nqBoICOniJcsgkATRVi8ICUsAMRM9li7IV+fOnddzLeovF4nVIlh+s802W8+9KEH0ub5clAEnTD7F\n5SVWFhn4Sc+AVYhoMa+ZEK1evXpliRYWLbFqaaJFW/X2wgsvOMjX8mefdx07tE9CN5Wlw0knn+q+\nd8Lx7vjje5eVPyoT9zD3jAj3crj/5FqS9mJh4h6iDXJv1VtH3gNi/TbyVe/esPqrhYARr2oha+Xm\nRSCJpEsUhthAVhicsAgQi0Vw/FtvveX+/Oc/u5133tmtW7fOTxcR9eUipIsAeuK5Sv1yUax+eiCE\nXCHsGSgLBcRDGCFaxKthQcBFKq7DMNnSBItjPgjQe7k+PpjPa/fd27qJl00QmFK1n3fffDc8mLdr\n2WPLqkqM6D/ubSSp1jBNupJIEo18perRMmXLQMCIVxmgWZbKEUj6y19cbwMGDPAWDZb+wbXI+oss\n8YPgXsz35SIEjCB6sXQV++UixI/BhwE8PJ1FLuR1QPw+++zjiZaQLbFmyV7IVJhghUkXv8Xd+OKL\nL7pLJ1zqZs66zXU9uEsuNRJ7ntiuoUOHxmrtKtRY+i9p1jDcedxbQvALtaFe14k9Y0u6nvXCx+pN\nNwJGvNLdf6nUnhcqAwAEI4n/cQOquOCYh6tLly5+Y+JULF2PPvqo23PPPbNzdOX7clFIl8zPlWtS\nVCxZssUREI/+ECtNtoRIRREsIWOSRvIKDmAybdp0P8/Y7353Jz9TI8xUv2zpEnfnHXPqqnO9rWHc\nX1hB2afBjSdfGKOviSHQSAgY8Wqk3kxBWyBbvPRxm+EGS6JgKWKDhBBsvmLFCtejR49g+ZxLPOEi\npusPf/iD69ixo59pnklQZY4uPV0EhEziucJzdDEIM6DIVihOK19AvJAjTbI4FoKlLVv6nD4vedlT\nnmAgRBFrHeSRJYT+69hebtTIEUnsuvV0Yt6uQ7oeVPcA8rBitbaGUR/ua/7hScucWejMuwJ906Jz\nuJ/ttyEQhYARryhU7FzVEIBs8TLF6pVUERcdJIUYLojWpEmT/GzbV199tSdTb775pp/0lPgpIV3E\ndUHCiAeDdEFW2BDisoRksS8Up0Wevn37enIqMVvsIUVRREssVrIXghXey3X2QraEaFGnCCSLTdog\nk7w+++yz7rLLJrpLLv2V6/O94yV5Iver17zpTj7pJNe/fz8/S3oilfy3UtoaBkFii1MgLkL24yy3\n2mXxrGD5Qve4Mam27la+IZALASNeuZCx87EjIC/RJLsYaTTESyxGQrxYBuiUU07xXziefPLJHpvn\nnnvOde3aNRtET0yXuBaJB1u8eLGjzQToFyJaQq6EmELoCPAXosXAA7HbcccdW3xxCIHKRa7kvCZb\nUh57LUK02GOli9pkLclLL73Uu1tvvOmWxMZ7QboGDz7NtW/fvuBkqRqHJBzzfLCJcE9UIpTFtCUv\nv/xyKslL/+AjF4TYNBNDoBEQMOLVCL2YkjbwHyuuDnmRJlVtbfGSObuwehF7xcz6t99+u5+SAZL1\nzDPPuG7dunlL19KlS93dd9/tHn74Ybd8+fKCzWPiUvnyUAfEM23Ft771raxFChIIeWLgfO+997y7\nU8iUkCu9l/Sk4VjIllYIF6K2aIWJlpAsvcf6RXwbU2rcc888N3nyZDd9xo2JJF/DzxzhVq160c2Y\n/vnkt7rtaTuGvIvwDLGVIjxv5OHZS6PERRz5QKZnz54egnHjxrmzzz47VXC0bdvWrySB0qXoP3Xq\nVDdo0KBsW3m/1VJ4Z/HOYBWME0880c2aNauW1SeyLiNede6WfA9Tvmt1Vrvk6onpwt3BSzTpwouJ\nDTJDcD3kSzasXQcccIAbNmyYw+LFS+TWW2/16Qu1C3IlRIvpHiBEQvKEIDE4COmCOKED14RYrV27\n1tdLWZp8CdmSctgjlC/xZZpoQaIgW+JC1ARLSJg+h8UPMnnEEUdk3Y+jRp3r5t1zj7v+humJIV9Y\nukaPvsDhCm4E0hW+p3h+9DNUyBpGWqxdDH5J/ZAl3Mao3/LPWiVWL3mf7r777gEpXxVVTaLPif4o\nGSZeEovJtSlTpriBAwdy6KXexAsltA68MyFgzSwbNXPjre3FI5DvwS6mFF6YaQmQpa0QFiEqxGtx\nDvchZOSaa67xW6F25wuIj5ohnsFg66239hOiCunSe44hVAwcuDGxYhBPJmQLnYVooRvkStogREvI\nVnjPdSFaco1zbK+99pqDeDGJKuWBBfvLLvtVMAv+Pu6HQQzVLy8eU/eYL3Ev0vZGJF20iz5nEylk\nDcPK1a9fv1STLtpKOyCQxIaWQyDHjx+ftRalzdIlfZ3mPURQ+mDkyJFGvNLcmaZ7OhDgv27inCr5\nb7XWLYVcsEFCEIgGE6guWbIkpyrEZR0exOOwYdEiRgsiJK4+rGaQJDaxVuk9S7cceuih3joRJlyS\nTvLz3y+uR+LKvvrVr2Z11EQLIqUJVZhYaYIl14RsyZ5FtSGDHTp08BhI48EG6R+4sbbccis36pxz\n3Isvrqrb144yQeqxx/VOXUyXYFrOnntNhOdMiBjkRL4elnOSLo17yCbPFJZz7rlSBGsfgz7SqlWr\nFtagUsqpd9pyrXSQHm0Bq1c70AHShcuR/mhmArxhvTrB6m0eBHhZslRNOf+p1hMlIR9YvNgOPvhg\nt/3222dVgvRgBfrVr37lXRcspn3dddc53JGs64hVi+B8JlqVdR2ZB4ypI/hUno1BgW3OnDl+oORY\nrpGODWsTMWYySz7kC0KH5Qsd33jjDR9jxteVTO5KoD5Ys2eg4Vjv5VjSkI7AfdrDV5ky6Sskk/nK\nIHnUI2RUSJcAwRI8M2+d6efKOrZXb8cUDrUSrFzn/mK0n5V+zNixTUW6whhDTiBibBxjYeb+gYA1\ngkC4yvnnDTcXzxUSJiAQALmviYMiHeRAzrEnjeSPwpHwAPLqPPyzUigfehFzpvPxm/NRwnMoaSkb\nkfw6vegi5bCXfOxFwu188skn5VJ2r9MQp6Ulqt359NfuRdFNl9dMx6kkXtx0+ibkZuIcTFqL3IBc\n50EIX9dlcBwWHjbK1Tdtrrp03mL103nKOS71xtftBQvy8zBJ++RloXUp5sHW6aOO+Y+b2KY0CZgg\nYkHCIsTGi/vUU0/11yBRd955p4/3YhkhvjhkSSH9JWSYaAnZ0nssXZAgzjFQkgeiBmEjxgxrF1Yz\ndIIAQQIhRxAl+nSPPfbw9zZlCMmCXNGf8luuQbIgZ0K0KEeIFuXSRogeHwjw0QDlCBa+0Tn+MLgz\nQWmPHkd41yPB7c8+tyJH6spPQ7iYGLV7QDLe+evb7t777q3prPSVt6C6JdDfCJP+NorwDuEDF56T\nUkQP8szHl0943/H+1gL5kOBwfZ5jrkWRDSFwPJ9RhIaxiY13sBZ5p1NmtUUTIeoK68I5jZ1OD0ZR\n7Rb9aVtY+Edx//3396cZf2677bZwkqb5nSriRWfxAHCzh0mUPBz6JseUycCBCImSnuWG0mUQkKiF\ncnhoKDcsnONa+EYtVb9wuaX8LufG1+Vz0/PgaLzkZRH3Q4+bkf/C0yZCSNlDwNh++ctfuhkzZnhr\nElNEiBuR4HesYbgjV69e7ckTJEoTLPBlk3NcZ+PLyG233dZbtbCSUVYuogVhgjyxCZmC9HXv3t2T\nPoiZkC1JI0QLi5i2aPFVJmSLPGy0jzaxHV5mfw0bOsSToI02+oLbu+PXHQQsTgsYZE4I1/JnnnaT\np0x2UyZf43YNLDwmLRFI4z88LVvQ8hf3NXGTtKtY4f2m3/P5iBdjgn4f6jooI0wmeAeHSZrOwzHP\nO+9T9iLUowmNnNd7xpZCZev05RxDgiBDIuG281vrLdgxdkSNi1IOe9oXpb+UQRojXqCQAunTp0/O\nBwP1wzc5N5X2I3MzyEOobwqYvL4hwuXkgib8IJaqX65yC52v5MaXsvM9ODz0cT0UzD9FrFM9B0Ze\nfEKipP2V7rHwMADg8sMiJV8/EgD8+OOPe+IlBEvvtUUL9+G9997r5wLDfYiIRYugeT0jvpAocRNG\nWbOOPPJIT+SoD5LFJu5DyhOiRWyXEC2NC32FVOqaoq8nXDLOx6Btu83W3gLWrVt37xIkFqtUgbhd\nOekaN3DQaZ7MvfKXlz3huuXmG8smiKXqkMb0xOeVS6DjaG81njvaI/dpMTrqf47F2pIvH2mIpeK5\nZq/HBcqS8hgj9BjCWDN//nyfj7zapRlOq9+t1MeXylKf1lGny6Wz1KmvY0QI66Cv62NtxZK2yXX9\nG71ENz12cI71a0V/jRf40HYtmujp8nWaZjjeMC2NhDRpRs7ntHQ2m7ZW0dH6vwmIl+5sbgZNwBjI\nKEsL1/UNo+vSRA4SJw9Hufrpeos9ruTG13XodoXnVhGsK32wCfitJ+nS7eVY92v4Wim/GQBoG5Yp\nSJMQL8jUTjvt5O9VsWixj4rTIjieexP3HqQoF9ESsqX3EDH5zTFWLYjWQQcd5F2HuDzzES0IlxYG\nM/qJLS6hrHPPPcetWLkicHkNc5tusrG7ZNxYT4KJBYNIYb2K2ojbOunkU137du09cVseWAVZnJv+\nw8JVT0IRFz7VLId/CrAOJUXieu74p6AU4iXvMXDQ40AuXHgPSjr24feikAXe+7pNjEGadIR/6zFJ\n/vlHB4gPzzFCfXp80br7BFX4o4kX7dF16mNJxzmtP/gIIRO8pD2UJ+OjqC7Y8pvruixJ0wz71BAv\nueHpFP6b0DcovzV50jc56TUx45r+TyVMzEivb5ZwXdSjbx65OSvRjzqLlUpvfKkn3C4eLHm4SKNf\nKpKnnD0vySQNktJf5bRF58GKx+AG6ZIvEPlqkfguXHbs//rXv64XEM81LE64+N5++2239957xxoQ\nT7nEfHGPEqclFq0w0dJtoR2QJIkL0tfiOiY+57xzR7lFixb6e+vM4We4Dl9v5zbfLIgxCwhZePvi\nF4Ln/H9+5N2WELepU651/YPg6mrqGFdbk1AOVs8kYRXXc8d9StuKFV2vfm9H5YdAhNNAIvR7UYiC\nLpc0mnRJ2bxjRTSpEaLCNf6JZhPrEHWJQYF9tSXcZj2O6WNpn253OC+65sJL2hHGV5cnaZph//m3\n8iloqe4guQm02tywYgni4eBGF+ZNeh4CIWTy8HATaAIn5em69EMi16M+69V5StVPyi1mr+vJd+OH\n2xouO6pdnNOkM5ynEX6DX1T/lNo2BgARsXoJCWPPdYLmmYYBkTgqSBfbI4884r/0xNrFb70nrfyW\n9JIf4sbG7zCp0uSKe//wwCoHqcJKEDUIM4DVgxijC7qxmVQHgXr0a76WxPncEWBfrOh/IGU8yJU3\n6p1IWk0WpDwZQ7ieK1+4PsnLmKPfs2IIkPFLxitN+KinWkI9ooOML+xFX9onbZRz6EIa/c6J0k+n\nL+d6VJ5GOJcai5e+0Yml0oMOxwS7awl3ODd7+EHQljDJq+vhnH7oJE3UXucrR7+oMqPO6XbJjR/G\nQkgX+XV6XV6x7dJ5yjkWa0o5eauRhxeMvFziLF8TInEdMsP9iy++6L8gxB0ocVoQnn333dffj5AQ\n7kvZS5pSAuKl/6PaA7nBJcqmRc4Z+dGo2HG1EIjrudP/8BSja4eXj40AADlaSURBVK73XzF5q5UG\nEkNclLaI6bqwNDGGCBHT16pxrP8RFSuXJoa1IoDVaFtSy0wN8aoUQB7A8ENYjQG4Uj0bMX+pL8so\nDHhxC8EodS8vE8rlHiDol5daHP2PLlifsExJnBYB7fL14V577eWXG4JYSUA8MV9ihYJ06RitUgPi\no7AKn5NgeYmNkb2cD6e334aAIJDU5070K7Qv5R/M8PggZet/qqU82ZMm13skXJ7+xx/yxT/+4lYk\nhIVNp4mLrEo7cu0hXlIvOtMe/c7UxEzSURbnRf9c+yjjRi49mul8aoiXvtEl4DtXZ3Nep6dDo/57\n4MbWDxXp9I3F7/B1zkWJrq8c/aLKjDqn9bMbPwqhwud4udD3UfdE4dwtU+iYLebDIkAea5VYrr7+\n9a/7DJAzzvGlGfFOYbKlp3kgTgsiRx7K10SzZe3F/4L8so0Oll6R4+JzW0pDoHIE4nzuitVGvy/D\nRChcBlae8Pue39r6I+95cb1RBuVqoiLlas8DepCH8vTzLKQNjwwbYSxaZ7kuZVZrr61v6C31orNu\nqz4mTSFMC+kreBZK12jXU0O8wh1eSkdwI8mDIQ8A+eVFoMviur7xww8iabFcyMPDAI5Uop8voMg/\n4XoqvfGLrLbsZFh6xMJSdiEJzaitXbgXmbIBaxdWK4iVkC9mvGduLPqqU6dO2SkewhOXQrTY5N5i\nH5dIPBfEi/4oJUA5Lh2sHEOg1gjogT3qXR7WBxefpGPPby1i/cH9pseJ8GSo4d/irkMfnY9//qQ+\n6mGc0u90nVbrke9Y58+XTl+TdnFOE0bRW9Iy/gim1IP3QEia5NXjoy6L67qt/NbjGb+bRVJDvPSN\nwc0qhIeOkgdEBiwd78XNoS0b/FcR/gJSSJl0ur7ZqEf/x0NZ+sYWvWRPGaXoJ3UWu6/0xi+2nnzp\ndPvzpeMa7qxGHOSFFLHHOoWVSlyNEC823I0yQzzxXvfff79r166dTwtRqybR0v0SjufKFfel81Tr\nmHuBuL8rr7wqmIz2Ij9lBNNGhLcRZ410V141ya/NF45Pq5ZujVZuIz53/NPAPzTFih7Yw4N+VBmQ\nCMYPnmv2mlQwLkh5ECLGEhHK1vOWacJBWj3maOsSY4/UR52a6JFPjytSV6E94w9laR0K5aGeKJIX\nVb9uN/jo1U8gnDI+QNB0W9FB4wmWUXUW0rURrqfmq0Y6EBIkDw83F1uU6BuDNHIj0MmUIze0EC5u\nFv2lIvn1TasfBl2ffhDL1U+XV+wx+qEzIjd+VN6oGz8qXannBHv89+EHK6qsOAYAjXVUHeWcq+Sh\nZwDYNXDd4QrEtc2LDiIVFs6zPffcc8GSNse71157ze0a5KuVoCdWx3A8F7+FkFVbH+p58MGH3Ow5\nc91dd8513z32uGCw2cN9dbvt3Kl9+0ZC8cILLwTLJn3oZt12u+vdu7c7/PBu7ohgcDj0kK7B8eGR\neezkfxAAI6yblUrSnjveJeF7OV8b0V/GCd6VjAW5nntIBtc1OZCyIQnheCXew4xHeqyQ9LKnLkJP\ndJ3kY+yJqkfysWeOLJ1PXwsfo1+h8sJ5wr9lDJPzlMkWFtKBk+Aavs5vxh7aHRYZizkfRerC6Rv2\ndzBopEYCcpQJbgQmN8m5Bf9ZZNsTfDnSIl2x1yggeMha5A3XiR7BjMPZujgoVT/yBDdoth6tX6Fr\npA3rpH9TLvpo0XUFD4W+5I91mcHD1eJ6FO5gVEgWLVqUOeywwwolS931YA28zPnnn+/1DqaTyOTa\nSBBMlOo3jsGjVkJdwYsub3XoFkx7kTdNuReDhb8zPzjpFH+f/nT4zzO33nZ75o3Va8oq7p5778+M\nOu/8TEDA/HbDDTcUbFtZFTVIJvo0mGuuQVrzn2ZMnDgx069fv/+cKOJIv7sCMtMih37nBUTAv9N5\n9+l3afi93KKA4AdlhvMEhClDvvAYofNyXesmdXKesSss+v0d1on0Aclsobe8n8NjWbhc+U07RAf2\n4TokneypMyCRLfKgY758ur1RY5CU3eh7/ltPndCxugO5Sbjxwx2p03BDhEU/LDwoYaLCjaXTUE+h\nG4s6itWPtPkepnzXyFvqja/LC2NFeegtDx7t1pLvwdbpwscM7IFrIHw69b8hkxCLYiRMtsK/iymj\nlDSQrVLqKDV9IV2oWwjSFVddXTbZylUPBA5C126vdpkrrrgyV7KmP8+zXIh4pw0kSBfkqxTRxCP8\nXtPvPIiXSfUQYAyR8YWxqJkllcSrmTssjW3nP+9qWVXqhUexg1oUAdIWsLj1r8SCha6VDNTUHSwD\n9DkhCghXtQUrGAQMkheFc7XrT3r5pfxzkPS2iH68S0rta6xO/GPNM8teW6GMeAmy1d9r65hY46pf\nazJrSE1wffDQmKQUAeJNCKhuBCFuRmKiiJ3KJ8Q2SVqdjnPEqsQR+6bLJZ4LKSUGRuennyTuS58v\n5nj+/AXuqCOPCqbT2MwtDPp62JDTi8lWUZqjj+zpWCi79wnfc4MHDXYXXTymovIaLTP9OXfu3IZp\nFvcmzwztKkUCspUNhA/+scgbk1VKuZa2eAQ07oG1q6jY4OJLT1/KDdOnsmmcNgR4UQYxOWlTO1Lf\nyy+/3E8NwUWC5mkbZExIj86Ui3iRBnIUlUfnL+WYsiB0bJWIkLZSdLv44rFu6JAh7pcB8Zl42QTX\npvUOlahQcl5I3u1B4P7vf/+4Y/HtuAltyQolIAMY8I/B9OnTGwYPSCRz4JUjBLQHoSc+a75g+HLK\ntjyFEQBzyBcSWBkLZ2j0FMk0xJlWjYQA7ivivHBFpVlwlwbvg5xbMHFq5thjj81cdtllmeuvvz4b\ncJ+rzeAShwsW1wtlxSmUV4xLJ5j2IRN8pZh5dMmyOKsvuyyC+HE9xoFr2UrUKSNtps/YpP245oqN\nRayT2kVXW2lbdIwRLkbEXI1Fw192Qu3qxd1okslsAAiNTi6tffVHoH///l6JNFu+sCLwHzeL9AaD\nQNbylQvdHXfc0VvEmEaiW7du2YWqsZSJYBVDyrFUoQ+WKaxu1RJcxFjBotyqZ519jluxYoWbPPna\nmlu58rV3+Jkj3Ly773Izb51Ztts1X/lJuRZ2C0f1ExZaLEVpd/WjP8+eWTOTcveZHpUgYMSrEvQs\nb9EIMEgwMLCPGsSLLqjOCSFIuBYhkoEFz82ePdstXLjQbx9//HFe7Tp06OAJmBAxEkPCGFRKJU/g\nyCAkrsG8FVd4EXJHn2lymFTSJU0V8rXssWWpvt+kPbLXBIr+0H0iafSee4Q04orW19J0zPPBxrNn\nYgikHQEjXmnvwRTpD1lhEEjryxNrHbpDejAUs/3zn//02z/+8Q/3+OOPu5/85Cf+NxOAFpJDDjnE\nTw6KNYyFsxlYtDUsV/4oIpQrbVznNdFjRvk5AeG8+ZZbEmXpCrcV8rVq1YtuxvRpqSVf9LW28nCP\nlCrcsxA2TdpKLaOe6dEbaxf3YJr/aasnhlZ3shAw4pWs/mhobXhx7rbbbt5SBAFLk4h1CdcNgwCk\nK5g01X322WcO0vXJJ5+4lStXOqxeuBi5FsTWuMWLF7uHH37Y/f3vfy/Y3J122skTu+7du3uCSoYw\nEWMQinIpFSw8hgRgQPtvvvkWN33Gja7rwV1iKLW6RRBsf+CBB7jzzh1V3YpiKh2MIVsicfQ1ZfK8\n4XIsh7iJLvXaozMbBNLEEGgEBIx4NUIvpqgNP/3pT/3Akrb/vsN6i7VLSNdHH33k5s2b51iTERIG\nIYN8QZxYSujDDz90v/vd79yjjz7qHnvssYI91qZNm/XckgzIWMfqJQzgB3U5yI0YOcr9aED0Uj/1\n0i1Xvc8+t8Kd0Ps4N278OE+Yc6Wr53n9LGDRqYb7GMLMJtbSera3lLpFb/5pMzEEGgUBI16N0pMp\naQeDNwMLRIYtDSKuDgYtLAeIEK9PP/3UQbruuecev1js+++/739DvnBDIhAvFtJmYWzZL1++3JOw\nRx55xAeo+4QF/gwJpmxg3UIhX2FrWIHsFV8mrov+mzrl2orLqmUB102b4W6acUNggZydCFcVJEIT\niVpZoaiHZw8ykwbheUPntFrq0oCx6VgfBIx41Qf3pq6VF+q+++7rgk/eq/LffZzgipuGwYoYNRFN\nvJ5//nlv0dpmm23cunXrvFsRMoY1TKxeLKYN6YoiYZzHEgYJg8BhHSskxxxzjCdgkDCwRKpJxOiz\n7//39/18WR07tC+kXuKun3Tyqe6gg7q4YUOH1EU3bdWCvAuBr6UykD0hXvperqUOxdbFcwfpwq0/\n2lyMxcJm6VKCgBGvlHRUo6lJoDoWLwakarhW4sBLXv7oh75aNPG67777gjiiAx3Wrg8++MBvEC+s\nYZAv0rJBjNggYRAwTcI4FosYgfmQsGnTpvkydL1Rx5tuuqmTLyXzxYdF5S32HMRl7077uFEjRxSb\nJVHp5t033w0fNtTV6itHiCr3jwgkIgmC9QjSlXQrkkwdoQlrEvAzHQyBOBAw4hUHilZGWQgwADBA\n8XJN2tdKQrrQK+rlD5HCmrVgwQLXtWtX716EbEG82LPhbhTyRVrZNFiQsDARo4ybb77Z/fznP/dk\n7PXXX89axIqND8MlCQnDIibYlmsRE2sXSwHVelZ6jVWlx9W0enG/gJMIZF1wl3NJ2WO9HT58eGIt\nzkl+LySlD02PdCNgxCvd/Zd67eUli0UpKZYvIV2Am4sUQryYx4s4Lr5ihGBBtPiqkY1jTbwItpdN\npqCAiFGOlldffdVbzlje5LnnnvNuRIkLk32p8WEdO3bMxoaVEx9GbNcXN/6Su/jC0VrV1B2L1WvF\nyhWx6K4JOSQrKfdvvsbhbhSSmESLs7wPcj13+dpm1wyBtCBgxCstPdXAevKyxfXBy7begxe6sL5d\nr169vHsxn9UiWJrFffvb3/bkS6aVEAuX3ss12UO8cEHyW0gY+yeffNJbSZgVH+sUU1C88847bo89\n9ljPNSkkTMeH3X333UVNWyHxYVjEBO9c1jAGab5kZC3ENMZ2hR+bbt26uzPOGFbWF46QFjaRpLgP\nRZ9Ce9Fd4sv4ZwfyFY5fLFRONa4X889ONeq1Mg2BeiBgxKseqFud6yHAIDBgwAA3ceLEun3tSFzJ\nHXfc4XUjvgoSlksgiYcddpi/LJYrIVEQKr1BsjTZEtKl98E6co55vDbffHOfVtySDJbbbrutPx8V\nHwbx0iSMwHziwwjWv//++3Opnz1fKD4MQnz9tOnuzjvmZPOk+eDKSde4VwJMf3XpJQWbIZYhSQhh\nEdIi59KyD5Mu0VtivrjX6/W1I88S9UNk0SHfPzuit+0NgTQjYMQrzb3XYLoTIwP5YXCDiNVqkGOA\n5cUvpEtg7devn9eD39olKIMYk8Hq8xwLCWMvREz2YTLGb8gXcWK4AyFdQsZ02qefftqx3BBlaomK\nD9MkjGD9SuPDxowZ51pts21qg+o1XhzLvF653I3cg9wPSFrch17ZPH/kfs31PHGd5w6B+NTKkgfO\nfLHIs84+LdPL5IHaLhkCRSFgxKsomCxRrRDgZczL/4ILLnAQH17IuQaMSnWSumSw4cUPAXvllVey\nRe+zzz4OlyKDsJAs/kMnVkq75+RY0lCAJmEcazIGscKNiKWLpYOEhEXtOYcbEnImJE7Kpj6pmy8j\nJVAfAqa/lJQvJkuJD9tkk01clwMPcmPGjUvFLPXZTitwgLtx4sTLvJuVeyAtQfEFmhV5uRDp0pl4\n1ngWIGHVfO6oE7LF84arm+NqPeO6fXZsCCQFASNeSekJ06MFAgwYvPyJt4KAyUu6RaIyf1A2L3sG\nGV781CP/5TMQc/ynP/0pWzqzyLMYNiRMky5Ijrj/2AsBymYMDoSIsZcN8vTSSy+5tWvXuk6dOmXd\nkpzXFi85Zv/aa6/5dLgd+U1aCBl7IXS6XtEL8iWbkC9tFZP5w6Liw2gv1jZpgy4/zccDB53m/rzy\ned/vjWLViuqPUkiX5Of+51mT545/RHge4hD5R4dnDxGS53/YH0OgiRAw4tVEnZ3GpgoBIxaF/4r5\nb5yBoNTBAKsGpImXPqQKMpdvUOH6jBkzspBBZIYOHer69u3r15sUMiOWJX7nIl/ZQoIDSAy6bLXV\nVu5rX/ua/y3ESfZCqMLWL6xV2223nSMuS5MyIWGSj3LYtAhJ1HpDxPgthCwcH/aNb3zD7blnO3fb\nbbfqolJ/PGbcBPfZp5+4//3f81LfllwNKId06bLknxMhSTx38uzpdIWOKYfnjucXVz4frUDsSn1+\nC9Vj1w2BNCFgxCtNvdXkuvLyZuNFjjuQ4HbIGBuC9YJNBh1xI4kriZe9DCCkyycQl+uuu84NHDiw\nRTLyX3HFFVnCsvHGGzs2IWBCcFpkUj/QHSsb9WtLEsfUKXvIlN6EhGGhYqoJ+R2155xsQsKiiJi4\nJSFf6K8tYZCxSZMmua232c5NvGyCakH6D5lW4saAVN9y843pb0xEC+T+l+ciIklJp+SZ497lnxYI\nOWXLF7EUxrE8Z7meO56/uHQqqQGW2BBIGAJGvBLWIaZOcQjolzvHCAMOx3pAkJd9KS98yA8bVqXf\n//73fsoIrVXbtm3djTfe6K1PX/rSl7wFir1YjiA0iHY9ir7ok0uoU0STMCFPELF3333Xzx/Wvn17\nT8y05SsXCRPXpBA5KZv6RMcwCYOMzZhxk+uwd6eGCawXbBuZePEMIKXc7z5DkX/kPoZk5XvueAbR\nQT+LRVZhyQyBhkfAiFfDd7E1sFQEICSQE5kUlfUTTz755PWK+fWvf+0OPvhgt9lmm7kvf/nLjmB0\nrF/iziMDxIbBMEwI1yss4oQQMfayQZ4Y9HbeeWf/FaRYtjgvJCyKgMk1IWGk0USM6qlD3KUQsZkz\nZ7lv7rd/wxGv1WvedDu2ae3bGwF7ak9Vm3SlFhhT3BBIGAKf/2ueMKVMHUOg3ggI6YGAQVBw8bVr\n166FWj/+8Y8dMTB/+9vf/GzzTHjKrPVCbiiDhcCRcv7z1yRIyBzE7oADDnAszE2sF6SPaSi22GIL\nt+WWW/rYMdyYrVq18u7MqD3xZWzkIS+kUSx2EC70ps20vRElzcse5eoPcfNVy9KVq147bwgYAqUj\nsFHpWSyHIdD4CAjpWbx4sZ86ggWwIVkXXnihwwImMmHCBLdq1Sp33nnneaKi3XgSjwX5iUPQCWHP\nrPPE3OC6lDplL5Ys2Yu1qxhLmKQlr9QXh+5WRvUQgHRBuArFLVZPAyvZEDAESkHAiFcpaFnapkEA\n0kEAP/FcEnjO/mc/+5lr3bq1D7wXMJhqgnm2cD3iAiQOa+XKle6oo47ycV8Qoqi4L8lfzh79mMAV\nHXcNBl2sVFjFECFg7NmEgLEX16TeC9kK7zf64hfLUS3xeZhEtd1eLa2XiVc6h4JGunIAY6cNgQQj\nYMQrwZ1jqtUHAbH0sGA1k5t+9NFH3hUn0zj06dPHEyzm/xKBAPXs2dONHz/eL/1z6KGH+nwQHx33\nBUGS8iVvuXsIFwMv8WPa2gEBEyLGXjaIVxQR43yYdPF7y8AV2YjyajAn2n6dD0h904x0pb4LrQFN\nioARrybt+DQ3W76swtUmx1HtgZiwEV8lX1lFpYs6R9m487AMQZyEtEBcIDIE1eN67B9MMKnl7LPP\ndmPGjPETo0oe0lMGErfli3ahKy5HLULu2FM/IoRM2hAmYeirSdjGG2/k/vLyS7rYhjjGbZx2MdKV\n9h40/ZsZASNezdz7KWo7X2wxnxBkR+YSEjKlLU+6SQxO5GOG7Iceesjtsssufh4vyBJ5cwl5IGyQ\nJMiKkCZIDJuc5xqTQp5zzjnuueeeyxY3atQoH/c1ZMiQrJsPkkM5MmkpiYUcZTOWeUBbaGuuNul6\npA1SlSZhEDQhX+yZJ21asEB2o8mLL65y7UMfSqSpjUa60tRbpqshsD4CNp3E+pjYmQQhANFiY7CR\nyU+x7mjXWrHqykSQlEd+CBtlhssSC5JYioSM4H775JNPHF8vMsv7Bx984L9mZLmdZcuW+S8ftS6Q\nt9/+9rf+60G+PsRVKV8PQtritH5BFhHqLFWkneTTRIwljYhn09dLLTuJ6VkyqOvBXVz/kLUyibqG\ndTLSFUbEfhsC6UPAiFf6+qwpNIYksbQIkosgVQKEJnRYxGQQFtIlZQvpELccrkfIF3Ffb7zxhnvk\nkUf8TPIQsaVLl/qvHiWv7O+77z4fEybzfUG+sH5BvtgQbZWSfKXuw7qXml/SS5vZH3FED3fWyHPc\n0Uf2lMup37dv197NvHVmTgthUhtopCupPWN6GQKlIWDEqzS8LHWVEcByAwlikNGEqFrVQlaoD6uX\nrCEXZTWChLBh/YJ88dXim2++GaxluKe3fGH9YluzZo0bMGDAeupec8017lvf+lZ23iyZbJUvJbF8\nhV2A6xVQ5Im4yJdUN+KskW7jL23iLr5wtJxK9X7J0sfcD/v3cytWrkhVO4x0paq7TFlDIC8CNoFq\nXnjsYi0RwApFnBKbELBq14/bkrpwOUKY0CFKhBhhoXr22Wf9LPVdu3b1bkSZkJQJTHfccUcfi8ak\npFpOP/10v8ZjvslWxdKk85V6DGmkPXEI5fzj04/dQ4seiKO4RJRx9z3z3LHH9U6ELsUqAZmmX8Mu\n8WLzWzpDwBBIFgJm8UpWfzStNlidcC+yQYbqIVgVxPqFHlED3aJFizwxZNZ3rF+yrJDEffHFHJYv\nfl977bUtJlulTfvuu6+f74v8Ou4Ly5fEfVXqdizXOkI+vhIVYbBnwzV3/Q3TfVyUXEvrvlu37u6M\nM4Z5op2GNsRtwUxDm01HQ6DRETDi1eg9nPD2MdBjbWIP2WGgr6egB+QLaw+DnpAvzkNMIIVimZK4\nLwm6J+6LWC8hXxL3ddFFF63XpPnz5/v5vnTcl3zxGEfcVzEDdphoYWmU9mqFL754rHvn3bVu4mUT\n9OnUHc/67Wx37dWT3KJFC1OhezF9mIqGmJKGgCHQAgEjXi3gsB+1RAAyI9YtTXJqqUOuuiBfEBP0\nQk+28HQNOu4L8oX1S8iXfPEI+SLu64c//OF6VU2ePNkx0aqslyhxXxCvSskX+kIetc60RUsuoqXT\ncEw5zJK//NnnXccO7cOXU/P7pJNPdQd1OdANGzY08TrTV/JsJF5ZU9AQMARKQsCIV0lwWeI4EcDS\nxaDOIBNlaYmzrnLKgnxNnz7dL3StCYwuS8gX1i+C7iFfLJQN4RLyJUH3p512midmOv+IESPcKaec\n4skX1i8hX1i/Kg26l3g1sSJWMpATZP/ZZ/9MrdVr3n3z3fCAcC17bFki7zV9Txjp0mjYsSHQeAgY\n8Wq8Pk1Fi/iCkAGGLYmkCxBxffJlJYKeuURcjzLfl5CvqLivcePGuSVLlrQoihnyL730Uk++sH4x\n35dMtgr5EgLWIlPoBxYuLHRaIFroXQnhkvLSbvU6tldv1+OI7om3dsXVX9JvtjcEDIHkIWDEK3l9\n0vAaQWjElSfWmKQ2GkIDccE6x3xiuUTIl477wvIlrkcd93Xvvfe6SZMmtSiKWfVZZHunnXbyBAzy\nhfVLFuiGfCESeB8mWpDXXFa5uAbzK6+aFEwU+5i75eYbW+ie9B9XTrrGzbn9t4mP7Yqrn5LeH6af\nIdDsCBjxavY7oMbthzBAtnCDQWbSIBJUD2GEhOUTCBjki03HfeFu1Nvzzz/vfvazn61X1MyZM/06\njxJ0L65HiNszzzzj00O+8hGtcKFgjsUqFzELp8/1m3J69z7e9T7he27YkNNzJUvUeZm3a/KUyQX7\nrp6KG+mqJ/pWtyFQWwSMeNUW76avTcgWJCZNgsuRDQJTSHTcl5AvHfclBIygeyx/Ybn44os9+Xrn\nnXcc84Fh/dpuu+1c586ds25HsXyF8+b6DXmE8Fbq1qUcpsR4dMmyxE8vsXrNm27w4NNcjx5HuGFD\nh+SCpu7njXTVvQtMAUOgpggY8aop3M1dGQOMBNRXSgDqgSQWI4iSLGWUTwdxPUbFfQnxYk8QfniR\nbcrdb7/93HXXXZcNutdxX3zxCPEqlXzFNcDPnj3HjQoWBk/63F6syQjGSXaNxtUn+e5Fu2YIGALJ\nQsCIV7L6o6G1wU3Hli9WKskAlEocw+RLz/fFGo+vv/561v0Ytcg2cV+33357lnxh/apkke24XI70\n0Vlnn+NWrFjhJk++1rVpvUPium34mSPcqlUvuhnTp1Vs5atG4+gLcWFXo3wr0xAwBJKLgBGv5PZN\nQ2lWKmlJauMhjljtirF6SRsgYH/4wx/cu+++66ecYJHtdu3aOaaMwCJD/JZMtnrhhRdKtuw+zkW2\nxVWK27FSEfI1duzYRM3vlQbSFUfMXaX9Z/kNAUOgPghsWJ9qrdZiEWjbtm3WrTR+/PgW2cTdxH7B\nggUtruX7MXXq1GyZpbqr8pWb7xrxUZCVNLoYdbtog0wxoc+HjyGasj300ENu9913D2KNeriePXu6\no446yrVp0ya7ziOYsM7jIYcc4qZNmxYuyh155JG+rHXr1nmixpeSkDfmDcOVKTFl62WMOAHhEvIV\ncbmkU5eMH+vat2/vTuh9nCOIvd5CTBeTpCbd0mWkq953itVvCNQXgaYnXpAZITCQHJP4EcCtcscd\nd/j4qPhLr22J8nEApEqLkCzZi1tV9q1atfL3GfFZWLr4WpEvF5m3C9IlC20znQQfHkDMtLDINoRP\nFtnGQkbAPnOGlUq+0Cmsv66rlGPI15jA4nVI14Mc0zbUSyB+J590ktsqwDLJ7kUjXfW6Q6xeQyA5\nCGyUHFVMk0ZFACLRq1cvF4d7KwkYQVzCli/OFRKxLurlgDjHb70xZ9eUKVOC+KnJ7u67784WS7A9\nLkvm+5IpKySOjD1lhOf7ymYOHfChADFGlU4xQbHHH987mCNrkbvggl+6ZUuXunPPPbdmrkesXDdM\nv9Gde85ZfoqSfv36hVqajJ9xxtclo0WmhSFgCJSLgBGvcpGrUb5Vq1bVqKbqVVPM/FfVqz3ekqUt\nWIyKIVvh2iFaQpLE0ip7SJOQJ/ZYufi6Ucd9PfXUU27//fd3999/v9t5552zBEwH3ZOXOig3l4jL\nF0Igx7nSFnMeLCBxV199rdu749fdxWMvcf37nVrVwPvrps1wN824wbVus2PeZZ2K0b+aaYx0VRNd\nK9sQSB8CG6ZP5Xg0JiaKgWnkyJHZAl966SV/LsrliEtSx1uRl3PkCYt2XxLTg1CPDLCSXn6zRx82\n5mqSskmn66TcfHLbbbdl81MGZXGuHCmlvYXKh6SIi65Q2qRfpx39gyklZDAtR1/pd4gWM9OzPJC4\nHrfYYgtPhHA94oLs2rWru/7669er5jvf+Y4DV4n7YnkicTviekTEGrZe5n+fEKtXruulnofAnXvu\nOZ4ELX/madc9IGPn/mK0e/a5FaUWlTM9Fi4IV7du3T3pGjp0qJ8uIg7LXc5KK7gg90lS9augaZbV\nEDAEykSgaYlXsXhBrCAwEKcwyeIc15588sm8xZGmEGmCdEHSCpWVqyIIVp8+fVrkpyzOFapblxlH\ne3V5uLOQXWP4ik6Xi558JDBo0CCP29Zbb50ltkJsOAempCFtuP90eaUex0FaRE8sVGHyJTFf7CXu\ni+kktLDoNot4E/clc4IR98W0FcXGfWGpgsDFKWDD3Fkzb53pPv3kY28BY61EYsDKCcIXssXXipC5\nBxbMd/369fVLAOHmTKoY6Upqz5hehkB9ETBXYwH8w2QmnPy9997zgzsuQQKowwKhKkZKIUdR5UEs\ncgkEEfcUX9UVkkrbGy4/7mBiyBPtKcaSR9+E8T/xxBMdC1XzlWElAmGBVFZqyYN8IZAvRMiYuB05\nzzEbywmFF9meMGGCJ9sssg3Z0rFfBPFLXqnHVxL6Aymmn+ImxxAwtnNHjfQfDEC6rrnqSl/7fp0P\ncHt32scf77FHW/+Fp6j1wgsvBETyQ/eXl19yL/x5ZUAMF7kfnHSKO/I7PdwZw34Su55Sb5x7I11x\nomllGQKNhcCGjdWc4lsDCcEVw0AmwmDMOYmrgsxoCxRpuc5G8LMIA3w+4kO58+fPz+aVfOH9wIED\ns2nOPvvs8OWCv3PpR8Z8+knBcbVXymMf5ySR4kothnRpHfRxHGVQHiRFrHm6/HKOhRRBsnA9Eq/F\nTPV89Yi7ERceli/ckKNGjXJDhrRc/mbhwoWB662be+WVV7zrkS8emXIC1yNTTkDG5L6N0o+2QLyq\nJejfP3DPTp1yrVuxcoW3hPU58QS3+Wabus8+/cTNnTPH3ThjRnZ77dVX3WZf3sQvSXT++f/rdceC\nRuA8uiZdwJIN0mliCBgChsB6CAQv5KaWgKxkAlD8FhCkFlgE1pHstYAUtbjGj1x59XnKDkjXenk5\nIfWyD4hgZBp0knSUq0XOsy+kH2nWrl3rswekMVsm50XKba/kj9qff/75GbZKJSDDmcCi2EJv3f5S\njymLMsuV4Cu+zGGHHVZu9pz5ApKUCSxXmYA0ZQIClQlIfWb16tWZwAqUCb5ozCxevDgzb968zGWX\nXRaJRfAlZGb58uWZYODPvP3225kgBiwTuB8zgfsxQ9lsuYQ2mVSGwMsvv5xhMzEEDAFDIBcCTWvx\nCgbqgqKtXVFuOtxWIrjAsHxFSVTecLpi0oTz6N9aFzkfLrNQjFNc7ZX62WMVisNKgTUujC+WRCyD\nASH1FkWsiuGNa6TB1aqlkJVSp63lsbgaJe4L6xexXVi7JO4LK1jHjh399AnhuK/Bgwf7OdNkvi+C\n7on7KmayVSw0cVnxaolZUurCyoXEcb/7guyPIWAINCQCFuOVp1s1USH2qZAwmIfjvCAHxUg4XzF5\ndJqoesJlhomLzs9xHO0Nl0msSxwDUThWC1cvrtlCosmnfMAgecJlyvl677XrEV0kTos9hExvxH0R\n8/bcc89l1WYeLUj0L37xixYxXwTwE/dFfkTqkYwyrQR9Jsdyzfb5ETDSlR8fu2oIGAL/QcAsXv/B\nwo4SjIC2xkG4iiFd4eZAwnQ+XWY4bb1/CymCJMmUE8R9MdO9WL4k7uuSSy5xp5xySguVZ8+e7QP/\nJe6Lrx5lpvt8cV9m9WoBY1E/jHQVBZMlMgQMgX8jYMQrz62grUg6OD7w22aDlfWxTp+n2KpciiIR\nYQtXIf309bjai+VEBqa4Gq71LLXMSvKWWlel6cXtiKVLky8JuhcChuvxpGC5HCxcWiBdkE1NvsLr\nPJKee1jL4YfHP8WELr+RjuXejsOq20i4WFsMAUMgNwLmasyNjY8LEvcbxEa7rfJkq8sl3GbhOC/t\nSsPtWIh0EAcVd3uxoMjgFBcwtKucrz6pX2MSlz7VLgcCBvkK77XrkeNDDz3UL7I9YMCAFiqxyPY1\n11zjvvWtb2WnnIBs4XpEyIuIlY1jiAT9xj5uIY6Mbd37H7jXXnvdvfHGGy2qIJ6tfft2Lpjj338Z\nCBFMosh9XQ2Mkthe08kQMATiQcAsXgrHsIVIEy3iaPRcWxAU4r7EKhE1270quuqHBJ9r/fiNziJh\nUibn9b5a7SVmqFLRukGeaFu4v/LVQVrw0cRLl5kvb9Q1iEMt46DkPsP1SJwWQfeyyDaWL3TB8iWT\nreZaZJuZ7t9//31XaJFtyAT9FkffUcYNN9zgBg46zbVv194NH36mu3/+A+6DDz9yrbbexp3at2+L\n7cAuB7mPPv7UvfLqG+6yiVf4Z8xPwHrVJE8Go/qj1ueMdNUacavPEGgcBMzipfqSwZkBDssQc3kR\nD8RgLVYgBntNZlTWsi0wuoxKjyvVrxrtxeJ1+eWXV9o0b23UpIl+YcNKhzUvF4kiD/0a5YrNlacY\nZSETtK2Wwr2JpUoHx3OO39r6xe9ci2w/8MAD7vbbb89avpjjC5FytfWL9j0YzGpfrsWJvHffc6+7\ndMJ4PwHqQQcf7M4444ySF9Bm5vpHHl3ili5Z6o468ii3V/uvu+N793L9g7nB6iFGuuqButVpCDQQ\nAsELt6ll1qxZ682HFBCvLCbM9RQM7uulCW6B7Lnw/Fr8luu6rGyh/z6QNOyZWytKyC/pwvXIefaB\n6y2bTp/nOJwv1zxe1F9Oe6P0lnPMaRRYZORn2XvmICvUD+F25/tNWTKvWTlKMYfXnDlzyslacR6Z\njysIks988sknfr6vd999N/P6669nVq5cmQlIZiYgPZm77747E8R9Rd4XwSLbmeeffz7z6quvZt55\n551MYAWLnO8rIK2ZYGHuknRmPrBgpvlMu73aZYLFsjPLn32+pPz5Er+xek3m19dPzxx+eDe/3X77\n7HzJY79m83TFDqkVaAg0HQJN72rEBRcQk/WmgQgGbS9Yv5544gmfBuuKFixEBKGXG2+ky6r0GF2w\ncqCvCPoGxLIk/eJuLy4rpNL5obBq0b5wH/jCS/xDGZQVnm6jlGIeeuihmlu8RD9xO2KdIuge16Ne\nZFu7HotZZBvXoyyyHZ7vCxdmsR9IYAW86OIxbvCgwX45oIWBxWvUyBElW7iknVH7Nq13cD8a8Pk6\njaf07e+uuuoqhxuy0vsrqq7wOalD7unwdfttCBgChkAxCGwA1SwmoaUxBMpFgPUMcVf99Kc/LbeI\nFvlwMRLDJi7gFhfz/IBUQlArJcpz5871bRGXU54qq36Jx5cNlyGkiWWCmDaCGC42SBVTSUCs+PKR\nvZYf//jHbujQoX6aCiZjhcARPwahw2UpJK+Qy5HrF1zwS9e6zY6OecQ6dmivq6nq8ZhxE9y555zl\nrrjiSjds2NCq1AXpgnDVMq6vKg2xQg0BQ6DuCBjxqnsXNL4CBFYT5yUWg7haDPHSMVzEcmnBooV1\nS2LAtDVQpyv1WAhkHLFrpdYdlV7+d2KRbDbIV+CC9CQL0sUmVq1gSSF3zz33tCime/fujkW2mSOM\ngH3mC9PkC8saBCwX+Zo+fbobO2asO33oMDdsyOktyq7VDxbgxnLdunVrN37cmFgJkpGuWvWi1WMI\nNAcCRryao5/r2kpcUJCfID7GWw3qqkwMlWP1gITUOrg+n+pCvrB8Qb6CtRmz5AvLl5AvjpctW+Yu\nuuiiFsXhnvztb3/rv4qEgAn5wo2J9QvyhYUPArarmmLirLPPcXfOneOuv2G6X9S6RaE1/kEQ/ujR\nF7g333zTzZg+LRbyZaSrxp1o1RkCTYBA08d4NUEf172JEJV+/frF8nVjvRuD9Y72JIl0gYm4BCXu\nizm6cBtCophmQsd9HXLIIS5YZLsFlKzt2LNnT0fsGscQNSZbxXomcV8QLqyKEGkE0rVixQpHLFfX\ng7u0KK8eP4j/mjrlWte27R6ub78BWT3L1cVIV7nIWT5DwBDIh4BZvPKhY9diQwALEbFeWE3SHCcD\nwTn//PMDy8ro2LCJu6Bw3BduR4n7Etcj+zVr1rjTTjvNEyytw4gRI/wSROJ6hMDJOo8QO8jZvHvv\n96Rr8uRrHYQnaTL8zBHBlDAvlm35MtKVtB41fQyBxkHAiFfj9GXiW0KAPVuSSUs+ELF2oTskEgKp\nhXYlScT1qOO+IF8E12vyxW9io5YsWdJC/eOPP96dd9553mImrkchXzfddFMQRzXe3T5nbk2D6Fso\nWMQPJmylrbfcfGMRqf+TxEjXf7CwI0PAEIgfASNe8WNqJeZAQKxeMrDlSJbY07jaIF5RE3fSNi1J\ncEcK+ZIvHnEZQr5wIWryRdzXzJkzHYRKyy677OJ+/etfu5133jkbdI9rkaWJHl2yLBHuRa1v+JiY\nr8GDT3NdDjww+NLynPDlyN9yb6bZKhvZMDtpCBgCiUHAiFdiuqI5FIG0ECPElAxpEggXOjMwFyO0\nMZyWuLB6DOgQMMgXmwTdQ74k6F5I2NKlS92FF164XvMgZZ06dfKxXqef/hPX5/s/qNvXi+spV+AE\nXzv+sH8/N3nKZG9tzZfcSFc+dOyaIWAIxIWAEa+4kLRyikIAQoLliKkYoixHRRVS40QMyPvuu68L\nZnCvKKieciQwXZpQKxeljvuCfBE0D/kKux5Xr17twotsoyuLbC9b9nv3j8BqVqrrTtpar/2Vk65x\nc27/rVu0aGFOFbBY1osY51TKLhgChkBDImDEqyG7NdmNEpejDHZJ1haixIDM3F0yf1ec+oZdlJBS\ntmqIuB513BfkS1yPerJVgu4hYWEJlv9JdFxXWF/5zez2PY7oHjnBKn1QKwIs+tjeEDAEmhcBI17N\n2/d1bTmuO4LVsQLVw/1WbOMhXWzoWgshaD8cuB+nJSZMvsT1iOUL16OQL46ZbDVY79E3+8ADurge\nwQLVF184uhYwxF7HvPvmu+HBrPbLHlvW4n4z0hU71FagIWAIFEDAiFcBgOxy9RDA1QjxYvBLIvlK\nin5hFyVYQcbKFSFfMtkqQfcy0z0ETJMvHfcVLFCdyKkjisXhpJNPdQd1OTBr9TLSVSxyls4QMATi\nRMCIV5xoWlklI5AUcqMVx72IWzGppBD90E1LOS5KifuSme7DcV8QMCxf//uL813XQ7/lJl42QVeZ\numOsXpeMG+tjvYx0pa77TGFDoGEQMOLVMF2Z3oZAvhgI+WqwEktOHAhAaiTeB52SaImLameUi1La\nEZVezgn5kiknIF96vi/I13/3+W83c9ZtiZ8+QtqUb9+tW3f3jW/s0xCrKORrp10zBAyB5CKwUXJV\nM82aBQHip4j5gijU82tHiBaz67OhR1pIF/dJlMWL9miJclEyEz/yhS98we/10kPMUn/XXXe5vTvt\n0xCkiwZ2PfTb7h+ffuLban8MAUPAEKgHAmbxqgfqVmckAkJ8hIBBJmohWLkk2J99Nb5erEU7CtUR\n5aKUwP1w3JcE3Q8/8+dup52/ltqg+jAmMq/XipUrwpfstyFgCBgCNUHALF41gdkqKQYBCBcuM4gP\nhIA9WzUtT2Jtg+QRN1UrslcMHnGnAUcw1hIO3IeAHXbYYdlFt1e9+IL7/g9+oLOk+lgW86bd9XZr\npxpIU94QMATKRsAsXmVDZxmriQDWL6xPDJCQL+LA4iJFWH4gXLgTEfa4F00+R2DRokUOArZ27Vp3\n4okn+uNGwoY1HDt8vZ2/rxqpXdYWQ8AQSAcCG6ZDTdOy2RDAMgP5IuAeK9huu+2Wjb3id6kiZAuC\n1apVK18uhIuyjHS1RLNbt26ObZtttgmsXSe3vNgAv3bdbXe3bt0HDdASa4IhYAikEQFzNaax15pI\nZwgYGyQJEsaGJQy3GRYwriGy9z+CP+JCY8/2yiuveBeaBM7HZT2T+hptT5A9uG2xxRaN1jS3xx5t\n3dw5cxquXdYgQ8AQSAcCRrzS0U9NryVEC3cjGyKECouVBMf7C//+A7Fig2jhqgwTM53WjqMR+MJG\nX3RYhxpNGpFMNlofWXsMgUZGwIhXI/duA7eNwGgLjq5uBzOxaiPK13be2f3hiccbsWnWJkPAEEgB\nAhumQEdT0RAwBAyB2BDo2KG9W/nnlbGVZwUZAoaAIVAKAka8SkHL0hoChoAhYAgYAoaAIVABAka8\nKgDPshoChkD6EHj2OZs8NX29ZhobAo2DgBGvxulLa4khECsCsoxQrIUmoLBXX3vN/eCkUxKgialg\nCBgCzYiAEa9m7HVrsyFQBAL/+udn7q9vv11ESktiCBgChoAhUCwCRryKRcrSGQJNhgBfjb711psN\n1+qnnvqja9+uXcO1yxpkCBgC6UDAiFc6+sm0NARqjgDE6ze33FTzeqtd4V9efsltueXm1a7GyjcE\nDAFDIBIBI16RsNhJQ8AQ+HxR7W5uydLHGgqMF4KpJGxC3YbqUmuMIZAqBIx4paq7TFlDoLYIHHBg\nF/fgQ4trW+n/397d9ER1hmEcv+YDsNRUUDMJLEhdYayg3dD6/sZAurOFIU2qSNGkTaoZSXShKGqi\nCRo7VYkVW0QDTtqmMbY2gcS2GKDMoo3ESGUjfgLWyjNqAqiYyDkz5z7nPyvmDPOc+/nds7hyXp7j\n495ciHwyOcniuz4aMzQCCMwvQPCa34dPEYi0wNo1lRr8+6/QGAyPjGhHojY082EiCCBgT4DgZa9n\nVIxA3gTcsy4fjN1XWNa+yvT16sO1VXnzY0cIIIDAXAGC11wR3iOAwCyBmto6XbrUOWubxTe3bv+e\nO83owiQvBBBAoFACBK9CybNfBIwINO/ZrVu//qLJJ7aXlrja1aXmlhYj6pSJAAJhFSB4hbWzzAsB\njwTi8bhWrvpA31+56tGI+R/GHe36Z3hIDfWsWJ9/ffaIAAIzBWJPp18zN/A3AgggMFcgm82qoqJC\n//53XyveL5/7ceDf7/y0XlVVldq3lyNegW8WBSIQcgGOeIW8wUwPAS8E3GKqR462qa2tzYvh8jpG\nx7nz09d2PeZoV17V2RkCCLxJgOD1Jhm2I4DALIGWL5tzp+tckLHycndjnj/bocOHD8ktCMsLAQQQ\nKLQAwavQHWD/CBgRcMEl/V06F2SsrGafSqX0WUMDK9Ub+Y1RJgJREOAaryh0mTki4KFAR8dZZTIZ\n/djdreIl73k4srdDffX1Nxoff6iff8p4OzCjIYAAAgsQIHgtAI+vIhBVgf0HUhobG1M6/W0gw5cL\nXdnRkemAeJNTjFH9kTJvBAIqwKnGgDaGshAIssDJE8dVXl6upqY9gVvfy4Uut+7YmTOnCV1B/hFR\nGwIRFSB4RbTxTBuBhQrMDF9BuObLLfD68vRiz/UeHoS90AbzfQQQ8EWA4OULK4MiEA0BF74qV6/W\n541J3ei9WbBJu7sX3dE3d01X15XLhK6CdYIdI4DA2wQIXm8T4nMEEJhXoLU1pfYT7TrUelC7duf/\n1KNb3uKTutpcAHQX0rNsxLzt4kMEECiwAMGrwA1g9wiEQcA9eHrw3qBisZg+rq7WsfZTvk/LPQao\nJlGnTF9vbpkLFwB5IYAAAkEX4K7GoHeI+hAwJtDf368LFztzq8Vv2LRFjcl6T+987LzcpT/uPH/2\nYupgSslk0pgQ5SKAQJQFCF5R7j5zR8BHARfAuq9d18ULaX2xq0mVVWu0ZfPGdwph7ujW3bt/qu9G\nj5YUF6tx+pqyRCLBaUUf+8fQCCDgjwDByx9XRkUAgRcCExMTGhgY0O3f7uha9w/aUVOr0tIyLVq8\nWGVlpSoqKnrFanQ0q6mpKT36fzz3nerqj7Ru/Xpt37aVC+df0WIDAghYEiB4WeoWtSIQAgF3JCyb\nzeqpYhoaGn7tjEpKSrRsaYmWL1+WC1rxePy1/8dGBBBAwJoAwctax6gXAQQQQAABBMwKcFej2dZR\nOAIIIIAAAghYEyB4WesY9SKAAAIIIICAWQGCl9nWUTgCCCCAAAIIWBMgeFnrGPUigAACCCCAgFkB\ngpfZ1lE4AggggAACCFgTIHhZ6xj1IoAAAggggIBZAYKX2dZROAIIIIAAAghYEyB4WesY9SKAAAII\nIICAWQGCl9nWUTgCCCCAAAIIWBMgeFnrGPUigAACCCCAgFkBgpfZ1lE4AggggAACCFgTIHhZ6xj1\nIoAAAggggIBZAYKX2dZROAIIIIAAAghYEyB4WesY9SKAAAIIIICAWQGCl9nWUTgCCCCAAAIIWBMg\neFnrGPUigAACCCCAgFkBgpfZ1lE4AggggAACCFgTIHhZ6xj1IoAAAggggIBZAYKX2dZROAIIIIAA\nAghYEyB4WesY9SKAAAIIIICAWYFnu/zIiInRwogAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='sentiment_network_sparse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_most_similar_words(focus = \"order\"):\n",
    "    most_similar = Counter()\n",
    "\n",
    "    for word in mlp_full.word2index.keys():\n",
    "        most_similar[word] = np.dot(mlp_full.weights_0_1[mlp_full.word2index[word]],mlp_full.weights_0_1[mlp_full.word2index[focus]])\n",
    "        print(mlp_full.word2index[word])\n",
    "    return most_similar.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n",
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4284\n",
      "4285\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4293\n",
      "4294\n",
      "4295\n",
      "4296\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4306\n",
      "4307\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4316\n",
      "4317\n",
      "4318\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4480\n",
      "4481\n",
      "4482\n",
      "4483\n",
      "4484\n",
      "4485\n",
      "4486\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('pharmacy', 0.013380953395084253),\n",
       " ('for', 0.011128128040469868),\n",
       " ('patient', 0.010827071437381392),\n",
       " ('in', 0.010190827415715739),\n",
       " ('order', 0.0094536423232835474),\n",
       " ('entered', 0.0089316239848573013),\n",
       " ('an', 0.0069450899437979059),\n",
       " ('home', 0.0065168047345890191),\n",
       " ('sent', 0.0060580739323997032),\n",
       " ('received', 0.0058985617439693619),\n",
       " ('put', 0.0057905746588803163),\n",
       " ('a', 0.0054770300233020069),\n",
       " ('have', 0.0046783671686652373),\n",
       " ('we', 0.0046333300820567067),\n",
       " ('benadryl', 0.0045824471633143151),\n",
       " ('time', 0.0045523721152053338),\n",
       " ('call', 0.004453212720405577),\n",
       " ('placed', 0.0043109770477115679),\n",
       " ('called', 0.0043038442495954123),\n",
       " ('correct', 0.0041237447519320135),\n",
       " ('back', 0.0041235122638407212),\n",
       " ('them', 0.0040594142718657321),\n",
       " ('25mg', 0.0040568670870190764),\n",
       " ('did', 0.0039642291899716232),\n",
       " ('computer', 0.003917819064943432),\n",
       " ('her', 0.0038455998789596719),\n",
       " ('2', 0.0037619056688039162),\n",
       " ('contacted', 0.0037387227441755613),\n",
       " ('has', 0.0037182206142230738),\n",
       " ('scan', 0.0036741016094932882),\n",
       " ('to', 0.0035895304147804076),\n",
       " ('o2', 0.0035275115387500768),\n",
       " ('from', 0.0035043847917531523),\n",
       " ('doses', 0.0034058081701557434),\n",
       " ('room', 0.0033723406728735847),\n",
       " ('treatment', 0.0032975643220060297),\n",
       " ('these', 0.003213969936980917),\n",
       " ('him', 0.0032092443568000782),\n",
       " ('she', 0.0031925947849247125),\n",
       " ('different', 0.0031700288488778136),\n",
       " ('tech', 0.0031166166336384902),\n",
       " ('50mg', 0.0031060185267425349),\n",
       " ('he', 0.0030788936979501053),\n",
       " ('daily', 0.003070051760909547),\n",
       " (\"patient's\", 0.0030269224725989626),\n",
       " ('pharmacist', 0.0030133855949722155),\n",
       " ('the', 0.0030016262835350178),\n",
       " ('breathing', 0.0029974615700950956),\n",
       " ('respiratory', 0.0028986263125828347),\n",
       " ('tid', 0.0028496135430873711),\n",
       " ('taken', 0.002837187435648595),\n",
       " ('bid', 0.0028322575257517749),\n",
       " ('s', 0.0028145449255465175),\n",
       " ('itching', 0.0027839120906437967),\n",
       " ('ct', 0.0027807877453317753),\n",
       " ('could', 0.0027378353160496765),\n",
       " ('written', 0.0027235758315622945),\n",
       " ('used', 0.0027149146710297202),\n",
       " ('prescription', 0.0026324655631324977),\n",
       " ('but', 0.0026110525979624356),\n",
       " ('phone', 0.0026096751395165503),\n",
       " ('scanning', 0.002601700870873512),\n",
       " ('days', 0.002580522294346996),\n",
       " ('red', 0.0025680975770317836),\n",
       " ('caught', 0.0024831304491877183),\n",
       " ('went', 0.0024828777743220948),\n",
       " ('test', 0.0024508352801918733),\n",
       " ('stay', 0.0024469408161485202),\n",
       " ('under', 0.0024291340759276794),\n",
       " ('continued', 0.0023509752227397038),\n",
       " ('oxygen', 0.0023376934434237032),\n",
       " ('began', 0.0023210825360769089),\n",
       " ('profile', 0.0023113972615707861),\n",
       " ('.', 0.0023102457253368317),\n",
       " ('spoke', 0.002271959312854027),\n",
       " ('know', 0.0022441630875353709),\n",
       " ('completed', 0.0022306601615614879),\n",
       " ('complaining', 0.0022001519939478745),\n",
       " ('symptoms', 0.002197905947199822),\n",
       " ('case', 0.0021968728477193885),\n",
       " ('name', 0.0021889002033717792),\n",
       " ('is', 0.0021823719721945937),\n",
       " ('upon', 0.0021685137133021469),\n",
       " ('tablets', 0.0021570971174405163),\n",
       " ('face', 0.0021559209254264707),\n",
       " ('no', 0.002148692475014547),\n",
       " ('being', 0.0021005380940836318),\n",
       " ('chart', 0.0020965097361140841),\n",
       " ('let', 0.0020950544507271321),\n",
       " ('medicine', 0.0020795627902760495),\n",
       " ('ivp', 0.0020773047769507662),\n",
       " ('where', 0.0020763771124471843),\n",
       " ('as', 0.0020728444318931149),\n",
       " ('post', 0.002066356943799902),\n",
       " ('side', 0.0020631074542271466),\n",
       " ('here', 0.0020521752359349112),\n",
       " ('any', 0.0020404001359683116),\n",
       " ('having', 0.0020358052290160456),\n",
       " ('filled', 0.0020033540277864929),\n",
       " ('admission', 0.0019893322885076656),\n",
       " ('rec', 0.0019762824925613157),\n",
       " ('were', 0.0019636246419618515),\n",
       " ('patch', 0.0019480329801387962),\n",
       " ('medications', 0.0019392333220116145),\n",
       " ('code', 0.0019235962965764035),\n",
       " ('contrast', 0.0019133207630443413),\n",
       " ('ok', 0.0019088035704495697),\n",
       " ('active', 0.0019062953563227024),\n",
       " ('remote', 0.0019026946416232802),\n",
       " ('would', 0.0019026009426920437),\n",
       " ('ir', 0.0018955925283087596),\n",
       " ('responded', 0.0018884140760744607),\n",
       " ('returned', 0.0018837900093616983),\n",
       " ('intubated', 0.0018822012057637964),\n",
       " ('became', 0.0018779249037923045),\n",
       " ('without', 0.0018667230823002855),\n",
       " ('allergy', 0.0018634156680665812),\n",
       " ('ed', 0.0018625165289185158),\n",
       " ('be', 0.0018507711404979095),\n",
       " ('throat', 0.0018461301012187019),\n",
       " ('getting', 0.0018457787085257604),\n",
       " ('administered', 0.001832710216547812),\n",
       " ('within', 0.0018185465204137111),\n",
       " ('obtained', 0.0018112573984136681),\n",
       " ('unresponsive', 0.0018081202030614985),\n",
       " ('10/325mg', 0.0018014637234870345),\n",
       " ('20', 0.0018007344783735448),\n",
       " ('normally', 0.0017921579308146955),\n",
       " ('remains', 0.0017863062546067312),\n",
       " ('better', 0.0017778603642871448),\n",
       " ('hand', 0.001759689533254711),\n",
       " ('understanding', 0.001755801560030669),\n",
       " ('resident', 0.0017526670590776467),\n",
       " ('mg', 0.0017456962971943791),\n",
       " ('if', 0.001729167958066755),\n",
       " ('telephone', 0.0017259625375061634),\n",
       " ('exam', 0.0017252846508665428),\n",
       " ('right', 0.0017081594044191298),\n",
       " ('100', 0.0016949171669190259),\n",
       " ('please', 0.001682476484563817),\n",
       " ('emr', 0.0016798171080158911),\n",
       " ('also', 0.0016755861219078416),\n",
       " ('rt', 0.0016739437493064027),\n",
       " ('fever', 0.0016722435992080843),\n",
       " ('4', 0.0016720702945202752),\n",
       " ('coumadin', 0.0016637123421414661),\n",
       " ('child', 0.0016635364666606374),\n",
       " ('pyxis', 0.0016586447402524717),\n",
       " ('like', 0.0016490761398302686),\n",
       " ('too', 0.0016362758594418061),\n",
       " ('radiologist', 0.0016320454617150082),\n",
       " ('bleeding', 0.001628135561480528),\n",
       " ('500mg', 0.0016239175255658366),\n",
       " ('send', 0.0016227389643490111),\n",
       " ('scopalamine', 0.0016202399036029031),\n",
       " ('injection', 0.0016087231873892962),\n",
       " ('cannot', 0.0016066845020273187),\n",
       " ('asked', 0.0015998156475322029),\n",
       " ('stopped', 0.0015932500830517994),\n",
       " ('q6h', 0.0015916900722331567),\n",
       " ('label', 0.0015894326035114697),\n",
       " ('return', 0.001589383645826066),\n",
       " ('feel', 0.0015892649529813921),\n",
       " ('center', 0.0015841303798009251),\n",
       " ('fine', 0.0015823208100546869),\n",
       " ('needed', 0.0015789882995332976),\n",
       " ('hives', 0.0015761005976004548),\n",
       " ('place', 0.0015664830923835635),\n",
       " ('told', 0.0015585796624921727),\n",
       " ('epinephrine', 0.0015569126292805128),\n",
       " ('corrected', 0.0015568518669634105),\n",
       " ('pulse', 0.0015561727795716739),\n",
       " ('starting', 0.0015536683080678553),\n",
       " ('oxycodone', 0.0015529577213627961),\n",
       " ('phoned', 0.0015471551315666789),\n",
       " ('will', 0.0015413891542962049),\n",
       " ('message', 0.0015394390365743612),\n",
       " ('throughout', 0.0015385301036234453),\n",
       " ('another', 0.0015304996758916346),\n",
       " ('chair', 0.0015265324322199143),\n",
       " ('into', 0.0015208410400453763),\n",
       " ('asking', 0.0015189989566631549),\n",
       " ('was', 0.0015095474334612378),\n",
       " ('more', 0.001504138474506837),\n",
       " ('applied', 0.0015012504319181896),\n",
       " ('0945', 0.0014904807753101481),\n",
       " ('high', 0.0014895081295843995),\n",
       " ('nursing', 0.0014866908881790996),\n",
       " ('going', 0.0014825083459234307),\n",
       " ('medical', 0.0014799702852348073),\n",
       " ('650mg', 0.0014789096192320665),\n",
       " ('intended', 0.0014780141646076354),\n",
       " ('minutes', 0.001471082818439275),\n",
       " ('actually', 0.0014641255501882484),\n",
       " ('b', 0.0014628869425785639),\n",
       " ('requested', 0.0014590232483482836),\n",
       " ('breath', 0.0014464228140435608),\n",
       " ('shortness', 0.0014464228140435608),\n",
       " ('evening', 0.001445151479162886),\n",
       " ('therapy', 0.0014441307737194328),\n",
       " ('regarding', 0.0014395870030374169),\n",
       " ('saturation', 0.0014333748245118937),\n",
       " ('chest', 0.0014319296838271687),\n",
       " ('took', 0.0014294427464351799),\n",
       " ('history', 0.0014172761836166161),\n",
       " ('look', 0.0014162610243123436),\n",
       " ('hospice', 0.0014153167628793701),\n",
       " ('push', 0.0014134007330985732),\n",
       " ('take', 0.0014108995994765929),\n",
       " ('treatments', 0.0014089794758931106),\n",
       " ('seem', 0.0014063918173950086),\n",
       " ('known', 0.0014060186405463805),\n",
       " ('than', 0.0013981594876325302),\n",
       " ('sign', 0.0013958032582477311),\n",
       " ('injected', 0.0013934168595914559),\n",
       " ('eyes', 0.0013872713670116435),\n",
       " ('norvasc', 0.0013810460900512964),\n",
       " ('reversal', 0.0013810109411243198),\n",
       " ('rph', 0.0013800316367431711),\n",
       " ('his', 0.0013775329238276401),\n",
       " ('presented', 0.0013741264306453762),\n",
       " ('medication', 0.0013723573825905097),\n",
       " ('100mg', 0.0013630201929597375),\n",
       " ('come', 0.0013609371692319485),\n",
       " ('air', 0.0013602391226983316),\n",
       " ('wait', 0.0013590796158018507),\n",
       " ('realize', 0.0013582546864646648),\n",
       " ('narcan', 0.001352977917615818),\n",
       " ('q24h', 0.0013494625598156969),\n",
       " ('all', 0.0013485579255663018),\n",
       " ('changed', 0.0013477657544472847),\n",
       " ('able', 0.0013462263229044782),\n",
       " ('out', 0.0013418717295954207),\n",
       " ('twice', 0.0013411488932478857),\n",
       " ('inr', 0.0013402304858494275),\n",
       " ('patients', 0.00133721770595453),\n",
       " ('informed', 0.0013371347465849755),\n",
       " ('c/o', 0.0013348053924826264),\n",
       " ('work', 0.001331202910579973),\n",
       " ('both', 0.0013288597904061465),\n",
       " ('respirations', 0.0013272631379938967),\n",
       " ('tonight', 0.0013242925614315303),\n",
       " ('po', 0.0013225542613997067),\n",
       " ('t', 0.0013139846748210183),\n",
       " ('head', 0.0013098352708251371),\n",
       " ('duoneb', 0.001308964605181123),\n",
       " ('respond', 0.0013035892046221324),\n",
       " ('questions', 0.00130277093234567),\n",
       " ('delivered', 0.0012975835720796401),\n",
       " ('status', 0.0012772839370438129),\n",
       " ('get', 0.0012712511026479849),\n",
       " ('brain', 0.0012709891131940489),\n",
       " ('admitted', 0.0012579200218473391),\n",
       " ('closed', 0.0012561641282475369),\n",
       " ('errors', 0.0012559483326397341),\n",
       " ('multiple', 0.0012535788550094855),\n",
       " ('pressure', 0.0012520788386081571),\n",
       " ('hospital', 0.0012513866237505574),\n",
       " ('assigned', 0.0012495791944124967),\n",
       " ('since', 0.0012490307953046747),\n",
       " ('vistaril', 0.0012458890649210352),\n",
       " ('currently', 0.0012406393192116146),\n",
       " ('vomiting', 0.0012381143038847223),\n",
       " ('discharged', 0.0012308750603507632),\n",
       " ('several', 0.0012261728463535246),\n",
       " ('eating', 0.0012251314800966263),\n",
       " ('stress', 0.0012247817067061364),\n",
       " ('liquid', 0.0012199309861211753),\n",
       " ('acid', 0.0012155929224821858),\n",
       " ('ox', 0.0012144557445553034),\n",
       " ('discharge', 0.0012132888839500465),\n",
       " ('prescriptions', 0.0012086917523542841),\n",
       " ('discuss', 0.0012062424323085914),\n",
       " ('through', 0.0012057820127462995),\n",
       " ('discontinue', 0.0012030101051373975),\n",
       " ('drink', 0.0011977388495494593),\n",
       " ('question', 0.0011976482340971656),\n",
       " ('hydrocodone/apap', 0.0011976235100829282),\n",
       " ('cell', 0.0011944367282754836),\n",
       " ('recieve', 0.001192638788519846),\n",
       " ('powder', 0.0011894992067641337),\n",
       " ('extended', 0.0011882034386268162),\n",
       " ('script', 0.001187063566765473),\n",
       " ('arrival', 0.0011853005037052791),\n",
       " ('tell', 0.0011849822935901702),\n",
       " ('unable', 0.0011849460525525804),\n",
       " ('hydro', 0.0011832970835574915),\n",
       " ('box', 0.0011832612123664332),\n",
       " ('weekend', 0.0011803348763778803),\n",
       " ('voiced', 0.0011784901714511475),\n",
       " ('copy', 0.0011780465829096217),\n",
       " ('first', 0.0011768490047537592),\n",
       " ('90%', 0.00117561896475588),\n",
       " ('pull', 0.0011752054480805778),\n",
       " ('refilled', 0.0011711236749179885),\n",
       " ('nebulizer', 0.0011706581062150949),\n",
       " ('solucortef', 0.0011680918205187582),\n",
       " ('facility', 0.0011680830403692131),\n",
       " ('appropriately', 0.0011662201844983068),\n",
       " ('3/30', 0.0011652759787577698),\n",
       " ('sleep', 0.001163249026852514),\n",
       " ('flomax', 0.00116265839280521),\n",
       " ('card', 0.0011586250727016597),\n",
       " ('neb', 0.0011537062570054391),\n",
       " ('pm', 0.0011509844093623976),\n",
       " ('list', 0.0011507179966900516),\n",
       " ('providers', 0.001145287470621722),\n",
       " ('physician', 0.0011439908007887729),\n",
       " ('same', 0.0011439574381274479),\n",
       " ('omitted', 0.0011435382906694288),\n",
       " ('dosages', 0.0011430541533842045),\n",
       " ('giving', 0.0011424211587839311),\n",
       " ('100ml', 0.0011419127747441305),\n",
       " ('=', 0.001140112468237984),\n",
       " ('6', 0.0011387062784343623),\n",
       " ('icu', 0.0011320239954512974),\n",
       " ('provided', 0.0011293492161875611),\n",
       " ('ltc', 0.001124294502429724),\n",
       " ('ancef', 0.00112068685750853),\n",
       " ('observation', 0.0011205669506567195),\n",
       " ('chemotherapy', 0.0011133777335981955),\n",
       " ('80', 0.0011103397791814248),\n",
       " ('approximately', 0.0011095586649810343),\n",
       " ('injury', 0.0011078415397875112),\n",
       " ('returning', 0.001105644442009477),\n",
       " ('go', 0.0011053817397801001),\n",
       " ('nc', 0.0011030324718718314),\n",
       " ('don', 0.0011021453036929123),\n",
       " ('3', 0.0011016265270842062),\n",
       " ('taking', 0.0010995419445300905),\n",
       " ('hard', 0.0010923606807569481),\n",
       " ('increase', 0.001089454954588271),\n",
       " ('vomitting', 0.0010894262261944426),\n",
       " ('refused', 0.0010883571756738048),\n",
       " ('moved', 0.0010879985300554233),\n",
       " ('fixed', 0.001086243380208775),\n",
       " ('until', 0.0010835073074945611),\n",
       " ('zantac', 0.0010825539753468697),\n",
       " ('are', 0.001079409052189008),\n",
       " ('1400', 0.0010790791874394667),\n",
       " ('finished', 0.0010775759484415253),\n",
       " ('almost', 0.0010772468697388172),\n",
       " ('drug', 0.0010743449747616617),\n",
       " ('assessed', 0.001069953297992677),\n",
       " ('[redacted]', 0.0010662640406449979),\n",
       " ('sticker', 0.0010651725871756842),\n",
       " ('tablet', 0.0010648159508391997),\n",
       " ('they', 0.0010636889665267238),\n",
       " ('11', 0.0010632716610300215),\n",
       " ('25', 0.0010606651979805232),\n",
       " ('transcribed', 0.0010588165235774012),\n",
       " ('monday', 0.0010491995725626232),\n",
       " ('2030', 0.0010452303108172611),\n",
       " ('2mg/1ml', 0.0010443606723835577),\n",
       " ('radiology', 0.0010426338101605353),\n",
       " ('forearm', 0.0010385009600824484),\n",
       " ('station', 0.001037843010278758),\n",
       " ('nausea', 0.0010337668507283218),\n",
       " ('bin', 0.0010330436577478406),\n",
       " ('during', 0.0010324016673935545),\n",
       " ('beginning', 0.0010302330022129258),\n",
       " ('pre-medicated', 0.0010257405920574675),\n",
       " ('still', 0.0010252846361897092),\n",
       " ('our', 0.0010199752706270531),\n",
       " ('complained', 0.0010190699798011925),\n",
       " ('because', 0.001014506503519164),\n",
       " ('scheduling', 0.0010134183282111565),\n",
       " ('son', 0.0010127723946139302),\n",
       " ('ordering', 0.001008085862318138),\n",
       " ('takes', 0.0010062376351253196),\n",
       " ('transported', 0.001006215391839968),\n",
       " ('daughter', 0.0010060950947376375),\n",
       " ('less', 0.0010050494238113858),\n",
       " ('infed', 0.0010022510062879769),\n",
       " ('vancomycin', 0.0010005835161399292),\n",
       " ('process', 0.001000514798283555),\n",
       " ('approved', 0.00099468778856319669),\n",
       " ('record', 0.00098915586588433258),\n",
       " ('wanting', 0.00098703487350349493),\n",
       " ('mental', 0.00098476758629585659),\n",
       " ('medrol', 0.00098290448952854871),\n",
       " ('barium', 0.00098281079304183183),\n",
       " ('cpoe', 0.00097855938651831122),\n",
       " ('mistakenly', 0.00097843030302601874),\n",
       " ('meds', 0.00097833399200624284),\n",
       " ('febrile', 0.00097775204972332217),\n",
       " ('sitting', 0.00097601822389027182),\n",
       " ('rooms', 0.00097443257380174918),\n",
       " ('clonazepam', 0.00097388246895036945),\n",
       " ('resulting', 0.00097373099877241266),\n",
       " ('signed', 0.00097364601835623135),\n",
       " ('selected', 0.00097223682440007633),\n",
       " ('past', 0.00096928464808153782),\n",
       " ('0600', 0.0009670482587368827),\n",
       " ('write', 0.00096564649853095167),\n",
       " ('neither', 0.00096408833293702722),\n",
       " ('methadone', 0.00096278231934495643),\n",
       " ('fentanyl', 0.00096089902297250137),\n",
       " ('dizziness', 0.00095899781108908723),\n",
       " ('issue', 0.00095649787359742102),\n",
       " ('1/30/15', 0.00095639006190089825),\n",
       " ('error', 0.0009511479582182921),\n",
       " ('package', 0.00095112267068601225),\n",
       " ('outside', 0.00095026299028620927),\n",
       " ('ceftriaxone', 0.00094557422724881018),\n",
       " ('r', 0.00094366903276806502),\n",
       " ('250/50', 0.00093547145210838914),\n",
       " ('friday', 0.00093447532924972193),\n",
       " ('100%', 0.00093397789258624895),\n",
       " ('immediately', 0.00093248665990546421),\n",
       " ('full', 0.00093006126245141177),\n",
       " ('9am', 0.00092610363086907861),\n",
       " ('decided', 0.00092082011845972915),\n",
       " ('imaging', 0.00091977942943646774),\n",
       " ('1315', 0.00091887807121970497),\n",
       " ('hasnt', 0.00091267364446735667),\n",
       " ('hematoma', 0.00091248469783303504),\n",
       " ('2015', 0.00091143892273282145),\n",
       " ('oxycontin', 0.00090974630499071889),\n",
       " ('use', 0.00090851515678271521),\n",
       " ('manual', 0.0009067929499377152),\n",
       " ('1110', 0.00090671830963632064),\n",
       " ('developed', 0.00090604611430806126),\n",
       " ('bottles', 0.00090520437073092746),\n",
       " ('working', 0.00090520281906613916),\n",
       " ('reconciliation', 0.00090499414024727918),\n",
       " ('flushed', 0.00090133122762564859),\n",
       " ('assured', 0.00090011954534453169),\n",
       " ('chloride', 0.00089936320970931548),\n",
       " ('usually', 0.00089786861934352538),\n",
       " ('doing', 0.00089537227719144316),\n",
       " ('appeared', 0.00089527559148238364),\n",
       " ('recovery', 0.00089019806688286863),\n",
       " ('rolled', 0.00088806804196397645),\n",
       " ('dispensed', 0.00088804730769456957),\n",
       " ('[facility]', 0.00088788533103261369),\n",
       " ('says', 0.00088520471640482707),\n",
       " ('partial', 0.00088397311274609862),\n",
       " ('angiogram', 0.00087869350168897937),\n",
       " ('required', 0.00087313476284655732),\n",
       " ('arms', 0.00087229222111474662),\n",
       " ('timely', 0.00087147548444288644),\n",
       " ('vaccines', 0.00087058841505483126),\n",
       " ('polio', 0.00087058841505483126),\n",
       " ('dtap', 0.00087058841505483126),\n",
       " ('stock', 0.00087055401188005906),\n",
       " ('modified', 0.0008686827200888107),\n",
       " ('own', 0.00086763717346258944),\n",
       " ('lorazepam', 0.00086118321841019364),\n",
       " ('cough', 0.00085953688211432586),\n",
       " ('verified', 0.00085702762170569008),\n",
       " ('afrin', 0.00085483846049153739),\n",
       " ('grabbed', 0.00085432260224277369),\n",
       " ('92%', 0.000853857397448557),\n",
       " ('finally', 0.00085353158063045478),\n",
       " ('release', 0.00085095081920582541),\n",
       " ('prn', 0.00084911300405230534),\n",
       " ('confirmation', 0.00084732927640805591),\n",
       " ('rapid', 0.0008462841709511921),\n",
       " ('etc', 0.00084602756421639936),\n",
       " ('arrest', 0.00084598068364865155),\n",
       " (\".'\", 0.00084321222699281656),\n",
       " ('bed', 0.00084300690755810754),\n",
       " ('bubble', 0.00084198398875333358),\n",
       " ('100mg/2ml', 0.00084188419805203418),\n",
       " ('xxx', 0.00084152312604014083),\n",
       " ('shaken', 0.00083846730531972834),\n",
       " ('breakfast', 0.00083757553367421291),\n",
       " ('packet', 0.00083748252056993781),\n",
       " ('1630', 0.00083528309974551429),\n",
       " ('unit', 0.00083511413127060027),\n",
       " ('obtain', 0.00083410036563251867),\n",
       " ('personal', 0.00083402424295795621),\n",
       " ('transcription', 0.00082985755791775261),\n",
       " ('reports', 0.00082857188098446328),\n",
       " ('opioid', 0.00082801889960511699),\n",
       " ('sob', 0.00082584597828772759),\n",
       " ('sit', 0.00082463236584637159),\n",
       " ('refill', 0.00082377950273245047),\n",
       " ('putting', 0.00081539876888679955),\n",
       " ('saved', 0.00081538144991107693),\n",
       " ('prescriber', 0.00081092533355984944),\n",
       " ('blue', 0.00080997918355894068),\n",
       " ('office', 0.00080827644272898783),\n",
       " ('last', 0.00080752162853653495),\n",
       " ('elevated', 0.00080431537126121188),\n",
       " ('performed', 0.00080036394535631808),\n",
       " ('indicate', 0.0007975796220007535),\n",
       " ('override', 0.00079717615300955655),\n",
       " ('saturations', 0.00079341542189210459),\n",
       " ('xarelto', 0.0007928405833565593),\n",
       " ('subsided', 0.000789384577655594),\n",
       " ('omni', 0.00078592845785805505),\n",
       " ('1100', 0.00078589607667518976),\n",
       " ('-', 0.00078176114421281049),\n",
       " ('lack', 0.00078067676094174614),\n",
       " ('lab', 0.00077915067188687073),\n",
       " ('images', 0.00077872892361156073),\n",
       " ('rx', 0.00077706339734638316),\n",
       " ('mouth', 0.00077576759348243964),\n",
       " ('pack', 0.00077516093550200518),\n",
       " ('arm', 0.00077321174757693947),\n",
       " ('750mg', 0.00077021027008326794),\n",
       " ('reviewed', 0.00076827106345203091),\n",
       " ('had', 0.00076727696855750102),\n",
       " ('late', 0.00076681257130209815),\n",
       " ('score', 0.00076580997078356204),\n",
       " ('97%', 0.00076565967541863348),\n",
       " ('supply', 0.00076440173941133257),\n",
       " ('me', 0.00076425875426387128),\n",
       " ('ac', 0.00076300514911407285),\n",
       " ('bupivacaine', 0.00076155591087096049),\n",
       " ('determine', 0.00076127172466848234),\n",
       " ('4kg', 0.00076084298938025141),\n",
       " ('site', 0.00076048851465562316),\n",
       " ('cipro', 0.00075808160148323602),\n",
       " ('else', 0.00075659271252923326),\n",
       " ('1:1000', 0.0007527322551169691),\n",
       " ('overdose', 0.00075258976130061707),\n",
       " ('keep', 0.00075144041047452603),\n",
       " ('inject', 0.00074660309281619958),\n",
       " ('1127', 0.00074568426571495561),\n",
       " ('waiting', 0.00074521348423402212),\n",
       " ('tingling', 0.00074435831117968378),\n",
       " ('emesis', 0.00074435831117968378),\n",
       " ('gi', 0.0007441535626238389),\n",
       " ('got', 0.00074316318538182743),\n",
       " ('xray', 0.00074267735617407284),\n",
       " ('stretcher', 0.00074267735617407284),\n",
       " ('arrived', 0.00074195910586492462),\n",
       " ('resulted', 0.00074138361925744347),\n",
       " ('filed', 0.00074137259338264848),\n",
       " ('outpatient', 0.00074044908388968666),\n",
       " ('advised', 0.00074040402839410126),\n",
       " ('ivpb', 0.00073972917423347829),\n",
       " ('mixed', 0.00073878814891871936),\n",
       " ('week', 0.00073692510793917662),\n",
       " ('date', 0.00073549746219833591),\n",
       " ('correctly', 0.00073467968638317276),\n",
       " ('good', 0.00073399883166420064),\n",
       " ('assistance', 0.0007318137308918156),\n",
       " ('ovarian', 0.00073079002422962594),\n",
       " ('except', 0.00072891586361663319),\n",
       " ('10mg', 0.00072807644544898133),\n",
       " ('confirm', 0.0007277744177456105),\n",
       " ('redness', 0.00072734061851726707),\n",
       " ('pts', 0.00072675982651009561),\n",
       " ('mother', 0.00072473880758977863),\n",
       " ('400mg', 0.00072413846943458098),\n",
       " ('1105', 0.00072412650126881212),\n",
       " ('pcp', 0.00072207928912632285),\n",
       " ('colonoscopy', 0.00072189496282724962),\n",
       " ('narcotics', 0.00072155295549645494),\n",
       " ('initiated', 0.00071790144794549055),\n",
       " ('2l', 0.00071742549962168012),\n",
       " ('consult', 0.00071619066793019381),\n",
       " ('found', 0.00071079677804278718),\n",
       " ('male', 0.00070654808990570103),\n",
       " ('tried', 0.00070639816006970132),\n",
       " ('give', 0.00070497277889943995),\n",
       " ('extra', 0.00070446987417981631),\n",
       " (\"'we\", 0.00070280368634517427),\n",
       " ('prepared', 0.00070192271966857181),\n",
       " ('cpr', 0.00070019929065161864),\n",
       " ('directions', 0.0006995014334315097),\n",
       " ('paged', 0.00069947367200682447),\n",
       " ('98%', 0.0006982871505661068),\n",
       " ('qid', 0.00069667864787669646),\n",
       " ('vss', 0.00069550102784617204),\n",
       " ('250mg', 0.00069505271572532681),\n",
       " ('cross', 0.00069116709782681752),\n",
       " ('lot', 0.00068874096019130328),\n",
       " ('100mcg', 0.00068870402483346888),\n",
       " ('1gm', 0.00068798345365856414),\n",
       " ('normal', 0.00068758154176587591),\n",
       " ('upper', 0.00068265666821608979),\n",
       " ('allergic', 0.00068164170721040089),\n",
       " ('possible', 0.00067760520729459627),\n",
       " ('rash', 0.00067473947589389226),\n",
       " ('thanks', 0.00067419219404014983),\n",
       " ('duplicates', 0.0006733798950807543),\n",
       " ('1205', 0.00067259501840347537),\n",
       " ('other', 0.00067093897209922386),\n",
       " ('capsule', 0.00067092802897190322),\n",
       " ('response', 0.00066930205002187573),\n",
       " ('op', 0.00066885563458690222),\n",
       " ('requiring', 0.00066873976919198637),\n",
       " ('tomorrow', 0.00066844343099939092),\n",
       " ('0815', 0.00066734572910610304),\n",
       " ('talking', 0.00066704565558821979),\n",
       " ('2l/nc', 0.00066348877829142539),\n",
       " ('avoided', 0.00066181776820455605),\n",
       " ('cost', 0.00066145727272717055),\n",
       " ('outer', 0.00066135371755160098),\n",
       " ('labeled', 0.00066096331151648652),\n",
       " ('released', 0.00065944099293501856),\n",
       " ('vs', 0.00065914538723242232),\n",
       " ('encouraged', 0.00065887647976693936),\n",
       " ('formula', 0.0006580697155019364),\n",
       " ('flush', 0.00065726874307734707),\n",
       " ('cold', 0.00065502684785018845),\n",
       " ('reaction', 0.0006542163128680907),\n",
       " ('family', 0.00065411769521470889),\n",
       " ('0935', 0.00065342628515517674),\n",
       " ('pressures', 0.00065288426729643895),\n",
       " ('200mg', 0.00065245242599820089),\n",
       " ('disease', 0.00065241792688605247),\n",
       " ('contact', 0.00065164307980046336),\n",
       " ('resting', 0.00065157603365898268),\n",
       " ('sats', 0.00064933593214506905),\n",
       " ('caregiver', 0.00064802120409653734),\n",
       " ('q12', 0.00064685641845850734),\n",
       " ('copied', 0.00064685641845850734),\n",
       " ('actively', 0.00064637154660104976),\n",
       " ('groggy', 0.00064637154660104976),\n",
       " ('03:55', 0.00064637154660104976),\n",
       " ('n/v', 0.00064637154660104976),\n",
       " ('attending', 0.00064637154660104976),\n",
       " ('05:43', 0.00064637154660104976),\n",
       " ('baby', 0.0006459808498795465),\n",
       " ('885kg', 0.0006459808498795465),\n",
       " ('000kg', 0.0006459808498795465),\n",
       " ('skin', 0.00064586447068760999),\n",
       " ('cleocin', 0.00064562452992405974),\n",
       " ('seemed', 0.0006453393164030859),\n",
       " ('conerning', 0.0006453393164030859),\n",
       " ('clot', 0.0006453393164030859),\n",
       " ('relay', 0.0006453393164030859),\n",
       " ('.the', 0.0006453393164030859),\n",
       " ('excessive', 0.0006453393164030859),\n",
       " ('microsurgical', 0.0006453393164030859),\n",
       " ('vasectomy', 0.0006453393164030859),\n",
       " ('special', 0.0006453393164030859),\n",
       " ('oncoming', 0.0006453393164030859),\n",
       " ('omission', 0.0006453393164030859),\n",
       " ('hematology', 0.0006453393164030859),\n",
       " ('version', 0.0006453393164030859),\n",
       " ('1pm', 0.0006453393164030859),\n",
       " ('/bruise', 0.0006453393164030859),\n",
       " ('6/7', 0.0006453393164030859),\n",
       " ('.she', 0.0006453393164030859),\n",
       " ('scrotum', 0.0006453393164030859),\n",
       " ('bleeding/', 0.0006453393164030859),\n",
       " ('tranexamic', 0.0006453393164030859),\n",
       " ('bleed', 0.0006453393164030859),\n",
       " ('7pm', 0.0006453393164030859),\n",
       " ('length', 0.0006453393164030859),\n",
       " ('expected', 0.0006453393164030859),\n",
       " ('7th', 0.0006453393164030859),\n",
       " ('disorder', 0.0006453393164030859),\n",
       " (',[redacted](', 0.0006453393164030859),\n",
       " ('6/8/15', 0.0006453393164030859),\n",
       " ('on/', 0.0006453393164030859),\n",
       " ('disorder/', 0.0006453393164030859),\n",
       " ('clotting', 0.0006453393164030859),\n",
       " ('6/2', 0.0006453393164030859),\n",
       " ('uncertain', 0.0006453393164030859),\n",
       " ('availability', 0.0006453393164030859),\n",
       " ('sunday', 0.0006453393164030859),\n",
       " ('transfusions', 0.0006453393164030859),\n",
       " ('capusules', 0.0006453393164030859),\n",
       " ('1005', 0.000645091066130197),\n",
       " ('glanced', 0.000645091066130197),\n",
       " ('hydroxyzine', 0.000645091066130197),\n",
       " ('area', 0.00064489289544637524),\n",
       " ('stools/', 0.00064435699407585343),\n",
       " ('warfarin:', 0.00064435699407585343),\n",
       " ('tarry', 0.00064435699407585343),\n",
       " ('8-', 0.00064435699407585343),\n",
       " ('explained', 0.00064318806651075941),\n",
       " ('interaction', 0.00064230679965372685),\n",
       " ('inspection', 0.0006406918312597496),\n",
       " ('assisted', 0.00064055319690150408),\n",
       " ('plan', 0.00064043275837471873),\n",
       " ('hydrocodone', 0.0006388600125974296),\n",
       " ('azythromicin', 0.00063824318199596),\n",
       " ('unavailable', 0.00063824318199596),\n",
       " ('providing', 0.00063824318199596),\n",
       " ('manor', 0.00063824318199596),\n",
       " ('order/dose', 0.00063774568833193507),\n",
       " ('.8kg', 0.00063774568833193507),\n",
       " ('.8lbs', 0.00063774568833193507),\n",
       " ('excrete', 0.00063774568833193507),\n",
       " ('toxic', 0.00063774568833193507),\n",
       " ('larger', 0.00063774568833193507),\n",
       " ('writing', 0.00063774568833193507),\n",
       " ('redose', 0.00063774568833193507),\n",
       " ('4/15', 0.00063774568833193507),\n",
       " ('enterted', 0.00063774568833193507),\n",
       " ('numerically', 0.00063774568833193507),\n",
       " ('.27kg', 0.00063774568833193507),\n",
       " ('poorly', 0.00063721620431828746),\n",
       " ('electronically', 0.00063710517946823867),\n",
       " ('large', 0.00063595377096393384),\n",
       " ('miralax', 0.00063590015372098191),\n",
       " ('consent', 0.00063570845658153822),\n",
       " ('ventilator', 0.00063543849912752598),\n",
       " (\"'oh\", 0.00063379535471843923),\n",
       " ('covering', 0.00063238834833880041),\n",
       " ('aroung', 0.00063190933000136396),\n",
       " ('prescibed', 0.00063190933000136396),\n",
       " ('scaned', 0.00063190933000136396),\n",
       " ('738', 0.00063190933000136396),\n",
       " ('8/6/2015', 0.00063190933000136396),\n",
       " ('foley', 0.00063190933000136396),\n",
       " ('stents', 0.00063190933000136396),\n",
       " ('peeing', 0.00063190933000136396),\n",
       " ('alot', 0.00063190933000136396),\n",
       " ('voiding', 0.00063190933000136396),\n",
       " ('bladder', 0.00063190933000136396),\n",
       " ('til', 0.00063190933000136396),\n",
       " ('day', 0.00063187037905407533),\n",
       " ('thus', 0.0006315458102641499),\n",
       " ('questioning', 0.00062969889130909114),\n",
       " ('pentacel', 0.00062876974824565169),\n",
       " ('05/04/2015', 0.00062876974824565169),\n",
       " ('absent', 0.00062876974824565169),\n",
       " ('apn', 0.00062876974824565169),\n",
       " ('includes', 0.00062876974824565169),\n",
       " ('re', 0.00062837255664792272),\n",
       " ('qa', 0.00062837255664792272),\n",
       " ('system', 0.00062807023278551449),\n",
       " ('stabilized', 0.00062762577659983981),\n",
       " ('sr', 0.0006268734056967078),\n",
       " ('tongue', 0.00062658125786797271),\n",
       " ('enough', 0.00062531543660610651),\n",
       " ('pill', 0.00062490082719611061),\n",
       " ('together', 0.00062480607057617044),\n",
       " ('hospitalist', 0.00062471243276246186),\n",
       " ('40mg', 0.00062425653828981215),\n",
       " ('demerol', 0.00062402085797071951),\n",
       " ('states', 0.00062401888492253895),\n",
       " ('1/13/15', 0.00062224441584863774),\n",
       " ('roommate', 0.00062224441584863774),\n",
       " ('inadverntly', 0.00062224441584863774),\n",
       " ('merrem', 0.00062190667157403464),\n",
       " ('comment', 0.00062190667157403464),\n",
       " ('1441', 0.00062190667157403464),\n",
       " ('1221', 0.00062190667157403464),\n",
       " ('h', 0.00062190667157403464),\n",
       " ('1050', 0.00062190667157403464),\n",
       " ('abx', 0.00062190667157403464),\n",
       " ('neutropenia', 0.00062190667157403464),\n",
       " ('mou', 0.00062190667157403464),\n",
       " ('2sss', 0.00062190667157403464),\n",
       " ('mix', 0.00062091053768067864),\n",
       " ('clarify', 0.00062078107453145668),\n",
       " ('swelling', 0.00062057830447053125),\n",
       " ('mon-thu', 0.00061982814435524033),\n",
       " ('sioc', 0.00061982814435524033),\n",
       " ('swing', 0.00061982814435524033),\n",
       " ('ortho', 0.00061982814435524033),\n",
       " ('e110', 0.00061982814435524033),\n",
       " ('tkr', 0.00061982814435524033),\n",
       " ('tetracaine', 0.00061899037382969456),\n",
       " ('lollipops', 0.00061899037382969456),\n",
       " ('routed', 0.00061899037382969456),\n",
       " ('0311', 0.00061808032452865386),\n",
       " ('5/6/15', 0.00061808032452865386),\n",
       " ('imitrex', 0.00061808032452865386),\n",
       " ('mentioned', 0.00061744540571928162),\n",
       " ('bicep', 0.00061634293167765221),\n",
       " ('1310', 0.00061634293167765221),\n",
       " ('bendaryl', 0.00061634293167765221),\n",
       " ('blotchy', 0.00061634293167765221),\n",
       " ('20mg', 0.00061601926884545576),\n",
       " ('aerosol', 0.00061533175495968504),\n",
       " ('successfully', 0.00061456098355992274),\n",
       " ('calls', 0.0006145384078178758),\n",
       " ('originally', 0.0006145384078178758),\n",
       " ('validate', 0.0006145384078178758),\n",
       " ('pharmnet', 0.0006145384078178758),\n",
       " ('wouold', 0.0006145384078178758),\n",
       " ('examining', 0.0006145384078178758),\n",
       " ('pharmacies', 0.0006145384078178758),\n",
       " ('grossly', 0.0006145384078178758),\n",
       " ('significant', 0.0006145384078178758),\n",
       " ('containers', 0.0006145384078178758),\n",
       " ('substances', 0.00061453120443152062),\n",
       " ('medication-induced', 0.00061453120443152062),\n",
       " ('authorize', 0.00061453120443152062),\n",
       " ('noticed', 0.00061446971540171278),\n",
       " ('cuff', 0.00061317518925516588),\n",
       " ('inflated', 0.00061317518925516588),\n",
       " ('pressue', 0.00061317518925516588),\n",
       " ('wiht', 0.00061317518925516588),\n",
       " ('inflate', 0.00061317518925516588),\n",
       " ('0130-3/23/15', 0.0006129761906122842),\n",
       " ('decreasing', 0.0006129761906122842),\n",
       " ('remainder', 0.0006129761906122842),\n",
       " ('20-30', 0.00061283296217569351),\n",
       " ('diagnosis', 0.00061257551890284666),\n",
       " ('sedation', 0.00061206144532091383),\n",
       " ('dropping', 0.00061192643768023054),\n",
       " ('recovered', 0.00061192643768023054),\n",
       " ('weaned', 0.00061192643768023054),\n",
       " ('solu-medrol', 0.00061192643768023054),\n",
       " ('intense', 0.00061192643768023054),\n",
       " ('6l', 0.00061192643768023054),\n",
       " ('paclitaxel', 0.00061192643768023054),\n",
       " ('titrated', 0.00061192643768023054),\n",
       " ('complications', 0.00061192643768023054),\n",
       " ('cardiacs', 0.00061154812025903033),\n",
       " ('tnkase', 0.00061154812025903033),\n",
       " ('occurring', 0.00061154812025903033),\n",
       " ('altepase', 0.00061154812025903033),\n",
       " ('.nurse', 0.00061154812025903033),\n",
       " ('non-hemmoragic', 0.00061154812025903033),\n",
       " ('neurologist', 0.00061154812025903033),\n",
       " ('o/c', 0.00061154812025903033),\n",
       " ('doseage', 0.00061154812025903033),\n",
       " ('class', 0.00061152068593517384),\n",
       " ('communication', 0.00061134403495627528),\n",
       " ('offered', 0.00061133739014412902),\n",
       " ('refills', 0.00061046105006820552),\n",
       " ('sleepy', 0.00060939260488553472),\n",
       " ('responding', 0.00060939260488553472),\n",
       " ('drowsy', 0.00060939260488553472),\n",
       " ('pct', 0.00060939260488553472),\n",
       " ('npo', 0.0006088178462799863),\n",
       " ('techs', 0.00060801744883185859),\n",
       " ('trying', 0.00060769944459272446),\n",
       " ('group', 0.00060572137010080974),\n",
       " ('warm', 0.00060522249355094858),\n",
       " ('1124', 0.00060499588838415616),\n",
       " ('program', 0.00060458017124491198),\n",
       " ('additional', 0.00060447353077612619),\n",
       " ('filling', 0.00060410857986377842),\n",
       " ('caused', 0.0006038783258225306),\n",
       " (',1200', 0.00060386100162877906),\n",
       " ('3/31', 0.00060386100162877906),\n",
       " (',2130', 0.00060386100162877906),\n",
       " ('2130', 0.00060386100162877906),\n",
       " ('propranolol', 0.00060386100162877906),\n",
       " (',1700', 0.00060386100162877906),\n",
       " ('spouse', 0.00060372908179813446),\n",
       " ('pre-op;', 0.00060141024717395744),\n",
       " ('cefaclor', 0.00060141024717395744),\n",
       " ('cefazolin', 0.00060141024717395744),\n",
       " ('floor', 0.00060085646600984669),\n",
       " ('reporter', 0.00060079799879083826),\n",
       " ('pcu', 0.00059742311917024586),\n",
       " ('verifiy', 0.00059642339704269777),\n",
       " ('despensed', 0.00059642339704269777),\n",
       " ('physican', 0.00059642339704269777),\n",
       " ('treated', 0.00059544280916205795),\n",
       " ('lunch', 0.00059524800066391016),\n",
       " ('short', 0.00059399814110256213),\n",
       " ('.d', 0.00059399814110256213),\n",
       " ('learned', 0.00059376352186914097),\n",
       " ('.t', 0.00059376352186914097),\n",
       " ('23rd', 0.00059376352186914097),\n",
       " ('22nd', 0.00059376352186914097),\n",
       " ('mylcion', 0.00059334750991030054),\n",
       " ('1003', 0.00059334750991030054),\n",
       " ('mylicon', 0.00059334750991030054),\n",
       " ('832', 0.00059334750991030054),\n",
       " ('walk', 0.00059334750991030054),\n",
       " ('1318', 0.00059334750991030054),\n",
       " ('relief', 0.00059294555415783236),\n",
       " ('0806', 0.00059179714483023746),\n",
       " ('1442', 0.00059179714483023746),\n",
       " ('4/22', 0.00059179714483023746),\n",
       " ('rest', 0.00059126795653063674),\n",
       " ('375mg', 0.00059114447750835007),\n",
       " ('dementia', 0.00059071494438527549),\n",
       " ('consulted', 0.00058913331192172774),\n",
       " ('provider', 0.00058838605551770891),\n",
       " ('experienced', 0.00058734832150968001),\n",
       " ('heard', 0.00058646991424992419),\n",
       " (\"a's\", 0.00058646991424992419),\n",
       " ('180', 0.00058646991424992419),\n",
       " ('accidently', 0.00058646991424992419),\n",
       " ('dinner', 0.00058646991424992419),\n",
       " (\"b's\", 0.00058646991424992419),\n",
       " ('confronted', 0.00058646991424992419),\n",
       " ('134', 0.00058646991424992419),\n",
       " ('sugars', 0.00058646991424992419),\n",
       " ('orally', 0.00058548371480405485),\n",
       " ('brief', 0.00058407871902574685),\n",
       " ('dose-missed', 0.00058343608481911755),\n",
       " ('monitoring', 0.00058341217571437421),\n",
       " ('opposite', 0.00058321943385637048),\n",
       " ('qod', 0.00058321943385637048),\n",
       " ('problem', 0.00058321943385637048),\n",
       " ('1749', 0.00058174277006899111),\n",
       " ('syrup', 0.00058174277006899111),\n",
       " ('guaifen/cod', 0.00058174277006899111),\n",
       " ('trendelenberg', 0.00058125745004297376),\n",
       " ('advair', 0.00058079519891725436),\n",
       " ('ago', 0.00058066643297987653),\n",
       " ('unsure', 0.00057980182738467923),\n",
       " ('falling', 0.0005795297827675351),\n",
       " ('3l', 0.00057922032356624658),\n",
       " ('suggested', 0.00057870180066251907),\n",
       " ('furosemide', 0.00057493509610230672),\n",
       " ('check', 0.00057429014258605048),\n",
       " ('rather', 0.00057294111652504654),\n",
       " ('pending', 0.00057284870381680566),\n",
       " ('vascular', 0.00057284870381680566),\n",
       " ('25ml/hr', 0.00057284870381680566),\n",
       " ('voided', 0.00057284870381680566),\n",
       " ('0.375mg', 0.00057233248047464417),\n",
       " ('digoxin', 0.00057233248047464417),\n",
       " ('administrations', 0.00057136550151586562),\n",
       " ('0556', 0.00057136550151586562),\n",
       " ('housekeeper', 0.00057136550151586562),\n",
       " ('1325', 0.00057136550151586562),\n",
       " ('5/30/15', 0.00057136550151586562),\n",
       " ('identifier', 0.00057136550151586562),\n",
       " ('118-2', 0.00057136550151586562),\n",
       " ('desk', 0.00057136550151586562),\n",
       " ('searched', 0.00057136550151586562),\n",
       " (\"'valproic\", 0.00057025360607909994),\n",
       " ('valproic', 0.00057025360607909994),\n",
       " ('4/28/15', 0.00057025360607909994),\n",
       " ('sig', 0.00057025360607909994),\n",
       " ('xopenex', 0.00057019854316466858),\n",
       " ('1715', 0.00057019854316466858),\n",
       " ('therapist', 0.00057019854316466858),\n",
       " ('800', 0.00057019854316466858),\n",
       " (\"wouldn't\", 0.00056945260357521522),\n",
       " ('09:00', 0.00056818766094308558),\n",
       " ('09:39', 0.00056818766094308558),\n",
       " ('north', 0.00056818766094308558),\n",
       " ('2ns', 0.00056818766094308558),\n",
       " ('21:00', 0.00056818766094308558),\n",
       " ('07:26', 0.00056818766094308558),\n",
       " ('cardiac', 0.00056657186972786436),\n",
       " ('0840', 0.00056409993078579271),\n",
       " ('1332', 0.00056409993078579271),\n",
       " ('cc', 0.00056306711637494483),\n",
       " ('1200', 0.00056252007331423625),\n",
       " ('cancer', 0.00056239546236929632),\n",
       " ('gicen', 0.00056220032533944495),\n",
       " ('seroquel', 0.00056168702174613512),\n",
       " ('4/20', 0.00056168702174613512),\n",
       " ('wear', 0.0005616585467904696),\n",
       " ('processed', 0.00056158347451176391),\n",
       " ('events', 0.00056141497712899099),\n",
       " ('hypokalemia', 0.00056141497712899099),\n",
       " ('pulse/no', 0.00056141497712899099),\n",
       " ('management/review', 0.00056141497712899099),\n",
       " ('45kg', 0.00056141497712899099),\n",
       " ('fracture', 0.00056141497712899099),\n",
       " ('3/17', 0.00056141497712899099),\n",
       " ('qip', 0.00056141497712899099),\n",
       " ('verbalize', 0.00056141497712899099),\n",
       " ('1237', 0.00056141497712899099),\n",
       " ('81yo', 0.00056141497712899099),\n",
       " ('1040', 0.00056141497712899099),\n",
       " ('immediate', 0.00056141497712899099),\n",
       " ('cubicle', 0.00056107107580955515),\n",
       " ('packed', 0.00056107107580955515),\n",
       " ('diovan', 0.00056107107580955515),\n",
       " ('apology', 0.00056072945851848191),\n",
       " ('accepted', 0.00056072945851848191),\n",
       " ('calmer', 0.00055994273513629809),\n",
       " ('helps', 0.00055994273513629809),\n",
       " ('duo', 0.00055994273513629809),\n",
       " ('one', 0.00055944458454552123),\n",
       " ('review', 0.00055806755919548309),\n",
       " ('1145', 0.00055531795569302498),\n",
       " ('np', 0.0005547115651655984),\n",
       " ('complete', 0.00055453700900481341),\n",
       " ('minute', 0.00055097252262864603),\n",
       " ('.07mg', 0.00055075212794171555),\n",
       " ('.3mg', 0.00055075212794171555),\n",
       " ('1841', 0.00055075212794171555),\n",
       " ('.03-0', 0.00055075212794171555),\n",
       " ('iv/io', 0.00055075212794171555),\n",
       " ('=0', 0.00055075212794171555),\n",
       " ('1:10000', 0.00055075212794171555),\n",
       " ('consultation', 0.0005491184588720027),\n",
       " ('narcotic', 0.00054762844350787212),\n",
       " ('or', 0.00054651451479990074),\n",
       " ('pio', 0.00054597016233941839),\n",
       " ('requip', 0.00054597016233941839),\n",
       " ('nico-span', 0.00054561775664493852),\n",
       " ('800mg', 0.00054561775664493852),\n",
       " ('.75', 0.00054453066457390946),\n",
       " ('.175', 0.00054453066457390946),\n",
       " ('levothyroxine', 0.00054453066457390946),\n",
       " ('lips', 0.00054337526108281457),\n",
       " ('overriden', 0.00054337526108281457),\n",
       " ('risks', 0.00054337526108281457),\n",
       " ('agonal', 0.00054337526108281457),\n",
       " ('called-transfer', 0.00054337526108281457),\n",
       " ('outway', 0.00054337526108281457),\n",
       " ('lethargic', 0.00054337526108281457),\n",
       " ('0400', 0.00054337526108281457),\n",
       " ('-dilaudid', 0.00054337526108281457),\n",
       " ('benefits', 0.00054337526108281457),\n",
       " ('xanax', 0.00054192421394270226),\n",
       " ('october', 0.00054192421394270226),\n",
       " ('23', 0.00054192421394270226),\n",
       " ('overide', 0.00054192421394270226),\n",
       " ('reach', 0.00053775998433175951),\n",
       " ('dropped', 0.00053683057705932596),\n",
       " ('d', 0.00053652062204926688),\n",
       " ...]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_similar_words(\"pharmacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n",
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4284\n",
      "4285\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4293\n",
      "4294\n",
      "4295\n",
      "4296\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4306\n",
      "4307\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4316\n",
      "4317\n",
      "4318\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4480\n",
      "4481\n",
      "4482\n",
      "4483\n",
      "4484\n",
      "4485\n",
      "4486\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('pharmacy', 0.013380953395084253),\n",
       " ('for', 0.011128128040469868),\n",
       " ('patient', 0.010827071437381392),\n",
       " ('in', 0.010190827415715739),\n",
       " ('order', 0.0094536423232835474),\n",
       " ('entered', 0.0089316239848573013),\n",
       " ('an', 0.0069450899437979059),\n",
       " ('home', 0.0065168047345890191),\n",
       " ('sent', 0.0060580739323997032),\n",
       " ('received', 0.0058985617439693619),\n",
       " ('put', 0.0057905746588803163),\n",
       " ('a', 0.0054770300233020069),\n",
       " ('have', 0.0046783671686652373),\n",
       " ('we', 0.0046333300820567067),\n",
       " ('benadryl', 0.0045824471633143151),\n",
       " ('time', 0.0045523721152053338),\n",
       " ('call', 0.004453212720405577),\n",
       " ('placed', 0.0043109770477115679),\n",
       " ('called', 0.0043038442495954123),\n",
       " ('correct', 0.0041237447519320135),\n",
       " ('back', 0.0041235122638407212),\n",
       " ('them', 0.0040594142718657321),\n",
       " ('25mg', 0.0040568670870190764),\n",
       " ('did', 0.0039642291899716232),\n",
       " ('computer', 0.003917819064943432),\n",
       " ('her', 0.0038455998789596719),\n",
       " ('2', 0.0037619056688039162),\n",
       " ('contacted', 0.0037387227441755613),\n",
       " ('has', 0.0037182206142230738),\n",
       " ('scan', 0.0036741016094932882),\n",
       " ('to', 0.0035895304147804076),\n",
       " ('o2', 0.0035275115387500768),\n",
       " ('from', 0.0035043847917531523),\n",
       " ('doses', 0.0034058081701557434),\n",
       " ('room', 0.0033723406728735847),\n",
       " ('treatment', 0.0032975643220060297),\n",
       " ('these', 0.003213969936980917),\n",
       " ('him', 0.0032092443568000782),\n",
       " ('she', 0.0031925947849247125),\n",
       " ('different', 0.0031700288488778136),\n",
       " ('tech', 0.0031166166336384902),\n",
       " ('50mg', 0.0031060185267425349),\n",
       " ('he', 0.0030788936979501053),\n",
       " ('daily', 0.003070051760909547),\n",
       " (\"patient's\", 0.0030269224725989626),\n",
       " ('pharmacist', 0.0030133855949722155),\n",
       " ('the', 0.0030016262835350178),\n",
       " ('breathing', 0.0029974615700950956),\n",
       " ('respiratory', 0.0028986263125828347),\n",
       " ('tid', 0.0028496135430873711),\n",
       " ('taken', 0.002837187435648595),\n",
       " ('bid', 0.0028322575257517749),\n",
       " ('s', 0.0028145449255465175),\n",
       " ('itching', 0.0027839120906437967),\n",
       " ('ct', 0.0027807877453317753),\n",
       " ('could', 0.0027378353160496765),\n",
       " ('written', 0.0027235758315622945),\n",
       " ('used', 0.0027149146710297202),\n",
       " ('prescription', 0.0026324655631324977),\n",
       " ('but', 0.0026110525979624356),\n",
       " ('phone', 0.0026096751395165503),\n",
       " ('scanning', 0.002601700870873512),\n",
       " ('days', 0.002580522294346996),\n",
       " ('red', 0.0025680975770317836),\n",
       " ('caught', 0.0024831304491877183),\n",
       " ('went', 0.0024828777743220948),\n",
       " ('test', 0.0024508352801918733),\n",
       " ('stay', 0.0024469408161485202),\n",
       " ('under', 0.0024291340759276794),\n",
       " ('continued', 0.0023509752227397038),\n",
       " ('oxygen', 0.0023376934434237032),\n",
       " ('began', 0.0023210825360769089),\n",
       " ('profile', 0.0023113972615707861),\n",
       " ('.', 0.0023102457253368317),\n",
       " ('spoke', 0.002271959312854027),\n",
       " ('know', 0.0022441630875353709),\n",
       " ('completed', 0.0022306601615614879),\n",
       " ('complaining', 0.0022001519939478745),\n",
       " ('symptoms', 0.002197905947199822),\n",
       " ('case', 0.0021968728477193885),\n",
       " ('name', 0.0021889002033717792),\n",
       " ('is', 0.0021823719721945937),\n",
       " ('upon', 0.0021685137133021469),\n",
       " ('tablets', 0.0021570971174405163),\n",
       " ('face', 0.0021559209254264707),\n",
       " ('no', 0.002148692475014547),\n",
       " ('being', 0.0021005380940836318),\n",
       " ('chart', 0.0020965097361140841),\n",
       " ('let', 0.0020950544507271321),\n",
       " ('medicine', 0.0020795627902760495),\n",
       " ('ivp', 0.0020773047769507662),\n",
       " ('where', 0.0020763771124471843),\n",
       " ('as', 0.0020728444318931149),\n",
       " ('post', 0.002066356943799902),\n",
       " ('side', 0.0020631074542271466),\n",
       " ('here', 0.0020521752359349112),\n",
       " ('any', 0.0020404001359683116),\n",
       " ('having', 0.0020358052290160456),\n",
       " ('filled', 0.0020033540277864929),\n",
       " ('admission', 0.0019893322885076656),\n",
       " ('rec', 0.0019762824925613157),\n",
       " ('were', 0.0019636246419618515),\n",
       " ('patch', 0.0019480329801387962),\n",
       " ('medications', 0.0019392333220116145),\n",
       " ('code', 0.0019235962965764035),\n",
       " ('contrast', 0.0019133207630443413),\n",
       " ('ok', 0.0019088035704495697),\n",
       " ('active', 0.0019062953563227024),\n",
       " ('remote', 0.0019026946416232802),\n",
       " ('would', 0.0019026009426920437),\n",
       " ('ir', 0.0018955925283087596),\n",
       " ('responded', 0.0018884140760744607),\n",
       " ('returned', 0.0018837900093616983),\n",
       " ('intubated', 0.0018822012057637964),\n",
       " ('became', 0.0018779249037923045),\n",
       " ('without', 0.0018667230823002855),\n",
       " ('allergy', 0.0018634156680665812),\n",
       " ('ed', 0.0018625165289185158),\n",
       " ('be', 0.0018507711404979095),\n",
       " ('throat', 0.0018461301012187019),\n",
       " ('getting', 0.0018457787085257604),\n",
       " ('administered', 0.001832710216547812),\n",
       " ('within', 0.0018185465204137111),\n",
       " ('obtained', 0.0018112573984136681),\n",
       " ('unresponsive', 0.0018081202030614985),\n",
       " ('10/325mg', 0.0018014637234870345),\n",
       " ('20', 0.0018007344783735448),\n",
       " ('normally', 0.0017921579308146955),\n",
       " ('remains', 0.0017863062546067312),\n",
       " ('better', 0.0017778603642871448),\n",
       " ('hand', 0.001759689533254711),\n",
       " ('understanding', 0.001755801560030669),\n",
       " ('resident', 0.0017526670590776467),\n",
       " ('mg', 0.0017456962971943791),\n",
       " ('if', 0.001729167958066755),\n",
       " ('telephone', 0.0017259625375061634),\n",
       " ('exam', 0.0017252846508665428),\n",
       " ('right', 0.0017081594044191298),\n",
       " ('100', 0.0016949171669190259),\n",
       " ('please', 0.001682476484563817),\n",
       " ('emr', 0.0016798171080158911),\n",
       " ('also', 0.0016755861219078416),\n",
       " ('rt', 0.0016739437493064027),\n",
       " ('fever', 0.0016722435992080843),\n",
       " ('4', 0.0016720702945202752),\n",
       " ('coumadin', 0.0016637123421414661),\n",
       " ('child', 0.0016635364666606374),\n",
       " ('pyxis', 0.0016586447402524717),\n",
       " ('like', 0.0016490761398302686),\n",
       " ('too', 0.0016362758594418061),\n",
       " ('radiologist', 0.0016320454617150082),\n",
       " ('bleeding', 0.001628135561480528),\n",
       " ('500mg', 0.0016239175255658366),\n",
       " ('send', 0.0016227389643490111),\n",
       " ('scopalamine', 0.0016202399036029031),\n",
       " ('injection', 0.0016087231873892962),\n",
       " ('cannot', 0.0016066845020273187),\n",
       " ('asked', 0.0015998156475322029),\n",
       " ('stopped', 0.0015932500830517994),\n",
       " ('q6h', 0.0015916900722331567),\n",
       " ('label', 0.0015894326035114697),\n",
       " ('return', 0.001589383645826066),\n",
       " ('feel', 0.0015892649529813921),\n",
       " ('center', 0.0015841303798009251),\n",
       " ('fine', 0.0015823208100546869),\n",
       " ('needed', 0.0015789882995332976),\n",
       " ('hives', 0.0015761005976004548),\n",
       " ('place', 0.0015664830923835635),\n",
       " ('told', 0.0015585796624921727),\n",
       " ('epinephrine', 0.0015569126292805128),\n",
       " ('corrected', 0.0015568518669634105),\n",
       " ('pulse', 0.0015561727795716739),\n",
       " ('starting', 0.0015536683080678553),\n",
       " ('oxycodone', 0.0015529577213627961),\n",
       " ('phoned', 0.0015471551315666789),\n",
       " ('will', 0.0015413891542962049),\n",
       " ('message', 0.0015394390365743612),\n",
       " ('throughout', 0.0015385301036234453),\n",
       " ('another', 0.0015304996758916346),\n",
       " ('chair', 0.0015265324322199143),\n",
       " ('into', 0.0015208410400453763),\n",
       " ('asking', 0.0015189989566631549),\n",
       " ('was', 0.0015095474334612378),\n",
       " ('more', 0.001504138474506837),\n",
       " ('applied', 0.0015012504319181896),\n",
       " ('0945', 0.0014904807753101481),\n",
       " ('high', 0.0014895081295843995),\n",
       " ('nursing', 0.0014866908881790996),\n",
       " ('going', 0.0014825083459234307),\n",
       " ('medical', 0.0014799702852348073),\n",
       " ('650mg', 0.0014789096192320665),\n",
       " ('intended', 0.0014780141646076354),\n",
       " ('minutes', 0.001471082818439275),\n",
       " ('actually', 0.0014641255501882484),\n",
       " ('b', 0.0014628869425785639),\n",
       " ('requested', 0.0014590232483482836),\n",
       " ('breath', 0.0014464228140435608),\n",
       " ('shortness', 0.0014464228140435608),\n",
       " ('evening', 0.001445151479162886),\n",
       " ('therapy', 0.0014441307737194328),\n",
       " ('regarding', 0.0014395870030374169),\n",
       " ('saturation', 0.0014333748245118937),\n",
       " ('chest', 0.0014319296838271687),\n",
       " ('took', 0.0014294427464351799),\n",
       " ('history', 0.0014172761836166161),\n",
       " ('look', 0.0014162610243123436),\n",
       " ('hospice', 0.0014153167628793701),\n",
       " ('push', 0.0014134007330985732),\n",
       " ('take', 0.0014108995994765929),\n",
       " ('treatments', 0.0014089794758931106),\n",
       " ('seem', 0.0014063918173950086),\n",
       " ('known', 0.0014060186405463805),\n",
       " ('than', 0.0013981594876325302),\n",
       " ('sign', 0.0013958032582477311),\n",
       " ('injected', 0.0013934168595914559),\n",
       " ('eyes', 0.0013872713670116435),\n",
       " ('norvasc', 0.0013810460900512964),\n",
       " ('reversal', 0.0013810109411243198),\n",
       " ('rph', 0.0013800316367431711),\n",
       " ('his', 0.0013775329238276401),\n",
       " ('presented', 0.0013741264306453762),\n",
       " ('medication', 0.0013723573825905097),\n",
       " ('100mg', 0.0013630201929597375),\n",
       " ('come', 0.0013609371692319485),\n",
       " ('air', 0.0013602391226983316),\n",
       " ('wait', 0.0013590796158018507),\n",
       " ('realize', 0.0013582546864646648),\n",
       " ('narcan', 0.001352977917615818),\n",
       " ('q24h', 0.0013494625598156969),\n",
       " ('all', 0.0013485579255663018),\n",
       " ('changed', 0.0013477657544472847),\n",
       " ('able', 0.0013462263229044782),\n",
       " ('out', 0.0013418717295954207),\n",
       " ('twice', 0.0013411488932478857),\n",
       " ('inr', 0.0013402304858494275),\n",
       " ('patients', 0.00133721770595453),\n",
       " ('informed', 0.0013371347465849755),\n",
       " ('c/o', 0.0013348053924826264),\n",
       " ('work', 0.001331202910579973),\n",
       " ('both', 0.0013288597904061465),\n",
       " ('respirations', 0.0013272631379938967),\n",
       " ('tonight', 0.0013242925614315303),\n",
       " ('po', 0.0013225542613997067),\n",
       " ('t', 0.0013139846748210183),\n",
       " ('head', 0.0013098352708251371),\n",
       " ('duoneb', 0.001308964605181123),\n",
       " ('respond', 0.0013035892046221324),\n",
       " ('questions', 0.00130277093234567),\n",
       " ('delivered', 0.0012975835720796401),\n",
       " ('status', 0.0012772839370438129),\n",
       " ('get', 0.0012712511026479849),\n",
       " ('brain', 0.0012709891131940489),\n",
       " ('admitted', 0.0012579200218473391),\n",
       " ('closed', 0.0012561641282475369),\n",
       " ('errors', 0.0012559483326397341),\n",
       " ('multiple', 0.0012535788550094855),\n",
       " ('pressure', 0.0012520788386081571),\n",
       " ('hospital', 0.0012513866237505574),\n",
       " ('assigned', 0.0012495791944124967),\n",
       " ('since', 0.0012490307953046747),\n",
       " ('vistaril', 0.0012458890649210352),\n",
       " ('currently', 0.0012406393192116146),\n",
       " ('vomiting', 0.0012381143038847223),\n",
       " ('discharged', 0.0012308750603507632),\n",
       " ('several', 0.0012261728463535246),\n",
       " ('eating', 0.0012251314800966263),\n",
       " ('stress', 0.0012247817067061364),\n",
       " ('liquid', 0.0012199309861211753),\n",
       " ('acid', 0.0012155929224821858),\n",
       " ('ox', 0.0012144557445553034),\n",
       " ('discharge', 0.0012132888839500465),\n",
       " ('prescriptions', 0.0012086917523542841),\n",
       " ('discuss', 0.0012062424323085914),\n",
       " ('through', 0.0012057820127462995),\n",
       " ('discontinue', 0.0012030101051373975),\n",
       " ('drink', 0.0011977388495494593),\n",
       " ('question', 0.0011976482340971656),\n",
       " ('hydrocodone/apap', 0.0011976235100829282),\n",
       " ('cell', 0.0011944367282754836),\n",
       " ('recieve', 0.001192638788519846),\n",
       " ('powder', 0.0011894992067641337),\n",
       " ('extended', 0.0011882034386268162),\n",
       " ('script', 0.001187063566765473),\n",
       " ('arrival', 0.0011853005037052791),\n",
       " ('tell', 0.0011849822935901702),\n",
       " ('unable', 0.0011849460525525804),\n",
       " ('hydro', 0.0011832970835574915),\n",
       " ('box', 0.0011832612123664332),\n",
       " ('weekend', 0.0011803348763778803),\n",
       " ('voiced', 0.0011784901714511475),\n",
       " ('copy', 0.0011780465829096217),\n",
       " ('first', 0.0011768490047537592),\n",
       " ('90%', 0.00117561896475588),\n",
       " ('pull', 0.0011752054480805778),\n",
       " ('refilled', 0.0011711236749179885),\n",
       " ('nebulizer', 0.0011706581062150949),\n",
       " ('solucortef', 0.0011680918205187582),\n",
       " ('facility', 0.0011680830403692131),\n",
       " ('appropriately', 0.0011662201844983068),\n",
       " ('3/30', 0.0011652759787577698),\n",
       " ('sleep', 0.001163249026852514),\n",
       " ('flomax', 0.00116265839280521),\n",
       " ('card', 0.0011586250727016597),\n",
       " ('neb', 0.0011537062570054391),\n",
       " ('pm', 0.0011509844093623976),\n",
       " ('list', 0.0011507179966900516),\n",
       " ('providers', 0.001145287470621722),\n",
       " ('physician', 0.0011439908007887729),\n",
       " ('same', 0.0011439574381274479),\n",
       " ('omitted', 0.0011435382906694288),\n",
       " ('dosages', 0.0011430541533842045),\n",
       " ('giving', 0.0011424211587839311),\n",
       " ('100ml', 0.0011419127747441305),\n",
       " ('=', 0.001140112468237984),\n",
       " ('6', 0.0011387062784343623),\n",
       " ('icu', 0.0011320239954512974),\n",
       " ('provided', 0.0011293492161875611),\n",
       " ('ltc', 0.001124294502429724),\n",
       " ('ancef', 0.00112068685750853),\n",
       " ('observation', 0.0011205669506567195),\n",
       " ('chemotherapy', 0.0011133777335981955),\n",
       " ('80', 0.0011103397791814248),\n",
       " ('approximately', 0.0011095586649810343),\n",
       " ('injury', 0.0011078415397875112),\n",
       " ('returning', 0.001105644442009477),\n",
       " ('go', 0.0011053817397801001),\n",
       " ('nc', 0.0011030324718718314),\n",
       " ('don', 0.0011021453036929123),\n",
       " ('3', 0.0011016265270842062),\n",
       " ('taking', 0.0010995419445300905),\n",
       " ('hard', 0.0010923606807569481),\n",
       " ('increase', 0.001089454954588271),\n",
       " ('vomitting', 0.0010894262261944426),\n",
       " ('refused', 0.0010883571756738048),\n",
       " ('moved', 0.0010879985300554233),\n",
       " ('fixed', 0.001086243380208775),\n",
       " ('until', 0.0010835073074945611),\n",
       " ('zantac', 0.0010825539753468697),\n",
       " ('are', 0.001079409052189008),\n",
       " ('1400', 0.0010790791874394667),\n",
       " ('finished', 0.0010775759484415253),\n",
       " ('almost', 0.0010772468697388172),\n",
       " ('drug', 0.0010743449747616617),\n",
       " ('assessed', 0.001069953297992677),\n",
       " ('[redacted]', 0.0010662640406449979),\n",
       " ('sticker', 0.0010651725871756842),\n",
       " ('tablet', 0.0010648159508391997),\n",
       " ('they', 0.0010636889665267238),\n",
       " ('11', 0.0010632716610300215),\n",
       " ('25', 0.0010606651979805232),\n",
       " ('transcribed', 0.0010588165235774012),\n",
       " ('monday', 0.0010491995725626232),\n",
       " ('2030', 0.0010452303108172611),\n",
       " ('2mg/1ml', 0.0010443606723835577),\n",
       " ('radiology', 0.0010426338101605353),\n",
       " ('forearm', 0.0010385009600824484),\n",
       " ('station', 0.001037843010278758),\n",
       " ('nausea', 0.0010337668507283218),\n",
       " ('bin', 0.0010330436577478406),\n",
       " ('during', 0.0010324016673935545),\n",
       " ('beginning', 0.0010302330022129258),\n",
       " ('pre-medicated', 0.0010257405920574675),\n",
       " ('still', 0.0010252846361897092),\n",
       " ('our', 0.0010199752706270531),\n",
       " ('complained', 0.0010190699798011925),\n",
       " ('because', 0.001014506503519164),\n",
       " ('scheduling', 0.0010134183282111565),\n",
       " ('son', 0.0010127723946139302),\n",
       " ('ordering', 0.001008085862318138),\n",
       " ('takes', 0.0010062376351253196),\n",
       " ('transported', 0.001006215391839968),\n",
       " ('daughter', 0.0010060950947376375),\n",
       " ('less', 0.0010050494238113858),\n",
       " ('infed', 0.0010022510062879769),\n",
       " ('vancomycin', 0.0010005835161399292),\n",
       " ('process', 0.001000514798283555),\n",
       " ('approved', 0.00099468778856319669),\n",
       " ('record', 0.00098915586588433258),\n",
       " ('wanting', 0.00098703487350349493),\n",
       " ('mental', 0.00098476758629585659),\n",
       " ('medrol', 0.00098290448952854871),\n",
       " ('barium', 0.00098281079304183183),\n",
       " ('cpoe', 0.00097855938651831122),\n",
       " ('mistakenly', 0.00097843030302601874),\n",
       " ('meds', 0.00097833399200624284),\n",
       " ('febrile', 0.00097775204972332217),\n",
       " ('sitting', 0.00097601822389027182),\n",
       " ('rooms', 0.00097443257380174918),\n",
       " ('clonazepam', 0.00097388246895036945),\n",
       " ('resulting', 0.00097373099877241266),\n",
       " ('signed', 0.00097364601835623135),\n",
       " ('selected', 0.00097223682440007633),\n",
       " ('past', 0.00096928464808153782),\n",
       " ('0600', 0.0009670482587368827),\n",
       " ('write', 0.00096564649853095167),\n",
       " ('neither', 0.00096408833293702722),\n",
       " ('methadone', 0.00096278231934495643),\n",
       " ('fentanyl', 0.00096089902297250137),\n",
       " ('dizziness', 0.00095899781108908723),\n",
       " ('issue', 0.00095649787359742102),\n",
       " ('1/30/15', 0.00095639006190089825),\n",
       " ('error', 0.0009511479582182921),\n",
       " ('package', 0.00095112267068601225),\n",
       " ('outside', 0.00095026299028620927),\n",
       " ('ceftriaxone', 0.00094557422724881018),\n",
       " ('r', 0.00094366903276806502),\n",
       " ('250/50', 0.00093547145210838914),\n",
       " ('friday', 0.00093447532924972193),\n",
       " ('100%', 0.00093397789258624895),\n",
       " ('immediately', 0.00093248665990546421),\n",
       " ('full', 0.00093006126245141177),\n",
       " ('9am', 0.00092610363086907861),\n",
       " ('decided', 0.00092082011845972915),\n",
       " ('imaging', 0.00091977942943646774),\n",
       " ('1315', 0.00091887807121970497),\n",
       " ('hasnt', 0.00091267364446735667),\n",
       " ('hematoma', 0.00091248469783303504),\n",
       " ('2015', 0.00091143892273282145),\n",
       " ('oxycontin', 0.00090974630499071889),\n",
       " ('use', 0.00090851515678271521),\n",
       " ('manual', 0.0009067929499377152),\n",
       " ('1110', 0.00090671830963632064),\n",
       " ('developed', 0.00090604611430806126),\n",
       " ('bottles', 0.00090520437073092746),\n",
       " ('working', 0.00090520281906613916),\n",
       " ('reconciliation', 0.00090499414024727918),\n",
       " ('flushed', 0.00090133122762564859),\n",
       " ('assured', 0.00090011954534453169),\n",
       " ('chloride', 0.00089936320970931548),\n",
       " ('usually', 0.00089786861934352538),\n",
       " ('doing', 0.00089537227719144316),\n",
       " ('appeared', 0.00089527559148238364),\n",
       " ('recovery', 0.00089019806688286863),\n",
       " ('rolled', 0.00088806804196397645),\n",
       " ('dispensed', 0.00088804730769456957),\n",
       " ('[facility]', 0.00088788533103261369),\n",
       " ('says', 0.00088520471640482707),\n",
       " ('partial', 0.00088397311274609862),\n",
       " ('angiogram', 0.00087869350168897937),\n",
       " ('required', 0.00087313476284655732),\n",
       " ('arms', 0.00087229222111474662),\n",
       " ('timely', 0.00087147548444288644),\n",
       " ('vaccines', 0.00087058841505483126),\n",
       " ('polio', 0.00087058841505483126),\n",
       " ('dtap', 0.00087058841505483126),\n",
       " ('stock', 0.00087055401188005906),\n",
       " ('modified', 0.0008686827200888107),\n",
       " ('own', 0.00086763717346258944),\n",
       " ('lorazepam', 0.00086118321841019364),\n",
       " ('cough', 0.00085953688211432586),\n",
       " ('verified', 0.00085702762170569008),\n",
       " ('afrin', 0.00085483846049153739),\n",
       " ('grabbed', 0.00085432260224277369),\n",
       " ('92%', 0.000853857397448557),\n",
       " ('finally', 0.00085353158063045478),\n",
       " ('release', 0.00085095081920582541),\n",
       " ('prn', 0.00084911300405230534),\n",
       " ('confirmation', 0.00084732927640805591),\n",
       " ('rapid', 0.0008462841709511921),\n",
       " ('etc', 0.00084602756421639936),\n",
       " ('arrest', 0.00084598068364865155),\n",
       " (\".'\", 0.00084321222699281656),\n",
       " ('bed', 0.00084300690755810754),\n",
       " ('bubble', 0.00084198398875333358),\n",
       " ('100mg/2ml', 0.00084188419805203418),\n",
       " ('xxx', 0.00084152312604014083),\n",
       " ('shaken', 0.00083846730531972834),\n",
       " ('breakfast', 0.00083757553367421291),\n",
       " ('packet', 0.00083748252056993781),\n",
       " ('1630', 0.00083528309974551429),\n",
       " ('unit', 0.00083511413127060027),\n",
       " ('obtain', 0.00083410036563251867),\n",
       " ('personal', 0.00083402424295795621),\n",
       " ('transcription', 0.00082985755791775261),\n",
       " ('reports', 0.00082857188098446328),\n",
       " ('opioid', 0.00082801889960511699),\n",
       " ('sob', 0.00082584597828772759),\n",
       " ('sit', 0.00082463236584637159),\n",
       " ('refill', 0.00082377950273245047),\n",
       " ('putting', 0.00081539876888679955),\n",
       " ('saved', 0.00081538144991107693),\n",
       " ('prescriber', 0.00081092533355984944),\n",
       " ('blue', 0.00080997918355894068),\n",
       " ('office', 0.00080827644272898783),\n",
       " ('last', 0.00080752162853653495),\n",
       " ('elevated', 0.00080431537126121188),\n",
       " ('performed', 0.00080036394535631808),\n",
       " ('indicate', 0.0007975796220007535),\n",
       " ('override', 0.00079717615300955655),\n",
       " ('saturations', 0.00079341542189210459),\n",
       " ('xarelto', 0.0007928405833565593),\n",
       " ('subsided', 0.000789384577655594),\n",
       " ('omni', 0.00078592845785805505),\n",
       " ('1100', 0.00078589607667518976),\n",
       " ('-', 0.00078176114421281049),\n",
       " ('lack', 0.00078067676094174614),\n",
       " ('lab', 0.00077915067188687073),\n",
       " ('images', 0.00077872892361156073),\n",
       " ('rx', 0.00077706339734638316),\n",
       " ('mouth', 0.00077576759348243964),\n",
       " ('pack', 0.00077516093550200518),\n",
       " ('arm', 0.00077321174757693947),\n",
       " ('750mg', 0.00077021027008326794),\n",
       " ('reviewed', 0.00076827106345203091),\n",
       " ('had', 0.00076727696855750102),\n",
       " ('late', 0.00076681257130209815),\n",
       " ('score', 0.00076580997078356204),\n",
       " ('97%', 0.00076565967541863348),\n",
       " ('supply', 0.00076440173941133257),\n",
       " ('me', 0.00076425875426387128),\n",
       " ('ac', 0.00076300514911407285),\n",
       " ('bupivacaine', 0.00076155591087096049),\n",
       " ('determine', 0.00076127172466848234),\n",
       " ('4kg', 0.00076084298938025141),\n",
       " ('site', 0.00076048851465562316),\n",
       " ('cipro', 0.00075808160148323602),\n",
       " ('else', 0.00075659271252923326),\n",
       " ('1:1000', 0.0007527322551169691),\n",
       " ('overdose', 0.00075258976130061707),\n",
       " ('keep', 0.00075144041047452603),\n",
       " ('inject', 0.00074660309281619958),\n",
       " ('1127', 0.00074568426571495561),\n",
       " ('waiting', 0.00074521348423402212),\n",
       " ('tingling', 0.00074435831117968378),\n",
       " ('emesis', 0.00074435831117968378),\n",
       " ('gi', 0.0007441535626238389),\n",
       " ('got', 0.00074316318538182743),\n",
       " ('xray', 0.00074267735617407284),\n",
       " ('stretcher', 0.00074267735617407284),\n",
       " ('arrived', 0.00074195910586492462),\n",
       " ('resulted', 0.00074138361925744347),\n",
       " ('filed', 0.00074137259338264848),\n",
       " ('outpatient', 0.00074044908388968666),\n",
       " ('advised', 0.00074040402839410126),\n",
       " ('ivpb', 0.00073972917423347829),\n",
       " ('mixed', 0.00073878814891871936),\n",
       " ('week', 0.00073692510793917662),\n",
       " ('date', 0.00073549746219833591),\n",
       " ('correctly', 0.00073467968638317276),\n",
       " ('good', 0.00073399883166420064),\n",
       " ('assistance', 0.0007318137308918156),\n",
       " ('ovarian', 0.00073079002422962594),\n",
       " ('except', 0.00072891586361663319),\n",
       " ('10mg', 0.00072807644544898133),\n",
       " ('confirm', 0.0007277744177456105),\n",
       " ('redness', 0.00072734061851726707),\n",
       " ('pts', 0.00072675982651009561),\n",
       " ('mother', 0.00072473880758977863),\n",
       " ('400mg', 0.00072413846943458098),\n",
       " ('1105', 0.00072412650126881212),\n",
       " ('pcp', 0.00072207928912632285),\n",
       " ('colonoscopy', 0.00072189496282724962),\n",
       " ('narcotics', 0.00072155295549645494),\n",
       " ('initiated', 0.00071790144794549055),\n",
       " ('2l', 0.00071742549962168012),\n",
       " ('consult', 0.00071619066793019381),\n",
       " ('found', 0.00071079677804278718),\n",
       " ('male', 0.00070654808990570103),\n",
       " ('tried', 0.00070639816006970132),\n",
       " ('give', 0.00070497277889943995),\n",
       " ('extra', 0.00070446987417981631),\n",
       " (\"'we\", 0.00070280368634517427),\n",
       " ('prepared', 0.00070192271966857181),\n",
       " ('cpr', 0.00070019929065161864),\n",
       " ('directions', 0.0006995014334315097),\n",
       " ('paged', 0.00069947367200682447),\n",
       " ('98%', 0.0006982871505661068),\n",
       " ('qid', 0.00069667864787669646),\n",
       " ('vss', 0.00069550102784617204),\n",
       " ('250mg', 0.00069505271572532681),\n",
       " ('cross', 0.00069116709782681752),\n",
       " ('lot', 0.00068874096019130328),\n",
       " ('100mcg', 0.00068870402483346888),\n",
       " ('1gm', 0.00068798345365856414),\n",
       " ('normal', 0.00068758154176587591),\n",
       " ('upper', 0.00068265666821608979),\n",
       " ('allergic', 0.00068164170721040089),\n",
       " ('possible', 0.00067760520729459627),\n",
       " ('rash', 0.00067473947589389226),\n",
       " ('thanks', 0.00067419219404014983),\n",
       " ('duplicates', 0.0006733798950807543),\n",
       " ('1205', 0.00067259501840347537),\n",
       " ('other', 0.00067093897209922386),\n",
       " ('capsule', 0.00067092802897190322),\n",
       " ('response', 0.00066930205002187573),\n",
       " ('op', 0.00066885563458690222),\n",
       " ('requiring', 0.00066873976919198637),\n",
       " ('tomorrow', 0.00066844343099939092),\n",
       " ('0815', 0.00066734572910610304),\n",
       " ('talking', 0.00066704565558821979),\n",
       " ('2l/nc', 0.00066348877829142539),\n",
       " ('avoided', 0.00066181776820455605),\n",
       " ('cost', 0.00066145727272717055),\n",
       " ('outer', 0.00066135371755160098),\n",
       " ('labeled', 0.00066096331151648652),\n",
       " ('released', 0.00065944099293501856),\n",
       " ('vs', 0.00065914538723242232),\n",
       " ('encouraged', 0.00065887647976693936),\n",
       " ('formula', 0.0006580697155019364),\n",
       " ('flush', 0.00065726874307734707),\n",
       " ('cold', 0.00065502684785018845),\n",
       " ('reaction', 0.0006542163128680907),\n",
       " ('family', 0.00065411769521470889),\n",
       " ('0935', 0.00065342628515517674),\n",
       " ('pressures', 0.00065288426729643895),\n",
       " ('200mg', 0.00065245242599820089),\n",
       " ('disease', 0.00065241792688605247),\n",
       " ('contact', 0.00065164307980046336),\n",
       " ('resting', 0.00065157603365898268),\n",
       " ('sats', 0.00064933593214506905),\n",
       " ('caregiver', 0.00064802120409653734),\n",
       " ('q12', 0.00064685641845850734),\n",
       " ('copied', 0.00064685641845850734),\n",
       " ('actively', 0.00064637154660104976),\n",
       " ('groggy', 0.00064637154660104976),\n",
       " ('03:55', 0.00064637154660104976),\n",
       " ('n/v', 0.00064637154660104976),\n",
       " ('attending', 0.00064637154660104976),\n",
       " ('05:43', 0.00064637154660104976),\n",
       " ('baby', 0.0006459808498795465),\n",
       " ('885kg', 0.0006459808498795465),\n",
       " ('000kg', 0.0006459808498795465),\n",
       " ('skin', 0.00064586447068760999),\n",
       " ('cleocin', 0.00064562452992405974),\n",
       " ('seemed', 0.0006453393164030859),\n",
       " ('conerning', 0.0006453393164030859),\n",
       " ('clot', 0.0006453393164030859),\n",
       " ('relay', 0.0006453393164030859),\n",
       " ('.the', 0.0006453393164030859),\n",
       " ('excessive', 0.0006453393164030859),\n",
       " ('microsurgical', 0.0006453393164030859),\n",
       " ('vasectomy', 0.0006453393164030859),\n",
       " ('special', 0.0006453393164030859),\n",
       " ('oncoming', 0.0006453393164030859),\n",
       " ('omission', 0.0006453393164030859),\n",
       " ('hematology', 0.0006453393164030859),\n",
       " ('version', 0.0006453393164030859),\n",
       " ('1pm', 0.0006453393164030859),\n",
       " ('/bruise', 0.0006453393164030859),\n",
       " ('6/7', 0.0006453393164030859),\n",
       " ('.she', 0.0006453393164030859),\n",
       " ('scrotum', 0.0006453393164030859),\n",
       " ('bleeding/', 0.0006453393164030859),\n",
       " ('tranexamic', 0.0006453393164030859),\n",
       " ('bleed', 0.0006453393164030859),\n",
       " ('7pm', 0.0006453393164030859),\n",
       " ('length', 0.0006453393164030859),\n",
       " ('expected', 0.0006453393164030859),\n",
       " ('7th', 0.0006453393164030859),\n",
       " ('disorder', 0.0006453393164030859),\n",
       " (',[redacted](', 0.0006453393164030859),\n",
       " ('6/8/15', 0.0006453393164030859),\n",
       " ('on/', 0.0006453393164030859),\n",
       " ('disorder/', 0.0006453393164030859),\n",
       " ('clotting', 0.0006453393164030859),\n",
       " ('6/2', 0.0006453393164030859),\n",
       " ('uncertain', 0.0006453393164030859),\n",
       " ('availability', 0.0006453393164030859),\n",
       " ('sunday', 0.0006453393164030859),\n",
       " ('transfusions', 0.0006453393164030859),\n",
       " ('capusules', 0.0006453393164030859),\n",
       " ('1005', 0.000645091066130197),\n",
       " ('glanced', 0.000645091066130197),\n",
       " ('hydroxyzine', 0.000645091066130197),\n",
       " ('area', 0.00064489289544637524),\n",
       " ('stools/', 0.00064435699407585343),\n",
       " ('warfarin:', 0.00064435699407585343),\n",
       " ('tarry', 0.00064435699407585343),\n",
       " ('8-', 0.00064435699407585343),\n",
       " ('explained', 0.00064318806651075941),\n",
       " ('interaction', 0.00064230679965372685),\n",
       " ('inspection', 0.0006406918312597496),\n",
       " ('assisted', 0.00064055319690150408),\n",
       " ('plan', 0.00064043275837471873),\n",
       " ('hydrocodone', 0.0006388600125974296),\n",
       " ('azythromicin', 0.00063824318199596),\n",
       " ('unavailable', 0.00063824318199596),\n",
       " ('providing', 0.00063824318199596),\n",
       " ('manor', 0.00063824318199596),\n",
       " ('order/dose', 0.00063774568833193507),\n",
       " ('.8kg', 0.00063774568833193507),\n",
       " ('.8lbs', 0.00063774568833193507),\n",
       " ('excrete', 0.00063774568833193507),\n",
       " ('toxic', 0.00063774568833193507),\n",
       " ('larger', 0.00063774568833193507),\n",
       " ('writing', 0.00063774568833193507),\n",
       " ('redose', 0.00063774568833193507),\n",
       " ('4/15', 0.00063774568833193507),\n",
       " ('enterted', 0.00063774568833193507),\n",
       " ('numerically', 0.00063774568833193507),\n",
       " ('.27kg', 0.00063774568833193507),\n",
       " ('poorly', 0.00063721620431828746),\n",
       " ('electronically', 0.00063710517946823867),\n",
       " ('large', 0.00063595377096393384),\n",
       " ('miralax', 0.00063590015372098191),\n",
       " ('consent', 0.00063570845658153822),\n",
       " ('ventilator', 0.00063543849912752598),\n",
       " (\"'oh\", 0.00063379535471843923),\n",
       " ('covering', 0.00063238834833880041),\n",
       " ('aroung', 0.00063190933000136396),\n",
       " ('prescibed', 0.00063190933000136396),\n",
       " ('scaned', 0.00063190933000136396),\n",
       " ('738', 0.00063190933000136396),\n",
       " ('8/6/2015', 0.00063190933000136396),\n",
       " ('foley', 0.00063190933000136396),\n",
       " ('stents', 0.00063190933000136396),\n",
       " ('peeing', 0.00063190933000136396),\n",
       " ('alot', 0.00063190933000136396),\n",
       " ('voiding', 0.00063190933000136396),\n",
       " ('bladder', 0.00063190933000136396),\n",
       " ('til', 0.00063190933000136396),\n",
       " ('day', 0.00063187037905407533),\n",
       " ('thus', 0.0006315458102641499),\n",
       " ('questioning', 0.00062969889130909114),\n",
       " ('pentacel', 0.00062876974824565169),\n",
       " ('05/04/2015', 0.00062876974824565169),\n",
       " ('absent', 0.00062876974824565169),\n",
       " ('apn', 0.00062876974824565169),\n",
       " ('includes', 0.00062876974824565169),\n",
       " ('re', 0.00062837255664792272),\n",
       " ('qa', 0.00062837255664792272),\n",
       " ('system', 0.00062807023278551449),\n",
       " ('stabilized', 0.00062762577659983981),\n",
       " ('sr', 0.0006268734056967078),\n",
       " ('tongue', 0.00062658125786797271),\n",
       " ('enough', 0.00062531543660610651),\n",
       " ('pill', 0.00062490082719611061),\n",
       " ('together', 0.00062480607057617044),\n",
       " ('hospitalist', 0.00062471243276246186),\n",
       " ('40mg', 0.00062425653828981215),\n",
       " ('demerol', 0.00062402085797071951),\n",
       " ('states', 0.00062401888492253895),\n",
       " ('1/13/15', 0.00062224441584863774),\n",
       " ('roommate', 0.00062224441584863774),\n",
       " ('inadverntly', 0.00062224441584863774),\n",
       " ('merrem', 0.00062190667157403464),\n",
       " ('comment', 0.00062190667157403464),\n",
       " ('1441', 0.00062190667157403464),\n",
       " ('1221', 0.00062190667157403464),\n",
       " ('h', 0.00062190667157403464),\n",
       " ('1050', 0.00062190667157403464),\n",
       " ('abx', 0.00062190667157403464),\n",
       " ('neutropenia', 0.00062190667157403464),\n",
       " ('mou', 0.00062190667157403464),\n",
       " ('2sss', 0.00062190667157403464),\n",
       " ('mix', 0.00062091053768067864),\n",
       " ('clarify', 0.00062078107453145668),\n",
       " ('swelling', 0.00062057830447053125),\n",
       " ('mon-thu', 0.00061982814435524033),\n",
       " ('sioc', 0.00061982814435524033),\n",
       " ('swing', 0.00061982814435524033),\n",
       " ('ortho', 0.00061982814435524033),\n",
       " ('e110', 0.00061982814435524033),\n",
       " ('tkr', 0.00061982814435524033),\n",
       " ('tetracaine', 0.00061899037382969456),\n",
       " ('lollipops', 0.00061899037382969456),\n",
       " ('routed', 0.00061899037382969456),\n",
       " ('0311', 0.00061808032452865386),\n",
       " ('5/6/15', 0.00061808032452865386),\n",
       " ('imitrex', 0.00061808032452865386),\n",
       " ('mentioned', 0.00061744540571928162),\n",
       " ('bicep', 0.00061634293167765221),\n",
       " ('1310', 0.00061634293167765221),\n",
       " ('bendaryl', 0.00061634293167765221),\n",
       " ('blotchy', 0.00061634293167765221),\n",
       " ('20mg', 0.00061601926884545576),\n",
       " ('aerosol', 0.00061533175495968504),\n",
       " ('successfully', 0.00061456098355992274),\n",
       " ('calls', 0.0006145384078178758),\n",
       " ('originally', 0.0006145384078178758),\n",
       " ('validate', 0.0006145384078178758),\n",
       " ('pharmnet', 0.0006145384078178758),\n",
       " ('wouold', 0.0006145384078178758),\n",
       " ('examining', 0.0006145384078178758),\n",
       " ('pharmacies', 0.0006145384078178758),\n",
       " ('grossly', 0.0006145384078178758),\n",
       " ('significant', 0.0006145384078178758),\n",
       " ('containers', 0.0006145384078178758),\n",
       " ('substances', 0.00061453120443152062),\n",
       " ('medication-induced', 0.00061453120443152062),\n",
       " ('authorize', 0.00061453120443152062),\n",
       " ('noticed', 0.00061446971540171278),\n",
       " ('cuff', 0.00061317518925516588),\n",
       " ('inflated', 0.00061317518925516588),\n",
       " ('pressue', 0.00061317518925516588),\n",
       " ('wiht', 0.00061317518925516588),\n",
       " ('inflate', 0.00061317518925516588),\n",
       " ('0130-3/23/15', 0.0006129761906122842),\n",
       " ('decreasing', 0.0006129761906122842),\n",
       " ('remainder', 0.0006129761906122842),\n",
       " ('20-30', 0.00061283296217569351),\n",
       " ('diagnosis', 0.00061257551890284666),\n",
       " ('sedation', 0.00061206144532091383),\n",
       " ('dropping', 0.00061192643768023054),\n",
       " ('recovered', 0.00061192643768023054),\n",
       " ('weaned', 0.00061192643768023054),\n",
       " ('solu-medrol', 0.00061192643768023054),\n",
       " ('intense', 0.00061192643768023054),\n",
       " ('6l', 0.00061192643768023054),\n",
       " ('paclitaxel', 0.00061192643768023054),\n",
       " ('titrated', 0.00061192643768023054),\n",
       " ('complications', 0.00061192643768023054),\n",
       " ('cardiacs', 0.00061154812025903033),\n",
       " ('tnkase', 0.00061154812025903033),\n",
       " ('occurring', 0.00061154812025903033),\n",
       " ('altepase', 0.00061154812025903033),\n",
       " ('.nurse', 0.00061154812025903033),\n",
       " ('non-hemmoragic', 0.00061154812025903033),\n",
       " ('neurologist', 0.00061154812025903033),\n",
       " ('o/c', 0.00061154812025903033),\n",
       " ('doseage', 0.00061154812025903033),\n",
       " ('class', 0.00061152068593517384),\n",
       " ('communication', 0.00061134403495627528),\n",
       " ('offered', 0.00061133739014412902),\n",
       " ('refills', 0.00061046105006820552),\n",
       " ('sleepy', 0.00060939260488553472),\n",
       " ('responding', 0.00060939260488553472),\n",
       " ('drowsy', 0.00060939260488553472),\n",
       " ('pct', 0.00060939260488553472),\n",
       " ('npo', 0.0006088178462799863),\n",
       " ('techs', 0.00060801744883185859),\n",
       " ('trying', 0.00060769944459272446),\n",
       " ('group', 0.00060572137010080974),\n",
       " ('warm', 0.00060522249355094858),\n",
       " ('1124', 0.00060499588838415616),\n",
       " ('program', 0.00060458017124491198),\n",
       " ('additional', 0.00060447353077612619),\n",
       " ('filling', 0.00060410857986377842),\n",
       " ('caused', 0.0006038783258225306),\n",
       " (',1200', 0.00060386100162877906),\n",
       " ('3/31', 0.00060386100162877906),\n",
       " (',2130', 0.00060386100162877906),\n",
       " ('2130', 0.00060386100162877906),\n",
       " ('propranolol', 0.00060386100162877906),\n",
       " (',1700', 0.00060386100162877906),\n",
       " ('spouse', 0.00060372908179813446),\n",
       " ('pre-op;', 0.00060141024717395744),\n",
       " ('cefaclor', 0.00060141024717395744),\n",
       " ('cefazolin', 0.00060141024717395744),\n",
       " ('floor', 0.00060085646600984669),\n",
       " ('reporter', 0.00060079799879083826),\n",
       " ('pcu', 0.00059742311917024586),\n",
       " ('verifiy', 0.00059642339704269777),\n",
       " ('despensed', 0.00059642339704269777),\n",
       " ('physican', 0.00059642339704269777),\n",
       " ('treated', 0.00059544280916205795),\n",
       " ('lunch', 0.00059524800066391016),\n",
       " ('short', 0.00059399814110256213),\n",
       " ('.d', 0.00059399814110256213),\n",
       " ('learned', 0.00059376352186914097),\n",
       " ('.t', 0.00059376352186914097),\n",
       " ('23rd', 0.00059376352186914097),\n",
       " ('22nd', 0.00059376352186914097),\n",
       " ('mylcion', 0.00059334750991030054),\n",
       " ('1003', 0.00059334750991030054),\n",
       " ('mylicon', 0.00059334750991030054),\n",
       " ('832', 0.00059334750991030054),\n",
       " ('walk', 0.00059334750991030054),\n",
       " ('1318', 0.00059334750991030054),\n",
       " ('relief', 0.00059294555415783236),\n",
       " ('0806', 0.00059179714483023746),\n",
       " ('1442', 0.00059179714483023746),\n",
       " ('4/22', 0.00059179714483023746),\n",
       " ('rest', 0.00059126795653063674),\n",
       " ('375mg', 0.00059114447750835007),\n",
       " ('dementia', 0.00059071494438527549),\n",
       " ('consulted', 0.00058913331192172774),\n",
       " ('provider', 0.00058838605551770891),\n",
       " ('experienced', 0.00058734832150968001),\n",
       " ('heard', 0.00058646991424992419),\n",
       " (\"a's\", 0.00058646991424992419),\n",
       " ('180', 0.00058646991424992419),\n",
       " ('accidently', 0.00058646991424992419),\n",
       " ('dinner', 0.00058646991424992419),\n",
       " (\"b's\", 0.00058646991424992419),\n",
       " ('confronted', 0.00058646991424992419),\n",
       " ('134', 0.00058646991424992419),\n",
       " ('sugars', 0.00058646991424992419),\n",
       " ('orally', 0.00058548371480405485),\n",
       " ('brief', 0.00058407871902574685),\n",
       " ('dose-missed', 0.00058343608481911755),\n",
       " ('monitoring', 0.00058341217571437421),\n",
       " ('opposite', 0.00058321943385637048),\n",
       " ('qod', 0.00058321943385637048),\n",
       " ('problem', 0.00058321943385637048),\n",
       " ('1749', 0.00058174277006899111),\n",
       " ('syrup', 0.00058174277006899111),\n",
       " ('guaifen/cod', 0.00058174277006899111),\n",
       " ('trendelenberg', 0.00058125745004297376),\n",
       " ('advair', 0.00058079519891725436),\n",
       " ('ago', 0.00058066643297987653),\n",
       " ('unsure', 0.00057980182738467923),\n",
       " ('falling', 0.0005795297827675351),\n",
       " ('3l', 0.00057922032356624658),\n",
       " ('suggested', 0.00057870180066251907),\n",
       " ('furosemide', 0.00057493509610230672),\n",
       " ('check', 0.00057429014258605048),\n",
       " ('rather', 0.00057294111652504654),\n",
       " ('pending', 0.00057284870381680566),\n",
       " ('vascular', 0.00057284870381680566),\n",
       " ('25ml/hr', 0.00057284870381680566),\n",
       " ('voided', 0.00057284870381680566),\n",
       " ('0.375mg', 0.00057233248047464417),\n",
       " ('digoxin', 0.00057233248047464417),\n",
       " ('administrations', 0.00057136550151586562),\n",
       " ('0556', 0.00057136550151586562),\n",
       " ('housekeeper', 0.00057136550151586562),\n",
       " ('1325', 0.00057136550151586562),\n",
       " ('5/30/15', 0.00057136550151586562),\n",
       " ('identifier', 0.00057136550151586562),\n",
       " ('118-2', 0.00057136550151586562),\n",
       " ('desk', 0.00057136550151586562),\n",
       " ('searched', 0.00057136550151586562),\n",
       " (\"'valproic\", 0.00057025360607909994),\n",
       " ('valproic', 0.00057025360607909994),\n",
       " ('4/28/15', 0.00057025360607909994),\n",
       " ('sig', 0.00057025360607909994),\n",
       " ('xopenex', 0.00057019854316466858),\n",
       " ('1715', 0.00057019854316466858),\n",
       " ('therapist', 0.00057019854316466858),\n",
       " ('800', 0.00057019854316466858),\n",
       " (\"wouldn't\", 0.00056945260357521522),\n",
       " ('09:00', 0.00056818766094308558),\n",
       " ('09:39', 0.00056818766094308558),\n",
       " ('north', 0.00056818766094308558),\n",
       " ('2ns', 0.00056818766094308558),\n",
       " ('21:00', 0.00056818766094308558),\n",
       " ('07:26', 0.00056818766094308558),\n",
       " ('cardiac', 0.00056657186972786436),\n",
       " ('0840', 0.00056409993078579271),\n",
       " ('1332', 0.00056409993078579271),\n",
       " ('cc', 0.00056306711637494483),\n",
       " ('1200', 0.00056252007331423625),\n",
       " ('cancer', 0.00056239546236929632),\n",
       " ('gicen', 0.00056220032533944495),\n",
       " ('seroquel', 0.00056168702174613512),\n",
       " ('4/20', 0.00056168702174613512),\n",
       " ('wear', 0.0005616585467904696),\n",
       " ('processed', 0.00056158347451176391),\n",
       " ('events', 0.00056141497712899099),\n",
       " ('hypokalemia', 0.00056141497712899099),\n",
       " ('pulse/no', 0.00056141497712899099),\n",
       " ('management/review', 0.00056141497712899099),\n",
       " ('45kg', 0.00056141497712899099),\n",
       " ('fracture', 0.00056141497712899099),\n",
       " ('3/17', 0.00056141497712899099),\n",
       " ('qip', 0.00056141497712899099),\n",
       " ('verbalize', 0.00056141497712899099),\n",
       " ('1237', 0.00056141497712899099),\n",
       " ('81yo', 0.00056141497712899099),\n",
       " ('1040', 0.00056141497712899099),\n",
       " ('immediate', 0.00056141497712899099),\n",
       " ('cubicle', 0.00056107107580955515),\n",
       " ('packed', 0.00056107107580955515),\n",
       " ('diovan', 0.00056107107580955515),\n",
       " ('apology', 0.00056072945851848191),\n",
       " ('accepted', 0.00056072945851848191),\n",
       " ('calmer', 0.00055994273513629809),\n",
       " ('helps', 0.00055994273513629809),\n",
       " ('duo', 0.00055994273513629809),\n",
       " ('one', 0.00055944458454552123),\n",
       " ('review', 0.00055806755919548309),\n",
       " ('1145', 0.00055531795569302498),\n",
       " ('np', 0.0005547115651655984),\n",
       " ('complete', 0.00055453700900481341),\n",
       " ('minute', 0.00055097252262864603),\n",
       " ('.07mg', 0.00055075212794171555),\n",
       " ('.3mg', 0.00055075212794171555),\n",
       " ('1841', 0.00055075212794171555),\n",
       " ('.03-0', 0.00055075212794171555),\n",
       " ('iv/io', 0.00055075212794171555),\n",
       " ('=0', 0.00055075212794171555),\n",
       " ('1:10000', 0.00055075212794171555),\n",
       " ('consultation', 0.0005491184588720027),\n",
       " ('narcotic', 0.00054762844350787212),\n",
       " ('or', 0.00054651451479990074),\n",
       " ('pio', 0.00054597016233941839),\n",
       " ('requip', 0.00054597016233941839),\n",
       " ('nico-span', 0.00054561775664493852),\n",
       " ('800mg', 0.00054561775664493852),\n",
       " ('.75', 0.00054453066457390946),\n",
       " ('.175', 0.00054453066457390946),\n",
       " ('levothyroxine', 0.00054453066457390946),\n",
       " ('lips', 0.00054337526108281457),\n",
       " ('overriden', 0.00054337526108281457),\n",
       " ('risks', 0.00054337526108281457),\n",
       " ('agonal', 0.00054337526108281457),\n",
       " ('called-transfer', 0.00054337526108281457),\n",
       " ('outway', 0.00054337526108281457),\n",
       " ('lethargic', 0.00054337526108281457),\n",
       " ('0400', 0.00054337526108281457),\n",
       " ('-dilaudid', 0.00054337526108281457),\n",
       " ('benefits', 0.00054337526108281457),\n",
       " ('xanax', 0.00054192421394270226),\n",
       " ('october', 0.00054192421394270226),\n",
       " ('23', 0.00054192421394270226),\n",
       " ('overide', 0.00054192421394270226),\n",
       " ('reach', 0.00053775998433175951),\n",
       " ('dropped', 0.00053683057705932596),\n",
       " ('d', 0.00053652062204926688),\n",
       " ...]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_similar_words(\"pharmacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "\n",
    "words_to_visualize = list()\n",
    "for word, ratio in pos_neg_ratios.most_common(500):\n",
    "    if(word in mlp_full.word2index.keys()):\n",
    "        words_to_visualize.append(word)\n",
    "    \n",
    "for word, ratio in list(reversed(pos_neg_ratios.most_common()))[0:500]:\n",
    "    if(word in mlp_full.word2index.keys()):\n",
    "        words_to_visualize.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "\n",
    "colors_list = list()\n",
    "vectors_list = list()\n",
    "for word in words_to_visualize:\n",
    "    if word in pos_neg_ratios.keys():\n",
    "        vectors_list.append(mlp_full.weights_0_1[mlp_full.word2index[word]])\n",
    "        if(pos_neg_ratios[word] > 0):\n",
    "            pos+=1\n",
    "            colors_list.append(\"#00ff00\")\n",
    "        else:\n",
    "            neg+=1\n",
    "            colors_list.append(\"#000000\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-25f7fcb002db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwords_top_ted_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m         \"\"\"\n\u001b[0;32m--> 884\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    787\u001b[0m                           \u001b[0mX_embedded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                           \u001b[0mneighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbors_nn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                           skip_num_points=skip_num_points)\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     def _tsne(self, P, degrees_of_freedom, n_samples, random_state,\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, random_state, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_iter'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'it'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopt_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, objective_error, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, min_error_diff, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mnew_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0minc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/scipy/linalg/misc.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(a, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Differs from numpy only in non-finite handling and the use of blas.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# Only use optimized norms if axis and keepdims are not specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SichengZhou/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1215\u001b[0;31m             \"array must not contain infs or NaNs\")\n\u001b[0m\u001b[1;32m   1216\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "words_top_ted_tsne = tsne.fit_transform(vectors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <div class=\"bk-plotdiv\" id=\"8e0a1e88-5c24-4e7a-86cc-3dea514dfd41\"></div>\n",
       "    </div>\n",
       "<script type=\"text/javascript\">\n",
       "  \n",
       "  (function(global) {\n",
       "    function now() {\n",
       "      return new Date();\n",
       "    }\n",
       "  \n",
       "    var force = false;\n",
       "  \n",
       "    if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "      window._bokeh_onload_callbacks = [];\n",
       "      window._bokeh_is_loading = undefined;\n",
       "    }\n",
       "  \n",
       "  \n",
       "    \n",
       "    if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "      window._bokeh_timeout = Date.now() + 0;\n",
       "      window._bokeh_failed_load = false;\n",
       "    }\n",
       "  \n",
       "    var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "       \"<div style='background-color: #fdd'>\\n\"+\n",
       "       \"<p>\\n\"+\n",
       "       \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "       \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "       \"</p>\\n\"+\n",
       "       \"<ul>\\n\"+\n",
       "       \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "       \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "       \"</ul>\\n\"+\n",
       "       \"<code>\\n\"+\n",
       "       \"from bokeh.resources import INLINE\\n\"+\n",
       "       \"output_notebook(resources=INLINE)\\n\"+\n",
       "       \"</code>\\n\"+\n",
       "       \"</div>\"}};\n",
       "  \n",
       "    function display_loaded() {\n",
       "      if (window.Bokeh !== undefined) {\n",
       "        var el = document.getElementById(\"8e0a1e88-5c24-4e7a-86cc-3dea514dfd41\");\n",
       "        el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "      } else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(display_loaded, 100)\n",
       "      }\n",
       "    }\n",
       "  \n",
       "    function run_callbacks() {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "      delete window._bokeh_onload_callbacks\n",
       "      console.info(\"Bokeh: all callbacks have finished\");\n",
       "    }\n",
       "  \n",
       "    function load_libs(js_urls, callback) {\n",
       "      window._bokeh_onload_callbacks.push(callback);\n",
       "      if (window._bokeh_is_loading > 0) {\n",
       "        console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "        return null;\n",
       "      }\n",
       "      if (js_urls == null || js_urls.length === 0) {\n",
       "        run_callbacks();\n",
       "        return null;\n",
       "      }\n",
       "      console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      window._bokeh_is_loading = js_urls.length;\n",
       "      for (var i = 0; i < js_urls.length; i++) {\n",
       "        var url = js_urls[i];\n",
       "        var s = document.createElement('script');\n",
       "        s.src = url;\n",
       "        s.async = false;\n",
       "        s.onreadystatechange = s.onload = function() {\n",
       "          window._bokeh_is_loading--;\n",
       "          if (window._bokeh_is_loading === 0) {\n",
       "            console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "            run_callbacks()\n",
       "          }\n",
       "        };\n",
       "        s.onerror = function() {\n",
       "          console.warn(\"failed to load library \" + url);\n",
       "        };\n",
       "        console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      }\n",
       "    };var element = document.getElementById(\"8e0a1e88-5c24-4e7a-86cc-3dea514dfd41\");\n",
       "    if (element == null) {\n",
       "      console.log(\"Bokeh: ERROR: autoload.js configured with elementid '8e0a1e88-5c24-4e7a-86cc-3dea514dfd41' but no matching script tag was found. \")\n",
       "      return false;\n",
       "    }\n",
       "  \n",
       "    var js_urls = [];\n",
       "  \n",
       "    var inline_js = [\n",
       "      function(Bokeh) {\n",
       "        (function() {\n",
       "          var fn = function() {\n",
       "            var docs_json = {\"b3fd5eb4-1f81-4254-9e3e-7a4fd33b42f6\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"8133b77e-40df-4737-979e-4c8c0fdbe69b\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"6389fe51-bf50-4dea-8f3c-f1582d37f718\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"8133b77e-40df-4737-979e-4c8c0fdbe69b\",\"type\":\"BasicTicker\"}},\"id\":\"786e5df4-d49a-4f78-9830-5ec84635d262\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"1493be11-a849-4ae0-8fec-175e121153dd\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"6389fe51-bf50-4dea-8f3c-f1582d37f718\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b3966e81-a82a-492e-83a5-6b105cf53ff1\",\"type\":\"BasicTicker\"}},\"id\":\"7d39940e-c81b-4895-acff-e0e3a0b35d8a\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"b3966e81-a82a-492e-83a5-6b105cf53ff1\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"6389fe51-bf50-4dea-8f3c-f1582d37f718\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b3966e81-a82a-492e-83a5-6b105cf53ff1\",\"type\":\"BasicTicker\"}},\"id\":\"fa67ae4c-deab-4765-8fcc-74aa0ab42ac7\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"4700ce40-0edd-4a8e-b033-ee28486d376c\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"plot\":{\"id\":\"6389fe51-bf50-4dea-8f3c-f1582d37f718\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"23e4f834-fcb1-4248-8e87-1397d9e7a4ac\",\"type\":\"PanTool\"},{\"attributes\":{\"plot\":{\"id\":\"6389fe51-bf50-4dea-8f3c-f1582d37f718\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"a670c12c-b4b6-442f-9a59-ad778c67725c\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"plot\":{\"id\":\"6389fe51-bf50-4dea-8f3c-f1582d37f718\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"45fc498e-d4ca-4515-af38-72d4b4fa9215\",\"type\":\"ResetTool\"},{\"attributes\":{\"plot\":{\"id\":\"6389fe51-bf50-4dea-8f3c-f1582d37f718\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"759a0410-a858-4d9c-b38d-3ab93e5096b9\",\"type\":\"SaveTool\"},{\"attributes\":{\"data_source\":{\"id\":\"ff04f82a-663b-4eed-be26-e4ed2eadc4b6\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"6c10cbaf-5935-4798-9f81-e1a251108d5e\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"ca074e69-4e14-4625-a01b-c9ab00ae1b3b\",\"type\":\"Circle\"},\"selection_glyph\":null},\"id\":\"baeb3988-3c45-4323-a41b-6cd086500a67\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"ca074e69-4e14-4625-a01b-c9ab00ae1b3b\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1493be11-a849-4ae0-8fec-175e121153dd\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"below\":[{\"id\":\"5d87390e-7d8b-4cb9-b9be-d3bc25bec7ff\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"7d39940e-c81b-4895-acff-e0e3a0b35d8a\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"5d87390e-7d8b-4cb9-b9be-d3bc25bec7ff\",\"type\":\"LinearAxis\"},{\"id\":\"786e5df4-d49a-4f78-9830-5ec84635d262\",\"type\":\"Grid\"},{\"id\":\"7d39940e-c81b-4895-acff-e0e3a0b35d8a\",\"type\":\"LinearAxis\"},{\"id\":\"fa67ae4c-deab-4765-8fcc-74aa0ab42ac7\",\"type\":\"Grid\"},{\"id\":\"baeb3988-3c45-4323-a41b-6cd086500a67\",\"type\":\"GlyphRenderer\"},{\"id\":\"03a0cc86-9170-44b4-b0d4-a8cf7d1098bb\",\"type\":\"LabelSet\"}],\"title\":{\"id\":\"08e6c645-c708-4c81-8ab7-b2aed49b5cd6\",\"type\":\"Title\"},\"tool_events\":{\"id\":\"07023797-b68c-4e79-b176-62cd0dcadb58\",\"type\":\"ToolEvents\"},\"toolbar\":{\"id\":\"b2c2ffdd-195d-4c01-aeec-a620e0c60c92\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"2236d90c-2133-470f-9386-d9d0472b2220\",\"type\":\"DataRange1d\"},\"y_range\":{\"id\":\"5f310744-56a0-46ef-9fed-a391e83a0237\",\"type\":\"DataRange1d\"}},\"id\":\"6389fe51-bf50-4dea-8f3c-f1582d37f718\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x1\",\"x2\",\"names\",\"color\"],\"data\":{\"color\":[\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#00ff00\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\",\"#000000\"],\"names\":[\"edie\",\"paulie\",\"felix\",\"polanski\",\"matthau\",\"victoria\",\"mildred\",\"gandhi\",\"flawless\",\"superbly\",\"perfection\",\"astaire\",\"captures\",\"voight\",\"wonderfully\",\"powell\",\"brosnan\",\"lily\",\"bakshi\",\"lincoln\",\"refreshing\",\"breathtaking\",\"bourne\",\"lemmon\",\"delightful\",\"flynn\",\"andrews\",\"homer\",\"beautifully\",\"soccer\",\"elvira\",\"underrated\",\"gripping\",\"superb\",\"delight\",\"welles\",\"sadness\",\"sinatra\",\"touching\",\"timeless\",\"macy\",\"unforgettable\",\"favorites\",\"stewart\",\"sullivan\",\"extraordinary\",\"hartley\",\"brilliantly\",\"friendship\",\"wonderful\",\"palma\",\"magnificent\",\"finest\",\"jackie\",\"ritter\",\"tremendous\",\"freedom\",\"fantastic\",\"terrific\",\"noir\",\"sidney\",\"outstanding\",\"pleasantly\",\"mann\",\"nancy\",\"marie\",\"marvelous\",\"excellent\",\"ruth\",\"stanwyck\",\"widmark\",\"splendid\",\"chan\",\"exceptional\",\"tender\",\"gentle\",\"poignant\",\"gem\",\"amazing\",\"chilling\",\"fisher\",\"davies\",\"captivating\",\"darker\",\"april\",\"kelly\",\"blake\",\"overlooked\",\"ralph\",\"bette\",\"hoffman\",\"cole\",\"shines\",\"powerful\",\"notch\",\"remarkable\",\"pitt\",\"winters\",\"vivid\",\"gritty\",\"giallo\",\"portrait\",\"innocence\",\"psychiatrist\",\"favorite\",\"ensemble\",\"stunning\",\"burns\",\"garbo\",\"barbara\",\"philip\",\"panic\",\"holly\",\"carol\",\"perfect\",\"appreciated\",\"favourite\",\"journey\",\"rural\",\"bond\",\"builds\",\"brilliant\",\"brooklyn\",\"von\",\"recommended\",\"unfolds\",\"daniel\",\"perfectly\",\"crafted\",\"prince\",\"troubled\",\"consequences\",\"haunting\",\"cinderella\",\"alexander\",\"emotions\",\"boxing\",\"subtle\",\"curtis\",\"rare\",\"loved\",\"daughters\",\"courage\",\"dentist\",\"highly\",\"nominated\",\"tony\",\"draws\",\"everyday\",\"contrast\",\"cried\",\"fabulous\",\"ned\",\"fay\",\"emma\",\"sensitive\",\"smooth\",\"dramas\",\"today\",\"helps\",\"inspiring\",\"jimmy\",\"awesome\",\"unique\",\"tragic\",\"intense\",\"stellar\",\"rival\",\"provides\",\"depression\",\"shy\",\"carrie\",\"blend\",\"hank\",\"diana\",\"adorable\",\"unexpected\",\"achievement\",\"bettie\",\"happiness\",\"glorious\",\"davis\",\"terrifying\",\"beauty\",\"ideal\",\"fears\",\"hong\",\"seasons\",\"fascinating\",\"carries\",\"satisfying\",\"definite\",\"touched\",\"greatest\",\"creates\",\"aunt\",\"walter\",\"spectacular\",\"portrayal\",\"ann\",\"enterprise\",\"musicals\",\"deeply\",\"incredible\",\"mature\",\"triumph\",\"margaret\",\"navy\",\"harry\",\"lucas\",\"sweet\",\"joey\",\"oscar\",\"balance\",\"warm\",\"ages\",\"guilt\",\"glover\",\"carrey\",\"learns\",\"unusual\",\"sons\",\"complex\",\"essence\",\"brazil\",\"widow\",\"solid\",\"beautiful\",\"holmes\",\"awe\",\"vhs\",\"eerie\",\"lonely\",\"grim\",\"sport\",\"debut\",\"destiny\",\"thrillers\",\"tears\",\"rose\",\"feelings\",\"ginger\",\"winning\",\"stanley\",\"cox\",\"paris\",\"heart\",\"hooked\",\"comfortable\",\"mgm\",\"masterpiece\",\"themes\",\"danny\",\"anime\",\"perry\",\"joy\",\"lovable\",\"mysteries\",\"hal\",\"louis\",\"charming\",\"urban\",\"allows\",\"impact\",\"italy\",\"gradually\",\"lifestyle\",\"spy\",\"treat\",\"subsequent\",\"kennedy\",\"loving\",\"surprising\",\"quiet\",\"winter\",\"reveals\",\"raw\",\"funniest\",\"pleased\",\"norman\",\"thief\",\"season\",\"secrets\",\"colorful\",\"highest\",\"compelling\",\"danes\",\"castle\",\"kudos\",\"great\",\"baseball\",\"subtitles\",\"bleak\",\"winner\",\"tragedy\",\"todd\",\"nicely\",\"arthur\",\"essential\",\"gorgeous\",\"fonda\",\"eastwood\",\"focuses\",\"enjoyed\",\"natural\",\"intensity\",\"witty\",\"rob\",\"worlds\",\"health\",\"magical\",\"deeper\",\"lucy\",\"moving\",\"lovely\",\"purple\",\"memorable\",\"sings\",\"craig\",\"modesty\",\"relate\",\"episodes\",\"strong\",\"smith\",\"tear\",\"apartment\",\"princess\",\"disagree\",\"kung\",\"adventure\",\"columbo\",\"jake\",\"adds\",\"hart\",\"strength\",\"realizes\",\"dave\",\"childhood\",\"forbidden\",\"tight\",\"surreal\",\"manager\",\"dancer\",\"studios\",\"con\",\"miike\",\"realistic\",\"explicit\",\"kurt\",\"traditional\",\"deals\",\"holds\",\"carl\",\"touches\",\"gene\",\"albert\",\"abc\",\"cry\",\"sides\",\"develops\",\"eyre\",\"dances\",\"oscars\",\"legendary\",\"hearted\",\"importance\",\"portraying\",\"impressed\",\"waters\",\"empire\",\"edge\",\"jean\",\"environment\",\"sentimental\",\"captured\",\"styles\",\"daring\",\"frank\",\"tense\",\"backgrounds\",\"matches\",\"gothic\",\"sharp\",\"achieved\",\"court\",\"steals\",\"rules\",\"colors\",\"reunion\",\"covers\",\"tale\",\"rain\",\"denzel\",\"stays\",\"blob\",\"maria\",\"conventional\",\"fresh\",\"midnight\",\"landscape\",\"animated\",\"titanic\",\"sunday\",\"spring\",\"cagney\",\"enjoyable\",\"immensely\",\"sir\",\"nevertheless\",\"driven\",\"performances\",\"memories\",\"nowadays\",\"simple\",\"golden\",\"leslie\",\"lovers\",\"relationship\",\"supporting\",\"che\",\"packed\",\"trek\",\"provoking\",\"strikes\",\"depiction\",\"emotional\",\"secretary\",\"influenced\",\"florida\",\"germany\",\"brings\",\"lewis\",\"elderly\",\"owner\",\"streets\",\"henry\",\"portrays\",\"bears\",\"china\",\"anger\",\"society\",\"available\",\"best\",\"bugs\",\"magic\",\"delivers\",\"verhoeven\",\"jim\",\"donald\",\"endearing\",\"relationships\",\"greatly\",\"charlie\",\"brad\",\"simon\",\"effectively\",\"march\",\"atmosphere\",\"influence\",\"genius\",\"emotionally\",\"ken\",\"identity\",\"sophisticated\",\"dan\",\"andrew\",\"india\",\"roy\",\"surprisingly\",\"sky\",\"romantic\",\"match\",\"meets\",\"cowboy\",\"wave\",\"bitter\",\"patient\",\"stylish\",\"britain\",\"affected\",\"beatty\",\"love\",\"paul\",\"andy\",\"performance\",\"patrick\",\"unlike\",\"brooks\",\"refuses\",\"award\",\"complaint\",\"ride\",\"dawson\",\"luke\",\"wells\",\"france\",\"sports\",\"handsome\",\"directs\",\"rebel\",\"boll\",\"uwe\",\"seagal\",\"unwatchable\",\"stinker\",\"mst\",\"incoherent\",\"unfunny\",\"waste\",\"blah\",\"horrid\",\"pointless\",\"atrocious\",\"redeeming\",\"prom\",\"drivel\",\"lousy\",\"worst\",\"laughable\",\"awful\",\"poorly\",\"wasting\",\"remotely\",\"existent\",\"boredom\",\"miserably\",\"sucks\",\"uninspired\",\"lame\",\"insult\",\"godzilla\",\"uninteresting\",\"gadget\",\"appalling\",\"unconvincing\",\"unintentional\",\"horrible\",\"amateurish\",\"pathetic\",\"idiotic\",\"stupidity\",\"cardboard\",\"wasted\",\"crap\",\"insulting\",\"tedious\",\"dreadful\",\"dire\",\"badly\",\"suck\",\"worse\",\"terrible\",\"embarrassing\",\"mess\",\"garbage\",\"pile\",\"stupid\",\"ashamed\",\"vampires\",\"worthless\",\"dull\",\"inept\",\"avoid\",\"wooden\",\"forgettable\",\"fulci\",\"crappy\",\"bat\",\"unbelievably\",\"whatsoever\",\"excuse\",\"rubbish\",\"ridiculous\",\"junk\",\"flop\",\"boring\",\"turkey\",\"shark\",\"topless\",\"ridiculously\",\"useless\",\"seed\",\"ripped\",\"embarrassed\",\"rambo\",\"costs\",\"hideous\",\"horrendous\",\"bother\",\"dumb\",\"disjointed\",\"plastic\",\"horribly\",\"fest\",\"ludicrous\",\"unintentionally\",\"obnoxious\",\"mildly\",\"bland\",\"mummy\",\"annoying\",\"amateur\",\"bad\",\"dinosaurs\",\"unless\",\"fails\",\"mediocre\",\"awake\",\"clichd\",\"clich\",\"meaningless\",\"disappointment\",\"zombies\",\"asleep\",\"miscast\",\"irritating\",\"utter\",\"disappointing\",\"screaming\",\"supposed\",\"kidding\",\"poor\",\"apes\",\"unbelievable\",\"fake\",\"dude\",\"dracula\",\"joke\",\"clumsy\",\"random\",\"cheap\",\"idiots\",\"devoid\",\"trite\",\"wannabe\",\"unbearable\",\"alright\",\"pretentious\",\"scooby\",\"sucked\",\"senseless\",\"bo\",\"bin\",\"coherent\",\"idiot\",\"toilet\",\"doo\",\"werewolf\",\"cabin\",\"generous\",\"offensive\",\"monkey\",\"painfully\",\"renting\",\"lazy\",\"disgusting\",\"blame\",\"walked\",\"seconds\",\"generic\",\"cheese\",\"sloppy\",\"huh\",\"retarded\",\"trash\",\"shelf\",\"ugly\",\"oh\",\"slightest\",\"explanation\",\"failed\",\"cringe\",\"blatant\",\"clue\",\"bored\",\"cgi\",\"sat\",\"paid\",\"warn\",\"painful\",\"nowhere\",\"bore\",\"absurd\",\"flies\",\"paint\",\"porn\",\"paper\",\"predictable\",\"pseudo\",\"repetitive\",\"outer\",\"brain\",\"sorry\",\"vampire\",\"motivation\",\"unrealistic\",\"wrestling\",\"overrated\",\"aliens\",\"halfway\",\"save\",\"santa\",\"security\",\"contrived\",\"lacks\",\"whale\",\"gore\",\"bunch\",\"hype\",\"flat\",\"noise\",\"below\",\"plain\",\"spending\",\"bothered\",\"annoyed\",\"sounded\",\"honestly\",\"minutes\",\"wreck\",\"lesbian\",\"chick\",\"dollar\",\"f\",\"secondly\",\"wanna\",\"rat\",\"errors\",\"shallow\",\"synopsis\",\"breasts\",\"gray\",\"yeah\",\"nonsense\",\"unnecessary\",\"swear\",\"grave\",\"ruined\",\"somebody\",\"elvis\",\"mindless\",\"terribly\",\"continuity\",\"hoping\",\"ha\",\"nudity\",\"endless\",\"decent\",\"torture\",\"rented\",\"disaster\",\"downright\",\"ok\",\"fat\",\"unpleasant\",\"figured\",\"rip\",\"throwing\",\"attempt\",\"weak\",\"slap\",\"jesus\",\"christian\",\"barely\",\"apparently\",\"implausible\",\"nothing\",\"clichs\",\"credibility\",\"bible\",\"explained\",\"presumably\",\"celluloid\",\"couldn\",\"money\",\"snake\",\"hollow\",\"load\",\"sake\",\"total\",\"priest\",\"supposedly\",\"consists\",\"zombie\",\"bomb\",\"ape\",\"bottom\",\"christ\",\"unfortunately\",\"bullets\",\"grade\",\"drags\",\"freak\",\"wolf\",\"fx\",\"offended\",\"script\",\"raped\",\"producers\",\"okay\",\"confusing\",\"stomach\",\"monster\",\"seriously\",\"alas\",\"promising\",\"knife\",\"substance\",\"premise\",\"threw\",\"k\",\"dear\",\"z\",\"write\",\"rental\",\"warned\",\"zero\",\"semi\",\"guess\",\"scientist\",\"logic\",\"vague\",\"slasher\",\"throw\",\"accents\",\"alien\",\"silly\",\"clown\",\"skip\",\"instead\",\"blank\",\"throat\",\"lab\",\"par\",\"gag\",\"execution\",\"nose\",\"hated\",\"effort\",\"shoot\",\"fill\",\"gratuitous\",\"burn\",\"none\",\"cameras\",\"assume\",\"stick\",\"reasonable\",\"failure\",\"pie\",\"rent\",\"dubbing\",\"weren\",\"truck\",\"stock\",\"thin\",\"daddy\",\"holy\",\"exercise\",\"pg\",\"arm\",\"tried\",\"suppose\",\"advice\",\"gonna\",\"disbelief\",\"derek\",\"mean\",\"merit\",\"looked\",\"channel\",\"gross\",\"stereotypical\",\"hoped\",\"lacking\",\"spent\",\"stiff\",\"overdone\",\"low\",\"romero\",\"hour\",\"blair\",\"saved\",\"damage\",\"reason\",\"intentions\",\"sentence\",\"hardcore\",\"makeup\",\"lack\",\"makers\",\"empty\",\"holes\",\"wouldn\",\"proof\",\"demon\",\"toys\",\"doll\",\"utterly\",\"originality\",\"bush\",\"saying\",\"cover\",\"meat\",\"forest\",\"deserve\",\"sum\",\"bucks\",\"hills\",\"watchable\",\"lacked\",\"handed\",\"mistake\",\"please\",\"whoever\",\"sadistic\",\"monsters\",\"screenwriter\",\"neither\",\"nuclear\",\"sequels\",\"flesh\",\"lying\",\"creature\",\"annie\",\"propaganda\",\"leonard\",\"thats\",\"racist\",\"convince\",\"asian\",\"why\",\"rex\",\"satan\",\"remake\",\"fail\",\"ah\",\"loser\",\"favor\",\"except\",\"flick\",\"freddy\",\"relies\",\"spare\",\"dialog\",\"lou\",\"dragged\",\"guy\",\"problem\",\"melting\",\"flash\",\"im\",\"least\",\"mouth\",\"sole\",\"hell\",\"jerk\",\"drink\",\"intent\",\"shower\",\"fifteen\",\"wasn\",\"thugs\",\"corpse\",\"virus\",\"idea\",\"budget\",\"minimal\",\"reasonably\",\"naked\",\"rick\",\"category\",\"cheesy\",\"judging\",\"half\",\"pregnant\",\"no\",\"millions\",\"stereotypes\",\"juvenile\",\"weekend\",\"convoluted\",\"laurel\",\"killings\",\"sequel\",\"hire\",\"somewhere\",\"frankly\",\"paying\",\"someone\",\"cant\",\"cash\",\"research\",\"dimensional\",\"walk\",\"editing\",\"conceived\",\"scare\",\"positive\",\"anything\"],\"x1\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[1000]},\"x2\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[1000]}}},\"id\":\"ff04f82a-663b-4eed-be26-e4ed2eadc4b6\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"fill_color\":{\"field\":\"color\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"6c10cbaf-5935-4798-9f81-e1a251108d5e\",\"type\":\"Circle\"},{\"attributes\":{\"plot\":null,\"text\":\"vector T-SNE for most polarized words\"},\"id\":\"08e6c645-c708-4c81-8ab7-b2aed49b5cd6\",\"type\":\"Title\"},{\"attributes\":{\"callback\":null},\"id\":\"2236d90c-2133-470f-9386-d9d0472b2220\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"07023797-b68c-4e79-b176-62cd0dcadb58\",\"type\":\"ToolEvents\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"23e4f834-fcb1-4248-8e87-1397d9e7a4ac\",\"type\":\"PanTool\"},{\"id\":\"a670c12c-b4b6-442f-9a59-ad778c67725c\",\"type\":\"WheelZoomTool\"},{\"id\":\"45fc498e-d4ca-4515-af38-72d4b4fa9215\",\"type\":\"ResetTool\"},{\"id\":\"759a0410-a858-4d9c-b38d-3ab93e5096b9\",\"type\":\"SaveTool\"}]},\"id\":\"b2c2ffdd-195d-4c01-aeec-a620e0c60c92\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null},\"id\":\"5f310744-56a0-46ef-9fed-a391e83a0237\",\"type\":\"DataRange1d\"},{\"attributes\":{\"formatter\":{\"id\":\"4700ce40-0edd-4a8e-b033-ee28486d376c\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"6389fe51-bf50-4dea-8f3c-f1582d37f718\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"8133b77e-40df-4737-979e-4c8c0fdbe69b\",\"type\":\"BasicTicker\"}},\"id\":\"5d87390e-7d8b-4cb9-b9be-d3bc25bec7ff\",\"type\":\"LinearAxis\"},{\"attributes\":{\"plot\":{\"id\":\"6389fe51-bf50-4dea-8f3c-f1582d37f718\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"source\":{\"id\":\"ff04f82a-663b-4eed-be26-e4ed2eadc4b6\",\"type\":\"ColumnDataSource\"},\"text\":{\"field\":\"names\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"03a0cc86-9170-44b4-b0d4-a8cf7d1098bb\",\"type\":\"LabelSet\"}],\"root_ids\":[\"6389fe51-bf50-4dea-8f3c-f1582d37f718\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.5\"}};\n",
       "            var render_items = [{\"docid\":\"b3fd5eb4-1f81-4254-9e3e-7a4fd33b42f6\",\"elementid\":\"8e0a1e88-5c24-4e7a-86cc-3dea514dfd41\",\"modelid\":\"6389fe51-bf50-4dea-8f3c-f1582d37f718\"}];\n",
       "            \n",
       "            Bokeh.embed.embed_items(docs_json, render_items);\n",
       "          };\n",
       "          if (document.readyState != \"loading\") fn();\n",
       "          else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "        })();\n",
       "      },\n",
       "      function(Bokeh) {\n",
       "      }\n",
       "    ];\n",
       "  \n",
       "    function run_inline_js() {\n",
       "      \n",
       "      if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "        for (var i = 0; i < inline_js.length; i++) {\n",
       "          inline_js[i](window.Bokeh);\n",
       "        }if (force === true) {\n",
       "          display_loaded();\n",
       "        }} else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(run_inline_js, 100);\n",
       "      } else if (!window._bokeh_failed_load) {\n",
       "        console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "        window._bokeh_failed_load = true;\n",
       "      } else if (force !== true) {\n",
       "        var cell = $(document.getElementById(\"8e0a1e88-5c24-4e7a-86cc-3dea514dfd41\")).parents('.cell').data().cell;\n",
       "        cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "      }\n",
       "  \n",
       "    }\n",
       "  \n",
       "    if (window._bokeh_is_loading === 0) {\n",
       "      console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "      run_inline_js();\n",
       "    } else {\n",
       "      load_libs(js_urls, function() {\n",
       "        console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }(this));\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"vector T-SNE for most polarized words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0],\n",
    "                                    x2=words_top_ted_tsne[:,1],\n",
    "                                    names=words_to_visualize,\n",
    "                                    color=colors_list))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source, fill_color=\"color\")\n",
    "\n",
    "word_labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(word_labels)\n",
    "\n",
    "show(p)\n",
    "\n",
    "# green indicates positive words, black indicates negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
